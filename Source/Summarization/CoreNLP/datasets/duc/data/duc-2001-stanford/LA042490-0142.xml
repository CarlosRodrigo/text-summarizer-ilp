<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA042490-0142">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Elizabeth Taylor is breathing with the assistance of a ventilator after undergoing surgery aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks, her physicians said Monday.</content>
      <tokens>
        <token id="1" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="breathing" lemma="breathe" stem="breath" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="assistance" lemma="assistance" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="undergoing" lemma="undergo" stem="undergo" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="aimed" lemma="aim" stem="aim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="determining" lemma="determine" stem="determin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="kept" lemma="keep" stem="kept" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="hospitalized" lemma="hospitalize" stem="hospit" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="28" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Elizabeth) (NNP Taylor)) (VP (VBZ is) (VP (VBG breathing) (PP (IN with) (NP (NP (DT the) (NN assistance)) (PP (IN of) (NP (DT a) (NN ventilator))))) (PP (IN after) (S (VP (VBG undergoing) (NP (NP (NN surgery)) (VP (VBN aimed) (PP (IN at) (S (VP (VBG determining) (NP (NP (DT the) (NN cause)) (PP (IN of) (NP (NN pneumonia))) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN kept) (S (NP (PRP$ her)) (VP (VBN hospitalized) (PP (IN for) (NP (CD three) (NNS weeks))))))))))))))))))))) (, ,) (NP (PRP$ her) (NNS physicians)) (VP (VBD said) (NP-TMP (NNP Monday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="determining the cause of pneumonia that has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="2" string="the assistance of a ventilator" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="assistance" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="3" string="surgery aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks" type="NP">
          <tokens>
            <token id="13" string="surgery" />
            <token id="14" string="aimed" />
            <token id="15" string="at" />
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="4" string="Elizabeth Taylor" type="NP">
          <tokens>
            <token id="1" string="Elizabeth" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="5" string="undergoing surgery aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="12" string="undergoing" />
            <token id="13" string="surgery" />
            <token id="14" string="aimed" />
            <token id="15" string="at" />
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="6" string="that has kept her hospitalized for three weeks" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="7" string="is breathing with the assistance of a ventilator after undergoing surgery aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="breathing" />
            <token id="5" string="with" />
            <token id="6" string="the" />
            <token id="7" string="assistance" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="ventilator" />
            <token id="11" string="after" />
            <token id="12" string="undergoing" />
            <token id="13" string="surgery" />
            <token id="14" string="aimed" />
            <token id="15" string="at" />
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="8" string="her physicians" type="NP">
          <tokens>
            <token id="30" string="her" />
            <token id="31" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="9" string="a ventilator" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="10" string="breathing with the assistance of a ventilator after undergoing surgery aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="4" string="breathing" />
            <token id="5" string="with" />
            <token id="6" string="the" />
            <token id="7" string="assistance" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="ventilator" />
            <token id="11" string="after" />
            <token id="12" string="undergoing" />
            <token id="13" string="surgery" />
            <token id="14" string="aimed" />
            <token id="15" string="at" />
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="11" string="has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="12" string="three weeks" type="NP">
          <tokens>
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="13" string="kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="14" string="aimed at determining the cause of pneumonia that has kept her hospitalized for three weeks" type="VP">
          <tokens>
            <token id="14" string="aimed" />
            <token id="15" string="at" />
            <token id="16" string="determining" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="15" string="the cause of pneumonia that has kept her hospitalized for three weeks" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="pneumonia" />
            <token id="21" string="that" />
            <token id="22" string="has" />
            <token id="23" string="kept" />
            <token id="24" string="her" />
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="16" string="the cause" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="cause" />
          </tokens>
        </chunking>
        <chunking id="17" string="her" type="NP">
          <tokens>
            <token id="24" string="her" />
          </tokens>
        </chunking>
        <chunking id="18" string="said Monday" type="VP">
          <tokens>
            <token id="32" string="said" />
            <token id="33" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="19" string="pneumonia" type="NP">
          <tokens>
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="20" string="hospitalized for three weeks" type="VP">
          <tokens>
            <token id="25" string="hospitalized" />
            <token id="26" string="for" />
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="21" string="the assistance" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="assistance" />
          </tokens>
        </chunking>
        <chunking id="22" string="surgery" type="NP">
          <tokens>
            <token id="13" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Elizabeth</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">breathing</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">breathing</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">said</governor>
          <dependent id="4">breathing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">assistance</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">assistance</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">breathing</governor>
          <dependent id="7">assistance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">ventilator</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ventilator</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">assistance</governor>
          <dependent id="10">ventilator</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">undergoing</governor>
          <dependent id="11">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">breathing</governor>
          <dependent id="12">undergoing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">undergoing</governor>
          <dependent id="13">surgery</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">surgery</governor>
          <dependent id="14">aimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">determining</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">aimed</governor>
          <dependent id="16">determining</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">cause</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">determining</governor>
          <dependent id="18">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">pneumonia</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">cause</governor>
          <dependent id="20">pneumonia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">kept</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">kept</governor>
          <dependent id="22">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">cause</governor>
          <dependent id="23">kept</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">hospitalized</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">kept</governor>
          <dependent id="25">hospitalized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">weeks</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">weeks</governor>
          <dependent id="27">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">hospitalized</governor>
          <dependent id="28">weeks</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">physicians</governor>
          <dependent id="30">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">said</governor>
          <dependent id="31">physicians</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="32">said</governor>
          <dependent id="33">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="2" string="Elizabeth Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Elizabeth" />
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="Monday" />
          </tokens>
        </entity>
        <entity id="4" string="three weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="three" />
            <token id="28" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Academy Award-winning actress was admitted to St. John&amp;apost;s Hospital in Santa Monica last week for treatment of the pneumonia, and was listed in serious condition in the hospital&amp;apost;s intensive-care unit on Monday, her doctors said in a prepared statement.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="3" string="Award-winning" lemma="award-winning" stem="award-win" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="admitted" lemma="admit" stem="admit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Monica" lemma="Monica" stem="monica" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="treatment" lemma="treatment" stem="treatment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="listed" lemma="list" stem="list" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="intensive-care" lemma="intensive-care" stem="intensive-car" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="prepared" lemma="prepared" stem="prepar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP Academy) (JJ Award-winning) (NN actress)) (VP (VP (VBD was) (VP (VBN admitted) (PP (TO to) (NP (NP (NP (NNP St.) (NNP John) (POS 's)) (NN Hospital)) (PP (IN in) (NP (NNP Santa) (NNP Monica))))) (NP-TMP (JJ last) (NN week)) (PP (IN for) (NP (NP (NN treatment)) (PP (IN of) (NP (DT the) (NN pneumonia))))))) (, ,) (CC and) (VP (VBD was) (VP (VBN listed) (PP (IN in) (NP (NP (JJ serious) (NN condition)) (PP (IN in) (NP (NP (DT the) (NN hospital) (POS 's)) (JJ intensive-care) (NN unit))))) (PP (IN on) (NP (NNP Monday))))))) (, ,) (NP (PRP$ her) (NNS doctors)) (VP (VBD said) (PP (IN in) (NP (DT a) (JJ prepared) (NN statement)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="serious condition" type="NP">
          <tokens>
            <token id="27" string="serious" />
            <token id="28" string="condition" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Academy Award-winning actress" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Academy" />
            <token id="3" string="Award-winning" />
            <token id="4" string="actress" />
          </tokens>
        </chunking>
        <chunking id="3" string="St. John 's Hospital" type="NP">
          <tokens>
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
          </tokens>
        </chunking>
        <chunking id="4" string="the hospital 's intensive-care unit" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
            <token id="33" string="intensive-care" />
            <token id="34" string="unit" />
          </tokens>
        </chunking>
        <chunking id="5" string="St. John 's Hospital in Santa Monica" type="NP">
          <tokens>
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
            <token id="12" string="in" />
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="6" string="her doctors" type="NP">
          <tokens>
            <token id="38" string="her" />
            <token id="39" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="7" string="St. John 's" type="NP">
          <tokens>
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="treatment" type="NP">
          <tokens>
            <token id="18" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="9" string="Santa Monica" type="NP">
          <tokens>
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="10" string="the pneumonia" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="11" string="was listed in serious condition in the hospital 's intensive-care unit on Monday" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="listed" />
            <token id="26" string="in" />
            <token id="27" string="serious" />
            <token id="28" string="condition" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
            <token id="33" string="intensive-care" />
            <token id="34" string="unit" />
            <token id="35" string="on" />
            <token id="36" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="12" string="was admitted to St. John 's Hospital in Santa Monica last week for treatment of the pneumonia , and was listed in serious condition in the hospital 's intensive-care unit on Monday" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="admitted" />
            <token id="7" string="to" />
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
            <token id="12" string="in" />
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
            <token id="15" string="last" />
            <token id="16" string="week" />
            <token id="17" string="for" />
            <token id="18" string="treatment" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="pneumonia" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="was" />
            <token id="25" string="listed" />
            <token id="26" string="in" />
            <token id="27" string="serious" />
            <token id="28" string="condition" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
            <token id="33" string="intensive-care" />
            <token id="34" string="unit" />
            <token id="35" string="on" />
            <token id="36" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="13" string="was admitted to St. John 's Hospital in Santa Monica last week for treatment of the pneumonia" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="admitted" />
            <token id="7" string="to" />
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
            <token id="12" string="in" />
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
            <token id="15" string="last" />
            <token id="16" string="week" />
            <token id="17" string="for" />
            <token id="18" string="treatment" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="14" string="the hospital 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="serious condition in the hospital 's intensive-care unit" type="NP">
          <tokens>
            <token id="27" string="serious" />
            <token id="28" string="condition" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
            <token id="33" string="intensive-care" />
            <token id="34" string="unit" />
          </tokens>
        </chunking>
        <chunking id="16" string="treatment of the pneumonia" type="NP">
          <tokens>
            <token id="18" string="treatment" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="17" string="admitted to St. John 's Hospital in Santa Monica last week for treatment of the pneumonia" type="VP">
          <tokens>
            <token id="6" string="admitted" />
            <token id="7" string="to" />
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
            <token id="12" string="in" />
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
            <token id="15" string="last" />
            <token id="16" string="week" />
            <token id="17" string="for" />
            <token id="18" string="treatment" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="18" string="listed in serious condition in the hospital 's intensive-care unit on Monday" type="VP">
          <tokens>
            <token id="25" string="listed" />
            <token id="26" string="in" />
            <token id="27" string="serious" />
            <token id="28" string="condition" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="hospital" />
            <token id="32" string="'s" />
            <token id="33" string="intensive-care" />
            <token id="34" string="unit" />
            <token id="35" string="on" />
            <token id="36" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="19" string="Monday" type="NP">
          <tokens>
            <token id="36" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="20" string="said in a prepared statement" type="VP">
          <tokens>
            <token id="40" string="said" />
            <token id="41" string="in" />
            <token id="42" string="a" />
            <token id="43" string="prepared" />
            <token id="44" string="statement" />
          </tokens>
        </chunking>
        <chunking id="21" string="a prepared statement" type="NP">
          <tokens>
            <token id="42" string="a" />
            <token id="43" string="prepared" />
            <token id="44" string="statement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">actress</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">actress</governor>
          <dependent id="2">Academy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">actress</governor>
          <dependent id="3">Award-winning</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">admitted</governor>
          <dependent id="4">actress</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">admitted</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="40">said</governor>
          <dependent id="6">admitted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Hospital</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">John</governor>
          <dependent id="8">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">Hospital</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">John</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">admitted</governor>
          <dependent id="11">Hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Monica</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Monica</governor>
          <dependent id="13">Santa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Hospital</governor>
          <dependent id="14">Monica</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">week</governor>
          <dependent id="15">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">admitted</governor>
          <dependent id="16">week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">treatment</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">admitted</governor>
          <dependent id="18">treatment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">pneumonia</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">pneumonia</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">treatment</governor>
          <dependent id="21">pneumonia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">admitted</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">listed</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">admitted</governor>
          <dependent id="25">listed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">condition</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">condition</governor>
          <dependent id="27">serious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">listed</governor>
          <dependent id="28">condition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">unit</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">hospital</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">unit</governor>
          <dependent id="31">hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">hospital</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">unit</governor>
          <dependent id="33">intensive-care</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">condition</governor>
          <dependent id="34">unit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Monday</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">listed</governor>
          <dependent id="36">Monday</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">doctors</governor>
          <dependent id="38">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">said</governor>
          <dependent id="39">doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="40">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">statement</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">statement</governor>
          <dependent id="42">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">statement</governor>
          <dependent id="43">prepared</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">said</governor>
          <dependent id="44">statement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Santa Monica" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Santa" />
            <token id="14" string="Monica" />
          </tokens>
        </entity>
        <entity id="2" string="Academy Award-winning" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Academy" />
            <token id="3" string="Award-winning" />
          </tokens>
        </entity>
        <entity id="3" string="St. John 's Hospital" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="St." />
            <token id="9" string="John" />
            <token id="10" string="'s" />
            <token id="11" string="Hospital" />
          </tokens>
        </entity>
        <entity id="4" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="last" />
            <token id="16" string="week" />
          </tokens>
        </entity>
        <entity id="5" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="6" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="36" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>&amp;quot;She is seriously ill and on Sunday underwent a lung biopsy to further determine the cause of her pneumonia,&amp;quot; the physicians&amp;apost; statement said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ill" lemma="ill" stem="ill" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="underwent" lemma="undergo" stem="underw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="lung" lemma="lung" stem="lung" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="further" lemma="further" stem="further" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="24" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VP (VBZ is) (ADVP (RB seriously)) (ADJP (JJ ill))) (CC and) (VP (PP (IN on) (NP (NNP Sunday))) (VBD underwent) (NP (DT a) (NN lung) (NN biopsy)) (PP (TO to) (NP (JJ further))) (S (VP (VB determine) (NP (NP (DT the) (NN cause)) (PP (IN of) (NP (PRP$ her) (NN pneumonia))))))))) (, ,) ('' '') (NP (NP (DT the) (NNS physicians) (POS ')) (NN statement)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the physicians ' statement" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="physicians" />
            <token id="25" string="'" />
            <token id="26" string="statement" />
          </tokens>
        </chunking>
        <chunking id="2" string="determine the cause of her pneumonia" type="VP">
          <tokens>
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="her" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="3" string="ill" type="ADJP">
          <tokens>
            <token id="5" string="ill" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sunday" type="NP">
          <tokens>
            <token id="8" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="a lung biopsy" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="lung" />
            <token id="12" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="is seriously ill and on Sunday underwent a lung biopsy to further determine the cause of her pneumonia" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="seriously" />
            <token id="5" string="ill" />
            <token id="6" string="and" />
            <token id="7" string="on" />
            <token id="8" string="Sunday" />
            <token id="9" string="underwent" />
            <token id="10" string="a" />
            <token id="11" string="lung" />
            <token id="12" string="biopsy" />
            <token id="13" string="to" />
            <token id="14" string="further" />
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="her" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="8" string="is seriously ill" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="seriously" />
            <token id="5" string="ill" />
          </tokens>
        </chunking>
        <chunking id="9" string="the physicians '" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="physicians" />
            <token id="25" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="her pneumonia" type="NP">
          <tokens>
            <token id="19" string="her" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="11" string="the cause" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="cause" />
          </tokens>
        </chunking>
        <chunking id="12" string="on Sunday underwent a lung biopsy to further determine the cause of her pneumonia" type="VP">
          <tokens>
            <token id="7" string="on" />
            <token id="8" string="Sunday" />
            <token id="9" string="underwent" />
            <token id="10" string="a" />
            <token id="11" string="lung" />
            <token id="12" string="biopsy" />
            <token id="13" string="to" />
            <token id="14" string="further" />
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="her" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="13" string="the cause of her pneumonia" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="her" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="14" string="further" type="NP">
          <tokens>
            <token id="14" string="further" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="27" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">ill</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">ill</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">ill</governor>
          <dependent id="4">seriously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="5">ill</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">ill</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Sunday</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">underwent</governor>
          <dependent id="8">Sunday</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">ill</governor>
          <dependent id="9">underwent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">biopsy</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">biopsy</governor>
          <dependent id="11">lung</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">underwent</governor>
          <dependent id="12">biopsy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">further</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">underwent</governor>
          <dependent id="14">further</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">underwent</governor>
          <dependent id="15">determine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">cause</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">determine</governor>
          <dependent id="17">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">pneumonia</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">pneumonia</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">cause</governor>
          <dependent id="20">pneumonia</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">physicians</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">statement</governor>
          <dependent id="24">physicians</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">physicians</governor>
          <dependent id="25">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">statement</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="2" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>&amp;quot;After surgery, her breathing is now being assisted by a ventilator.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="breathing" lemma="breathing" stem="breath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assisted" lemma="assist" stem="assist" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN After) (NP (NN surgery))) (, ,) (NP (PRP$ her) (NN breathing)) (VP (VBZ is) (ADVP (RB now)) (VP (VBG being) (VP (VBN assisted) (PP (IN by) (NP (DT a) (NN ventilator)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assisted by a ventilator" type="VP">
          <tokens>
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="2" string="being assisted by a ventilator" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="3" string="her breathing" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="breathing" />
          </tokens>
        </chunking>
        <chunking id="4" string="is now being assisted by a ventilator" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="now" />
            <token id="9" string="being" />
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ventilator" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="6" string="surgery" type="NP">
          <tokens>
            <token id="3" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">surgery</governor>
          <dependent id="2">After</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">assisted</governor>
          <dependent id="3">surgery</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">breathing</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">assisted</governor>
          <dependent id="6">breathing</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">assisted</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">assisted</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">assisted</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">assisted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">ventilator</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">ventilator</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">assisted</governor>
          <dependent id="13">ventilator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;Her condition is presently stabilizing, and her physicians are pleased with her progress.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="presently" lemma="presently" stem="present" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="stabilizing" lemma="stabilize" stem="stabil" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pleased" lemma="please" stem="pleas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ Her) (NN condition)) (VP (VBZ is) (ADVP (RB presently)) (VP (VBG stabilizing)))) (, ,) (CC and) (S (NP (PRP$ her) (NNS physicians)) (VP (VBP are) (VP (VBN pleased) (PP (IN with) (NP (PRP$ her) (NN progress)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Her condition" type="NP">
          <tokens>
            <token id="2" string="Her" />
            <token id="3" string="condition" />
          </tokens>
        </chunking>
        <chunking id="2" string="stabilizing" type="VP">
          <tokens>
            <token id="6" string="stabilizing" />
          </tokens>
        </chunking>
        <chunking id="3" string="pleased with her progress" type="VP">
          <tokens>
            <token id="12" string="pleased" />
            <token id="13" string="with" />
            <token id="14" string="her" />
            <token id="15" string="progress" />
          </tokens>
        </chunking>
        <chunking id="4" string="her physicians" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="5" string="her progress" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="progress" />
          </tokens>
        </chunking>
        <chunking id="6" string="is presently stabilizing" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="presently" />
            <token id="6" string="stabilizing" />
          </tokens>
        </chunking>
        <chunking id="7" string="are pleased with her progress" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="pleased" />
            <token id="13" string="with" />
            <token id="14" string="her" />
            <token id="15" string="progress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">condition</governor>
          <dependent id="2">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">stabilizing</governor>
          <dependent id="3">condition</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">stabilizing</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">stabilizing</governor>
          <dependent id="5">presently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">stabilizing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">stabilizing</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">physicians</governor>
          <dependent id="9">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">pleased</governor>
          <dependent id="10">physicians</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">pleased</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">stabilizing</governor>
          <dependent id="12">pleased</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">progress</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">progress</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pleased</governor>
          <dependent id="15">progress</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The statement provided no additional details of Taylor&amp;apost;s condition, and hospital officials declined to comment beyond the statement.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="provided" lemma="provide" stem="provid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="details" lemma="detail" stem="detail" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="comment" lemma="comment" stem="comment" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN statement)) (VP (VBD provided) (NP (NP (DT no) (JJ additional) (NNS details)) (PP (IN of) (NP (NP (NNP Taylor) (POS 's)) (NN condition)))))) (, ,) (CC and) (S (NP (NN hospital) (NNS officials)) (VP (VBD declined) (S (VP (TO to) (VP (VB comment) (PP (IN beyond) (NP (DT the) (NN statement)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no additional details" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="additional" />
            <token id="6" string="details" />
          </tokens>
        </chunking>
        <chunking id="2" string="hospital officials" type="NP">
          <tokens>
            <token id="13" string="hospital" />
            <token id="14" string="officials" />
          </tokens>
        </chunking>
        <chunking id="3" string="declined to comment beyond the statement" type="VP">
          <tokens>
            <token id="15" string="declined" />
            <token id="16" string="to" />
            <token id="17" string="comment" />
            <token id="18" string="beyond" />
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="4" string="The statement" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="statement" />
          </tokens>
        </chunking>
        <chunking id="5" string="the statement" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="6" string="no additional details of Taylor 's condition" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="additional" />
            <token id="6" string="details" />
            <token id="7" string="of" />
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="condition" />
          </tokens>
        </chunking>
        <chunking id="7" string="comment beyond the statement" type="VP">
          <tokens>
            <token id="17" string="comment" />
            <token id="18" string="beyond" />
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="8" string="to comment beyond the statement" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="comment" />
            <token id="18" string="beyond" />
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="9" string="Taylor 's" type="NP">
          <tokens>
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Taylor 's condition" type="NP">
          <tokens>
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="condition" />
          </tokens>
        </chunking>
        <chunking id="11" string="provided no additional details of Taylor 's condition" type="VP">
          <tokens>
            <token id="3" string="provided" />
            <token id="4" string="no" />
            <token id="5" string="additional" />
            <token id="6" string="details" />
            <token id="7" string="of" />
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="condition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">statement</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">provided</governor>
          <dependent id="2">statement</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">provided</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">details</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">details</governor>
          <dependent id="5">additional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">provided</governor>
          <dependent id="6">details</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">condition</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">condition</governor>
          <dependent id="8">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Taylor</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">details</governor>
          <dependent id="10">condition</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">provided</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officials</governor>
          <dependent id="13">hospital</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">declined</governor>
          <dependent id="14">officials</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">provided</governor>
          <dependent id="15">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">comment</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">declined</governor>
          <dependent id="17">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">statement</governor>
          <dependent id="18">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">statement</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">comment</governor>
          <dependent id="20">statement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Lisa del Favero, a New York City publicist for Taylor, said the actress is &amp;quot;seriously ill, but she&amp;apost;s not on her deathbed.</content>
      <tokens>
        <token id="1" string="Lisa" lemma="Lisa" stem="lisa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="del" lemma="del" stem="del" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Favero" lemma="Favero" stem="favero" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="publicist" lemma="publicist" stem="publicist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="ill" lemma="ill" stem="ill" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="deathbed" lemma="deathb" stem="deathb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Lisa) (NNP del) (NNP Favero)) (, ,) (NP (NP (DT a) (NNP New) (NNP York) (NNP City) (NN publicist)) (PP (IN for) (NP (NNP Taylor)))) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (NN actress)) (VP (VBZ is) (`` ``) (ADVP (RB seriously)) (ADJP (RB ill))))))) (, ,) (CC but) (S (NP (PRP she)) (VP (VBZ 's) (RB not) (PP (IN on) (NP (NP (PRP$ her)) (VP (VBN deathbed)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lisa del Favero" type="NP">
          <tokens>
            <token id="1" string="Lisa" />
            <token id="2" string="del" />
            <token id="3" string="Favero" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor" type="NP">
          <tokens>
            <token id="11" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="3" string="is `` seriously ill" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="&quot;" />
            <token id="18" string="seriously" />
            <token id="19" string="ill" />
          </tokens>
        </chunking>
        <chunking id="4" string="deathbed" type="VP">
          <tokens>
            <token id="27" string="deathbed" />
          </tokens>
        </chunking>
        <chunking id="5" string="ill" type="ADJP">
          <tokens>
            <token id="19" string="ill" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="22" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s not on her deathbed" type="VP">
          <tokens>
            <token id="23" string="'s" />
            <token id="24" string="not" />
            <token id="25" string="on" />
            <token id="26" string="her" />
            <token id="27" string="deathbed" />
          </tokens>
        </chunking>
        <chunking id="8" string="a New York City publicist for Taylor" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="New" />
            <token id="7" string="York" />
            <token id="8" string="City" />
            <token id="9" string="publicist" />
            <token id="10" string="for" />
            <token id="11" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lisa del Favero , a New York City publicist for Taylor ," type="NP">
          <tokens>
            <token id="1" string="Lisa" />
            <token id="2" string="del" />
            <token id="3" string="Favero" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="New" />
            <token id="7" string="York" />
            <token id="8" string="City" />
            <token id="9" string="publicist" />
            <token id="10" string="for" />
            <token id="11" string="Taylor" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the actress" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="actress" />
          </tokens>
        </chunking>
        <chunking id="11" string="her" type="NP">
          <tokens>
            <token id="26" string="her" />
          </tokens>
        </chunking>
        <chunking id="12" string="said the actress is `` seriously ill" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="the" />
            <token id="15" string="actress" />
            <token id="16" string="is" />
            <token id="17" string="&quot;" />
            <token id="18" string="seriously" />
            <token id="19" string="ill" />
          </tokens>
        </chunking>
        <chunking id="13" string="the actress is `` seriously ill" type="SBAR">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="actress" />
            <token id="16" string="is" />
            <token id="17" string="&quot;" />
            <token id="18" string="seriously" />
            <token id="19" string="ill" />
          </tokens>
        </chunking>
        <chunking id="14" string="a New York City publicist" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="New" />
            <token id="7" string="York" />
            <token id="8" string="City" />
            <token id="9" string="publicist" />
          </tokens>
        </chunking>
        <chunking id="15" string="her deathbed" type="NP">
          <tokens>
            <token id="26" string="her" />
            <token id="27" string="deathbed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Favero</governor>
          <dependent id="1">Lisa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Favero</governor>
          <dependent id="2">del</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="3">Favero</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">publicist</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">publicist</governor>
          <dependent id="6">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">publicist</governor>
          <dependent id="7">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">publicist</governor>
          <dependent id="8">City</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Favero</governor>
          <dependent id="9">publicist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Taylor</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">publicist</governor>
          <dependent id="11">Taylor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">actress</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">ill</governor>
          <dependent id="15">actress</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">ill</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">ill</governor>
          <dependent id="18">seriously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="19">ill</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">said</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">her</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">her</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">her</governor>
          <dependent id="24">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">her</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">said</governor>
          <dependent id="26">her</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">her</governor>
          <dependent id="27">deathbed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lisa del Favero" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lisa" />
            <token id="2" string="del" />
            <token id="3" string="Favero" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="New York City" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="New" />
            <token id="7" string="York" />
            <token id="8" string="City" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>We&amp;apost;re not talking about anything terminal.&amp;quot;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="terminal" lemma="terminal" stem="termin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP 're) (RB not) (VP (VBG talking) (PP (IN about) (ADJP (NN anything) (JJ terminal))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="anything terminal" type="ADJP">
          <tokens>
            <token id="6" string="anything" />
            <token id="7" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="2" string="'re not talking about anything terminal" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="not" />
            <token id="4" string="talking" />
            <token id="5" string="about" />
            <token id="6" string="anything" />
            <token id="7" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="3" string="talking about anything terminal" type="VP">
          <tokens>
            <token id="4" string="talking" />
            <token id="5" string="about" />
            <token id="6" string="anything" />
            <token id="7" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">talking</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">talking</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">talking</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">terminal</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">terminal</governor>
          <dependent id="6">anything</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">talking</governor>
          <dependent id="7">terminal</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Taylor&amp;apost;s doctors expect to have results of the biopsy by Thursday, she said.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="expect" lemma="expect" stem="expect" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="results" lemma="result" stem="result" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Taylor) (POS 's)) (NNS doctors)) (VP (VBP expect) (S (VP (TO to) (VP (VB have) (NP (NP (NNS results)) (PP (IN of) (NP (DT the) (NN biopsy)))) (PP (IN by) (NP (NNP Thursday)))))))) (, ,) (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the biopsy" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thursday" type="NP">
          <tokens>
            <token id="12" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="3" string="expect to have results of the biopsy by Thursday" type="VP">
          <tokens>
            <token id="4" string="expect" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="results" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="biopsy" />
            <token id="11" string="by" />
            <token id="12" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="4" string="results of the biopsy" type="NP">
          <tokens>
            <token id="7" string="results" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="5" string="Taylor 's doctors" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
            <token id="3" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="6" string="Taylor 's" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have results of the biopsy by Thursday" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="results" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="biopsy" />
            <token id="11" string="by" />
            <token id="12" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="results" type="NP">
          <tokens>
            <token id="7" string="results" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="have results of the biopsy by Thursday" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="results" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="biopsy" />
            <token id="11" string="by" />
            <token id="12" string="Thursday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">doctors</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Taylor</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">expect</governor>
          <dependent id="3">doctors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="4">expect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">have</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">expect</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="7">results</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">biopsy</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">biopsy</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">results</governor>
          <dependent id="10">biopsy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Thursday</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">have</governor>
          <dependent id="12">Thursday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Thursday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Del Favero said Taylor&amp;apost;s four children -- Maria Burton-Carson, Liza Todd-Tivey and Christopher and Michael Wilding -- were with her at the hospital.</content>
      <tokens>
        <token id="1" string="Del" lemma="Del" stem="del" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Favero" lemma="Favero" stem="favero" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Maria" lemma="Maria" stem="maria" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Burton-Carson" lemma="Burton-Carson" stem="burton-carson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Liza" lemma="Liza" stem="liza" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Todd-Tivey" lemma="Todd-Tivey" stem="todd-tivei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Wilding" lemma="Wilding" stem="wild" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Del) (NNP Favero)) (VP (VBD said) (SBAR (S (NP (NP (NP (NNP Taylor) (POS 's)) (CD four) (NNS children)) (PRN (: --) (NP (NP (NNP Maria) (NNP Burton-Carson)) (, ,) (NP (NNP Liza) (NNP Todd-Tivey)) (CC and) (NP (NNP Christopher) (CC and) (NNP Michael) (NNP Wilding))) (: --))) (VP (VBD were) (PP (IN with) (NP (PRP$ her))) (PP (IN at) (NP (DT the) (NN hospital))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Taylor 's four children -- Maria Burton-Carson , Liza Todd-Tivey and Christopher and Michael Wilding --" type="NP">
          <tokens>
            <token id="4" string="Taylor" />
            <token id="5" string="'s" />
            <token id="6" string="four" />
            <token id="7" string="children" />
            <token id="8" string="--" />
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
            <token id="11" string="," />
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
            <token id="14" string="and" />
            <token id="15" string="Christopher" />
            <token id="16" string="and" />
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
            <token id="19" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor 's four children" type="NP">
          <tokens>
            <token id="4" string="Taylor" />
            <token id="5" string="'s" />
            <token id="6" string="four" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taylor 's four children -- Maria Burton-Carson , Liza Todd-Tivey and Christopher and Michael Wilding -- were with her at the hospital" type="SBAR">
          <tokens>
            <token id="4" string="Taylor" />
            <token id="5" string="'s" />
            <token id="6" string="four" />
            <token id="7" string="children" />
            <token id="8" string="--" />
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
            <token id="11" string="," />
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
            <token id="14" string="and" />
            <token id="15" string="Christopher" />
            <token id="16" string="and" />
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
            <token id="19" string="--" />
            <token id="20" string="were" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="4" string="Maria Burton-Carson , Liza Todd-Tivey and Christopher and Michael Wilding" type="NP">
          <tokens>
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
            <token id="11" string="," />
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
            <token id="14" string="and" />
            <token id="15" string="Christopher" />
            <token id="16" string="and" />
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
          </tokens>
        </chunking>
        <chunking id="5" string="Liza Todd-Tivey" type="NP">
          <tokens>
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
          </tokens>
        </chunking>
        <chunking id="6" string="were with her at the hospital" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="7" string="Del Favero" type="NP">
          <tokens>
            <token id="1" string="Del" />
            <token id="2" string="Favero" />
          </tokens>
        </chunking>
        <chunking id="8" string="said Taylor 's four children -- Maria Burton-Carson , Liza Todd-Tivey and Christopher and Michael Wilding -- were with her at the hospital" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="Taylor" />
            <token id="5" string="'s" />
            <token id="6" string="four" />
            <token id="7" string="children" />
            <token id="8" string="--" />
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
            <token id="11" string="," />
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
            <token id="14" string="and" />
            <token id="15" string="Christopher" />
            <token id="16" string="and" />
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
            <token id="19" string="--" />
            <token id="20" string="were" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="9" string="Maria Burton-Carson" type="NP">
          <tokens>
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="22" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="Christopher and Michael Wilding" type="NP">
          <tokens>
            <token id="15" string="Christopher" />
            <token id="16" string="and" />
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
          </tokens>
        </chunking>
        <chunking id="12" string="Taylor 's" type="NP">
          <tokens>
            <token id="4" string="Taylor" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the hospital" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="hospital" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Favero</governor>
          <dependent id="1">Del</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Favero</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">children</governor>
          <dependent id="4">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Taylor</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">children</governor>
          <dependent id="6">four</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">her</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Burton-Carson</governor>
          <dependent id="9">Maria</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">children</governor>
          <dependent id="10">Burton-Carson</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Todd-Tivey</governor>
          <dependent id="12">Liza</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Burton-Carson</governor>
          <dependent id="13">Todd-Tivey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Burton-Carson</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Wilding</governor>
          <dependent id="15">Christopher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Christopher</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Christopher</governor>
          <dependent id="17">Michael</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Burton-Carson</governor>
          <dependent id="18">Wilding</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">her</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">her</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">hospital</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">hospital</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">her</governor>
          <dependent id="25">hospital</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Wilding" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Michael" />
            <token id="18" string="Wilding" />
          </tokens>
        </entity>
        <entity id="2" string="Del Favero" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Del" />
            <token id="2" string="Favero" />
          </tokens>
        </entity>
        <entity id="3" string="Christopher" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Christopher" />
          </tokens>
        </entity>
        <entity id="4" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Taylor" />
          </tokens>
        </entity>
        <entity id="5" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="four" />
          </tokens>
        </entity>
        <entity id="6" string="Maria Burton-Carson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Maria" />
            <token id="10" string="Burton-Carson" />
          </tokens>
        </entity>
        <entity id="7" string="Liza Todd-Tivey" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Liza" />
            <token id="13" string="Todd-Tivey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Taking a biopsy on the actress is called Sutton&amp;apost;s law in medicine, after legendary holdup man Willie (the Actor) Sutton who said he robbed banks &amp;quot;because that&amp;apost;s where the money is,&amp;quot; said Dr. John G. Mohler, a pulmonary disease specialist at the USC School of Medicine.</content>
      <tokens>
        <token id="1" string="Taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Sutton" lemma="Sutton" stem="sutton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="medicine" lemma="medicine" stem="medicin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="legendary" lemma="legendary" stem="legendari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="holdup" lemma="holdup" stem="holdup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Willie" lemma="Willie" stem="willi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Actor" lemma="actor" stem="actor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Sutton" lemma="Sutton" stem="sutton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="robbed" lemma="rob" stem="rob" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="banks" lemma="bank" stem="bank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="G." lemma="G." stem="g." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="44" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="pulmonary" lemma="pulmonary" stem="pulmonari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="49" string="specialist" lemma="specialist" stem="specialist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="USC" lemma="USC" stem="usc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="53" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="54" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="55" string="Medicine" lemma="Medicine" stem="medicin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (VP (VBG Taking) (NP (DT a) (NN biopsy)) (PP (IN on) (NP (DT the) (NN actress))))) (VP (VBZ is) (VP (VBN called) (NP (NP (NNP Sutton) (POS 's)) (NN law)) (PP (IN in) (NP (NN medicine))) (, ,) (PP (IN after) (NP (JJ legendary) (NN holdup) (NN man)) (NP-TMP (NP (NNP Willie) (PRN (-LRB- -LRB-) (NP (DT the) (NN Actor)) (-RRB- -RRB-)) (NNP Sutton)) (SBAR (WHNP (WP who)) (S (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD robbed) (NP (NNS banks)) (`` ``) (SBAR (IN because) (S (NP (DT that)) (VP (VBZ 's) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN money)) (VP (VBZ is)))))))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Dr.) (NNP John) (NNP G.) (NNP Mohler)) (, ,) (NP (NP (DT a) (JJ pulmonary) (NN disease) (NN specialist)) (PP (IN at) (NP (NP (DT the) (NNP USC) (NNP School)) (PP (IN of) (NP (NNP Medicine))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="banks" type="NP">
          <tokens>
            <token id="29" string="banks" />
          </tokens>
        </chunking>
        <chunking id="2" string="where the money is" type="SBAR">
          <tokens>
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taking a biopsy on the actress" type="VP">
          <tokens>
            <token id="1" string="Taking" />
            <token id="2" string="a" />
            <token id="3" string="biopsy" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="actress" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sutton 's" type="NP">
          <tokens>
            <token id="9" string="Sutton" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="medicine" type="NP">
          <tokens>
            <token id="13" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="6" string="is" type="VP">
          <tokens>
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dr. John G. Mohler" type="NP">
          <tokens>
            <token id="41" string="Dr." />
            <token id="42" string="John" />
            <token id="43" string="G." />
            <token id="44" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="8" string="robbed banks `` because that 's where the money is" type="VP">
          <tokens>
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="9" string="Willie -LRB- the Actor -RRB- Sutton" type="NP">
          <tokens>
            <token id="19" string="Willie" />
            <token id="20" string="(" />
            <token id="21" string="the" />
            <token id="22" string="Actor" />
            <token id="23" string=")" />
            <token id="24" string="Sutton" />
          </tokens>
        </chunking>
        <chunking id="10" string="the money" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="money" />
          </tokens>
        </chunking>
        <chunking id="11" string="called Sutton 's law in medicine , after legendary holdup man Willie -LRB- the Actor -RRB- Sutton who said he robbed banks `` because that 's where the money is" type="VP">
          <tokens>
            <token id="8" string="called" />
            <token id="9" string="Sutton" />
            <token id="10" string="'s" />
            <token id="11" string="law" />
            <token id="12" string="in" />
            <token id="13" string="medicine" />
            <token id="14" string="," />
            <token id="15" string="after" />
            <token id="16" string="legendary" />
            <token id="17" string="holdup" />
            <token id="18" string="man" />
            <token id="19" string="Willie" />
            <token id="20" string="(" />
            <token id="21" string="the" />
            <token id="22" string="Actor" />
            <token id="23" string=")" />
            <token id="24" string="Sutton" />
            <token id="25" string="who" />
            <token id="26" string="said" />
            <token id="27" string="he" />
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="12" string="Medicine" type="NP">
          <tokens>
            <token id="55" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sutton 's law" type="NP">
          <tokens>
            <token id="9" string="Sutton" />
            <token id="10" string="'s" />
            <token id="11" string="law" />
          </tokens>
        </chunking>
        <chunking id="14" string="he robbed banks `` because that 's where the money is" type="SBAR">
          <tokens>
            <token id="27" string="he" />
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="15" string="a biopsy" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="a pulmonary disease specialist at the USC School of Medicine" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="pulmonary" />
            <token id="48" string="disease" />
            <token id="49" string="specialist" />
            <token id="50" string="at" />
            <token id="51" string="the" />
            <token id="52" string="USC" />
            <token id="53" string="School" />
            <token id="54" string="of" />
            <token id="55" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="18" string="a pulmonary disease specialist" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="pulmonary" />
            <token id="48" string="disease" />
            <token id="49" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="19" string="legendary holdup man" type="NP">
          <tokens>
            <token id="16" string="legendary" />
            <token id="17" string="holdup" />
            <token id="18" string="man" />
          </tokens>
        </chunking>
        <chunking id="20" string="is called Sutton 's law in medicine , after legendary holdup man Willie -LRB- the Actor -RRB- Sutton who said he robbed banks `` because that 's where the money is" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="called" />
            <token id="9" string="Sutton" />
            <token id="10" string="'s" />
            <token id="11" string="law" />
            <token id="12" string="in" />
            <token id="13" string="medicine" />
            <token id="14" string="," />
            <token id="15" string="after" />
            <token id="16" string="legendary" />
            <token id="17" string="holdup" />
            <token id="18" string="man" />
            <token id="19" string="Willie" />
            <token id="20" string="(" />
            <token id="21" string="the" />
            <token id="22" string="Actor" />
            <token id="23" string=")" />
            <token id="24" string="Sutton" />
            <token id="25" string="who" />
            <token id="26" string="said" />
            <token id="27" string="he" />
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="21" string="'s where the money is" type="VP">
          <tokens>
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="22" string="the USC School" type="NP">
          <tokens>
            <token id="51" string="the" />
            <token id="52" string="USC" />
            <token id="53" string="School" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Actor" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Actor" />
          </tokens>
        </chunking>
        <chunking id="24" string="because that 's where the money is" type="SBAR">
          <tokens>
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="25" string="said he robbed banks `` because that 's where the money is" type="VP">
          <tokens>
            <token id="26" string="said" />
            <token id="27" string="he" />
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="26" string="that" type="NP">
          <tokens>
            <token id="32" string="that" />
          </tokens>
        </chunking>
        <chunking id="27" string="who said he robbed banks `` because that 's where the money is" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="said" />
            <token id="27" string="he" />
            <token id="28" string="robbed" />
            <token id="29" string="banks" />
            <token id="30" string="&quot;" />
            <token id="31" string="because" />
            <token id="32" string="that" />
            <token id="33" string="'s" />
            <token id="34" string="where" />
            <token id="35" string="the" />
            <token id="36" string="money" />
            <token id="37" string="is" />
          </tokens>
        </chunking>
        <chunking id="28" string="the actress" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="actress" />
          </tokens>
        </chunking>
        <chunking id="29" string="where" type="WHADVP">
          <tokens>
            <token id="34" string="where" />
          </tokens>
        </chunking>
        <chunking id="30" string="the USC School of Medicine" type="NP">
          <tokens>
            <token id="51" string="the" />
            <token id="52" string="USC" />
            <token id="53" string="School" />
            <token id="54" string="of" />
            <token id="55" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="31" string="said" type="VP">
          <tokens>
            <token id="40" string="said" />
          </tokens>
        </chunking>
        <chunking id="32" string="Dr. John G. Mohler , a pulmonary disease specialist at the USC School of Medicine" type="NP">
          <tokens>
            <token id="41" string="Dr." />
            <token id="42" string="John" />
            <token id="43" string="G." />
            <token id="44" string="Mohler" />
            <token id="45" string="," />
            <token id="46" string="a" />
            <token id="47" string="pulmonary" />
            <token id="48" string="disease" />
            <token id="49" string="specialist" />
            <token id="50" string="at" />
            <token id="51" string="the" />
            <token id="52" string="USC" />
            <token id="53" string="School" />
            <token id="54" string="of" />
            <token id="55" string="Medicine" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubjpass">
          <governor id="8">called</governor>
          <dependent id="1">Taking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">biopsy</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Taking</governor>
          <dependent id="3">biopsy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">actress</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">actress</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Taking</governor>
          <dependent id="6">actress</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">called</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="40">said</governor>
          <dependent id="8">called</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">law</governor>
          <dependent id="9">Sutton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Sutton</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">called</governor>
          <dependent id="11">law</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">medicine</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">called</governor>
          <dependent id="13">medicine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">man</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">man</governor>
          <dependent id="16">legendary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">man</governor>
          <dependent id="17">holdup</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">called</governor>
          <dependent id="18">man</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Sutton</governor>
          <dependent id="19">Willie</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Actor</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">Sutton</governor>
          <dependent id="22">Actor</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">man</governor>
          <dependent id="24">Sutton</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">Sutton</governor>
          <dependent id="26">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">robbed</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="28">robbed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">robbed</governor>
          <dependent id="29">banks</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">'s</governor>
          <dependent id="31">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">'s</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">robbed</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">is</governor>
          <dependent id="34">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">money</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">is</governor>
          <dependent id="36">money</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">'s</governor>
          <dependent id="37">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="40">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Mohler</governor>
          <dependent id="41">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Mohler</governor>
          <dependent id="42">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Mohler</governor>
          <dependent id="43">G.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">said</governor>
          <dependent id="44">Mohler</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">specialist</governor>
          <dependent id="46">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">specialist</governor>
          <dependent id="47">pulmonary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">specialist</governor>
          <dependent id="48">disease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="44">Mohler</governor>
          <dependent id="49">specialist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">School</governor>
          <dependent id="50">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="53">School</governor>
          <dependent id="51">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">School</governor>
          <dependent id="52">USC</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">specialist</governor>
          <dependent id="53">School</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">Medicine</governor>
          <dependent id="54">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="53">School</governor>
          <dependent id="55">Medicine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Willie" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Willie" />
          </tokens>
        </entity>
        <entity id="2" string="John G. Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="John" />
            <token id="43" string="G." />
            <token id="44" string="Mohler" />
          </tokens>
        </entity>
        <entity id="3" string="USC School of Medicine" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="52" string="USC" />
            <token id="53" string="School" />
            <token id="54" string="of" />
            <token id="55" string="Medicine" />
          </tokens>
        </entity>
        <entity id="4" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="48" string="disease" />
          </tokens>
        </entity>
        <entity id="5" string="Sutton" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Sutton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;If you don&amp;apost;t know what the trouble is, you grab a biopsy and study it, because that&amp;apost;s where the problem is,&amp;quot; Mohler explained.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="grab" lemma="grab" stem="grab" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="study" lemma="study" stem="studi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN If) (S (NP (PRP you)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN trouble)) (VP (VBZ is)))))))) (, ,) (NP (PRP you)) (VP (VP (VBP grab) (NP (DT a) (NN biopsy))) (CC and) (VP (VB study) (NP (PRP it))) (, ,) (SBAR (IN because) (S (NP (DT that)) (VP (VBZ 's) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN problem)) (VP (VBZ is))))))))) (, ,) ('' '') (NP (NNP Mohler)) (VP (VBD explained)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="where the problem is" type="SBAR">
          <tokens>
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="problem" />
            <token id="26" string="is" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mohler" type="NP">
          <tokens>
            <token id="29" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="3" string="what the trouble is" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="the" />
            <token id="9" string="trouble" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="4" string="the problem" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="problem" />
          </tokens>
        </chunking>
        <chunking id="5" string="is" type="VP">
          <tokens>
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the trouble" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="8" string="explained" type="VP">
          <tokens>
            <token id="30" string="explained" />
          </tokens>
        </chunking>
        <chunking id="9" string="that" type="NP">
          <tokens>
            <token id="21" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="do n't know what the trouble is" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="know" />
            <token id="7" string="what" />
            <token id="8" string="the" />
            <token id="9" string="trouble" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s where the problem is" type="VP">
          <tokens>
            <token id="22" string="'s" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="problem" />
            <token id="26" string="is" />
          </tokens>
        </chunking>
        <chunking id="12" string="grab a biopsy" type="VP">
          <tokens>
            <token id="13" string="grab" />
            <token id="14" string="a" />
            <token id="15" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="13" string="know what the trouble is" type="VP">
          <tokens>
            <token id="6" string="know" />
            <token id="7" string="what" />
            <token id="8" string="the" />
            <token id="9" string="trouble" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="14" string="study it" type="VP">
          <tokens>
            <token id="17" string="study" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="because that 's where the problem is" type="SBAR">
          <tokens>
            <token id="20" string="because" />
            <token id="21" string="that" />
            <token id="22" string="'s" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="problem" />
            <token id="26" string="is" />
          </tokens>
        </chunking>
        <chunking id="16" string="If you do n't know what the trouble is" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="know" />
            <token id="7" string="what" />
            <token id="8" string="the" />
            <token id="9" string="trouble" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="17" string="grab a biopsy and study it , because that 's where the problem is" type="VP">
          <tokens>
            <token id="13" string="grab" />
            <token id="14" string="a" />
            <token id="15" string="biopsy" />
            <token id="16" string="and" />
            <token id="17" string="study" />
            <token id="18" string="it" />
            <token id="19" string="," />
            <token id="20" string="because" />
            <token id="21" string="that" />
            <token id="22" string="'s" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="problem" />
            <token id="26" string="is" />
          </tokens>
        </chunking>
        <chunking id="18" string="where" type="WHADVP">
          <tokens>
            <token id="23" string="where" />
          </tokens>
        </chunking>
        <chunking id="19" string="a biopsy" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="20" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">know</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">know</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">know</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">know</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">grab</governor>
          <dependent id="6">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">is</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">trouble</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="9">trouble</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">know</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">grab</governor>
          <dependent id="12">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">explained</governor>
          <dependent id="13">grab</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">biopsy</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">grab</governor>
          <dependent id="15">biopsy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">grab</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">grab</governor>
          <dependent id="17">study</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">study</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">'s</governor>
          <dependent id="20">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">'s</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">grab</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">is</governor>
          <dependent id="23">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">problem</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">is</governor>
          <dependent id="25">problem</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">'s</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">explained</governor>
          <dependent id="29">Mohler</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">explained</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Mohler" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>&amp;quot;The problem is not easily found another way.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="easily" lemma="easily" stem="easili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (NN problem)) (VP (VBZ is) (RB not) (ADVP (RB easily)) (VP (VBN found) (NP (DT another) (NN way)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="another way" type="NP">
          <tokens>
            <token id="8" string="another" />
            <token id="9" string="way" />
          </tokens>
        </chunking>
        <chunking id="2" string="is not easily found another way" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="not" />
            <token id="6" string="easily" />
            <token id="7" string="found" />
            <token id="8" string="another" />
            <token id="9" string="way" />
          </tokens>
        </chunking>
        <chunking id="3" string="found another way" type="VP">
          <tokens>
            <token id="7" string="found" />
            <token id="8" string="another" />
            <token id="9" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="The problem" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">problem</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">found</governor>
          <dependent id="3">problem</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">found</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">found</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">found</governor>
          <dependent id="6">easily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">way</governor>
          <dependent id="8">another</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">found</governor>
          <dependent id="9">way</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;You study the biopsy because that will dictate your therapy.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="study" lemma="study" stem="studi" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dictate" lemma="dictate" stem="dictat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (VBP study) (NP (DT the) (NN biopsy)) (SBAR (IN because) (S (NP (DT that)) (VP (MD will) (VP (VB dictate) (NP (PRP$ your) (NN therapy))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="7" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="dictate your therapy" type="VP">
          <tokens>
            <token id="9" string="dictate" />
            <token id="10" string="your" />
            <token id="11" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="3" string="will dictate your therapy" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="dictate" />
            <token id="10" string="your" />
            <token id="11" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="4" string="your therapy" type="NP">
          <tokens>
            <token id="10" string="your" />
            <token id="11" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="5" string="study the biopsy because that will dictate your therapy" type="VP">
          <tokens>
            <token id="3" string="study" />
            <token id="4" string="the" />
            <token id="5" string="biopsy" />
            <token id="6" string="because" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="dictate" />
            <token id="10" string="your" />
            <token id="11" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="6" string="the biopsy" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="7" string="because that will dictate your therapy" type="SBAR">
          <tokens>
            <token id="6" string="because" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="dictate" />
            <token id="10" string="your" />
            <token id="11" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="8" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">study</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">study</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">biopsy</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">study</governor>
          <dependent id="5">biopsy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">dictate</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">dictate</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">dictate</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">study</governor>
          <dependent id="9">dictate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">therapy</governor>
          <dependent id="10">your</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">dictate</governor>
          <dependent id="11">therapy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>If they (took a biopsy), I&amp;apost;m sure she was not responding to antibiotics.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="responding" lemma="respond" stem="respond" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="antibiotics" lemma="antibiotic" stem="antibiot" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (NP (PRP they)) (PRN (-LRB- -LRB-) (VP (VBD took) (NP (DT a) (NN biopsy))) (-RRB- -RRB-))) (, ,) (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ sure))))) (NP (PRP she)) (VP (VBD was) (RB not) (VP (VBG responding) (PP (TO to) (NP (NNS antibiotics))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="'m sure" type="VP">
          <tokens>
            <token id="10" string="'m" />
            <token id="11" string="sure" />
          </tokens>
        </chunking>
        <chunking id="3" string="sure" type="ADJP">
          <tokens>
            <token id="11" string="sure" />
          </tokens>
        </chunking>
        <chunking id="4" string="was not responding to antibiotics" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="not" />
            <token id="15" string="responding" />
            <token id="16" string="to" />
            <token id="17" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="5" string="responding to antibiotics" type="VP">
          <tokens>
            <token id="15" string="responding" />
            <token id="16" string="to" />
            <token id="17" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="6" string="If they -LRB- took a biopsy -RRB- , I 'm sure" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="they" />
            <token id="3" string="(" />
            <token id="4" string="took" />
            <token id="5" string="a" />
            <token id="6" string="biopsy" />
            <token id="7" string=")" />
            <token id="8" string="," />
            <token id="9" string="I" />
            <token id="10" string="'m" />
            <token id="11" string="sure" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="took a biopsy" type="VP">
          <tokens>
            <token id="4" string="took" />
            <token id="5" string="a" />
            <token id="6" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="9" string="a biopsy" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="10" string="antibiotics" type="NP">
          <tokens>
            <token id="17" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="they -LRB- took a biopsy -RRB-" type="NP">
          <tokens>
            <token id="2" string="they" />
            <token id="3" string="(" />
            <token id="4" string="took" />
            <token id="5" string="a" />
            <token id="6" string="biopsy" />
            <token id="7" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="11">sure</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sure</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">they</governor>
          <dependent id="4">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">biopsy</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">took</governor>
          <dependent id="6">biopsy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sure</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">sure</governor>
          <dependent id="10">'m</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">responding</governor>
          <dependent id="11">sure</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">responding</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">responding</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">responding</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">responding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">antibiotics</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">responding</governor>
          <dependent id="17">antibiotics</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Mohler said Taylor&amp;apost;s doctors are taking a prudent course by placing her on a ventilator.</content>
      <tokens>
        <token id="1" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prudent" lemma="prudent" stem="prudent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mohler)) (VP (VBD said) (SBAR (S (NP (NP (NNP Taylor) (POS 's)) (NNS doctors)) (VP (VBP are) (VP (VBG taking) (NP (DT a) (JJ prudent) (NN course)) (PP (IN by) (S (VP (VBG placing) (NP (PRP$ her)) (PP (IN on) (NP (DT a) (NN ventilator))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mohler" type="NP">
          <tokens>
            <token id="1" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor 's doctors are taking a prudent course by placing her on a ventilator" type="SBAR">
          <tokens>
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
            <token id="5" string="doctors" />
            <token id="6" string="are" />
            <token id="7" string="taking" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="course" />
            <token id="11" string="by" />
            <token id="12" string="placing" />
            <token id="13" string="her" />
            <token id="14" string="on" />
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="3" string="taking a prudent course by placing her on a ventilator" type="VP">
          <tokens>
            <token id="7" string="taking" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="course" />
            <token id="11" string="by" />
            <token id="12" string="placing" />
            <token id="13" string="her" />
            <token id="14" string="on" />
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="4" string="are taking a prudent course by placing her on a ventilator" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="taking" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="course" />
            <token id="11" string="by" />
            <token id="12" string="placing" />
            <token id="13" string="her" />
            <token id="14" string="on" />
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="5" string="a prudent course" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="course" />
          </tokens>
        </chunking>
        <chunking id="6" string="said Taylor 's doctors are taking a prudent course by placing her on a ventilator" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
            <token id="5" string="doctors" />
            <token id="6" string="are" />
            <token id="7" string="taking" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="course" />
            <token id="11" string="by" />
            <token id="12" string="placing" />
            <token id="13" string="her" />
            <token id="14" string="on" />
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="7" string="her" type="NP">
          <tokens>
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="8" string="Taylor 's doctors" type="NP">
          <tokens>
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
            <token id="5" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="9" string="Taylor 's" type="NP">
          <tokens>
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="a ventilator" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="11" string="placing her on a ventilator" type="VP">
          <tokens>
            <token id="12" string="placing" />
            <token id="13" string="her" />
            <token id="14" string="on" />
            <token id="15" string="a" />
            <token id="16" string="ventilator" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Mohler</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">doctors</governor>
          <dependent id="3">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Taylor</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">taking</governor>
          <dependent id="5">doctors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">taking</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">taking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">course</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">course</governor>
          <dependent id="9">prudent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">taking</governor>
          <dependent id="10">course</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">placing</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">taking</governor>
          <dependent id="12">placing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">placing</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">ventilator</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ventilator</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">placing</governor>
          <dependent id="16">ventilator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mohler" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>She suffered a near-fatal bout of pneumonia in 1961, and Mohler said &amp;quot;it would seem that there is something basically wrong with her lung structure or function.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="near-fatal" lemma="near-fatal" stem="near-fat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="bout" lemma="bout" stem="bout" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="1961" lemma="1961" stem="1961" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="seem" lemma="seem" stem="seem" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="basically" lemma="basically" stem="basic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="lung" lemma="lung" stem="lung" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="structure" lemma="structure" stem="structur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="function" lemma="function" stem="function" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD suffered) (NP (NP (DT a) (JJ near-fatal) (NN bout)) (PP (IN of) (NP (NN pneumonia)))) (PP (IN in) (NP (CD 1961))))) (, ,) (CC and) (S (NP (NNP Mohler)) (VP (VBD said) (S (`` ``) (NP (PRP it)) (VP (MD would) (VP (VB seem) (SBAR (IN that) (S (NP (EX there)) (VP (VBZ is) (NP (NP (NN something)) (ADJP (RB basically) (JJ wrong)) (PP (IN with) (NP (PRP$ her) (NN lung) (NN structure) (CC or) (NN function)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suffered a near-fatal bout of pneumonia in 1961" type="VP">
          <tokens>
            <token id="2" string="suffered" />
            <token id="3" string="a" />
            <token id="4" string="near-fatal" />
            <token id="5" string="bout" />
            <token id="6" string="of" />
            <token id="7" string="pneumonia" />
            <token id="8" string="in" />
            <token id="9" string="1961" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mohler" type="NP">
          <tokens>
            <token id="12" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="3" string="basically wrong" type="ADJP">
          <tokens>
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="4" string="is something basically wrong with her lung structure or function" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="5" string="a near-fatal bout" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="near-fatal" />
            <token id="5" string="bout" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="something" type="NP">
          <tokens>
            <token id="21" string="something" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="something basically wrong with her lung structure or function" type="NP">
          <tokens>
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="10" string="that there is something basically wrong with her lung structure or function" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="there" />
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="19" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="would seem that there is something basically wrong with her lung structure or function" type="VP">
          <tokens>
            <token id="16" string="would" />
            <token id="17" string="seem" />
            <token id="18" string="that" />
            <token id="19" string="there" />
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="13" string="1961" type="NP">
          <tokens>
            <token id="9" string="1961" />
          </tokens>
        </chunking>
        <chunking id="14" string="a near-fatal bout of pneumonia" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="near-fatal" />
            <token id="5" string="bout" />
            <token id="6" string="of" />
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="15" string="pneumonia" type="NP">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="16" string="seem that there is something basically wrong with her lung structure or function" type="VP">
          <tokens>
            <token id="17" string="seem" />
            <token id="18" string="that" />
            <token id="19" string="there" />
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="17" string="said `` it would seem that there is something basically wrong with her lung structure or function" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="&quot;" />
            <token id="15" string="it" />
            <token id="16" string="would" />
            <token id="17" string="seem" />
            <token id="18" string="that" />
            <token id="19" string="there" />
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="basically" />
            <token id="23" string="wrong" />
            <token id="24" string="with" />
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
        <chunking id="18" string="her lung structure or function" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="lung" />
            <token id="27" string="structure" />
            <token id="28" string="or" />
            <token id="29" string="function" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">suffered</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">suffered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">bout</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">bout</governor>
          <dependent id="4">near-fatal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">suffered</governor>
          <dependent id="5">bout</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">pneumonia</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">bout</governor>
          <dependent id="7">pneumonia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1961</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">suffered</governor>
          <dependent id="9">1961</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">suffered</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Mohler</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">suffered</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">seem</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">seem</governor>
          <dependent id="16">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="17">seem</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">is</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="20">is</governor>
          <dependent id="19">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">seem</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">is</governor>
          <dependent id="21">something</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">wrong</governor>
          <dependent id="22">basically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">something</governor>
          <dependent id="23">wrong</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">structure</governor>
          <dependent id="24">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">structure</governor>
          <dependent id="25">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">structure</governor>
          <dependent id="26">lung</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">something</governor>
          <dependent id="27">structure</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">structure</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">structure</governor>
          <dependent id="29">function</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Mohler" />
          </tokens>
        </entity>
        <entity id="2" string="1961" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1961" />
          </tokens>
        </entity>
        <entity id="3" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>When she gets pneumonia, apparently it&amp;apost;s more severe.&amp;quot;</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="severe" lemma="severe" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VBZ gets) (NP (NN pneumonia))))) (, ,) (ADVP (RB apparently)) (NP (PRP it)) (VP (VBZ 's) (ADJP (RBR more) (JJ severe))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="2" string="When she gets pneumonia" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="she" />
            <token id="3" string="gets" />
            <token id="4" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="3" string="pneumonia" type="NP">
          <tokens>
            <token id="4" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s more severe" type="VP">
          <tokens>
            <token id="8" string="'s" />
            <token id="9" string="more" />
            <token id="10" string="severe" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="gets pneumonia" type="VP">
          <tokens>
            <token id="3" string="gets" />
            <token id="4" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="7" string="more severe" type="ADJP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="severe" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">gets</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">gets</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">severe</governor>
          <dependent id="3">gets</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">gets</governor>
          <dependent id="4">pneumonia</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">it</governor>
          <dependent id="6">apparently</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">severe</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">severe</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">severe</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">severe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="4" string="pneumonia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Emphasizing that he has no personal familiarity with the actress&amp;apost;s case, Mohler said he does not &amp;quot;blame her doctors for being conservative.</content>
      <tokens>
        <token id="1" string="Emphasizing" lemma="emphasize" stem="emphasiz" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="familiarity" lemma="familiarity" stem="familiar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="blame" lemma="blame" stem="blame" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Emphasizing) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ has) (NP (NP (DT no) (JJ personal) (NN familiarity)) (PP (IN with) (NP (NP (DT the) (NN actress) (POS 's)) (NN case))))))))) (, ,) (NP (NNP Mohler)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ does) (RB not) (VP (`` ``) (VB blame) (NP (PRP$ her) (NNS doctors)) (PP (IN for)) (S (VP (VBG being) (ADJP (JJ conservative))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mohler" type="NP">
          <tokens>
            <token id="14" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="2" string="he does not `` blame her doctors for being conservative" type="SBAR">
          <tokens>
            <token id="16" string="he" />
            <token id="17" string="does" />
            <token id="18" string="not" />
            <token id="19" string="&quot;" />
            <token id="20" string="blame" />
            <token id="21" string="her" />
            <token id="22" string="doctors" />
            <token id="23" string="for" />
            <token id="24" string="being" />
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="3" string="the actress 's case" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="no personal familiarity with the actress 's case" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="personal" />
            <token id="7" string="familiarity" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="conservative" type="ADJP">
          <tokens>
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="6" string="being conservative" type="VP">
          <tokens>
            <token id="24" string="being" />
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="7" string="no personal familiarity" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="personal" />
            <token id="7" string="familiarity" />
          </tokens>
        </chunking>
        <chunking id="8" string="that he has no personal familiarity with the actress 's case" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="he" />
            <token id="4" string="has" />
            <token id="5" string="no" />
            <token id="6" string="personal" />
            <token id="7" string="familiarity" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he does not `` blame her doctors for being conservative" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="he" />
            <token id="17" string="does" />
            <token id="18" string="not" />
            <token id="19" string="&quot;" />
            <token id="20" string="blame" />
            <token id="21" string="her" />
            <token id="22" string="doctors" />
            <token id="23" string="for" />
            <token id="24" string="being" />
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="10" string="her doctors" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="11" string="has no personal familiarity with the actress 's case" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="no" />
            <token id="6" string="personal" />
            <token id="7" string="familiarity" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="12" string="does not `` blame her doctors for being conservative" type="VP">
          <tokens>
            <token id="17" string="does" />
            <token id="18" string="not" />
            <token id="19" string="&quot;" />
            <token id="20" string="blame" />
            <token id="21" string="her" />
            <token id="22" string="doctors" />
            <token id="23" string="for" />
            <token id="24" string="being" />
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="13" string="the actress 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="Emphasizing that he has no personal familiarity with the actress 's case" type="VP">
          <tokens>
            <token id="1" string="Emphasizing" />
            <token id="2" string="that" />
            <token id="3" string="he" />
            <token id="4" string="has" />
            <token id="5" string="no" />
            <token id="6" string="personal" />
            <token id="7" string="familiarity" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="actress" />
            <token id="11" string="'s" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="`` blame her doctors for being conservative" type="VP">
          <tokens>
            <token id="19" string="&quot;" />
            <token id="20" string="blame" />
            <token id="21" string="her" />
            <token id="22" string="doctors" />
            <token id="23" string="for" />
            <token id="24" string="being" />
            <token id="25" string="conservative" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="15">said</governor>
          <dependent id="1">Emphasizing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">has</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Emphasizing</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">familiarity</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">familiarity</governor>
          <dependent id="6">personal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="7">familiarity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">case</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">actress</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">case</governor>
          <dependent id="10">actress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">actress</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">familiarity</governor>
          <dependent id="12">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Mohler</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">blame</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">blame</governor>
          <dependent id="17">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">blame</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="20">blame</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">doctors</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">blame</governor>
          <dependent id="22">doctors</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">blame</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">conservative</governor>
          <dependent id="24">being</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">blame</governor>
          <dependent id="25">conservative</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mohler" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="25" string="conservative" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Placing her on a ventilator would be a prudent and conservative thing to do, even if she didn&amp;apost;t have any difficulty.</content>
      <tokens>
        <token id="1" string="Placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prudent" lemma="prudent" stem="prudent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="12" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="difficulty" lemma="difficulty" stem="difficulti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Placing) (NP (PRP$ her)) (PP (IN on) (NP (DT a) (NN ventilator))))) (VP (MD would) (VP (VB be) (NP (DT a) (ADJP (JJ prudent) (CC and) (JJ conservative)) (NN thing) (S (VP (TO to) (VP (VB do))))) (, ,) (SBAR (RB even) (IN if) (S (NP (PRP she)) (VP (VBD did) (RB n't) (VP (VB have) (NP (DT any) (NN difficulty)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would be a prudent and conservative thing to do , even if she did n't have any difficulty" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="and" />
            <token id="11" string="conservative" />
            <token id="12" string="thing" />
            <token id="13" string="to" />
            <token id="14" string="do" />
            <token id="15" string="," />
            <token id="16" string="even" />
            <token id="17" string="if" />
            <token id="18" string="she" />
            <token id="19" string="did" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="2" string="any difficulty" type="NP">
          <tokens>
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="3" string="even if she did n't have any difficulty" type="SBAR">
          <tokens>
            <token id="16" string="even" />
            <token id="17" string="if" />
            <token id="18" string="she" />
            <token id="19" string="did" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="4" string="a prudent and conservative thing to do" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="and" />
            <token id="11" string="conservative" />
            <token id="12" string="thing" />
            <token id="13" string="to" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="do" type="VP">
          <tokens>
            <token id="14" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="did n't have any difficulty" type="VP">
          <tokens>
            <token id="19" string="did" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="7" string="a ventilator" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="18" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="Placing her on a ventilator" type="VP">
          <tokens>
            <token id="1" string="Placing" />
            <token id="2" string="her" />
            <token id="3" string="on" />
            <token id="4" string="a" />
            <token id="5" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="10" string="have any difficulty" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="11" string="be a prudent and conservative thing to do , even if she did n't have any difficulty" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="prudent" />
            <token id="10" string="and" />
            <token id="11" string="conservative" />
            <token id="12" string="thing" />
            <token id="13" string="to" />
            <token id="14" string="do" />
            <token id="15" string="," />
            <token id="16" string="even" />
            <token id="17" string="if" />
            <token id="18" string="she" />
            <token id="19" string="did" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="any" />
            <token id="23" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="12" string="prudent and conservative" type="ADJP">
          <tokens>
            <token id="9" string="prudent" />
            <token id="10" string="and" />
            <token id="11" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="13" string="her" type="NP">
          <tokens>
            <token id="2" string="her" />
          </tokens>
        </chunking>
        <chunking id="14" string="to do" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="do" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="12">thing</governor>
          <dependent id="1">Placing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Placing</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">ventilator</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ventilator</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Placing</governor>
          <dependent id="5">ventilator</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">thing</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">thing</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">thing</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">thing</governor>
          <dependent id="9">prudent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">prudent</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">prudent</governor>
          <dependent id="11">conservative</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">thing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">do</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">thing</governor>
          <dependent id="14">do</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">have</governor>
          <dependent id="16">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">have</governor>
          <dependent id="17">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">have</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">have</governor>
          <dependent id="19">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">have</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">thing</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">difficulty</governor>
          <dependent id="22">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">have</governor>
          <dependent id="23">difficulty</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="conservative" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>It may just be a precautionary step in this case.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="precautionary" lemma="precautionary" stem="precautionari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="step" lemma="step" stem="step" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (MD may) (ADVP (RB just)) (VP (VB be) (NP (NP (DT a) (JJ precautionary) (NN step)) (PP (IN in) (NP (DT this) (NN case)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a precautionary step in this case" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="precautionary" />
            <token id="7" string="step" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="be a precautionary step in this case" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="precautionary" />
            <token id="7" string="step" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="a precautionary step" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="precautionary" />
            <token id="7" string="step" />
          </tokens>
        </chunking>
        <chunking id="4" string="may just be a precautionary step in this case" type="VP">
          <tokens>
            <token id="2" string="may" />
            <token id="3" string="just" />
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="precautionary" />
            <token id="7" string="step" />
            <token id="8" string="in" />
            <token id="9" string="this" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="this case" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">step</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">step</governor>
          <dependent id="2">may</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">step</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">step</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">step</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">step</governor>
          <dependent id="6">precautionary</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">step</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">case</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">case</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">step</governor>
          <dependent id="10">case</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Taylor, 58, entered Daniel Freeman Marina Hospital in Marina del Rey on April 10 suffering what her publicist then described as a &amp;quot;severe sinus infection.&amp;quot;</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="58" lemma="58" stem="58" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="entered" lemma="enter" stem="enter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Freeman" lemma="Freeman" stem="freeman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Marina" lemma="Marina" stem="marina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Marina" lemma="Marina" stem="marina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="del" lemma="del" stem="del" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Rey" lemma="Rey" stem="rei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="suffering" lemma="suffer" stem="suffer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="publicist" lemma="publicist" stem="publicist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="severe" lemma="severe" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="sinus" lemma="sinus" stem="sinu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Taylor)) (, ,) (NP (CD 58)) (, ,)) (VP (VBD entered) (NP (NP (NNP Daniel) (NNP Freeman) (NNP Marina) (NNP Hospital)) (PP (IN in) (NP (NNP Marina) (NNP del) (NNP Rey)))) (PP (IN on) (NP (NP (NNP April) (CD 10)) (VP (VBG suffering) (SBAR (WHNP (WP what)) (S (NP (PRP$ her) (NN publicist)) (ADVP (RB then)) (VP (VBD described) (PP (IN as) (NP (DT a) (`` ``) (JJ severe) (NN sinus) (NN infection)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="her publicist" type="NP">
          <tokens>
            <token id="19" string="her" />
            <token id="20" string="publicist" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` severe sinus infection" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
        <chunking id="3" string="58" type="NP">
          <tokens>
            <token id="3" string="58" />
          </tokens>
        </chunking>
        <chunking id="4" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="5" string="April 10 suffering what her publicist then described as a `` severe sinus infection" type="NP">
          <tokens>
            <token id="15" string="April" />
            <token id="16" string="10" />
            <token id="17" string="suffering" />
            <token id="18" string="what" />
            <token id="19" string="her" />
            <token id="20" string="publicist" />
            <token id="21" string="then" />
            <token id="22" string="described" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
        <chunking id="6" string="Daniel Freeman Marina Hospital" type="NP">
          <tokens>
            <token id="6" string="Daniel" />
            <token id="7" string="Freeman" />
            <token id="8" string="Marina" />
            <token id="9" string="Hospital" />
          </tokens>
        </chunking>
        <chunking id="7" string="April 10" type="NP">
          <tokens>
            <token id="15" string="April" />
            <token id="16" string="10" />
          </tokens>
        </chunking>
        <chunking id="8" string="suffering what her publicist then described as a `` severe sinus infection" type="VP">
          <tokens>
            <token id="17" string="suffering" />
            <token id="18" string="what" />
            <token id="19" string="her" />
            <token id="20" string="publicist" />
            <token id="21" string="then" />
            <token id="22" string="described" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
        <chunking id="9" string="Taylor , 58 ," type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="," />
            <token id="3" string="58" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="Daniel Freeman Marina Hospital in Marina del Rey" type="NP">
          <tokens>
            <token id="6" string="Daniel" />
            <token id="7" string="Freeman" />
            <token id="8" string="Marina" />
            <token id="9" string="Hospital" />
            <token id="10" string="in" />
            <token id="11" string="Marina" />
            <token id="12" string="del" />
            <token id="13" string="Rey" />
          </tokens>
        </chunking>
        <chunking id="11" string="entered Daniel Freeman Marina Hospital in Marina del Rey on April 10 suffering what her publicist then described as a `` severe sinus infection" type="VP">
          <tokens>
            <token id="5" string="entered" />
            <token id="6" string="Daniel" />
            <token id="7" string="Freeman" />
            <token id="8" string="Marina" />
            <token id="9" string="Hospital" />
            <token id="10" string="in" />
            <token id="11" string="Marina" />
            <token id="12" string="del" />
            <token id="13" string="Rey" />
            <token id="14" string="on" />
            <token id="15" string="April" />
            <token id="16" string="10" />
            <token id="17" string="suffering" />
            <token id="18" string="what" />
            <token id="19" string="her" />
            <token id="20" string="publicist" />
            <token id="21" string="then" />
            <token id="22" string="described" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
        <chunking id="12" string="described as a `` severe sinus infection" type="VP">
          <tokens>
            <token id="22" string="described" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
        <chunking id="13" string="Marina del Rey" type="NP">
          <tokens>
            <token id="11" string="Marina" />
            <token id="12" string="del" />
            <token id="13" string="Rey" />
          </tokens>
        </chunking>
        <chunking id="14" string="what her publicist then described as a `` severe sinus infection" type="SBAR">
          <tokens>
            <token id="18" string="what" />
            <token id="19" string="her" />
            <token id="20" string="publicist" />
            <token id="21" string="then" />
            <token id="22" string="described" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="&quot;" />
            <token id="26" string="severe" />
            <token id="27" string="sinus" />
            <token id="28" string="infection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">entered</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Taylor</governor>
          <dependent id="3">58</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">entered</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Hospital</governor>
          <dependent id="6">Daniel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Hospital</governor>
          <dependent id="7">Freeman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Hospital</governor>
          <dependent id="8">Marina</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">entered</governor>
          <dependent id="9">Hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Rey</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Rey</governor>
          <dependent id="11">Marina</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Rey</governor>
          <dependent id="12">del</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Hospital</governor>
          <dependent id="13">Rey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">April</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">entered</governor>
          <dependent id="15">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">April</governor>
          <dependent id="16">10</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">April</governor>
          <dependent id="17">suffering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">described</governor>
          <dependent id="18">what</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">publicist</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">described</governor>
          <dependent id="20">publicist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">described</governor>
          <dependent id="21">then</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">suffering</governor>
          <dependent id="22">described</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">infection</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">infection</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">infection</governor>
          <dependent id="26">severe</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">infection</governor>
          <dependent id="27">sinus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">described</governor>
          <dependent id="28">infection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="April 10" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="April" />
            <token id="16" string="10" />
          </tokens>
        </entity>
        <entity id="2" string="58" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="58" />
          </tokens>
        </entity>
        <entity id="3" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="28" string="infection" />
          </tokens>
        </entity>
        <entity id="4" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="5" string="Daniel Freeman" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Daniel" />
            <token id="7" string="Freeman" />
          </tokens>
        </entity>
        <entity id="6" string="Marina Hospital" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Marina" />
            <token id="9" string="Hospital" />
          </tokens>
        </entity>
        <entity id="7" string="Marina del Rey" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Marina" />
            <token id="12" string="del" />
            <token id="13" string="Rey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>She was transferred to St. John&amp;apost;s April 16 when her condition worsened.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="transferred" lemma="transfer" stem="transfer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="worsened" lemma="worsen" stem="worsen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (VP (VBN transferred) (PP (TO to) (NP (NNP St.) (NNP John) (POS 's))) (NP-TMP (NNP April) (CD 16)) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ her) (NN condition)) (VP (VBD worsened)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="St. John 's" type="NP">
          <tokens>
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="worsened" type="VP">
          <tokens>
            <token id="13" string="worsened" />
          </tokens>
        </chunking>
        <chunking id="3" string="transferred to St. John 's April 16 when her condition worsened" type="VP">
          <tokens>
            <token id="3" string="transferred" />
            <token id="4" string="to" />
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="April" />
            <token id="9" string="16" />
            <token id="10" string="when" />
            <token id="11" string="her" />
            <token id="12" string="condition" />
            <token id="13" string="worsened" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="5" string="was transferred to St. John 's April 16 when her condition worsened" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="transferred" />
            <token id="4" string="to" />
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="April" />
            <token id="9" string="16" />
            <token id="10" string="when" />
            <token id="11" string="her" />
            <token id="12" string="condition" />
            <token id="13" string="worsened" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="when her condition worsened" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="her" />
            <token id="12" string="condition" />
            <token id="13" string="worsened" />
          </tokens>
        </chunking>
        <chunking id="8" string="her condition" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="condition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">transferred</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">transferred</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">transferred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">John</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">John</governor>
          <dependent id="5">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">transferred</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">John</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">transferred</governor>
          <dependent id="8">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">April</governor>
          <dependent id="9">16</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">worsened</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">condition</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">worsened</governor>
          <dependent id="12">condition</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">transferred</governor>
          <dependent id="13">worsened</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="St. John" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="St." />
            <token id="6" string="John" />
          </tokens>
        </entity>
        <entity id="2" string="April 16" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="April" />
            <token id="9" string="16" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Dr. Patricia Murray, an infectious disease specialist, said in a statement last week that Taylor had pneumonia and was &amp;quot;being treated intravenously with antibiotics and will remain hospitalized (indefinitely).&amp;quot;</content>
      <tokens>
        <token id="1" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Patricia" lemma="Patricia" stem="patricia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Murray" lemma="Murray" stem="murrai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="8" string="specialist" lemma="specialist" stem="specialist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="treated" lemma="treat" stem="treat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="intravenously" lemma="intravenously" stem="intraven" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="antibiotics" lemma="antibiotic" stem="antibiot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="remain" lemma="remain" stem="remain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="hospitalized" lemma="hospitalize" stem="hospit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="indefinitely" lemma="indefinitely" stem="indefinit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Dr.) (NNP Patricia) (NNP Murray)) (, ,) (NP (DT an) (JJ infectious) (NN disease) (NN specialist)) (, ,)) (VP (VBD said) (PP (IN in) (NP (DT a) (NN statement))) (NP-TMP (JJ last) (NN week)) (SBAR (IN that) (S (NP (NNP Taylor)) (VP (VP (VBD had) (NP (NP (NN pneumonia)) (CC and) (S (VP (VBD was) (`` ``) (VP (VBG being) (VP (VBN treated) (ADVP (RB intravenously)) (PP (IN with) (NP (NNS antibiotics))))))))) (CC and) (VP (MD will) (VP (VB remain) (VP (VBN hospitalized) (PRN (-LRB- -LRB-) (ADVP (RB indefinitely)) (-RRB- -RRB-))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="had pneumonia and was `` being treated intravenously with antibiotics and will remain hospitalized -LRB- indefinitely -RRB-" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="pneumonia" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
            <token id="28" string="and" />
            <token id="29" string="will" />
            <token id="30" string="remain" />
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="a statement" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="statement" />
          </tokens>
        </chunking>
        <chunking id="3" string="will remain hospitalized -LRB- indefinitely -RRB-" type="VP">
          <tokens>
            <token id="29" string="will" />
            <token id="30" string="remain" />
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="being treated intravenously with antibiotics" type="VP">
          <tokens>
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="5" string="Taylor" type="NP">
          <tokens>
            <token id="17" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dr. Patricia Murray , an infectious disease specialist ," type="NP">
          <tokens>
            <token id="1" string="Dr." />
            <token id="2" string="Patricia" />
            <token id="3" string="Murray" />
            <token id="4" string="," />
            <token id="5" string="an" />
            <token id="6" string="infectious" />
            <token id="7" string="disease" />
            <token id="8" string="specialist" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="Dr. Patricia Murray" type="NP">
          <tokens>
            <token id="1" string="Dr." />
            <token id="2" string="Patricia" />
            <token id="3" string="Murray" />
          </tokens>
        </chunking>
        <chunking id="8" string="was `` being treated intravenously with antibiotics" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="9" string="an infectious disease specialist" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="infectious" />
            <token id="7" string="disease" />
            <token id="8" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="10" string="hospitalized -LRB- indefinitely -RRB-" type="VP">
          <tokens>
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="11" string="said in a statement last week that Taylor had pneumonia and was `` being treated intravenously with antibiotics and will remain hospitalized -LRB- indefinitely -RRB-" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="statement" />
            <token id="14" string="last" />
            <token id="15" string="week" />
            <token id="16" string="that" />
            <token id="17" string="Taylor" />
            <token id="18" string="had" />
            <token id="19" string="pneumonia" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
            <token id="28" string="and" />
            <token id="29" string="will" />
            <token id="30" string="remain" />
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="12" string="treated intravenously with antibiotics" type="VP">
          <tokens>
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="13" string="that Taylor had pneumonia and was `` being treated intravenously with antibiotics and will remain hospitalized -LRB- indefinitely -RRB-" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="Taylor" />
            <token id="18" string="had" />
            <token id="19" string="pneumonia" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
            <token id="28" string="and" />
            <token id="29" string="will" />
            <token id="30" string="remain" />
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="pneumonia" type="NP">
          <tokens>
            <token id="19" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="15" string="remain hospitalized -LRB- indefinitely -RRB-" type="VP">
          <tokens>
            <token id="30" string="remain" />
            <token id="31" string="hospitalized" />
            <token id="32" string="(" />
            <token id="33" string="indefinitely" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="16" string="pneumonia and was `` being treated intravenously with antibiotics" type="NP">
          <tokens>
            <token id="19" string="pneumonia" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="17" string="antibiotics" type="NP">
          <tokens>
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="18" string="had pneumonia and was `` being treated intravenously with antibiotics" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="pneumonia" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="&quot;" />
            <token id="23" string="being" />
            <token id="24" string="treated" />
            <token id="25" string="intravenously" />
            <token id="26" string="with" />
            <token id="27" string="antibiotics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Murray</governor>
          <dependent id="1">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Murray</governor>
          <dependent id="2">Patricia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="3">Murray</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">specialist</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">specialist</governor>
          <dependent id="6">infectious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">specialist</governor>
          <dependent id="7">disease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Murray</governor>
          <dependent id="8">specialist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">statement</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">statement</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">said</governor>
          <dependent id="13">statement</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">week</governor>
          <dependent id="14">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">said</governor>
          <dependent id="15">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">had</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">had</governor>
          <dependent id="17">Taylor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">had</governor>
          <dependent id="19">pneumonia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">pneumonia</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">treated</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">treated</governor>
          <dependent id="23">being</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">pneumonia</governor>
          <dependent id="24">treated</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">treated</governor>
          <dependent id="25">intravenously</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">antibiotics</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">treated</governor>
          <dependent id="27">antibiotics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">had</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">remain</governor>
          <dependent id="29">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">had</governor>
          <dependent id="30">remain</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">remain</governor>
          <dependent id="31">hospitalized</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">hospitalized</governor>
          <dependent id="33">indefinitely</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Patricia Murray" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Patricia" />
            <token id="3" string="Murray" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Taylor" />
          </tokens>
        </entity>
        <entity id="4" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="last" />
            <token id="15" string="week" />
          </tokens>
        </entity>
        <entity id="5" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="pneumonia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Taylor has been plagued with health problems for years, particularly recurring back troubles that began with a fall from a horse during filming of the 1945 movie &amp;quot;National Velvet.&amp;quot;</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="plagued" lemma="plague" stem="plagu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="particularly" lemma="particularly" stem="particularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="recurring" lemma="recur" stem="recur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="troubles" lemma="trouble" stem="troubl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="horse" lemma="horse" stem="hors" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="filming" lemma="film" stem="film" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="1945" lemma="1945" stem="1945" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="31" string="Velvet" lemma="Velvet" stem="velvet" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Taylor)) (VP (VBZ has) (VP (VBN been) (VP (VBN plagued) (PP (IN with) (NP (NP (NN health) (NNS problems)) (PP (IN for) (NP (NNS years))))) (, ,) (S (ADVP (RB particularly)) (VP (VBG recurring) (PRT (RB back)) (NP (NP (NNS troubles)) (SBAR (WHNP (WDT that)) (S (VP (VBD began) (PP (IN with) (NP (DT a) (NN fall))) (PP (IN from) (NP (DT a) (NN horse))))))) (PP (IN during) (S (VP (VBG filming) (PP (IN of) (NP (NP (DT the) (CD 1945) (NN movie)) (`` ``) (NP (NNP National) (NNP Velvet)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="troubles that began with a fall from a horse" type="NP">
          <tokens>
            <token id="14" string="troubles" />
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
          </tokens>
        </chunking>
        <chunking id="2" string="a fall" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="fall" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="4" string="health problems for years" type="NP">
          <tokens>
            <token id="6" string="health" />
            <token id="7" string="problems" />
            <token id="8" string="for" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been plagued with health problems for years , particularly recurring back troubles that began with a fall from a horse during filming of the 1945 movie `` National Velvet" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="plagued" />
            <token id="5" string="with" />
            <token id="6" string="health" />
            <token id="7" string="problems" />
            <token id="8" string="for" />
            <token id="9" string="years" />
            <token id="10" string="," />
            <token id="11" string="particularly" />
            <token id="12" string="recurring" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
            <token id="23" string="during" />
            <token id="24" string="filming" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="6" string="that began with a fall from a horse" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
          </tokens>
        </chunking>
        <chunking id="7" string="began with a fall from a horse" type="VP">
          <tokens>
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
          </tokens>
        </chunking>
        <chunking id="8" string="troubles" type="NP">
          <tokens>
            <token id="14" string="troubles" />
          </tokens>
        </chunking>
        <chunking id="9" string="plagued with health problems for years , particularly recurring back troubles that began with a fall from a horse during filming of the 1945 movie `` National Velvet" type="VP">
          <tokens>
            <token id="4" string="plagued" />
            <token id="5" string="with" />
            <token id="6" string="health" />
            <token id="7" string="problems" />
            <token id="8" string="for" />
            <token id="9" string="years" />
            <token id="10" string="," />
            <token id="11" string="particularly" />
            <token id="12" string="recurring" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
            <token id="23" string="during" />
            <token id="24" string="filming" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="10" string="years" type="NP">
          <tokens>
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="the 1945 movie `` National Velvet" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 1945 movie" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
          </tokens>
        </chunking>
        <chunking id="13" string="filming of the 1945 movie `` National Velvet" type="VP">
          <tokens>
            <token id="24" string="filming" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="14" string="recurring back troubles that began with a fall from a horse during filming of the 1945 movie `` National Velvet" type="VP">
          <tokens>
            <token id="12" string="recurring" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
            <token id="23" string="during" />
            <token id="24" string="filming" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="15" string="a horse" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="horse" />
          </tokens>
        </chunking>
        <chunking id="16" string="National Velvet" type="NP">
          <tokens>
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="17" string="health problems" type="NP">
          <tokens>
            <token id="6" string="health" />
            <token id="7" string="problems" />
          </tokens>
        </chunking>
        <chunking id="18" string="been plagued with health problems for years , particularly recurring back troubles that began with a fall from a horse during filming of the 1945 movie `` National Velvet" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="plagued" />
            <token id="5" string="with" />
            <token id="6" string="health" />
            <token id="7" string="problems" />
            <token id="8" string="for" />
            <token id="9" string="years" />
            <token id="10" string="," />
            <token id="11" string="particularly" />
            <token id="12" string="recurring" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="that" />
            <token id="16" string="began" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="fall" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="horse" />
            <token id="23" string="during" />
            <token id="24" string="filming" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="1945" />
            <token id="28" string="movie" />
            <token id="29" string="&quot;" />
            <token id="30" string="National" />
            <token id="31" string="Velvet" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">plagued</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">plagued</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">plagued</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">plagued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">problems</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">problems</governor>
          <dependent id="6">health</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">plagued</governor>
          <dependent id="7">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">years</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">problems</governor>
          <dependent id="9">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">recurring</governor>
          <dependent id="11">particularly</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">plagued</governor>
          <dependent id="12">recurring</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">recurring</governor>
          <dependent id="13">back</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">recurring</governor>
          <dependent id="14">troubles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">began</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">troubles</governor>
          <dependent id="16">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">fall</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">fall</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">began</governor>
          <dependent id="19">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">horse</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">horse</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">began</governor>
          <dependent id="22">horse</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">filming</governor>
          <dependent id="23">during</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">recurring</governor>
          <dependent id="24">filming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">movie</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">movie</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">movie</governor>
          <dependent id="27">1945</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">filming</governor>
          <dependent id="28">movie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Velvet</governor>
          <dependent id="30">National</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">movie</governor>
          <dependent id="31">Velvet</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="fall" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="fall" />
          </tokens>
        </entity>
        <entity id="3" string="National" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="30" string="National" />
          </tokens>
        </entity>
        <entity id="4" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="1945" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="1945" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>In 1983, she acknowledged a 35-year addiction to sleeping pills and painkillers prescribed for a wide range of health problems.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="acknowledged" lemma="acknowledge" stem="acknowledg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="35-year" lemma="35-year" stem="35-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="sleeping" lemma="sleep" stem="sleep" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="pills" lemma="pill" stem="pill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="painkillers" lemma="painkiller" stem="painkil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="prescribed" lemma="prescribe" stem="prescrib" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wide" lemma="wide" stem="wide" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="range" lemma="range" stem="rang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1983))) (, ,) (NP (PRP she)) (VP (VBD acknowledged) (NP (DT a) (JJ 35-year) (NN addiction)) (PP (TO to) (NP (NP (VBG sleeping) (NNS pills) (CC and) (NNS painkillers)) (VP (VBN prescribed) (PP (IN for) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NN health) (NNS problems))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1983" type="NP">
          <tokens>
            <token id="2" string="1983" />
          </tokens>
        </chunking>
        <chunking id="2" string="prescribed for a wide range of health problems" type="VP">
          <tokens>
            <token id="14" string="prescribed" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="wide" />
            <token id="18" string="range" />
            <token id="19" string="of" />
            <token id="20" string="health" />
            <token id="21" string="problems" />
          </tokens>
        </chunking>
        <chunking id="3" string="sleeping pills and painkillers" type="NP">
          <tokens>
            <token id="10" string="sleeping" />
            <token id="11" string="pills" />
            <token id="12" string="and" />
            <token id="13" string="painkillers" />
          </tokens>
        </chunking>
        <chunking id="4" string="sleeping pills and painkillers prescribed for a wide range of health problems" type="NP">
          <tokens>
            <token id="10" string="sleeping" />
            <token id="11" string="pills" />
            <token id="12" string="and" />
            <token id="13" string="painkillers" />
            <token id="14" string="prescribed" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="wide" />
            <token id="18" string="range" />
            <token id="19" string="of" />
            <token id="20" string="health" />
            <token id="21" string="problems" />
          </tokens>
        </chunking>
        <chunking id="5" string="a wide range of health problems" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="wide" />
            <token id="18" string="range" />
            <token id="19" string="of" />
            <token id="20" string="health" />
            <token id="21" string="problems" />
          </tokens>
        </chunking>
        <chunking id="6" string="a wide range" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="wide" />
            <token id="18" string="range" />
          </tokens>
        </chunking>
        <chunking id="7" string="a 35-year addiction" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="35-year" />
            <token id="8" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="8" string="health problems" type="NP">
          <tokens>
            <token id="20" string="health" />
            <token id="21" string="problems" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="acknowledged a 35-year addiction to sleeping pills and painkillers prescribed for a wide range of health problems" type="VP">
          <tokens>
            <token id="5" string="acknowledged" />
            <token id="6" string="a" />
            <token id="7" string="35-year" />
            <token id="8" string="addiction" />
            <token id="9" string="to" />
            <token id="10" string="sleeping" />
            <token id="11" string="pills" />
            <token id="12" string="and" />
            <token id="13" string="painkillers" />
            <token id="14" string="prescribed" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="wide" />
            <token id="18" string="range" />
            <token id="19" string="of" />
            <token id="20" string="health" />
            <token id="21" string="problems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1983</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">acknowledged</governor>
          <dependent id="2">1983</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">acknowledged</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">acknowledged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">addiction</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">addiction</governor>
          <dependent id="7">35-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">acknowledged</governor>
          <dependent id="8">addiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">pills</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">pills</governor>
          <dependent id="10">sleeping</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">acknowledged</governor>
          <dependent id="11">pills</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">pills</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">pills</governor>
          <dependent id="13">painkillers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">pills</governor>
          <dependent id="14">prescribed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">range</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">range</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">range</governor>
          <dependent id="17">wide</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">prescribed</governor>
          <dependent id="18">range</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">problems</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">problems</governor>
          <dependent id="20">health</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">range</governor>
          <dependent id="21">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="35-year" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="35-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Taylor has been treated for alcohol and drug abuse problems at the Betty Ford Clinic.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="treated" lemma="treat" stem="treat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="alcohol" lemma="alcohol" stem="alcohol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Clinic" lemma="Clinic" stem="clinic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Taylor)) (VP (VBZ has) (VP (VBN been) (VP (VBN treated) (PP (IN for) (NP (UCP (NN alcohol) (CC and) (NN drug)) (NN abuse) (NNS problems))) (PP (IN at) (NP (DT the) (NNP Betty) (NNP Ford) (NNP Clinic)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="alcohol and drug abuse problems" type="NP">
          <tokens>
            <token id="6" string="alcohol" />
            <token id="7" string="and" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
            <token id="10" string="problems" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="3" string="been treated for alcohol and drug abuse problems at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="treated" />
            <token id="5" string="for" />
            <token id="6" string="alcohol" />
            <token id="7" string="and" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
            <token id="10" string="problems" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="4" string="has been treated for alcohol and drug abuse problems at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="treated" />
            <token id="5" string="for" />
            <token id="6" string="alcohol" />
            <token id="7" string="and" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
            <token id="10" string="problems" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Betty Ford Clinic" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="6" string="treated for alcohol and drug abuse problems at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="4" string="treated" />
            <token id="5" string="for" />
            <token id="6" string="alcohol" />
            <token id="7" string="and" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
            <token id="10" string="problems" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">treated</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">treated</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">treated</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">treated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">problems</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">problems</governor>
          <dependent id="6">alcohol</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">alcohol</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">alcohol</governor>
          <dependent id="8">drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">problems</governor>
          <dependent id="9">abuse</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">treated</governor>
          <dependent id="10">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Clinic</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Clinic</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Clinic</governor>
          <dependent id="13">Betty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Clinic</governor>
          <dependent id="14">Ford</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">treated</governor>
          <dependent id="15">Clinic</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Betty Ford Clinic" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="Elizabeth Taylor" id_sentence="1" />
      <mentions>
        <mention ids_tokens="19" string="her" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10" string="a precautionary step in this case" id_sentence="21" />
      <mentions>
        <mention ids_tokens="9-10" string="a ventilator" id_sentence="1" />
        <mention ids_tokens="12-13" string="a ventilator" id_sentence="4" />
        <mention ids_tokens="15-16" string="a ventilator" id_sentence="16" />
        <mention ids_tokens="4-5" string="a ventilator" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25-26-27-28" string="the cause of pneumonia that has kept her hospitalized for three weeks" id_sentence="1" />
      <mentions>
        <mention ids_tokens="16-20" string="the cause of her pneumonia" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="30-31" string="her physicians" id_sentence="1" />
      <mentions>
        <mention ids_tokens="23-25" string="the physicians'" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="The Academy Award-winning actress" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="She" id_sentence="3" />
        <mention ids_tokens="5" string="her" id_sentence="4" />
        <mention ids_tokens="2" string="Her" id_sentence="5" />
        <mention ids_tokens="9" string="her" id_sentence="5" />
        <mention ids_tokens="14" string="her" id_sentence="5" />
        <mention ids_tokens="14-15" string="the actress" id_sentence="7" />
        <mention ids_tokens="5-6" string="the actress" id_sentence="11" />
        <mention ids_tokens="9" string="I" id_sentence="15" />
        <mention ids_tokens="12" string="she" id_sentence="15" />
        <mention ids_tokens="13" string="her" id_sentence="16" />
        <mention ids_tokens="1" string="She" id_sentence="17" />
        <mention ids_tokens="9-11" string="the actress's" id_sentence="19" />
        <mention ids_tokens="21" string="her" id_sentence="19" />
        <mention ids_tokens="2" string="her" id_sentence="20" />
        <mention ids_tokens="18" string="she" id_sentence="20" />
        <mention ids_tokens="19" string="her" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13-14" string="St. John 's Hospital in Santa Monica" id_sentence="2" />
      <mentions>
        <mention ids_tokens="24-25" string="the hospital" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="20-21" string="the pneumonia" id_sentence="2" />
      <mentions>
        <mention ids_tokens="19-20" string="her pneumonia" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="a lung biopsy" id_sentence="3" />
      <mentions>
        <mention ids_tokens="9-10" string="the biopsy" id_sentence="9" />
        <mention ids_tokens="4-5" string="the biopsy" id_sentence="14" />
        <mention ids_tokens="7" string="that" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26" string="the physicians ' statement" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-2" string="The statement" id_sentence="6" />
        <mention ids_tokens="19-20" string="the statement" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="8-9" string="Taylor 's" id_sentence="6" />
      <mentions>
        <mention ids_tokens="11" string="Taylor" id_sentence="7" />
        <mention ids_tokens="1-3" string="Taylor , 58" id_sentence="22" />
        <mention ids_tokens="1" string="Taylor" id_sentence="22" />
        <mention ids_tokens="17" string="Taylor" id_sentence="24" />
        <mention ids_tokens="1" string="Taylor" id_sentence="25" />
        <mention ids_tokens="1" string="Taylor" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="13-14" string="hospital officials" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="We" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Lisa del Favero" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1-2" string="Del Favero" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11" string="a New York City publicist for Taylor" id_sentence="7" />
      <mentions>
        <mention ids_tokens="14" string="she" id_sentence="9" />
        <mention ids_tokens="19-20" string="her publicist" id_sentence="22" />
        <mention ids_tokens="1" string="She" id_sentence="23" />
        <mention ids_tokens="11" string="her" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="42-43-44" string="John G. Mohler" id_sentence="11" />
      <mentions>
        <mention ids_tokens="29" string="Mohler" id_sentence="12" />
        <mention ids_tokens="2" string="You" id_sentence="14" />
        <mention ids_tokens="10" string="your" id_sentence="14" />
        <mention ids_tokens="1" string="Mohler" id_sentence="16" />
        <mention ids_tokens="12" string="Mohler" id_sentence="17" />
        <mention ids_tokens="3" string="he" id_sentence="19" />
        <mention ids_tokens="14" string="Mohler" id_sentence="19" />
        <mention ids_tokens="16" string="he" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="24" type="PRONOMINAL">
      <referenced ids_tokens="3" string="you" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2-7" string="they ( took a biopsy )" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7" string="a near-fatal bout of pneumonia" id_sentence="17" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="29" type="PRONOMINAL">
      <referenced ids_tokens="25" string="her" id_sentence="17" />
      <mentions>
        <mention ids_tokens="2" string="she" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="the actress 's case" id_sentence="19" />
      <mentions>
        <mention ids_tokens="9-10" string="this case" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="2-3" string="Patricia Murray" id_sentence="24" />
      <mentions>
        <mention ids_tokens="4" string="she" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="health problems for years" id_sentence="25" />
      <mentions>
        <mention ids_tokens="20-21" string="health problems" id_sentence="26" />
      </mentions>
    </coreference>
  </coreferences>
</document>
