<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA080790-0111">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>As they scanned the flow of passengers at Los Angeles International Airport, police detective Clayton Searle and his fellow narcotics officer searched for the likely companion of the suspected drug courier who stood handcuffed nearby.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="scanned" lemma="scan" stem="scan" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="flow" lemma="flow" stem="flow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Airport" lemma="Airport" stem="airport" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="detective" lemma="detective" stem="detect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Clayton" lemma="Clayton" stem="clayton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="fellow" lemma="fellow" stem="fellow" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="searched" lemma="search" stem="search" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="companion" lemma="companion" stem="companion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="handcuffed" lemma="handcuff" stem="handcuf" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="nearby" lemma="nearby" stem="nearbi" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (PRP they)) (VP (VBD scanned) (NP (NP (DT the) (NN flow)) (PP (IN of) (NP (NNS passengers)))) (PP (IN at) (NP (NNP Los) (NNP Angeles) (NNP International) (NNP Airport)))))) (, ,) (NP (NP (NN police) (NN detective) (NNP Clayton) (NNP Searle)) (CC and) (NP (PRP$ his) (JJ fellow) (NNS narcotics) (NN officer))) (VP (VBD searched) (PP (IN for) (NP (NP (DT the) (JJ likely) (NN companion)) (PP (IN of) (NP (NP (DT the) (VBN suspected) (NN drug) (NN courier)) (SBAR (WHNP (WP who)) (S (VP (VBD stood) (S (ADJP (VBN handcuffed))) (ADVP (RB nearby)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the flow" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="flow" />
          </tokens>
        </chunking>
        <chunking id="2" string="passengers" type="NP">
          <tokens>
            <token id="7" string="passengers" />
          </tokens>
        </chunking>
        <chunking id="3" string="the suspected drug courier" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="suspected" />
            <token id="31" string="drug" />
            <token id="32" string="courier" />
          </tokens>
        </chunking>
        <chunking id="4" string="police detective Clayton Searle and his fellow narcotics officer" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="detective" />
            <token id="16" string="Clayton" />
            <token id="17" string="Searle" />
            <token id="18" string="and" />
            <token id="19" string="his" />
            <token id="20" string="fellow" />
            <token id="21" string="narcotics" />
            <token id="22" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="stood handcuffed nearby" type="VP">
          <tokens>
            <token id="34" string="stood" />
            <token id="35" string="handcuffed" />
            <token id="36" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="police detective Clayton Searle" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="detective" />
            <token id="16" string="Clayton" />
            <token id="17" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="8" string="the flow of passengers" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="flow" />
            <token id="6" string="of" />
            <token id="7" string="passengers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the likely companion of the suspected drug courier who stood handcuffed nearby" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="likely" />
            <token id="27" string="companion" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="suspected" />
            <token id="31" string="drug" />
            <token id="32" string="courier" />
            <token id="33" string="who" />
            <token id="34" string="stood" />
            <token id="35" string="handcuffed" />
            <token id="36" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="10" string="As they scanned the flow of passengers at Los Angeles International Airport" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="they" />
            <token id="3" string="scanned" />
            <token id="4" string="the" />
            <token id="5" string="flow" />
            <token id="6" string="of" />
            <token id="7" string="passengers" />
            <token id="8" string="at" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="International" />
            <token id="12" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="11" string="searched for the likely companion of the suspected drug courier who stood handcuffed nearby" type="VP">
          <tokens>
            <token id="23" string="searched" />
            <token id="24" string="for" />
            <token id="25" string="the" />
            <token id="26" string="likely" />
            <token id="27" string="companion" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="suspected" />
            <token id="31" string="drug" />
            <token id="32" string="courier" />
            <token id="33" string="who" />
            <token id="34" string="stood" />
            <token id="35" string="handcuffed" />
            <token id="36" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="12" string="Los Angeles International Airport" type="NP">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="International" />
            <token id="12" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="13" string="the likely companion" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="likely" />
            <token id="27" string="companion" />
          </tokens>
        </chunking>
        <chunking id="14" string="who stood handcuffed nearby" type="SBAR">
          <tokens>
            <token id="33" string="who" />
            <token id="34" string="stood" />
            <token id="35" string="handcuffed" />
            <token id="36" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="15" string="handcuffed" type="ADJP">
          <tokens>
            <token id="35" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="16" string="his fellow narcotics officer" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="fellow" />
            <token id="21" string="narcotics" />
            <token id="22" string="officer" />
          </tokens>
        </chunking>
        <chunking id="17" string="scanned the flow of passengers at Los Angeles International Airport" type="VP">
          <tokens>
            <token id="3" string="scanned" />
            <token id="4" string="the" />
            <token id="5" string="flow" />
            <token id="6" string="of" />
            <token id="7" string="passengers" />
            <token id="8" string="at" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="International" />
            <token id="12" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="18" string="the suspected drug courier who stood handcuffed nearby" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="suspected" />
            <token id="31" string="drug" />
            <token id="32" string="courier" />
            <token id="33" string="who" />
            <token id="34" string="stood" />
            <token id="35" string="handcuffed" />
            <token id="36" string="nearby" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">scanned</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">scanned</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">searched</governor>
          <dependent id="3">scanned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">flow</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">scanned</governor>
          <dependent id="5">flow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">passengers</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">flow</governor>
          <dependent id="7">passengers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Airport</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Airport</governor>
          <dependent id="9">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Airport</governor>
          <dependent id="10">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Airport</governor>
          <dependent id="11">International</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">scanned</governor>
          <dependent id="12">Airport</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Searle</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Searle</governor>
          <dependent id="15">detective</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Searle</governor>
          <dependent id="16">Clayton</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">searched</governor>
          <dependent id="17">Searle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Searle</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">officer</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">officer</governor>
          <dependent id="20">fellow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">officer</governor>
          <dependent id="21">narcotics</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Searle</governor>
          <dependent id="22">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">searched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">companion</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">companion</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">companion</governor>
          <dependent id="26">likely</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">searched</governor>
          <dependent id="27">companion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">courier</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">courier</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">courier</governor>
          <dependent id="30">suspected</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">courier</governor>
          <dependent id="31">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">companion</governor>
          <dependent id="32">courier</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">stood</governor>
          <dependent id="33">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">courier</governor>
          <dependent id="34">stood</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">stood</governor>
          <dependent id="35">handcuffed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">stood</governor>
          <dependent id="36">nearby</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles International Airport" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="International" />
            <token id="12" string="Airport" />
          </tokens>
        </entity>
        <entity id="2" string="Clayton Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Clayton" />
            <token id="17" string="Searle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>When Searle noticed a short, muscular black man walk toward them and then turn abruptly toward a bank of telephones, the plainclothes Los Angeles police detective moved in quickly to question him.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="noticed" lemma="notice" stem="notic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="muscular" lemma="muscular" stem="muscular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="walk" lemma="walk" stem="walk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="abruptly" lemma="abruptly" stem="abruptli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bank" lemma="bank" stem="bank" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="telephones" lemma="telephone" stem="telephon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="plainclothes" lemma="plainclothes" stem="plaincloth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="26" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="27" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="detective" lemma="detective" stem="detect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="question" lemma="question" stem="question" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NNP Searle)) (VP (VP (VBD noticed) (NP (NP (DT a) (JJ short) (, ,) (JJ muscular) (JJ black) (NN man) (NN walk)) (PP (IN toward) (NP (PRP them))))) (CC and) (RB then) (VP (VB turn) (ADVP (RB abruptly)) (PP (IN toward) (NP (NP (DT a) (NN bank)) (PP (IN of) (NP (NNS telephones))))))))) (, ,) (NP (NP (DT the) (NNS plainclothes)) (NP (NNP Los) (NNP Angeles) (NN police) (NN detective))) (VP (VBD moved) (ADVP (RB in)) (ADVP (RB quickly)) (S (VP (TO to) (VP (VB question) (NP (PRP him)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Searle" type="NP">
          <tokens>
            <token id="2" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="2" string="a short , muscular black man walk toward them" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="short" />
            <token id="6" string="," />
            <token id="7" string="muscular" />
            <token id="8" string="black" />
            <token id="9" string="man" />
            <token id="10" string="walk" />
            <token id="11" string="toward" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="telephones" type="NP">
          <tokens>
            <token id="21" string="telephones" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="to question him" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="question" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="When Searle noticed a short , muscular black man walk toward them and then turn abruptly toward a bank of telephones" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Searle" />
            <token id="3" string="noticed" />
            <token id="4" string="a" />
            <token id="5" string="short" />
            <token id="6" string="," />
            <token id="7" string="muscular" />
            <token id="8" string="black" />
            <token id="9" string="man" />
            <token id="10" string="walk" />
            <token id="11" string="toward" />
            <token id="12" string="them" />
            <token id="13" string="and" />
            <token id="14" string="then" />
            <token id="15" string="turn" />
            <token id="16" string="abruptly" />
            <token id="17" string="toward" />
            <token id="18" string="a" />
            <token id="19" string="bank" />
            <token id="20" string="of" />
            <token id="21" string="telephones" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="a bank" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="bank" />
          </tokens>
        </chunking>
        <chunking id="9" string="noticed a short , muscular black man walk toward them" type="VP">
          <tokens>
            <token id="3" string="noticed" />
            <token id="4" string="a" />
            <token id="5" string="short" />
            <token id="6" string="," />
            <token id="7" string="muscular" />
            <token id="8" string="black" />
            <token id="9" string="man" />
            <token id="10" string="walk" />
            <token id="11" string="toward" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="11" string="a short , muscular black man walk" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="short" />
            <token id="6" string="," />
            <token id="7" string="muscular" />
            <token id="8" string="black" />
            <token id="9" string="man" />
            <token id="10" string="walk" />
          </tokens>
        </chunking>
        <chunking id="12" string="turn abruptly toward a bank of telephones" type="VP">
          <tokens>
            <token id="15" string="turn" />
            <token id="16" string="abruptly" />
            <token id="17" string="toward" />
            <token id="18" string="a" />
            <token id="19" string="bank" />
            <token id="20" string="of" />
            <token id="21" string="telephones" />
          </tokens>
        </chunking>
        <chunking id="13" string="the plainclothes" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="plainclothes" />
          </tokens>
        </chunking>
        <chunking id="14" string="moved in quickly to question him" type="VP">
          <tokens>
            <token id="29" string="moved" />
            <token id="30" string="in" />
            <token id="31" string="quickly" />
            <token id="32" string="to" />
            <token id="33" string="question" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="question him" type="VP">
          <tokens>
            <token id="33" string="question" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="a bank of telephones" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="bank" />
            <token id="20" string="of" />
            <token id="21" string="telephones" />
          </tokens>
        </chunking>
        <chunking id="17" string="Los Angeles police detective" type="NP">
          <tokens>
            <token id="25" string="Los" />
            <token id="26" string="Angeles" />
            <token id="27" string="police" />
            <token id="28" string="detective" />
          </tokens>
        </chunking>
        <chunking id="18" string="noticed a short , muscular black man walk toward them and then turn abruptly toward a bank of telephones" type="VP">
          <tokens>
            <token id="3" string="noticed" />
            <token id="4" string="a" />
            <token id="5" string="short" />
            <token id="6" string="," />
            <token id="7" string="muscular" />
            <token id="8" string="black" />
            <token id="9" string="man" />
            <token id="10" string="walk" />
            <token id="11" string="toward" />
            <token id="12" string="them" />
            <token id="13" string="and" />
            <token id="14" string="then" />
            <token id="15" string="turn" />
            <token id="16" string="abruptly" />
            <token id="17" string="toward" />
            <token id="18" string="a" />
            <token id="19" string="bank" />
            <token id="20" string="of" />
            <token id="21" string="telephones" />
          </tokens>
        </chunking>
        <chunking id="19" string="the plainclothes Los Angeles police detective" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="plainclothes" />
            <token id="25" string="Los" />
            <token id="26" string="Angeles" />
            <token id="27" string="police" />
            <token id="28" string="detective" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">noticed</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">noticed</governor>
          <dependent id="2">Searle</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">moved</governor>
          <dependent id="3">noticed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">walk</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">walk</governor>
          <dependent id="5">short</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">walk</governor>
          <dependent id="7">muscular</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">walk</governor>
          <dependent id="8">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">walk</governor>
          <dependent id="9">man</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">noticed</governor>
          <dependent id="10">walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">them</governor>
          <dependent id="11">toward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">walk</governor>
          <dependent id="12">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">noticed</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">turn</governor>
          <dependent id="14">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">noticed</governor>
          <dependent id="15">turn</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">turn</governor>
          <dependent id="16">abruptly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">bank</governor>
          <dependent id="17">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">bank</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">turn</governor>
          <dependent id="19">bank</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">telephones</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">bank</governor>
          <dependent id="21">telephones</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">plainclothes</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">moved</governor>
          <dependent id="24">plainclothes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">detective</governor>
          <dependent id="25">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">detective</governor>
          <dependent id="26">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">detective</governor>
          <dependent id="27">police</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">plainclothes</governor>
          <dependent id="28">detective</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">moved</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">moved</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">moved</governor>
          <dependent id="31">quickly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">question</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">moved</governor>
          <dependent id="33">question</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">question</governor>
          <dependent id="34">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Los" />
            <token id="26" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Within minutes, however, their words had turned into violence, and the two men toppled to the terminal floor where Searle handcuffed his suspect and pulled him to his feet.</content>
      <tokens>
        <token id="1" string="Within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="toppled" lemma="topple" stem="toppl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="terminal" lemma="terminal" stem="termin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="floor" lemma="floor" stem="floor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="handcuffed" lemma="handcuff" stem="handcuf" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="pulled" lemma="pull" stem="pull" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Within) (NP (NNS minutes))) (, ,) (S (ADVP (RB however)) (, ,) (NP (PRP$ their) (NNS words)) (VP (VBD had) (VP (VBN turned) (PP (IN into) (NP (NN violence)))))) (, ,) (CC and) (S (NP (DT the) (CD two) (NNS men)) (VP (VBD toppled) (PP (TO to) (NP (DT the) (JJ terminal) (NN floor))) (SBAR (WHADVP (WRB where)) (S (NP (NNP Searle)) (VP (VP (VBD handcuffed) (NP (PRP$ his) (NN suspect))) (CC and) (VP (VBD pulled) (NP (PRP him)) (PP (TO to) (NP (PRP$ his) (NNS feet))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his suspect" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="had turned into violence" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="turned" />
            <token id="10" string="into" />
            <token id="11" string="violence" />
          </tokens>
        </chunking>
        <chunking id="3" string="his feet" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="feet" />
          </tokens>
        </chunking>
        <chunking id="4" string="Searle" type="NP">
          <tokens>
            <token id="23" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="5" string="toppled to the terminal floor where Searle handcuffed his suspect and pulled him to his feet" type="VP">
          <tokens>
            <token id="17" string="toppled" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="terminal" />
            <token id="21" string="floor" />
            <token id="22" string="where" />
            <token id="23" string="Searle" />
            <token id="24" string="handcuffed" />
            <token id="25" string="his" />
            <token id="26" string="suspect" />
            <token id="27" string="and" />
            <token id="28" string="pulled" />
            <token id="29" string="him" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="feet" />
          </tokens>
        </chunking>
        <chunking id="6" string="minutes" type="NP">
          <tokens>
            <token id="2" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="7" string="handcuffed his suspect and pulled him to his feet" type="VP">
          <tokens>
            <token id="24" string="handcuffed" />
            <token id="25" string="his" />
            <token id="26" string="suspect" />
            <token id="27" string="and" />
            <token id="28" string="pulled" />
            <token id="29" string="him" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="feet" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="29" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="handcuffed his suspect" type="VP">
          <tokens>
            <token id="24" string="handcuffed" />
            <token id="25" string="his" />
            <token id="26" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="10" string="where Searle handcuffed his suspect and pulled him to his feet" type="SBAR">
          <tokens>
            <token id="22" string="where" />
            <token id="23" string="Searle" />
            <token id="24" string="handcuffed" />
            <token id="25" string="his" />
            <token id="26" string="suspect" />
            <token id="27" string="and" />
            <token id="28" string="pulled" />
            <token id="29" string="him" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="feet" />
          </tokens>
        </chunking>
        <chunking id="11" string="their words" type="NP">
          <tokens>
            <token id="6" string="their" />
            <token id="7" string="words" />
          </tokens>
        </chunking>
        <chunking id="12" string="turned into violence" type="VP">
          <tokens>
            <token id="9" string="turned" />
            <token id="10" string="into" />
            <token id="11" string="violence" />
          </tokens>
        </chunking>
        <chunking id="13" string="where" type="WHADVP">
          <tokens>
            <token id="22" string="where" />
          </tokens>
        </chunking>
        <chunking id="14" string="violence" type="NP">
          <tokens>
            <token id="11" string="violence" />
          </tokens>
        </chunking>
        <chunking id="15" string="the two men" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="two" />
            <token id="16" string="men" />
          </tokens>
        </chunking>
        <chunking id="16" string="the terminal floor" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="terminal" />
            <token id="21" string="floor" />
          </tokens>
        </chunking>
        <chunking id="17" string="pulled him to his feet" type="VP">
          <tokens>
            <token id="28" string="pulled" />
            <token id="29" string="him" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="feet" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">minutes</governor>
          <dependent id="1">Within</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">turned</governor>
          <dependent id="2">minutes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">turned</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">words</governor>
          <dependent id="6">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">turned</governor>
          <dependent id="7">words</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">turned</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">turned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">violence</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">turned</governor>
          <dependent id="11">violence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">turned</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">men</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">men</governor>
          <dependent id="15">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">toppled</governor>
          <dependent id="16">men</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">turned</governor>
          <dependent id="17">toppled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">floor</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">floor</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">floor</governor>
          <dependent id="20">terminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">toppled</governor>
          <dependent id="21">floor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">handcuffed</governor>
          <dependent id="22">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">handcuffed</governor>
          <dependent id="23">Searle</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">toppled</governor>
          <dependent id="24">handcuffed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">suspect</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">handcuffed</governor>
          <dependent id="26">suspect</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">handcuffed</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">handcuffed</governor>
          <dependent id="28">pulled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">pulled</governor>
          <dependent id="29">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">feet</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">feet</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">pulled</governor>
          <dependent id="32">feet</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="minutes" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Placing his hand across the man&amp;apost;s mouth, the officer then marched him away before a gathering crowd of gaping passersby.</content>
      <tokens>
        <token id="1" string="Placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mouth" lemma="mouth" stem="mouth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="marched" lemma="march" stem="march" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="away" lemma="away" stem="awai" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="gathering" lemma="gathering" stem="gather" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="crowd" lemma="crowd" stem="crowd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="gaping" lemma="gaping" stem="gape" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="passersby" lemma="passersby" stem="passersbi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Placing) (NP (PRP$ his) (NN hand)) (PP (IN across) (NP (NP (DT the) (NN man) (POS 's)) (NN mouth))))) (, ,) (NP (DT the) (NN officer)) (ADVP (RB then)) (VP (VBD marched) (NP (PRP him)) (PRT (RP away)) (PP (IN before) (NP (NP (DT a) (NN gathering) (NN crowd)) (PP (IN of) (NP (JJ gaping) (NNS passersby)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a gathering crowd of gaping passersby" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="gathering" />
            <token id="19" string="crowd" />
            <token id="20" string="of" />
            <token id="21" string="gaping" />
            <token id="22" string="passersby" />
          </tokens>
        </chunking>
        <chunking id="2" string="Placing his hand across the man 's mouth" type="VP">
          <tokens>
            <token id="1" string="Placing" />
            <token id="2" string="his" />
            <token id="3" string="hand" />
            <token id="4" string="across" />
            <token id="5" string="the" />
            <token id="6" string="man" />
            <token id="7" string="'s" />
            <token id="8" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="3" string="his hand" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="hand" />
          </tokens>
        </chunking>
        <chunking id="4" string="gaping passersby" type="NP">
          <tokens>
            <token id="21" string="gaping" />
            <token id="22" string="passersby" />
          </tokens>
        </chunking>
        <chunking id="5" string="the man 's mouth" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="man" />
            <token id="7" string="'s" />
            <token id="8" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="6" string="the officer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="the man 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="man" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="marched him away before a gathering crowd of gaping passersby" type="VP">
          <tokens>
            <token id="13" string="marched" />
            <token id="14" string="him" />
            <token id="15" string="away" />
            <token id="16" string="before" />
            <token id="17" string="a" />
            <token id="18" string="gathering" />
            <token id="19" string="crowd" />
            <token id="20" string="of" />
            <token id="21" string="gaping" />
            <token id="22" string="passersby" />
          </tokens>
        </chunking>
        <chunking id="10" string="a gathering crowd" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="gathering" />
            <token id="19" string="crowd" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="13">marched</governor>
          <dependent id="1">Placing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">hand</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Placing</governor>
          <dependent id="3">hand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">mouth</governor>
          <dependent id="4">across</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">man</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">mouth</governor>
          <dependent id="6">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">man</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Placing</governor>
          <dependent id="8">mouth</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">marched</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">marched</governor>
          <dependent id="12">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">marched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">marched</governor>
          <dependent id="14">him</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">marched</governor>
          <dependent id="15">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">crowd</governor>
          <dependent id="16">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">crowd</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">crowd</governor>
          <dependent id="18">gathering</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">marched</governor>
          <dependent id="19">crowd</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">passersby</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">passersby</governor>
          <dependent id="21">gaping</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">crowd</governor>
          <dependent id="22">passersby</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Only later did Searle and his partner from the Drug Enforcement Administration realize that the suspected drug courier they had arrested on that March day in 1988 was Joe Morgan, the former Cincinnati Reds second baseman who was inducted Monday into Major League baseball&amp;apost;s Hall of Fame.</content>
      <tokens>
        <token id="1" string="Only" lemma="only" stem="only" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="partner" lemma="partner" stem="partner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="Drug" lemma="Drug" stem="drug" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="11" string="Enforcement" lemma="Enforcement" stem="enforcement" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="12" string="Administration" lemma="Administration" stem="administr" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="13" string="realize" lemma="realize" stem="realiz" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="25" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="27" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="28" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="Cincinnati" lemma="Cincinnati" stem="cincinnati" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="35" string="Reds" lemma="red" stem="red" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="36" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="37" string="baseman" lemma="baseman" stem="baseman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="inducted" lemma="induct" stem="induct" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="42" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="44" string="League" lemma="League" stem="leagu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="45" string="baseball" lemma="baseball" stem="basebal" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="46" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="47" string="Hall" lemma="hall" stem="hall" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="48" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="49" string="Fame" lemma="Fame" stem="fame" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (ADVP (RB Only) (RB later)) (VP (VBD did) (SBAR (S (NP (NP (NNP Searle)) (CC and) (NP (NP (PRP$ his) (NN partner)) (PP (IN from) (NP (DT the) (NNP Drug) (NNP Enforcement) (NNP Administration))))) (VP (VBP realize) (SBAR (IN that) (S (NP (NP (DT the) (VBN suspected) (NN drug) (NN courier)) (SBAR (S (NP (PRP they)) (VP (VBD had) (VP (VBN arrested) (PP (IN on) (NP (DT that) (NNP March) (NN day))) (PP (IN in) (NP (CD 1988)))))))) (VP (VBD was) (NP (NP (NNP Joe) (NNP Morgan)) (, ,) (NP (DT the) (JJ former) (NNP Cincinnati) (NNS Reds)))))))))) (NP (NP (JJ second) (NN baseman)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN inducted) (NP-TMP (NNP Monday)) (PP (IN into) (NP (NP (NP (NNP Major) (NNP League) (NN baseball) (POS 's)) (NN Hall)) (PP (IN of) (NP (NNP Fame)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his partner from the Drug Enforcement Administration" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="partner" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="2" string="did Searle and his partner from the Drug Enforcement Administration realize that the suspected drug courier they had arrested on that March day in 1988 was Joe Morgan , the former Cincinnati Reds" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="Searle" />
            <token id="5" string="and" />
            <token id="6" string="his" />
            <token id="7" string="partner" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
            <token id="13" string="realize" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
            <token id="28" string="was" />
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="3" string="realize that the suspected drug courier they had arrested on that March day in 1988 was Joe Morgan , the former Cincinnati Reds" type="VP">
          <tokens>
            <token id="13" string="realize" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
            <token id="28" string="was" />
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="4" string="Major League baseball 's" type="NP">
          <tokens>
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the suspected drug courier" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
          </tokens>
        </chunking>
        <chunking id="6" string="the former Cincinnati Reds" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the suspected drug courier they had arrested on that March day in 1988 was Joe Morgan , the former Cincinnati Reds" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
            <token id="28" string="was" />
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="8" string="inducted Monday into Major League baseball 's Hall of Fame" type="VP">
          <tokens>
            <token id="40" string="inducted" />
            <token id="41" string="Monday" />
            <token id="42" string="into" />
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="9" string="1988" type="NP">
          <tokens>
            <token id="27" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="second baseman" type="NP">
          <tokens>
            <token id="36" string="second" />
            <token id="37" string="baseman" />
          </tokens>
        </chunking>
        <chunking id="11" string="Major League baseball 's Hall of Fame" type="NP">
          <tokens>
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="12" string="Major League baseball 's Hall" type="NP">
          <tokens>
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
          </tokens>
        </chunking>
        <chunking id="13" string="Searle and his partner from the Drug Enforcement Administration realize that the suspected drug courier they had arrested on that March day in 1988 was Joe Morgan , the former Cincinnati Reds" type="SBAR">
          <tokens>
            <token id="4" string="Searle" />
            <token id="5" string="and" />
            <token id="6" string="his" />
            <token id="7" string="partner" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
            <token id="13" string="realize" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
            <token id="28" string="was" />
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="14" string="they had arrested on that March day in 1988" type="SBAR">
          <tokens>
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
          </tokens>
        </chunking>
        <chunking id="15" string="Searle" type="NP">
          <tokens>
            <token id="4" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="16" string="Searle and his partner from the Drug Enforcement Administration" type="NP">
          <tokens>
            <token id="4" string="Searle" />
            <token id="5" string="and" />
            <token id="6" string="his" />
            <token id="7" string="partner" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="17" string="Joe Morgan , the former Cincinnati Reds" type="NP">
          <tokens>
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="18" string="had arrested on that March day in 1988" type="VP">
          <tokens>
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
          </tokens>
        </chunking>
        <chunking id="19" string="who was inducted Monday into Major League baseball 's Hall of Fame" type="SBAR">
          <tokens>
            <token id="38" string="who" />
            <token id="39" string="was" />
            <token id="40" string="inducted" />
            <token id="41" string="Monday" />
            <token id="42" string="into" />
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="20" string="his partner" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="partner" />
          </tokens>
        </chunking>
        <chunking id="21" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="22" string="was inducted Monday into Major League baseball 's Hall of Fame" type="VP">
          <tokens>
            <token id="39" string="was" />
            <token id="40" string="inducted" />
            <token id="41" string="Monday" />
            <token id="42" string="into" />
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="23" string="Fame" type="NP">
          <tokens>
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="24" string="the Drug Enforcement Administration" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="25" string="was Joe Morgan , the former Cincinnati Reds" type="VP">
          <tokens>
            <token id="28" string="was" />
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
            <token id="31" string="," />
            <token id="32" string="the" />
            <token id="33" string="former" />
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </chunking>
        <chunking id="26" string="arrested on that March day in 1988" type="VP">
          <tokens>
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
          </tokens>
        </chunking>
        <chunking id="27" string="Joe Morgan" type="NP">
          <tokens>
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="28" string="that March day" type="NP">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
          </tokens>
        </chunking>
        <chunking id="29" string="second baseman who was inducted Monday into Major League baseball 's Hall of Fame" type="NP">
          <tokens>
            <token id="36" string="second" />
            <token id="37" string="baseman" />
            <token id="38" string="who" />
            <token id="39" string="was" />
            <token id="40" string="inducted" />
            <token id="41" string="Monday" />
            <token id="42" string="into" />
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="30" string="the suspected drug courier they had arrested on that March day in 1988" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="suspected" />
            <token id="17" string="drug" />
            <token id="18" string="courier" />
            <token id="19" string="they" />
            <token id="20" string="had" />
            <token id="21" string="arrested" />
            <token id="22" string="on" />
            <token id="23" string="that" />
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">later</governor>
          <dependent id="1">Only</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">did</governor>
          <dependent id="2">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">realize</governor>
          <dependent id="4">Searle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Searle</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">partner</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Searle</governor>
          <dependent id="7">partner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Administration</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Administration</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Administration</governor>
          <dependent id="10">Drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Administration</governor>
          <dependent id="11">Enforcement</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">partner</governor>
          <dependent id="12">Administration</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">did</governor>
          <dependent id="13">realize</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">Morgan</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">courier</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">courier</governor>
          <dependent id="16">suspected</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">courier</governor>
          <dependent id="17">drug</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">Morgan</governor>
          <dependent id="18">courier</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">arrested</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">arrested</governor>
          <dependent id="20">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">courier</governor>
          <dependent id="21">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">day</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">day</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">day</governor>
          <dependent id="24">March</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">arrested</governor>
          <dependent id="25">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">1988</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">arrested</governor>
          <dependent id="27">1988</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">Morgan</governor>
          <dependent id="28">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Morgan</governor>
          <dependent id="29">Joe</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">realize</governor>
          <dependent id="30">Morgan</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Reds</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Reds</governor>
          <dependent id="33">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Reds</governor>
          <dependent id="34">Cincinnati</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">Morgan</governor>
          <dependent id="35">Reds</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">baseman</governor>
          <dependent id="36">second</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="37">baseman</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="40">inducted</governor>
          <dependent id="38">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">inducted</governor>
          <dependent id="39">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="37">baseman</governor>
          <dependent id="40">inducted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="40">inducted</governor>
          <dependent id="41">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Hall</governor>
          <dependent id="42">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">baseball</governor>
          <dependent id="43">Major</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">baseball</governor>
          <dependent id="44">League</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="47">Hall</governor>
          <dependent id="45">baseball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">baseball</governor>
          <dependent id="46">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">inducted</governor>
          <dependent id="47">Hall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">Fame</governor>
          <dependent id="48">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">Hall</governor>
          <dependent id="49">Fame</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Major League baseball 's Hall of Fame" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="43" string="Major" />
            <token id="44" string="League" />
            <token id="45" string="baseball" />
            <token id="46" string="'s" />
            <token id="47" string="Hall" />
            <token id="48" string="of" />
            <token id="49" string="Fame" />
          </tokens>
        </entity>
        <entity id="3" string="Joe Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Joe" />
            <token id="30" string="Morgan" />
          </tokens>
        </entity>
        <entity id="4" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="36" string="second" />
          </tokens>
        </entity>
        <entity id="5" string="Drug Enforcement Administration" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Drug" />
            <token id="11" string="Enforcement" />
            <token id="12" string="Administration" />
          </tokens>
        </entity>
        <entity id="6" string="March day in 1988" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="March" />
            <token id="25" string="day" />
            <token id="26" string="in" />
            <token id="27" string="1988" />
          </tokens>
        </entity>
        <entity id="7" string="Cincinnati Reds" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="34" string="Cincinnati" />
            <token id="35" string="Reds" />
          </tokens>
        </entity>
        <entity id="8" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="41" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The 46-year-old Morgan, who is now an Oakland businessman and baseball broadcaster, is suing Searle and the city of Los Angeles in federal court, claiming that he was unfairly targeted because he is black and fit a certain &amp;quot;profile&amp;quot; that narcotics officers think a drug courier should look like.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="46-year-old" lemma="46-year-old" stem="46-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Oakland" lemma="Oakland" stem="oakland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="businessman" lemma="businessman" stem="businessman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="baseball" lemma="baseball" stem="basebal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="broadcaster" lemma="broadcaster" stem="broadcast" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="suing" lemma="sue" stem="su" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="23" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="claiming" lemma="claim" stem="claim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="unfairly" lemma="unfairly" stem="unfairli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="targeted" lemma="target" stem="target" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="fit" lemma="fit" stem="fit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="48" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="49" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="50" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="51" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="52" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="53" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="54" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ 46-year-old) (NNP Morgan)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (ADVP (RB now)) (NP (DT an) (NNP Oakland) (NN businessman) (CC and) (NN baseball) (NN broadcaster))))) (, ,)) (VP (VBZ is) (VP (VBG suing) (NP (NP (NNP Searle)) (CC and) (NP (NP (DT the) (NN city)) (PP (IN of) (NP (NNP Los) (NNP Angeles))))) (PP (IN in) (NP (JJ federal) (NN court))) (, ,) (S (VP (VBG claiming) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (ADVP (RB unfairly)) (VP (VP (VBN targeted) (SBAR (IN because) (S (NP (PRP he)) (VP (VBZ is) (ADJP (JJ black)))))) (CC and) (VP (VB fit) (NP (NP (DT a) (JJ certain) (`` ``) (NN profile) ('' '')) (SBAR (WHNP (WDT that)) (S (NP (NNS narcotics) (NNS officers)) (VP (VBP think) (SBAR (S (NP (DT a) (NN drug) (NN courier)) (VP (MD should) (VP (VB look) (PP (IN like))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who is now an Oakland businessman and baseball broadcaster" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="is" />
            <token id="7" string="now" />
            <token id="8" string="an" />
            <token id="9" string="Oakland" />
            <token id="10" string="businessman" />
            <token id="11" string="and" />
            <token id="12" string="baseball" />
            <token id="13" string="broadcaster" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="black" type="ADJP">
          <tokens>
            <token id="37" string="black" />
          </tokens>
        </chunking>
        <chunking id="4" string="The 46-year-old Morgan" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="46-year-old" />
            <token id="3" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="5" string="is now an Oakland businessman and baseball broadcaster" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="now" />
            <token id="8" string="an" />
            <token id="9" string="Oakland" />
            <token id="10" string="businessman" />
            <token id="11" string="and" />
            <token id="12" string="baseball" />
            <token id="13" string="broadcaster" />
          </tokens>
        </chunking>
        <chunking id="6" string="targeted because he is black" type="VP">
          <tokens>
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
          </tokens>
        </chunking>
        <chunking id="7" string="is black" type="VP">
          <tokens>
            <token id="36" string="is" />
            <token id="37" string="black" />
          </tokens>
        </chunking>
        <chunking id="8" string="a drug courier" type="NP">
          <tokens>
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
          </tokens>
        </chunking>
        <chunking id="9" string="think a drug courier should look like" type="VP">
          <tokens>
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="10" string="claiming that he was unfairly targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="28" string="claiming" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="unfairly" />
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="11" string="fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="12" string="a certain `` profile '' that narcotics officers think a drug courier should look like" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="13" string="The 46-year-old Morgan , who is now an Oakland businessman and baseball broadcaster ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="46-year-old" />
            <token id="3" string="Morgan" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="is" />
            <token id="7" string="now" />
            <token id="8" string="an" />
            <token id="9" string="Oakland" />
            <token id="10" string="businessman" />
            <token id="11" string="and" />
            <token id="12" string="baseball" />
            <token id="13" string="broadcaster" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="suing Searle and the city of Los Angeles in federal court , claiming that he was unfairly targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="16" string="suing" />
            <token id="17" string="Searle" />
            <token id="18" string="and" />
            <token id="19" string="the" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="in" />
            <token id="25" string="federal" />
            <token id="26" string="court" />
            <token id="27" string="," />
            <token id="28" string="claiming" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="unfairly" />
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="15" string="Los Angeles" type="NP">
          <tokens>
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="30" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="Searle and the city of Los Angeles" type="NP">
          <tokens>
            <token id="17" string="Searle" />
            <token id="18" string="and" />
            <token id="19" string="the" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="18" string="Searle" type="NP">
          <tokens>
            <token id="17" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="19" string="because he is black" type="SBAR">
          <tokens>
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
          </tokens>
        </chunking>
        <chunking id="20" string="that narcotics officers think a drug courier should look like" type="SBAR">
          <tokens>
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="21" string="should look like" type="VP">
          <tokens>
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="22" string="an Oakland businessman and baseball broadcaster" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="Oakland" />
            <token id="10" string="businessman" />
            <token id="11" string="and" />
            <token id="12" string="baseball" />
            <token id="13" string="broadcaster" />
          </tokens>
        </chunking>
        <chunking id="23" string="was unfairly targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="unfairly" />
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="24" string="narcotics officers" type="NP">
          <tokens>
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
          </tokens>
        </chunking>
        <chunking id="25" string="is suing Searle and the city of Los Angeles in federal court , claiming that he was unfairly targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="suing" />
            <token id="17" string="Searle" />
            <token id="18" string="and" />
            <token id="19" string="the" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="in" />
            <token id="25" string="federal" />
            <token id="26" string="court" />
            <token id="27" string="," />
            <token id="28" string="claiming" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="unfairly" />
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="26" string="targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="VP">
          <tokens>
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="27" string="federal court" type="NP">
          <tokens>
            <token id="25" string="federal" />
            <token id="26" string="court" />
          </tokens>
        </chunking>
        <chunking id="28" string="the city of Los Angeles" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="29" string="a certain `` profile ''" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="30" string="a drug courier should look like" type="SBAR">
          <tokens>
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="31" string="look like" type="VP">
          <tokens>
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
        <chunking id="32" string="that he was unfairly targeted because he is black and fit a certain `` profile '' that narcotics officers think a drug courier should look like" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="unfairly" />
            <token id="33" string="targeted" />
            <token id="34" string="because" />
            <token id="35" string="he" />
            <token id="36" string="is" />
            <token id="37" string="black" />
            <token id="38" string="and" />
            <token id="39" string="fit" />
            <token id="40" string="a" />
            <token id="41" string="certain" />
            <token id="42" string="&quot;" />
            <token id="43" string="profile" />
            <token id="44" string="&quot;" />
            <token id="45" string="that" />
            <token id="46" string="narcotics" />
            <token id="47" string="officers" />
            <token id="48" string="think" />
            <token id="49" string="a" />
            <token id="50" string="drug" />
            <token id="51" string="courier" />
            <token id="52" string="should" />
            <token id="53" string="look" />
            <token id="54" string="like" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Morgan</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Morgan</governor>
          <dependent id="2">46-year-old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">suing</governor>
          <dependent id="3">Morgan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">businessman</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">businessman</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">businessman</governor>
          <dependent id="7">now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">businessman</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">businessman</governor>
          <dependent id="9">Oakland</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Morgan</governor>
          <dependent id="10">businessman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">businessman</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">broadcaster</governor>
          <dependent id="12">baseball</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">businessman</governor>
          <dependent id="13">broadcaster</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">suing</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">suing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">suing</governor>
          <dependent id="17">Searle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Searle</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">city</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Searle</governor>
          <dependent id="20">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Angeles</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Angeles</governor>
          <dependent id="22">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">city</governor>
          <dependent id="23">Angeles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">court</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">court</governor>
          <dependent id="25">federal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">suing</governor>
          <dependent id="26">court</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">suing</governor>
          <dependent id="28">claiming</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">targeted</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">targeted</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">targeted</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">targeted</governor>
          <dependent id="32">unfairly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">claiming</governor>
          <dependent id="33">targeted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">black</governor>
          <dependent id="34">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">black</governor>
          <dependent id="35">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="37">black</governor>
          <dependent id="36">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">targeted</governor>
          <dependent id="37">black</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">targeted</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">targeted</governor>
          <dependent id="39">fit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">profile</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">profile</governor>
          <dependent id="41">certain</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">fit</governor>
          <dependent id="43">profile</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="48">think</governor>
          <dependent id="45">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">officers</governor>
          <dependent id="46">narcotics</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">think</governor>
          <dependent id="47">officers</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="43">profile</governor>
          <dependent id="48">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">courier</governor>
          <dependent id="49">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">courier</governor>
          <dependent id="50">drug</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="53">look</governor>
          <dependent id="51">courier</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="53">look</governor>
          <dependent id="52">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="48">think</governor>
          <dependent id="53">look</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="53">look</governor>
          <dependent id="54">like</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Searle" />
          </tokens>
        </entity>
        <entity id="3" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Morgan" />
          </tokens>
        </entity>
        <entity id="4" string="Oakland" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Oakland" />
          </tokens>
        </entity>
        <entity id="5" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
          </tokens>
        </entity>
        <entity id="6" string="46-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="46-year-old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>&amp;quot;There&amp;apost;s no doubt in our mind that the only reason they stopped Joe Morgan was because he is black and he was the first black who happened to come by,&amp;quot; said William Barnes, one of the attorneys representing the former ballplayer.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="27" string="black" lemma="black" stem="black" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="37" string="Barnes" lemma="Barnes" stem="barn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="ballplayer" lemma="ballplayer" stem="ballplay" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (EX There)) (VP (VBZ 's) (NP (NP (DT no) (NN doubt)) (PP (IN in) (NP (PRP$ our) (NN mind)))) (SBAR (IN that) (S (NP (NP (DT the) (JJ only) (NN reason)) (SBAR (S (NP (PRP they)) (VP (VBD stopped) (NP (NNP Joe) (NNP Morgan)))))) (VP (VBD was) (SBAR (IN because) (S (NP (PRP he)) (VP (VBZ is) (ADJP (JJ black)))))))))) (CC and) (S (NP (PRP he)) (VP (VBD was) (NP (NP (DT the) (JJ first) (NN black)) (SBAR (WHNP (WP who)) (S (VP (VBD happened) (S (VP (TO to) (VP (VB come) (PP (IN by)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP William) (NNP Barnes)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NNS attorneys)) (VP (VBG representing) (NP (DT the) (JJ former) (NN ballplayer))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="39" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="the first black who happened to come by" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="black" />
            <token id="28" string="who" />
            <token id="29" string="happened" />
            <token id="30" string="to" />
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="3" string="happened to come by" type="VP">
          <tokens>
            <token id="29" string="happened" />
            <token id="30" string="to" />
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="4" string="black" type="ADJP">
          <tokens>
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="5" string="William Barnes , one of the attorneys representing the former ballplayer" type="NP">
          <tokens>
            <token id="36" string="William" />
            <token id="37" string="Barnes" />
            <token id="38" string="," />
            <token id="39" string="one" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="attorneys" />
            <token id="43" string="representing" />
            <token id="44" string="the" />
            <token id="45" string="former" />
            <token id="46" string="ballplayer" />
          </tokens>
        </chunking>
        <chunking id="6" string="is black" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="7" string="was the first black who happened to come by" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="black" />
            <token id="28" string="who" />
            <token id="29" string="happened" />
            <token id="30" string="to" />
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s no doubt in our mind that the only reason they stopped Joe Morgan was because he is black" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="no" />
            <token id="5" string="doubt" />
            <token id="6" string="in" />
            <token id="7" string="our" />
            <token id="8" string="mind" />
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="only" />
            <token id="12" string="reason" />
            <token id="13" string="they" />
            <token id="14" string="stopped" />
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
            <token id="17" string="was" />
            <token id="18" string="because" />
            <token id="19" string="he" />
            <token id="20" string="is" />
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="9" string="the only reason" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="only" />
            <token id="12" string="reason" />
          </tokens>
        </chunking>
        <chunking id="10" string="to come by" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the only reason they stopped Joe Morgan was because he is black" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="only" />
            <token id="12" string="reason" />
            <token id="13" string="they" />
            <token id="14" string="stopped" />
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
            <token id="17" string="was" />
            <token id="18" string="because" />
            <token id="19" string="he" />
            <token id="20" string="is" />
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="12" string="one of the attorneys representing the former ballplayer" type="NP">
          <tokens>
            <token id="39" string="one" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="attorneys" />
            <token id="43" string="representing" />
            <token id="44" string="the" />
            <token id="45" string="former" />
            <token id="46" string="ballplayer" />
          </tokens>
        </chunking>
        <chunking id="13" string="stopped Joe Morgan" type="VP">
          <tokens>
            <token id="14" string="stopped" />
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="14" string="the attorneys" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="who happened to come by" type="SBAR">
          <tokens>
            <token id="28" string="who" />
            <token id="29" string="happened" />
            <token id="30" string="to" />
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="17" string="our mind" type="NP">
          <tokens>
            <token id="7" string="our" />
            <token id="8" string="mind" />
          </tokens>
        </chunking>
        <chunking id="18" string="representing the former ballplayer" type="VP">
          <tokens>
            <token id="43" string="representing" />
            <token id="44" string="the" />
            <token id="45" string="former" />
            <token id="46" string="ballplayer" />
          </tokens>
        </chunking>
        <chunking id="19" string="because he is black" type="SBAR">
          <tokens>
            <token id="18" string="because" />
            <token id="19" string="he" />
            <token id="20" string="is" />
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="20" string="the only reason they stopped Joe Morgan" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="only" />
            <token id="12" string="reason" />
            <token id="13" string="they" />
            <token id="14" string="stopped" />
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="21" string="William Barnes" type="NP">
          <tokens>
            <token id="36" string="William" />
            <token id="37" string="Barnes" />
          </tokens>
        </chunking>
        <chunking id="22" string="the first black" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="black" />
          </tokens>
        </chunking>
        <chunking id="23" string="they stopped Joe Morgan" type="SBAR">
          <tokens>
            <token id="13" string="they" />
            <token id="14" string="stopped" />
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="24" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="25" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="26" string="come by" type="VP">
          <tokens>
            <token id="31" string="come" />
            <token id="32" string="by" />
          </tokens>
        </chunking>
        <chunking id="27" string="the attorneys representing the former ballplayer" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="attorneys" />
            <token id="43" string="representing" />
            <token id="44" string="the" />
            <token id="45" string="former" />
            <token id="46" string="ballplayer" />
          </tokens>
        </chunking>
        <chunking id="28" string="Joe Morgan" type="NP">
          <tokens>
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="29" string="was because he is black" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="because" />
            <token id="19" string="he" />
            <token id="20" string="is" />
            <token id="21" string="black" />
          </tokens>
        </chunking>
        <chunking id="30" string="no doubt" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="31" string="no doubt in our mind" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="doubt" />
            <token id="6" string="in" />
            <token id="7" string="our" />
            <token id="8" string="mind" />
          </tokens>
        </chunking>
        <chunking id="32" string="said" type="VP">
          <tokens>
            <token id="35" string="said" />
          </tokens>
        </chunking>
        <chunking id="33" string="the former ballplayer" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="former" />
            <token id="46" string="ballplayer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">'s</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">said</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">doubt</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">'s</governor>
          <dependent id="5">doubt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">mind</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">mind</governor>
          <dependent id="7">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">doubt</governor>
          <dependent id="8">mind</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">was</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">reason</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">reason</governor>
          <dependent id="11">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">was</governor>
          <dependent id="12">reason</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">stopped</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">reason</governor>
          <dependent id="14">stopped</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Morgan</governor>
          <dependent id="15">Joe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">stopped</governor>
          <dependent id="16">Morgan</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">'s</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">black</governor>
          <dependent id="18">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">black</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">black</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">was</governor>
          <dependent id="21">black</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">'s</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">black</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">black</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">black</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">black</governor>
          <dependent id="26">first</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">'s</governor>
          <dependent id="27">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">happened</governor>
          <dependent id="28">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">black</governor>
          <dependent id="29">happened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">come</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">happened</governor>
          <dependent id="31">come</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">come</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="35">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Barnes</governor>
          <dependent id="36">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">said</governor>
          <dependent id="37">Barnes</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">Barnes</governor>
          <dependent id="39">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">attorneys</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">attorneys</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">one</governor>
          <dependent id="42">attorneys</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">attorneys</governor>
          <dependent id="43">representing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">ballplayer</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">ballplayer</governor>
          <dependent id="45">former</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">representing</governor>
          <dependent id="46">ballplayer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="26" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="39" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Joe Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Joe" />
            <token id="16" string="Morgan" />
          </tokens>
        </entity>
        <entity id="4" string="William Barnes" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="William" />
            <token id="37" string="Barnes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The Morgan case also reflects a growing criticism of police use of the drug courier profile to stem the flow of drugs through airports.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="reflects" lemma="reflect" stem="reflect" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="growing" lemma="grow" stem="grow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="stem" lemma="stem" stem="stem" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="flow" lemma="flow" stem="flow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="23" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="airports" lemma="airport" stem="airport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Morgan) (NN case)) (ADVP (RB also)) (VP (VBZ reflects) (NP (NP (DT a) (VBG growing) (NN criticism)) (PP (IN of) (NP (NP (NN police) (NN use)) (PP (IN of) (NP (DT the) (NN drug) (NN courier) (NN profile))))) (S (VP (TO to) (VP (VB stem) (NP (NP (DT the) (NN flow)) (PP (IN of) (NP (NNS drugs)))) (PP (IN through) (NP (NNS airports)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a growing criticism of police use of the drug courier profile to stem the flow of drugs through airports" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="growing" />
            <token id="8" string="criticism" />
            <token id="9" string="of" />
            <token id="10" string="police" />
            <token id="11" string="use" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="drug" />
            <token id="15" string="courier" />
            <token id="16" string="profile" />
            <token id="17" string="to" />
            <token id="18" string="stem" />
            <token id="19" string="the" />
            <token id="20" string="flow" />
            <token id="21" string="of" />
            <token id="22" string="drugs" />
            <token id="23" string="through" />
            <token id="24" string="airports" />
          </tokens>
        </chunking>
        <chunking id="2" string="the flow" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="flow" />
          </tokens>
        </chunking>
        <chunking id="3" string="airports" type="NP">
          <tokens>
            <token id="24" string="airports" />
          </tokens>
        </chunking>
        <chunking id="4" string="drugs" type="NP">
          <tokens>
            <token id="22" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="to stem the flow of drugs through airports" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="stem" />
            <token id="19" string="the" />
            <token id="20" string="flow" />
            <token id="21" string="of" />
            <token id="22" string="drugs" />
            <token id="23" string="through" />
            <token id="24" string="airports" />
          </tokens>
        </chunking>
        <chunking id="6" string="police use of the drug courier profile" type="NP">
          <tokens>
            <token id="10" string="police" />
            <token id="11" string="use" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="drug" />
            <token id="15" string="courier" />
            <token id="16" string="profile" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Morgan case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Morgan" />
            <token id="3" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="reflects a growing criticism of police use of the drug courier profile to stem the flow of drugs through airports" type="VP">
          <tokens>
            <token id="5" string="reflects" />
            <token id="6" string="a" />
            <token id="7" string="growing" />
            <token id="8" string="criticism" />
            <token id="9" string="of" />
            <token id="10" string="police" />
            <token id="11" string="use" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="drug" />
            <token id="15" string="courier" />
            <token id="16" string="profile" />
            <token id="17" string="to" />
            <token id="18" string="stem" />
            <token id="19" string="the" />
            <token id="20" string="flow" />
            <token id="21" string="of" />
            <token id="22" string="drugs" />
            <token id="23" string="through" />
            <token id="24" string="airports" />
          </tokens>
        </chunking>
        <chunking id="9" string="police use" type="NP">
          <tokens>
            <token id="10" string="police" />
            <token id="11" string="use" />
          </tokens>
        </chunking>
        <chunking id="10" string="the drug courier profile" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="drug" />
            <token id="15" string="courier" />
            <token id="16" string="profile" />
          </tokens>
        </chunking>
        <chunking id="11" string="a growing criticism" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="growing" />
            <token id="8" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="12" string="stem the flow of drugs through airports" type="VP">
          <tokens>
            <token id="18" string="stem" />
            <token id="19" string="the" />
            <token id="20" string="flow" />
            <token id="21" string="of" />
            <token id="22" string="drugs" />
            <token id="23" string="through" />
            <token id="24" string="airports" />
          </tokens>
        </chunking>
        <chunking id="13" string="the flow of drugs" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="flow" />
            <token id="21" string="of" />
            <token id="22" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">case</governor>
          <dependent id="2">Morgan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reflects</governor>
          <dependent id="3">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">reflects</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reflects</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">criticism</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">criticism</governor>
          <dependent id="7">growing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reflects</governor>
          <dependent id="8">criticism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">use</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">use</governor>
          <dependent id="10">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">criticism</governor>
          <dependent id="11">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">profile</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">profile</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">profile</governor>
          <dependent id="14">drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">profile</governor>
          <dependent id="15">courier</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">use</governor>
          <dependent id="16">profile</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">stem</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">criticism</governor>
          <dependent id="18">stem</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">flow</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">stem</governor>
          <dependent id="20">flow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">drugs</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">flow</governor>
          <dependent id="22">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">airports</governor>
          <dependent id="23">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">stem</governor>
          <dependent id="24">airports</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s purely based on race or dress, not on whether you are involved in any drug activity,&amp;quot; said Gary Trichter, a Houston defense lawyer and former police officer who specializes in such cases.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="purely" lemma="purely" stem="pure" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dress" lemma="dress" stem="dress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="activity" lemma="activity" stem="activ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Gary" lemma="Gary" stem="gari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Trichter" lemma="Trichter" stem="trichter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Houston" lemma="Houston" stem="houston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="specializes" lemma="specialize" stem="special" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (RB purely) (VBN based) (PP (IN on) (NP (NN race) (CC or) (NN dress)))) (, ,) (PP (RB not) (IN on) (SBAR (IN whether) (S (NP (PRP you)) (VP (VBP are) (VP (VBN involved) (PP (IN in) (NP (DT any) (NN drug) (NN activity)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Gary) (NNP Trichter)) (, ,) (NP (NP (DT a) (NNP Houston) (NN defense) (NN lawyer) (CC and) (JJ former) (NNS police) (NN officer)) (SBAR (WHNP (WP who)) (S (VP (VBZ specializes) (PP (IN in) (NP (JJ such) (NNS cases)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="specializes in such cases" type="VP">
          <tokens>
            <token id="36" string="specializes" />
            <token id="37" string="in" />
            <token id="38" string="such" />
            <token id="39" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="who specializes in such cases" type="SBAR">
          <tokens>
            <token id="35" string="who" />
            <token id="36" string="specializes" />
            <token id="37" string="in" />
            <token id="38" string="such" />
            <token id="39" string="cases" />
          </tokens>
        </chunking>
        <chunking id="3" string="purely based on race or dress" type="ADJP">
          <tokens>
            <token id="4" string="purely" />
            <token id="5" string="based" />
            <token id="6" string="on" />
            <token id="7" string="race" />
            <token id="8" string="or" />
            <token id="9" string="dress" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s purely based on race or dress , not on whether you are involved in any drug activity" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="purely" />
            <token id="5" string="based" />
            <token id="6" string="on" />
            <token id="7" string="race" />
            <token id="8" string="or" />
            <token id="9" string="dress" />
            <token id="10" string="," />
            <token id="11" string="not" />
            <token id="12" string="on" />
            <token id="13" string="whether" />
            <token id="14" string="you" />
            <token id="15" string="are" />
            <token id="16" string="involved" />
            <token id="17" string="in" />
            <token id="18" string="any" />
            <token id="19" string="drug" />
            <token id="20" string="activity" />
          </tokens>
        </chunking>
        <chunking id="6" string="involved in any drug activity" type="VP">
          <tokens>
            <token id="16" string="involved" />
            <token id="17" string="in" />
            <token id="18" string="any" />
            <token id="19" string="drug" />
            <token id="20" string="activity" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Houston defense lawyer and former police officer" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="Houston" />
            <token id="29" string="defense" />
            <token id="30" string="lawyer" />
            <token id="31" string="and" />
            <token id="32" string="former" />
            <token id="33" string="police" />
            <token id="34" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="are involved in any drug activity" type="VP">
          <tokens>
            <token id="15" string="are" />
            <token id="16" string="involved" />
            <token id="17" string="in" />
            <token id="18" string="any" />
            <token id="19" string="drug" />
            <token id="20" string="activity" />
          </tokens>
        </chunking>
        <chunking id="9" string="race or dress" type="NP">
          <tokens>
            <token id="7" string="race" />
            <token id="8" string="or" />
            <token id="9" string="dress" />
          </tokens>
        </chunking>
        <chunking id="10" string="Gary Trichter" type="NP">
          <tokens>
            <token id="24" string="Gary" />
            <token id="25" string="Trichter" />
          </tokens>
        </chunking>
        <chunking id="11" string="any drug activity" type="NP">
          <tokens>
            <token id="18" string="any" />
            <token id="19" string="drug" />
            <token id="20" string="activity" />
          </tokens>
        </chunking>
        <chunking id="12" string="such cases" type="NP">
          <tokens>
            <token id="38" string="such" />
            <token id="39" string="cases" />
          </tokens>
        </chunking>
        <chunking id="13" string="whether you are involved in any drug activity" type="SBAR">
          <tokens>
            <token id="13" string="whether" />
            <token id="14" string="you" />
            <token id="15" string="are" />
            <token id="16" string="involved" />
            <token id="17" string="in" />
            <token id="18" string="any" />
            <token id="19" string="drug" />
            <token id="20" string="activity" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
        <chunking id="15" string="Gary Trichter , a Houston defense lawyer and former police officer who specializes in such cases" type="NP">
          <tokens>
            <token id="24" string="Gary" />
            <token id="25" string="Trichter" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="Houston" />
            <token id="29" string="defense" />
            <token id="30" string="lawyer" />
            <token id="31" string="and" />
            <token id="32" string="former" />
            <token id="33" string="police" />
            <token id="34" string="officer" />
            <token id="35" string="who" />
            <token id="36" string="specializes" />
            <token id="37" string="in" />
            <token id="38" string="such" />
            <token id="39" string="cases" />
          </tokens>
        </chunking>
        <chunking id="16" string="a Houston defense lawyer and former police officer who specializes in such cases" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="Houston" />
            <token id="29" string="defense" />
            <token id="30" string="lawyer" />
            <token id="31" string="and" />
            <token id="32" string="former" />
            <token id="33" string="police" />
            <token id="34" string="officer" />
            <token id="35" string="who" />
            <token id="36" string="specializes" />
            <token id="37" string="in" />
            <token id="38" string="such" />
            <token id="39" string="cases" />
          </tokens>
        </chunking>
        <chunking id="17" string="you" type="NP">
          <tokens>
            <token id="14" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">based</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">based</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">based</governor>
          <dependent id="4">purely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="5">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">race</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">based</governor>
          <dependent id="7">race</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">race</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">race</governor>
          <dependent id="9">dress</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">involved</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">involved</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">involved</governor>
          <dependent id="13">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">involved</governor>
          <dependent id="14">you</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">involved</governor>
          <dependent id="15">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">based</governor>
          <dependent id="16">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">activity</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">activity</governor>
          <dependent id="18">any</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">activity</governor>
          <dependent id="19">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">involved</governor>
          <dependent id="20">activity</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Trichter</governor>
          <dependent id="24">Gary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="25">Trichter</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">lawyer</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">lawyer</governor>
          <dependent id="28">Houston</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">lawyer</governor>
          <dependent id="29">defense</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Trichter</governor>
          <dependent id="30">lawyer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">lawyer</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">officer</governor>
          <dependent id="32">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">officer</governor>
          <dependent id="33">police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">lawyer</governor>
          <dependent id="34">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">specializes</governor>
          <dependent id="35">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="30">lawyer</governor>
          <dependent id="36">specializes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">cases</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">cases</governor>
          <dependent id="38">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">specializes</governor>
          <dependent id="39">cases</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gary Trichter" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Gary" />
            <token id="25" string="Trichter" />
          </tokens>
        </entity>
        <entity id="2" string="Houston" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Houston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>First developed in the 1970s, the drug courier profile was based on patterns of behavior believed to be used by those who use commercial airline flights to transport narcotics.</content>
      <tokens>
        <token id="1" string="First" lemma="First" stem="first" pos="NNP" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="2" string="developed" lemma="develop" stem="develop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1970s" lemma="1970" stem="1970" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="patterns" lemma="pattern" stem="pattern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="behavior" lemma="behavior" stem="behavior" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="use" lemma="use" stem="us" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="commercial" lemma="commercial" stem="commerci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="airline" lemma="airline" stem="airlin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="flights" lemma="flight" stem="flight" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="transport" lemma="transport" stem="transport" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP First)) (VP (VBD developed) (PP (IN in) (NP (DT the) (NNS 1970s))))) (, ,) (NP (DT the) (NN drug) (NN courier) (NN profile)) (VP (VBD was) (VP (VBN based) (PP (IN on) (NP (NP (NNS patterns)) (PP (IN of) (NP (NP (NN behavior)) (VP (VBN believed) (S (VP (TO to) (VP (VB be) (VP (VBN used) (PP (IN by) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBP use) (S (NP (JJ commercial) (NN airline) (NNS flights)) (VP (TO to) (VP (VB transport) (NP (NNS narcotics))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="developed in the 1970s" type="VP">
          <tokens>
            <token id="2" string="developed" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="1970s" />
          </tokens>
        </chunking>
        <chunking id="2" string="behavior believed to be used by those who use commercial airline flights to transport narcotics" type="NP">
          <tokens>
            <token id="16" string="behavior" />
            <token id="17" string="believed" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="3" string="to transport narcotics" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="4" string="based on patterns of behavior believed to be used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="12" string="based" />
            <token id="13" string="on" />
            <token id="14" string="patterns" />
            <token id="15" string="of" />
            <token id="16" string="behavior" />
            <token id="17" string="believed" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="5" string="those who use commercial airline flights to transport narcotics" type="NP">
          <tokens>
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="6" string="First" type="NP">
          <tokens>
            <token id="1" string="First" />
          </tokens>
        </chunking>
        <chunking id="7" string="commercial airline flights" type="NP">
          <tokens>
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
          </tokens>
        </chunking>
        <chunking id="8" string="patterns" type="NP">
          <tokens>
            <token id="14" string="patterns" />
          </tokens>
        </chunking>
        <chunking id="9" string="narcotics" type="NP">
          <tokens>
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="10" string="the drug courier profile" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="drug" />
            <token id="9" string="courier" />
            <token id="10" string="profile" />
          </tokens>
        </chunking>
        <chunking id="11" string="who use commercial airline flights to transport narcotics" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="12" string="use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="13" string="to be used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="14" string="transport narcotics" type="VP">
          <tokens>
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="15" string="used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="16" string="the 1970s" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="1970s" />
          </tokens>
        </chunking>
        <chunking id="17" string="was based on patterns of behavior believed to be used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="based" />
            <token id="13" string="on" />
            <token id="14" string="patterns" />
            <token id="15" string="of" />
            <token id="16" string="behavior" />
            <token id="17" string="believed" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="18" string="patterns of behavior believed to be used by those who use commercial airline flights to transport narcotics" type="NP">
          <tokens>
            <token id="14" string="patterns" />
            <token id="15" string="of" />
            <token id="16" string="behavior" />
            <token id="17" string="believed" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="19" string="believed to be used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="17" string="believed" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="20" string="be used by those who use commercial airline flights to transport narcotics" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="used" />
            <token id="21" string="by" />
            <token id="22" string="those" />
            <token id="23" string="who" />
            <token id="24" string="use" />
            <token id="25" string="commercial" />
            <token id="26" string="airline" />
            <token id="27" string="flights" />
            <token id="28" string="to" />
            <token id="29" string="transport" />
            <token id="30" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="21" string="behavior" type="NP">
          <tokens>
            <token id="16" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="22" string="those" type="NP">
          <tokens>
            <token id="22" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">developed</governor>
          <dependent id="1">First</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">based</governor>
          <dependent id="2">developed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1970s</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">1970s</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">developed</governor>
          <dependent id="5">1970s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">profile</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">profile</governor>
          <dependent id="8">drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">profile</governor>
          <dependent id="9">courier</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">based</governor>
          <dependent id="10">profile</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">based</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">patterns</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">based</governor>
          <dependent id="14">patterns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">behavior</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">patterns</governor>
          <dependent id="16">behavior</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">behavior</governor>
          <dependent id="17">believed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">used</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">used</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">believed</governor>
          <dependent id="20">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">those</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">used</governor>
          <dependent id="22">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">use</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">those</governor>
          <dependent id="24">use</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">flights</governor>
          <dependent id="25">commercial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">flights</governor>
          <dependent id="26">airline</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">use</governor>
          <dependent id="27">flights</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">transport</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">use</governor>
          <dependent id="29">transport</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">transport</governor>
          <dependent id="30">narcotics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="First" type="ORDINAL" score="0.0">
          <tokens>
            <token id="1" string="First" />
          </tokens>
        </entity>
        <entity id="2" string="the 1970s" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="1970s" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Such suspicious behavior include erratic movements, paying for tickets with cash, using an alias, boarding a long flight without luggage and staying briefly in distant cities known to be sources of narcotics.</content>
      <tokens>
        <token id="1" string="Such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="suspicious" lemma="suspicious" stem="suspici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="behavior" lemma="behavior" stem="behavior" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="erratic" lemma="erratic" stem="errat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="movements" lemma="movement" stem="movement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="paying" lemma="pay" stem="pai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tickets" lemma="ticket" stem="ticket" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="cash" lemma="cash" stem="cash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="alias" lemma="alias" stem="alia" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="boarding" lemma="board" stem="board" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="flight" lemma="flight" stem="flight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="luggage" lemma="luggage" stem="luggag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="staying" lemma="stay" stem="stai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="briefly" lemma="briefly" stem="briefli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="distant" lemma="distant" stem="distant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="cities" lemma="city" stem="citi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Such) (JJ suspicious) (NN behavior)) (VP (VBP include) (NP (JJ erratic) (NNS movements)) (, ,) (S (VP (VP (VBG paying) (PP (IN for) (NP (NP (NNS tickets)) (PP (IN with) (NP (NN cash)))))) (, ,) (VP (VBG using) (NP (DT an) (NN alias))) (, ,) (VP (VBG boarding) (NP (DT a) (JJ long) (NN flight)) (PP (IN without) (NP (NN luggage)))) (CC and) (VP (VBG staying) (ADVP (NN briefly)) (PP (IN in) (NP (NP (JJ distant) (NNS cities)) (VP (VBN known) (S (VP (TO to) (VP (VB be) (NP (NP (NNS sources)) (PP (IN of) (NP (NNS narcotics)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="distant cities" type="NP">
          <tokens>
            <token id="28" string="distant" />
            <token id="29" string="cities" />
          </tokens>
        </chunking>
        <chunking id="2" string="using an alias" type="VP">
          <tokens>
            <token id="14" string="using" />
            <token id="15" string="an" />
            <token id="16" string="alias" />
          </tokens>
        </chunking>
        <chunking id="3" string="tickets" type="NP">
          <tokens>
            <token id="10" string="tickets" />
          </tokens>
        </chunking>
        <chunking id="4" string="include erratic movements , paying for tickets with cash , using an alias , boarding a long flight without luggage and staying briefly in distant cities known to be sources of narcotics" type="VP">
          <tokens>
            <token id="4" string="include" />
            <token id="5" string="erratic" />
            <token id="6" string="movements" />
            <token id="7" string="," />
            <token id="8" string="paying" />
            <token id="9" string="for" />
            <token id="10" string="tickets" />
            <token id="11" string="with" />
            <token id="12" string="cash" />
            <token id="13" string="," />
            <token id="14" string="using" />
            <token id="15" string="an" />
            <token id="16" string="alias" />
            <token id="17" string="," />
            <token id="18" string="boarding" />
            <token id="19" string="a" />
            <token id="20" string="long" />
            <token id="21" string="flight" />
            <token id="22" string="without" />
            <token id="23" string="luggage" />
            <token id="24" string="and" />
            <token id="25" string="staying" />
            <token id="26" string="briefly" />
            <token id="27" string="in" />
            <token id="28" string="distant" />
            <token id="29" string="cities" />
            <token id="30" string="known" />
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="5" string="paying for tickets with cash" type="VP">
          <tokens>
            <token id="8" string="paying" />
            <token id="9" string="for" />
            <token id="10" string="tickets" />
            <token id="11" string="with" />
            <token id="12" string="cash" />
          </tokens>
        </chunking>
        <chunking id="6" string="sources" type="NP">
          <tokens>
            <token id="33" string="sources" />
          </tokens>
        </chunking>
        <chunking id="7" string="boarding a long flight without luggage" type="VP">
          <tokens>
            <token id="18" string="boarding" />
            <token id="19" string="a" />
            <token id="20" string="long" />
            <token id="21" string="flight" />
            <token id="22" string="without" />
            <token id="23" string="luggage" />
          </tokens>
        </chunking>
        <chunking id="8" string="narcotics" type="NP">
          <tokens>
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="9" string="tickets with cash" type="NP">
          <tokens>
            <token id="10" string="tickets" />
            <token id="11" string="with" />
            <token id="12" string="cash" />
          </tokens>
        </chunking>
        <chunking id="10" string="staying briefly in distant cities known to be sources of narcotics" type="VP">
          <tokens>
            <token id="25" string="staying" />
            <token id="26" string="briefly" />
            <token id="27" string="in" />
            <token id="28" string="distant" />
            <token id="29" string="cities" />
            <token id="30" string="known" />
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="11" string="a long flight" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="long" />
            <token id="21" string="flight" />
          </tokens>
        </chunking>
        <chunking id="12" string="erratic movements" type="NP">
          <tokens>
            <token id="5" string="erratic" />
            <token id="6" string="movements" />
          </tokens>
        </chunking>
        <chunking id="13" string="known to be sources of narcotics" type="VP">
          <tokens>
            <token id="30" string="known" />
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="14" string="to be sources of narcotics" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="15" string="luggage" type="NP">
          <tokens>
            <token id="23" string="luggage" />
          </tokens>
        </chunking>
        <chunking id="16" string="an alias" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="alias" />
          </tokens>
        </chunking>
        <chunking id="17" string="sources of narcotics" type="NP">
          <tokens>
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="18" string="Such suspicious behavior" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="suspicious" />
            <token id="3" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="19" string="cash" type="NP">
          <tokens>
            <token id="12" string="cash" />
          </tokens>
        </chunking>
        <chunking id="20" string="paying for tickets with cash , using an alias , boarding a long flight without luggage and staying briefly in distant cities known to be sources of narcotics" type="VP">
          <tokens>
            <token id="8" string="paying" />
            <token id="9" string="for" />
            <token id="10" string="tickets" />
            <token id="11" string="with" />
            <token id="12" string="cash" />
            <token id="13" string="," />
            <token id="14" string="using" />
            <token id="15" string="an" />
            <token id="16" string="alias" />
            <token id="17" string="," />
            <token id="18" string="boarding" />
            <token id="19" string="a" />
            <token id="20" string="long" />
            <token id="21" string="flight" />
            <token id="22" string="without" />
            <token id="23" string="luggage" />
            <token id="24" string="and" />
            <token id="25" string="staying" />
            <token id="26" string="briefly" />
            <token id="27" string="in" />
            <token id="28" string="distant" />
            <token id="29" string="cities" />
            <token id="30" string="known" />
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="21" string="be sources of narcotics" type="VP">
          <tokens>
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="22" string="distant cities known to be sources of narcotics" type="NP">
          <tokens>
            <token id="28" string="distant" />
            <token id="29" string="cities" />
            <token id="30" string="known" />
            <token id="31" string="to" />
            <token id="32" string="be" />
            <token id="33" string="sources" />
            <token id="34" string="of" />
            <token id="35" string="narcotics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">behavior</governor>
          <dependent id="1">Such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">behavior</governor>
          <dependent id="2">suspicious</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">include</governor>
          <dependent id="3">behavior</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">include</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">movements</governor>
          <dependent id="5">erratic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">include</governor>
          <dependent id="6">movements</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">include</governor>
          <dependent id="8">paying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">tickets</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">paying</governor>
          <dependent id="10">tickets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">cash</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">tickets</governor>
          <dependent id="12">cash</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">paying</governor>
          <dependent id="14">using</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">alias</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">using</governor>
          <dependent id="16">alias</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">paying</governor>
          <dependent id="18">boarding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">flight</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">flight</governor>
          <dependent id="20">long</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">boarding</governor>
          <dependent id="21">flight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">luggage</governor>
          <dependent id="22">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">boarding</governor>
          <dependent id="23">luggage</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">paying</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">paying</governor>
          <dependent id="25">staying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">staying</governor>
          <dependent id="26">briefly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">cities</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">cities</governor>
          <dependent id="28">distant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">staying</governor>
          <dependent id="29">cities</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">cities</governor>
          <dependent id="30">known</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">sources</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">sources</governor>
          <dependent id="32">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">known</governor>
          <dependent id="33">sources</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">narcotics</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">sources</governor>
          <dependent id="35">narcotics</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Last year, the U.S. Supreme Court ruled that government agents may stop and question airline passengers who look and act like drug couriers.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="ruled" lemma="rule" stem="rule" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="agents" lemma="agent" stem="agent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="stop" lemma="stop" stem="stop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="question" lemma="question" stem="question" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="airline" lemma="airline" stem="airlin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="look" lemma="look" stem="look" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="act" lemma="act" stem="act" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="couriers" lemma="courier" stem="courier" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN year)) (, ,) (NP (DT the) (NNP U.S.) (NNP Supreme) (NNP Court)) (VP (VBD ruled) (SBAR (IN that) (S (NP (NN government) (NNS agents)) (VP (MD may) (VP (VB stop) (CC and) (VB question) (NP (NP (NN airline) (NNS passengers)) (SBAR (WHNP (WP who)) (S (VP (VBP look) (CC and) (VBP act) (PP (IN like) (NP (NN drug) (NNS couriers)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that government agents may stop and question airline passengers who look and act like drug couriers" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="government" />
            <token id="11" string="agents" />
            <token id="12" string="may" />
            <token id="13" string="stop" />
            <token id="14" string="and" />
            <token id="15" string="question" />
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="2" string="drug couriers" type="NP">
          <tokens>
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="3" string="government agents" type="NP">
          <tokens>
            <token id="10" string="government" />
            <token id="11" string="agents" />
          </tokens>
        </chunking>
        <chunking id="4" string="stop and question airline passengers who look and act like drug couriers" type="VP">
          <tokens>
            <token id="13" string="stop" />
            <token id="14" string="and" />
            <token id="15" string="question" />
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="5" string="airline passengers who look and act like drug couriers" type="NP">
          <tokens>
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="6" string="the U.S. Supreme Court" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="U.S." />
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
          </tokens>
        </chunking>
        <chunking id="7" string="look and act like drug couriers" type="VP">
          <tokens>
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="8" string="who look and act like drug couriers" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="9" string="ruled that government agents may stop and question airline passengers who look and act like drug couriers" type="VP">
          <tokens>
            <token id="8" string="ruled" />
            <token id="9" string="that" />
            <token id="10" string="government" />
            <token id="11" string="agents" />
            <token id="12" string="may" />
            <token id="13" string="stop" />
            <token id="14" string="and" />
            <token id="15" string="question" />
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="10" string="may stop and question airline passengers who look and act like drug couriers" type="VP">
          <tokens>
            <token id="12" string="may" />
            <token id="13" string="stop" />
            <token id="14" string="and" />
            <token id="15" string="question" />
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
            <token id="18" string="who" />
            <token id="19" string="look" />
            <token id="20" string="and" />
            <token id="21" string="act" />
            <token id="22" string="like" />
            <token id="23" string="drug" />
            <token id="24" string="couriers" />
          </tokens>
        </chunking>
        <chunking id="11" string="airline passengers" type="NP">
          <tokens>
            <token id="16" string="airline" />
            <token id="17" string="passengers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">ruled</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Court</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Court</governor>
          <dependent id="5">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Court</governor>
          <dependent id="6">Supreme</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">ruled</governor>
          <dependent id="7">Court</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">ruled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">stop</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">agents</governor>
          <dependent id="10">government</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">stop</governor>
          <dependent id="11">agents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">stop</governor>
          <dependent id="12">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">ruled</governor>
          <dependent id="13">stop</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">stop</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">stop</governor>
          <dependent id="15">question</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">passengers</governor>
          <dependent id="16">airline</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">stop</governor>
          <dependent id="17">passengers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">look</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">passengers</governor>
          <dependent id="19">look</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">look</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">look</governor>
          <dependent id="21">act</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">couriers</governor>
          <dependent id="22">like</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">couriers</governor>
          <dependent id="23">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">look</governor>
          <dependent id="24">couriers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="U.S." />
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>But the court said brief detentions must be based on a person&amp;apost;s behavior, not just on race or appearance.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="brief" lemma="brief" stem="brief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="detentions" lemma="detention" stem="detent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="behavior" lemma="behavior" stem="behavior" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NN court)) (VP (VBD said) (SBAR (S (NP (JJ brief) (NNS detentions)) (VP (MD must) (VP (VB be) (VP (VBN based) (PP (PP (IN on) (NP (NP (DT a) (NN person) (POS 's)) (NN behavior))) (, ,) (CONJP (RB not) (RB just)) (PP (IN on) (NP (NN race) (CC or) (NN appearance)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a person 's behavior" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="2" string="race or appearance" type="NP">
          <tokens>
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="3" string="brief detentions" type="NP">
          <tokens>
            <token id="5" string="brief" />
            <token id="6" string="detentions" />
          </tokens>
        </chunking>
        <chunking id="4" string="be based on a person 's behavior , not just on race or appearance" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="based" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="just" />
            <token id="18" string="on" />
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="5" string="must be based on a person 's behavior , not just on race or appearance" type="VP">
          <tokens>
            <token id="7" string="must" />
            <token id="8" string="be" />
            <token id="9" string="based" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="just" />
            <token id="18" string="on" />
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="6" string="based on a person 's behavior , not just on race or appearance" type="VP">
          <tokens>
            <token id="9" string="based" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="just" />
            <token id="18" string="on" />
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="7" string="a person 's" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="brief detentions must be based on a person 's behavior , not just on race or appearance" type="SBAR">
          <tokens>
            <token id="5" string="brief" />
            <token id="6" string="detentions" />
            <token id="7" string="must" />
            <token id="8" string="be" />
            <token id="9" string="based" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="just" />
            <token id="18" string="on" />
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="9" string="said brief detentions must be based on a person 's behavior , not just on race or appearance" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="brief" />
            <token id="6" string="detentions" />
            <token id="7" string="must" />
            <token id="8" string="be" />
            <token id="9" string="based" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="person" />
            <token id="13" string="'s" />
            <token id="14" string="behavior" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="just" />
            <token id="18" string="on" />
            <token id="19" string="race" />
            <token id="20" string="or" />
            <token id="21" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="10" string="the court" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="court" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">court</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">court</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">detentions</governor>
          <dependent id="5">brief</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">based</governor>
          <dependent id="6">detentions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">based</governor>
          <dependent id="7">must</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">based</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="9">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">behavior</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">person</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">behavior</governor>
          <dependent id="12">person</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">person</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">based</governor>
          <dependent id="14">behavior</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">just</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">behavior</governor>
          <dependent id="17">just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">race</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">behavior</governor>
          <dependent id="19">race</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">race</governor>
          <dependent id="20">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">race</governor>
          <dependent id="21">appearance</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;Profiles are important and we use them, but exactly how we use them or what the profile is I cannot tell you,&amp;quot; said Los Angeles Police Department Cmdr. William Booth.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Profiles" lemma="profile" stem="profil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="use" lemma="use" stem="us" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="exactly" lemma="exactly" stem="exactli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="use" lemma="use" stem="us" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="30" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="Cmdr." lemma="Cmdr." stem="cmdr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="Booth" lemma="Booth" stem="booth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (NNS Profiles)) (VP (VBP are) (ADJP (JJ important)))) (CC and) (S (NP (PRP we)) (VP (VP (VBP use) (NP (PRP them))) (, ,) (CC but) (ADVP (RB exactly)) (SBAR (SBAR (WHADVP (WRB how)) (S (NP (PRP we)) (VP (VBP use) (NP (PRP them))))) (CC or) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN profile)) (VP (VBZ is) (SBAR (S (NP (PRP I)) (VP (MD can) (RB not) (VP (VB tell) (NP (PRP you))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Los) (NNP Angeles) (NNP Police) (NNP Department) (NNP Cmdr.) (NNP William) (NNP Booth)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="use them , but exactly how we use them or what the profile is I can not tell you" type="VP">
          <tokens>
            <token id="7" string="use" />
            <token id="8" string="them" />
            <token id="9" string="," />
            <token id="10" string="but" />
            <token id="11" string="exactly" />
            <token id="12" string="how" />
            <token id="13" string="we" />
            <token id="14" string="use" />
            <token id="15" string="them" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="the" />
            <token id="19" string="profile" />
            <token id="20" string="is" />
            <token id="21" string="I" />
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell you" type="VP">
          <tokens>
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="3" string="what the profile is I can not tell you" type="SBAR">
          <tokens>
            <token id="17" string="what" />
            <token id="18" string="the" />
            <token id="19" string="profile" />
            <token id="20" string="is" />
            <token id="21" string="I" />
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="21" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="how we use them or what the profile is I can not tell you" type="SBAR">
          <tokens>
            <token id="12" string="how" />
            <token id="13" string="we" />
            <token id="14" string="use" />
            <token id="15" string="them" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="the" />
            <token id="19" string="profile" />
            <token id="20" string="is" />
            <token id="21" string="I" />
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="Los Angeles Police Department Cmdr. William Booth" type="NP">
          <tokens>
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="Police" />
            <token id="32" string="Department" />
            <token id="33" string="Cmdr." />
            <token id="34" string="William" />
            <token id="35" string="Booth" />
          </tokens>
        </chunking>
        <chunking id="9" string="are important" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="important" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="12" string="how" />
          </tokens>
        </chunking>
        <chunking id="11" string="I can not tell you" type="SBAR">
          <tokens>
            <token id="21" string="I" />
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="12" string="important" type="ADJP">
          <tokens>
            <token id="4" string="important" />
          </tokens>
        </chunking>
        <chunking id="13" string="the profile" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="profile" />
          </tokens>
        </chunking>
        <chunking id="14" string="is I can not tell you" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="I" />
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="15" string="Profiles" type="NP">
          <tokens>
            <token id="2" string="Profiles" />
          </tokens>
        </chunking>
        <chunking id="16" string="can not tell you" type="VP">
          <tokens>
            <token id="22" string="can" />
            <token id="23" string="not" />
            <token id="24" string="tell" />
            <token id="25" string="you" />
          </tokens>
        </chunking>
        <chunking id="17" string="use them" type="VP">
          <tokens>
            <token id="7" string="use" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="how we use them" type="SBAR">
          <tokens>
            <token id="12" string="how" />
            <token id="13" string="we" />
            <token id="14" string="use" />
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="20" string="you" type="NP">
          <tokens>
            <token id="25" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">important</governor>
          <dependent id="2">Profiles</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">important</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="4">important</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">important</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">use</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">important</governor>
          <dependent id="7">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">use</governor>
          <dependent id="8">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">use</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">use</governor>
          <dependent id="11">exactly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">use</governor>
          <dependent id="12">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">use</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">use</governor>
          <dependent id="14">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">use</governor>
          <dependent id="15">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">use</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">is</governor>
          <dependent id="17">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">profile</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">is</governor>
          <dependent id="19">profile</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">use</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">tell</governor>
          <dependent id="21">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">tell</governor>
          <dependent id="22">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">tell</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">is</governor>
          <dependent id="24">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">tell</governor>
          <dependent id="25">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="29">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="30">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="31">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="32">Department</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="33">Cmdr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Booth</governor>
          <dependent id="34">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="35">Booth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="Police" />
            <token id="32" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="William Booth" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="William" />
            <token id="35" string="Booth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;It is certainly not something based on any prejudice or racism.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="prejudice" lemma="prejudice" stem="prejudic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ is) (ADVP (RB certainly)) (RB not) (NP (NN something)) (PP (VBN based) (PP (IN on) (NP (DT any) (NN prejudice) (CC or) (NN racism))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is certainly not something based on any prejudice or racism" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="certainly" />
            <token id="5" string="not" />
            <token id="6" string="something" />
            <token id="7" string="based" />
            <token id="8" string="on" />
            <token id="9" string="any" />
            <token id="10" string="prejudice" />
            <token id="11" string="or" />
            <token id="12" string="racism" />
          </tokens>
        </chunking>
        <chunking id="2" string="any prejudice or racism" type="NP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="prejudice" />
            <token id="11" string="or" />
            <token id="12" string="racism" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="something" type="NP">
          <tokens>
            <token id="6" string="something" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">something</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">something</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">something</governor>
          <dependent id="4">certainly</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">something</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">prejudice</governor>
          <dependent id="7">based</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="7">based</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">prejudice</governor>
          <dependent id="9">any</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">something</governor>
          <dependent id="10">prejudice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">prejudice</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">prejudice</governor>
          <dependent id="12">racism</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>It&amp;apost;s based on trying to protect the public.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="protect" lemma="protect" stem="protect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (VP (VBN based) (PP (IN on) (S (VP (VBG trying) (S (VP (TO to) (VP (VB protect) (NP (DT the) (NN public)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to protect the public" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="protect" />
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s based on trying to protect the public" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="based" />
            <token id="4" string="on" />
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="protect" />
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="3" string="the public" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="4" string="based on trying to protect the public" type="VP">
          <tokens>
            <token id="3" string="based" />
            <token id="4" string="on" />
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="protect" />
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="trying to protect the public" type="VP">
          <tokens>
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="protect" />
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="protect the public" type="VP">
          <tokens>
            <token id="7" string="protect" />
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">based</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">based</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">based</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">trying</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">based</governor>
          <dependent id="5">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">protect</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">trying</governor>
          <dependent id="7">protect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">public</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">protect</governor>
          <dependent id="9">public</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>He said that last year, 254 narcotics arrests were made at Los Angeles International Airport.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="254" lemma="254" stem="254" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="arrests" lemma="arrest" stem="arrest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Airport" lemma="Airport" stem="airport" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (IN that) (S (NP-TMP (JJ last) (NN year)) (, ,) (NP (NP (CD 254) (NNS narcotics)) (NP (NNS arrests))) (VP (VBD were) (VP (VBN made) (PP (IN at) (NP (NNP Los) (NNP Angeles) (NNP International) (NNP Airport)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that last year , 254 narcotics arrests were made at Los Angeles International Airport" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="last" />
            <token id="5" string="year" />
            <token id="6" string="," />
            <token id="7" string="254" />
            <token id="8" string="narcotics" />
            <token id="9" string="arrests" />
            <token id="10" string="were" />
            <token id="11" string="made" />
            <token id="12" string="at" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="2" string="254 narcotics" type="NP">
          <tokens>
            <token id="7" string="254" />
            <token id="8" string="narcotics" />
          </tokens>
        </chunking>
        <chunking id="3" string="made at Los Angeles International Airport" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="at" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="4" string="arrests" type="NP">
          <tokens>
            <token id="9" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="5" string="were made at Los Angeles International Airport" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="made" />
            <token id="12" string="at" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="6" string="Los Angeles International Airport" type="NP">
          <tokens>
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="7" string="254 narcotics arrests" type="NP">
          <tokens>
            <token id="7" string="254" />
            <token id="8" string="narcotics" />
            <token id="9" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="said that last year , 254 narcotics arrests were made at Los Angeles International Airport" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="last" />
            <token id="5" string="year" />
            <token id="6" string="," />
            <token id="7" string="254" />
            <token id="8" string="narcotics" />
            <token id="9" string="arrests" />
            <token id="10" string="were" />
            <token id="11" string="made" />
            <token id="12" string="at" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">made</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">year</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="11">made</governor>
          <dependent id="5">year</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">narcotics</governor>
          <dependent id="7">254</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">made</governor>
          <dependent id="8">narcotics</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">narcotics</governor>
          <dependent id="9">arrests</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">made</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Airport</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Airport</governor>
          <dependent id="13">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Airport</governor>
          <dependent id="14">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Airport</governor>
          <dependent id="15">International</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">made</governor>
          <dependent id="16">Airport</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="254" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="254" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles International Airport" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="International" />
            <token id="16" string="Airport" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="last" />
            <token id="5" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Through Aug. 3 of this year, there have been 121 such arrests.</content>
      <tokens>
        <token id="1" string="Through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Aug." lemma="Aug." stem="aug." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="121" lemma="121" stem="121" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="arrests" lemma="arrest" stem="arrest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Through) (NP (NP (NNP Aug.) (CD 3)) (PP (IN of) (NP (DT this) (NN year))))) (, ,) (NP (EX there)) (VP (VBP have) (VP (VBN been) (NP (CD 121) (JJ such) (NNS arrests)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="have been 121 such arrests" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="121" />
            <token id="12" string="such" />
            <token id="13" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="3" string="Aug. 3 of this year" type="NP">
          <tokens>
            <token id="2" string="Aug." />
            <token id="3" string="3" />
            <token id="4" string="of" />
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="been 121 such arrests" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="121" />
            <token id="12" string="such" />
            <token id="13" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="5" string="Aug. 3" type="NP">
          <tokens>
            <token id="2" string="Aug." />
            <token id="3" string="3" />
          </tokens>
        </chunking>
        <chunking id="6" string="121 such arrests" type="NP">
          <tokens>
            <token id="11" string="121" />
            <token id="12" string="such" />
            <token id="13" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="7" string="this year" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Aug.</governor>
          <dependent id="1">Through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">arrests</governor>
          <dependent id="2">Aug.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Aug.</governor>
          <dependent id="3">3</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">year</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">year</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Aug.</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">arrests</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">arrests</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">arrests</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">arrests</governor>
          <dependent id="11">121</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">arrests</governor>
          <dependent id="12">such</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">arrests</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Aug. 3 of this year" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Aug." />
            <token id="3" string="3" />
            <token id="4" string="of" />
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="121" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="121" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Frank Schults, chief of public affairs for the DEA in Washington, denied that his agency uses drug courier profiles.</content>
      <tokens>
        <token id="1" string="Frank" lemma="Frank" stem="frank" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Schults" lemma="Schults" stem="schult" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="affairs" lemma="affair" stem="affair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="DEA" lemma="DEA" stem="dea" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="uses" lemma="use" stem="us" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="profiles" lemma="profile" stem="profil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Frank) (NNP Schults)) (, ,) (NP (NP (NN chief)) (PP (IN of) (NP (NP (JJ public) (NNS affairs)) (PP (IN for) (NP (NP (DT the) (NNP DEA)) (PP (IN in) (NP (NNP Washington)))))))) (, ,)) (VP (VBD denied) (SBAR (IN that) (S (NP (PRP$ his) (NN agency)) (VP (VBZ uses) (NP (NN drug) (NN courier) (NNS profiles)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="chief of public affairs for the DEA in Washington" type="NP">
          <tokens>
            <token id="4" string="chief" />
            <token id="5" string="of" />
            <token id="6" string="public" />
            <token id="7" string="affairs" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="DEA" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="2" string="that his agency uses drug courier profiles" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="his" />
            <token id="17" string="agency" />
            <token id="18" string="uses" />
            <token id="19" string="drug" />
            <token id="20" string="courier" />
            <token id="21" string="profiles" />
          </tokens>
        </chunking>
        <chunking id="3" string="his agency" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="agency" />
          </tokens>
        </chunking>
        <chunking id="4" string="chief" type="NP">
          <tokens>
            <token id="4" string="chief" />
          </tokens>
        </chunking>
        <chunking id="5" string="drug courier profiles" type="NP">
          <tokens>
            <token id="19" string="drug" />
            <token id="20" string="courier" />
            <token id="21" string="profiles" />
          </tokens>
        </chunking>
        <chunking id="6" string="public affairs" type="NP">
          <tokens>
            <token id="6" string="public" />
            <token id="7" string="affairs" />
          </tokens>
        </chunking>
        <chunking id="7" string="denied that his agency uses drug courier profiles" type="VP">
          <tokens>
            <token id="14" string="denied" />
            <token id="15" string="that" />
            <token id="16" string="his" />
            <token id="17" string="agency" />
            <token id="18" string="uses" />
            <token id="19" string="drug" />
            <token id="20" string="courier" />
            <token id="21" string="profiles" />
          </tokens>
        </chunking>
        <chunking id="8" string="public affairs for the DEA in Washington" type="NP">
          <tokens>
            <token id="6" string="public" />
            <token id="7" string="affairs" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="DEA" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="9" string="Washington" type="NP">
          <tokens>
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="10" string="the DEA in Washington" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="DEA" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="11" string="Frank Schults" type="NP">
          <tokens>
            <token id="1" string="Frank" />
            <token id="2" string="Schults" />
          </tokens>
        </chunking>
        <chunking id="12" string="uses drug courier profiles" type="VP">
          <tokens>
            <token id="18" string="uses" />
            <token id="19" string="drug" />
            <token id="20" string="courier" />
            <token id="21" string="profiles" />
          </tokens>
        </chunking>
        <chunking id="13" string="the DEA" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="DEA" />
          </tokens>
        </chunking>
        <chunking id="14" string="Frank Schults , chief of public affairs for the DEA in Washington ," type="NP">
          <tokens>
            <token id="1" string="Frank" />
            <token id="2" string="Schults" />
            <token id="3" string="," />
            <token id="4" string="chief" />
            <token id="5" string="of" />
            <token id="6" string="public" />
            <token id="7" string="affairs" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="DEA" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
            <token id="13" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Schults</governor>
          <dependent id="1">Frank</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">denied</governor>
          <dependent id="2">Schults</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Schults</governor>
          <dependent id="4">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">affairs</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">affairs</governor>
          <dependent id="6">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chief</governor>
          <dependent id="7">affairs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">DEA</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">DEA</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">affairs</governor>
          <dependent id="10">DEA</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Washington</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">DEA</governor>
          <dependent id="12">Washington</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">denied</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">uses</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">agency</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">uses</governor>
          <dependent id="17">agency</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">denied</governor>
          <dependent id="18">uses</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">profiles</governor>
          <dependent id="19">drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">profiles</governor>
          <dependent id="20">courier</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">uses</governor>
          <dependent id="21">profiles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Frank Schults" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Frank" />
            <token id="2" string="Schults" />
          </tokens>
        </entity>
        <entity id="3" string="DEA" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="DEA" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;We have any number of investigative techniques and ways to identify people involved in moving drugs, but a profile is not one of them,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="investigative" lemma="investigative" stem="investig" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="techniques" lemma="technique" stem="techniqu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ways" lemma="way" stem="wai" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="moving" lemma="move" stem="move" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP We)) (VP (VBP have) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (JJ investigative) (NNS techniques) (CC and) (NNS ways)))) (S (VP (TO to) (VP (VB identify) (NP (NP (NNS people)) (VP (VBN involved) (PP (IN in) (S (VP (VBG moving) (NP (NNS drugs)))))))))))) (, ,) (CC but) (S (NP (DT a) (NN profile)) (VP (VBZ is) (RB not) (NP (NP (CD one)) (PP (IN of) (NP (PRP them))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drugs" type="NP">
          <tokens>
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="24" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="any number of investigative techniques and ways" type="NP">
          <tokens>
            <token id="4" string="any" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="investigative" />
            <token id="8" string="techniques" />
            <token id="9" string="and" />
            <token id="10" string="ways" />
          </tokens>
        </chunking>
        <chunking id="4" string="a profile" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="profile" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="identify people involved in moving drugs" type="VP">
          <tokens>
            <token id="12" string="identify" />
            <token id="13" string="people" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="moving drugs" type="VP">
          <tokens>
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="have any number of investigative techniques and ways to identify people involved in moving drugs" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="any" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="investigative" />
            <token id="8" string="techniques" />
            <token id="9" string="and" />
            <token id="10" string="ways" />
            <token id="11" string="to" />
            <token id="12" string="identify" />
            <token id="13" string="people" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="11" string="one of them" type="NP">
          <tokens>
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="people involved in moving drugs" type="NP">
          <tokens>
            <token id="13" string="people" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="involved in moving drugs" type="VP">
          <tokens>
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="14" string="any number" type="NP">
          <tokens>
            <token id="4" string="any" />
            <token id="5" string="number" />
          </tokens>
        </chunking>
        <chunking id="15" string="is not one of them" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="not" />
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="investigative techniques and ways" type="NP">
          <tokens>
            <token id="7" string="investigative" />
            <token id="8" string="techniques" />
            <token id="9" string="and" />
            <token id="10" string="ways" />
          </tokens>
        </chunking>
        <chunking id="17" string="to identify people involved in moving drugs" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="identify" />
            <token id="13" string="people" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="moving" />
            <token id="17" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="30" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">number</governor>
          <dependent id="4">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="5">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">techniques</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">techniques</governor>
          <dependent id="7">investigative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="8">techniques</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">techniques</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">techniques</governor>
          <dependent id="10">ways</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">identify</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">have</governor>
          <dependent id="12">identify</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">identify</governor>
          <dependent id="13">people</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">people</governor>
          <dependent id="14">involved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">moving</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">involved</governor>
          <dependent id="16">moving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">moving</governor>
          <dependent id="17">drugs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">have</governor>
          <dependent id="19">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">profile</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">one</governor>
          <dependent id="21">profile</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">one</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">one</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">have</governor>
          <dependent id="24">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">them</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">one</governor>
          <dependent id="26">them</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="17" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Neither Booth nor Schults would comment on the Morgan lawsuit, which is scheduled to go to trial for a second time next month in Los Angeles.</content>
      <tokens>
        <token id="1" string="Neither" lemma="neither" stem="neither" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Booth" lemma="Booth" stem="booth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Schults" lemma="Schults" stem="schult" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="comment" lemma="comment" stem="comment" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="10" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="21" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="22" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="27" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Neither)) (NP (NNP Booth) (CC nor) (NNP Schults))) (VP (MD would) (VP (VB comment) (PP (IN on) (NP (NP (DT the) (NNP Morgan) (NN lawsuit)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN scheduled) (S (VP (TO to) (VP (VB go) (PP (TO to) (NP (NN trial))) (PP (IN for) (NP (DT a) (JJ second) (NN time))) (NP-TMP (JJ next) (NN month)) (PP (IN in) (NP (NNP Los) (NNP Angeles)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Morgan lawsuit , which is scheduled to go to trial for a second time next month in Los Angeles" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Morgan" />
            <token id="10" string="lawsuit" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Morgan lawsuit" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Morgan" />
            <token id="10" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="4" string="scheduled to go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="5" string="Booth nor Schults" type="NP">
          <tokens>
            <token id="2" string="Booth" />
            <token id="3" string="nor" />
            <token id="4" string="Schults" />
          </tokens>
        </chunking>
        <chunking id="6" string="would comment on the Morgan lawsuit , which is scheduled to go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="comment" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="Morgan" />
            <token id="10" string="lawsuit" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="7" string="trial" type="NP">
          <tokens>
            <token id="18" string="trial" />
          </tokens>
        </chunking>
        <chunking id="8" string="a second time" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="Neither" type="NP">
          <tokens>
            <token id="1" string="Neither" />
          </tokens>
        </chunking>
        <chunking id="10" string="to go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="11" string="which is scheduled to go to trial for a second time next month in Los Angeles" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="12" string="is scheduled to go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="13" string="comment on the Morgan lawsuit , which is scheduled to go to trial for a second time next month in Los Angeles" type="VP">
          <tokens>
            <token id="6" string="comment" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="Morgan" />
            <token id="10" string="lawsuit" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="scheduled" />
            <token id="15" string="to" />
            <token id="16" string="go" />
            <token id="17" string="to" />
            <token id="18" string="trial" />
            <token id="19" string="for" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="time" />
            <token id="23" string="next" />
            <token id="24" string="month" />
            <token id="25" string="in" />
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="14" string="Los Angeles" type="NP">
          <tokens>
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="15" string="Neither Booth nor Schults" type="NP">
          <tokens>
            <token id="1" string="Neither" />
            <token id="2" string="Booth" />
            <token id="3" string="nor" />
            <token id="4" string="Schults" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">comment</governor>
          <dependent id="1">Neither</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Neither</governor>
          <dependent id="2">Booth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Booth</governor>
          <dependent id="3">nor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Booth</governor>
          <dependent id="4">Schults</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">comment</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">lawsuit</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">lawsuit</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">lawsuit</governor>
          <dependent id="9">Morgan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">comment</governor>
          <dependent id="10">lawsuit</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">scheduled</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">scheduled</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">lawsuit</governor>
          <dependent id="14">scheduled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">go</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">scheduled</governor>
          <dependent id="16">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">trial</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">go</governor>
          <dependent id="18">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">time</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">time</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">time</governor>
          <dependent id="21">second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">go</governor>
          <dependent id="22">time</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">month</governor>
          <dependent id="23">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">go</governor>
          <dependent id="24">month</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Angeles</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Angeles</governor>
          <dependent id="26">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">go</governor>
          <dependent id="27">Angeles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booth" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Booth" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Morgan" />
          </tokens>
        </entity>
        <entity id="3" string="a second" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="Schults" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Schults" />
          </tokens>
        </entity>
        <entity id="5" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Los" />
            <token id="27" string="Angeles" />
          </tokens>
        </entity>
        <entity id="6" string="next month" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="next" />
            <token id="24" string="month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Morgan is seeking unspecified damages, claiming that his civil rights were violated.</content>
      <tokens>
        <token id="1" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="seeking" lemma="seek" stem="seek" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="unspecified" lemma="unspecified" stem="unspecifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="claiming" lemma="claim" stem="claim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="violated" lemma="violate" stem="violat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Morgan)) (VP (VBZ is) (VP (VBG seeking) (NP (JJ unspecified) (NNS damages)) (, ,) (S (VP (VBG claiming) (SBAR (IN that) (S (NP (PRP$ his) (JJ civil) (NNS rights)) (VP (VBD were) (VP (VBN violated))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were violated" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="2" string="is seeking unspecified damages , claiming that his civil rights were violated" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="seeking" />
            <token id="4" string="unspecified" />
            <token id="5" string="damages" />
            <token id="6" string="," />
            <token id="7" string="claiming" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="were" />
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="3" string="violated" type="VP">
          <tokens>
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="4" string="seeking unspecified damages , claiming that his civil rights were violated" type="VP">
          <tokens>
            <token id="3" string="seeking" />
            <token id="4" string="unspecified" />
            <token id="5" string="damages" />
            <token id="6" string="," />
            <token id="7" string="claiming" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="were" />
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="5" string="his civil rights" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
          </tokens>
        </chunking>
        <chunking id="6" string="Morgan" type="NP">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="7" string="claiming that his civil rights were violated" type="VP">
          <tokens>
            <token id="7" string="claiming" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="were" />
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="8" string="that his civil rights were violated" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="were" />
            <token id="13" string="violated" />
          </tokens>
        </chunking>
        <chunking id="9" string="unspecified damages" type="NP">
          <tokens>
            <token id="4" string="unspecified" />
            <token id="5" string="damages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">seeking</governor>
          <dependent id="1">Morgan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">seeking</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">seeking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">damages</governor>
          <dependent id="4">unspecified</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">seeking</governor>
          <dependent id="5">damages</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">seeking</governor>
          <dependent id="7">claiming</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">violated</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">rights</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">rights</governor>
          <dependent id="10">civil</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">violated</governor>
          <dependent id="11">rights</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">violated</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">claiming</governor>
          <dependent id="13">violated</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Last April, a six-person federal jury rejected Morgan&amp;apost;s case.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="six-person" lemma="six-person" stem="six-person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="rejected" lemma="reject" stem="reject" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NNP April)) (, ,) (NP (DT a) (JJ six-person) (JJ federal) (NN jury)) (VP (VBD rejected) (NP (NP (NNP Morgan) (POS 's)) (NN case))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Morgan 's case" type="NP">
          <tokens>
            <token id="9" string="Morgan" />
            <token id="10" string="'s" />
            <token id="11" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="rejected Morgan 's case" type="VP">
          <tokens>
            <token id="8" string="rejected" />
            <token id="9" string="Morgan" />
            <token id="10" string="'s" />
            <token id="11" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="a six-person federal jury" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="six-person" />
            <token id="6" string="federal" />
            <token id="7" string="jury" />
          </tokens>
        </chunking>
        <chunking id="4" string="Morgan 's" type="NP">
          <tokens>
            <token id="9" string="Morgan" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">April</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">rejected</governor>
          <dependent id="2">April</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">jury</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">jury</governor>
          <dependent id="5">six-person</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">jury</governor>
          <dependent id="6">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">rejected</governor>
          <dependent id="7">jury</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">rejected</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">case</governor>
          <dependent id="9">Morgan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Morgan</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">rejected</governor>
          <dependent id="11">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last April" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="April" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>But two months later, U.S. District Judge Mariana R. Pfaelzer set aside the verdict after ruling that she had failed to instruct jurors that Morgan had been illegally detained by police.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="9" string="Mariana" lemma="Mariana" stem="mariana" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Pfaelzer" lemma="Pfaelzer" stem="pfaelzer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="aside" lemma="aside" stem="asid" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ruling" lemma="rule" stem="rule" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="failed" lemma="fail" stem="fail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="instruct" lemma="instruct" stem="instruct" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="illegally" lemma="illegally" stem="illeg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="detained" lemma="detain" stem="detain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP-TMP (CD two) (NNS months) (RB later)) (, ,) (NP (NNP U.S.) (NNP District) (NNP Judge) (NNP Mariana) (NNP R.) (NNP Pfaelzer)) (VP (VBD set) (PRT (RP aside)) (NP (DT the) (NN verdict)) (PP (IN after) (S (VP (VBG ruling) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD had) (VP (VBN failed) (S (VP (TO to) (VP (VB instruct) (NP (NP (NNS jurors)) (SBAR (WHNP (WDT that)) (S (NP (NNP Morgan)) (VP (VBD had) (VP (VBN been) (VP (ADVP (RB illegally)) (VBN detained) (PP (IN by) (NP (NN police)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="set aside the verdict after ruling that she had failed to instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="aside" />
            <token id="14" string="the" />
            <token id="15" string="verdict" />
            <token id="16" string="after" />
            <token id="17" string="ruling" />
            <token id="18" string="that" />
            <token id="19" string="she" />
            <token id="20" string="had" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="the verdict" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="3" string="been illegally detained by police" type="VP">
          <tokens>
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="had been illegally detained by police" type="VP">
          <tokens>
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="jurors that Morgan had been illegally detained by police" type="NP">
          <tokens>
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="U.S. District Judge Mariana R. Pfaelzer" type="NP">
          <tokens>
            <token id="6" string="U.S." />
            <token id="7" string="District" />
            <token id="8" string="Judge" />
            <token id="9" string="Mariana" />
            <token id="10" string="R." />
            <token id="11" string="Pfaelzer" />
          </tokens>
        </chunking>
        <chunking id="7" string="that she had failed to instruct jurors that Morgan had been illegally detained by police" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="she" />
            <token id="20" string="had" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="ruling that she had failed to instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="17" string="ruling" />
            <token id="18" string="that" />
            <token id="19" string="she" />
            <token id="20" string="had" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="9" string="that Morgan had been illegally detained by police" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="19" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="failed to instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="jurors" type="NP">
          <tokens>
            <token id="24" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="13" string="police" type="NP">
          <tokens>
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="14" string="had failed to instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="20" string="had" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="15" string="illegally detained by police" type="VP">
          <tokens>
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="16" string="instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
        <chunking id="17" string="Morgan" type="NP">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="18" string="to instruct jurors that Morgan had been illegally detained by police" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="instruct" />
            <token id="24" string="jurors" />
            <token id="25" string="that" />
            <token id="26" string="Morgan" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="illegally" />
            <token id="30" string="detained" />
            <token id="31" string="by" />
            <token id="32" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">set</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">months</governor>
          <dependent id="2">two</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">set</governor>
          <dependent id="3">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">months</governor>
          <dependent id="4">later</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Pfaelzer</governor>
          <dependent id="6">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Pfaelzer</governor>
          <dependent id="7">District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Pfaelzer</governor>
          <dependent id="8">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Pfaelzer</governor>
          <dependent id="9">Mariana</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Pfaelzer</governor>
          <dependent id="10">R.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">set</governor>
          <dependent id="11">Pfaelzer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">set</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">set</governor>
          <dependent id="13">aside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">verdict</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">set</governor>
          <dependent id="15">verdict</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">ruling</governor>
          <dependent id="16">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">set</governor>
          <dependent id="17">ruling</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">failed</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">failed</governor>
          <dependent id="19">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">failed</governor>
          <dependent id="20">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">ruling</governor>
          <dependent id="21">failed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">instruct</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">failed</governor>
          <dependent id="23">instruct</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">instruct</governor>
          <dependent id="24">jurors</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">detained</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">detained</governor>
          <dependent id="26">Morgan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">detained</governor>
          <dependent id="27">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">detained</governor>
          <dependent id="28">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">detained</governor>
          <dependent id="29">illegally</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">jurors</governor>
          <dependent id="30">detained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">police</governor>
          <dependent id="31">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">detained</governor>
          <dependent id="32">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two months later" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="two" />
            <token id="3" string="months" />
            <token id="4" string="later" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </entity>
        <entity id="4" string="Mariana R. Pfaelzer" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Mariana" />
            <token id="10" string="R." />
            <token id="11" string="Pfaelzer" />
          </tokens>
        </entity>
        <entity id="5" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="8" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;quot;There isn&amp;apost;t any possible other conclusion but that the stop was illegal,&amp;quot; the judge concluded.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="conclusion" lemma="conclusion" stem="conclus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stop" lemma="stop" stem="stop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBZ is) (RB n't) (NP (DT any) (JJ possible) (JJ other) (NN conclusion)) (ADVP (CC but)) (SBAR (IN that) (S (NP (DT the) (NN stop)) (VP (VBD was) (ADJP (JJ illegal))))))) (, ,) ('' '') (NP (DT the) (NN judge)) (VP (VBD concluded)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the stop" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="stop" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="is n't any possible other conclusion but that the stop was illegal" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="n't" />
            <token id="5" string="any" />
            <token id="6" string="possible" />
            <token id="7" string="other" />
            <token id="8" string="conclusion" />
            <token id="9" string="but" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="stop" />
            <token id="13" string="was" />
            <token id="14" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="4" string="any possible other conclusion" type="NP">
          <tokens>
            <token id="5" string="any" />
            <token id="6" string="possible" />
            <token id="7" string="other" />
            <token id="8" string="conclusion" />
          </tokens>
        </chunking>
        <chunking id="5" string="concluded" type="VP">
          <tokens>
            <token id="19" string="concluded" />
          </tokens>
        </chunking>
        <chunking id="6" string="that the stop was illegal" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="stop" />
            <token id="13" string="was" />
            <token id="14" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="7" string="illegal" type="ADJP">
          <tokens>
            <token id="14" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="8" string="the judge" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="judge" />
          </tokens>
        </chunking>
        <chunking id="9" string="was illegal" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="illegal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">concluded</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">is</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">conclusion</governor>
          <dependent id="5">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">conclusion</governor>
          <dependent id="6">possible</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">conclusion</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="8">conclusion</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">illegal</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">stop</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">illegal</governor>
          <dependent id="12">stop</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">illegal</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">is</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">judge</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">concluded</governor>
          <dependent id="18">judge</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">concluded</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Both Searle, a 20-year Police Department veteran, and William Woessner, a DEA agent who was subsequently dropped from the lawsuit, have denied that they did anything wrong.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="20-year" lemma="20-year" stem="20-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="7" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="8" string="veteran" lemma="veteran" stem="veteran" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Woessner" lemma="Woessner" stem="woessner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="DEA" lemma="DEA" stem="dea" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="subsequently" lemma="subsequently" stem="subsequ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="denied" lemma="deny" stem="deni" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT Both) (NNP Searle)) (, ,) (NP (DT a) (JJ 20-year) (NNP Police) (NNP Department) (NN veteran)) (, ,) (CC and) (NP (NNP William) (NNP Woessner))) (, ,) (NP (NP (DT a) (NNP DEA) (NN agent)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADVP (RB subsequently)) (VP (VBN dropped) (PP (IN from) (NP (DT the) (NN lawsuit)))))))) (, ,)) (VP (VBP have) (VP (VBN denied) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD did) (ADJP (NN anything) (JJ wrong))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have denied that they did anything wrong" type="VP">
          <tokens>
            <token id="25" string="have" />
            <token id="26" string="denied" />
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="did" />
            <token id="30" string="anything" />
            <token id="31" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="2" string="that they did anything wrong" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="did" />
            <token id="30" string="anything" />
            <token id="31" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="3" string="who was subsequently dropped from the lawsuit" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="subsequently" />
            <token id="20" string="dropped" />
            <token id="21" string="from" />
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="4" string="a DEA agent who was subsequently dropped from the lawsuit" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="DEA" />
            <token id="16" string="agent" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="subsequently" />
            <token id="20" string="dropped" />
            <token id="21" string="from" />
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="5" string="did anything wrong" type="VP">
          <tokens>
            <token id="29" string="did" />
            <token id="30" string="anything" />
            <token id="31" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="6" string="Both Searle" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="7" string="a DEA agent" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="DEA" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
        <chunking id="8" string="was subsequently dropped from the lawsuit" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="subsequently" />
            <token id="20" string="dropped" />
            <token id="21" string="from" />
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="28" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="denied that they did anything wrong" type="VP">
          <tokens>
            <token id="26" string="denied" />
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="did" />
            <token id="30" string="anything" />
            <token id="31" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="11" string="dropped from the lawsuit" type="VP">
          <tokens>
            <token id="20" string="dropped" />
            <token id="21" string="from" />
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="12" string="William Woessner" type="NP">
          <tokens>
            <token id="11" string="William" />
            <token id="12" string="Woessner" />
          </tokens>
        </chunking>
        <chunking id="13" string="anything wrong" type="ADJP">
          <tokens>
            <token id="30" string="anything" />
            <token id="31" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="14" string="the lawsuit" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="15" string="Both Searle , a 20-year Police Department veteran , and William Woessner" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Searle" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="20-year" />
            <token id="6" string="Police" />
            <token id="7" string="Department" />
            <token id="8" string="veteran" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="William" />
            <token id="12" string="Woessner" />
          </tokens>
        </chunking>
        <chunking id="16" string="Both Searle , a 20-year Police Department veteran , and William Woessner , a DEA agent who was subsequently dropped from the lawsuit ," type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="Searle" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="20-year" />
            <token id="6" string="Police" />
            <token id="7" string="Department" />
            <token id="8" string="veteran" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="William" />
            <token id="12" string="Woessner" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="DEA" />
            <token id="16" string="agent" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="subsequently" />
            <token id="20" string="dropped" />
            <token id="21" string="from" />
            <token id="22" string="the" />
            <token id="23" string="lawsuit" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="a 20-year Police Department veteran" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="20-year" />
            <token id="6" string="Police" />
            <token id="7" string="Department" />
            <token id="8" string="veteran" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Searle</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">denied</governor>
          <dependent id="2">Searle</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">veteran</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">veteran</governor>
          <dependent id="5">20-year</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">veteran</governor>
          <dependent id="6">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">veteran</governor>
          <dependent id="7">Department</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Searle</governor>
          <dependent id="8">veteran</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Searle</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Woessner</governor>
          <dependent id="11">William</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Searle</governor>
          <dependent id="12">Woessner</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">agent</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">agent</governor>
          <dependent id="15">DEA</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Searle</governor>
          <dependent id="16">agent</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">dropped</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">dropped</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">dropped</governor>
          <dependent id="19">subsequently</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">agent</governor>
          <dependent id="20">dropped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">lawsuit</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">lawsuit</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">dropped</governor>
          <dependent id="23">lawsuit</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">denied</governor>
          <dependent id="25">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">denied</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">did</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">did</governor>
          <dependent id="28">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">denied</governor>
          <dependent id="29">did</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="31">wrong</governor>
          <dependent id="30">anything</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">did</governor>
          <dependent id="31">wrong</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="William Woessner" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="William" />
            <token id="12" string="Woessner" />
          </tokens>
        </entity>
        <entity id="3" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Police" />
            <token id="7" string="Department" />
          </tokens>
        </entity>
        <entity id="4" string="20-year" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="20-year" />
          </tokens>
        </entity>
        <entity id="5" string="DEA" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="DEA" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;quot;I wish that this hadn&amp;apost;t happened,&amp;quot; Searle said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="wish" lemma="wish" stem="wish" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="happened" lemma="happen" stem="happen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP wish) (SBAR (IN that) (S (NP (DT this)) (VP (VBD had) (RB n't) (VP (VBN happened))))))) (, ,) ('' '') (NP (NNP Searle)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had n't happened" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="n't" />
            <token id="8" string="happened" />
          </tokens>
        </chunking>
        <chunking id="2" string="Searle" type="NP">
          <tokens>
            <token id="11" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="wish that this had n't happened" type="VP">
          <tokens>
            <token id="3" string="wish" />
            <token id="4" string="that" />
            <token id="5" string="this" />
            <token id="6" string="had" />
            <token id="7" string="n't" />
            <token id="8" string="happened" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="5" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="that this had n't happened" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="this" />
            <token id="6" string="had" />
            <token id="7" string="n't" />
            <token id="8" string="happened" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="happened" type="VP">
          <tokens>
            <token id="8" string="happened" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wish</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="3">wish</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">happened</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">happened</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">happened</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">happened</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">wish</governor>
          <dependent id="8">happened</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Searle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Searle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>&amp;quot;I wish (Morgan) luck now that I know who he is.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wish" lemma="wish" stem="wish" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="luck" lemma="luck" stem="luck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP wish) (S (-LRB- -LRB-) (NP (NNP Morgan)) (-RRB- -RRB-) (NP (NN luck))) (SBAR (ADVP (RB now)) (IN that) (S (NP (PRP I)) (VP (VBP know) (SBAR (WHNP (WP who)) (S (NP (PRP he)) (VP (VBZ is)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="know who he is" type="VP">
          <tokens>
            <token id="11" string="know" />
            <token id="12" string="who" />
            <token id="13" string="he" />
            <token id="14" string="is" />
          </tokens>
        </chunking>
        <chunking id="2" string="luck" type="NP">
          <tokens>
            <token id="7" string="luck" />
          </tokens>
        </chunking>
        <chunking id="3" string="Morgan" type="NP">
          <tokens>
            <token id="5" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="is" type="VP">
          <tokens>
            <token id="14" string="is" />
          </tokens>
        </chunking>
        <chunking id="6" string="now that I know who he is" type="SBAR">
          <tokens>
            <token id="8" string="now" />
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="know" />
            <token id="12" string="who" />
            <token id="13" string="he" />
            <token id="14" string="is" />
          </tokens>
        </chunking>
        <chunking id="7" string="who he is" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="he" />
            <token id="14" string="is" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="wish -LRB- Morgan -RRB- luck now that I know who he is" type="VP">
          <tokens>
            <token id="3" string="wish" />
            <token id="4" string="(" />
            <token id="5" string="Morgan" />
            <token id="6" string=")" />
            <token id="7" string="luck" />
            <token id="8" string="now" />
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="know" />
            <token id="12" string="who" />
            <token id="13" string="he" />
            <token id="14" string="is" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wish</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wish</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">luck</governor>
          <dependent id="5">Morgan</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">wish</governor>
          <dependent id="7">luck</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">know</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">know</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">know</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">wish</governor>
          <dependent id="11">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">is</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">is</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">know</governor>
          <dependent id="14">is</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>I just hope I never see him again.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB just)) (VP (VBP hope) (SBAR (S (NP (PRP I)) (ADVP (RB never)) (VP (VBP see) (NP (PRP him)) (ADVP (RB again)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I never see him again" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="never" />
            <token id="6" string="see" />
            <token id="7" string="him" />
            <token id="8" string="again" />
          </tokens>
        </chunking>
        <chunking id="2" string="see him again" type="VP">
          <tokens>
            <token id="6" string="see" />
            <token id="7" string="him" />
            <token id="8" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="hope I never see him again" type="VP">
          <tokens>
            <token id="3" string="hope" />
            <token id="4" string="I" />
            <token id="5" string="never" />
            <token id="6" string="see" />
            <token id="7" string="him" />
            <token id="8" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">hope</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">hope</governor>
          <dependent id="2">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">hope</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">see</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">see</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">hope</governor>
          <dependent id="6">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">see</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">see</governor>
          <dependent id="8">again</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Morgan could not be reached for comment.</content>
      <tokens>
        <token id="1" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Morgan)) (VP (MD could) (RB not) (VP (VB be) (VP (VBN reached) (PP (IN for) (NP (NN comment)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Morgan" type="NP">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="2" string="be reached for comment" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
          </tokens>
        </chunking>
        <chunking id="3" string="comment" type="NP">
          <tokens>
            <token id="7" string="comment" />
          </tokens>
        </chunking>
        <chunking id="4" string="could not be reached for comment" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="not" />
            <token id="4" string="be" />
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
          </tokens>
        </chunking>
        <chunking id="5" string="reached for comment" type="VP">
          <tokens>
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">reached</governor>
          <dependent id="1">Morgan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">reached</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">reached</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">reached</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reached</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">comment</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">reached</governor>
          <dependent id="7">comment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>But in court documents, he said that on March 15, 1988, he was waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament and was innocently making a phone call when Searle suddenly grabbed his shoulder and spun him around.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="documents" lemma="document" stem="document" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="waiting" lemma="wait" stem="wait" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="20" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Airport" lemma="Airport" stem="airport" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="connecting" lemma="connect" stem="connect" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="flight" lemma="flight" stem="flight" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="Tucson" lemma="Tucson" stem="tucson" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="attend" lemma="attend" stem="attend" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="golf" lemma="golf" stem="golf" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="tournament" lemma="tournament" stem="tournament" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="innocently" lemma="innocently" stem="innoc" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="43" string="suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="grabbed" lemma="grab" stem="grab" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="shoulder" lemma="shoulder" stem="shoulder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="spun" lemma="spin" stem="spun" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="50" string="around" lemma="around" stem="around" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN in) (NP (NN court) (NNS documents))) (, ,) (NP (PRP he)) (VP (VP (VBD said) (SBAR (IN that) (S (PP (IN on) (NP (NNP March) (CD 15) (, ,) (CD 1988))) (, ,) (NP (PRP he)) (VP (VBD was) (VP (VBG waiting) (PP (IN at) (NP (NP (NNP Los) (NNP Angeles) (NNP International) (NNP Airport)) (PP (IN for) (NP (NP (DT a) (VBG connecting) (NN flight)) (PP (TO to) (NP (NNP Tucson))) (S (VP (TO to) (VP (VB attend) (NP (DT a) (NN golf) (NN tournament)))))))))))))) (CC and) (VP (VBD was) (VP (ADVP (RB innocently)) (VBG making) (NP (NP (DT a) (NN phone) (NN call)) (SBAR (WHADVP (WRB when)) (S (NP (NNP Searle)) (VP (VP (ADVP (RB suddenly)) (VBD grabbed) (NP (PRP$ his) (NN shoulder))) (CC and) (VP (VBD spun) (NP (PRP him)) (ADVP (RB around)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was innocently making a phone call when Searle suddenly grabbed his shoulder and spun him around" type="VP">
          <tokens>
            <token id="35" string="was" />
            <token id="36" string="innocently" />
            <token id="37" string="making" />
            <token id="38" string="a" />
            <token id="39" string="phone" />
            <token id="40" string="call" />
            <token id="41" string="when" />
            <token id="42" string="Searle" />
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="2" string="a connecting flight to Tucson to attend a golf tournament" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="3" string="was waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="waiting" />
            <token id="18" string="at" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="4" string="a phone call when Searle suddenly grabbed his shoulder and spun him around" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="phone" />
            <token id="40" string="call" />
            <token id="41" string="when" />
            <token id="42" string="Searle" />
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="5" string="suddenly grabbed his shoulder" type="VP">
          <tokens>
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="6" string="court documents" type="NP">
          <tokens>
            <token id="3" string="court" />
            <token id="4" string="documents" />
          </tokens>
        </chunking>
        <chunking id="7" string="his shoulder" type="NP">
          <tokens>
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="8" string="waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" type="VP">
          <tokens>
            <token id="17" string="waiting" />
            <token id="18" string="at" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="9" string="said that on March 15 , 1988 , he was waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="that" />
            <token id="9" string="on" />
            <token id="10" string="March" />
            <token id="11" string="15" />
            <token id="12" string="," />
            <token id="13" string="1988" />
            <token id="14" string="," />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="waiting" />
            <token id="18" string="at" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="10" string="a golf tournament" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="11" string="a connecting flight" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
          </tokens>
        </chunking>
        <chunking id="12" string="said that on March 15 , 1988 , he was waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament and was innocently making a phone call when Searle suddenly grabbed his shoulder and spun him around" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="that" />
            <token id="9" string="on" />
            <token id="10" string="March" />
            <token id="11" string="15" />
            <token id="12" string="," />
            <token id="13" string="1988" />
            <token id="14" string="," />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="waiting" />
            <token id="18" string="at" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
            <token id="34" string="and" />
            <token id="35" string="was" />
            <token id="36" string="innocently" />
            <token id="37" string="making" />
            <token id="38" string="a" />
            <token id="39" string="phone" />
            <token id="40" string="call" />
            <token id="41" string="when" />
            <token id="42" string="Searle" />
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="spun him around" type="VP">
          <tokens>
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="15" string="suddenly grabbed his shoulder and spun him around" type="VP">
          <tokens>
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="16" string="innocently making a phone call when Searle suddenly grabbed his shoulder and spun him around" type="VP">
          <tokens>
            <token id="36" string="innocently" />
            <token id="37" string="making" />
            <token id="38" string="a" />
            <token id="39" string="phone" />
            <token id="40" string="call" />
            <token id="41" string="when" />
            <token id="42" string="Searle" />
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
        <chunking id="17" string="a phone call" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="phone" />
            <token id="40" string="call" />
          </tokens>
        </chunking>
        <chunking id="18" string="March 15 , 1988" type="NP">
          <tokens>
            <token id="10" string="March" />
            <token id="11" string="15" />
            <token id="12" string="," />
            <token id="13" string="1988" />
          </tokens>
        </chunking>
        <chunking id="19" string="Searle" type="NP">
          <tokens>
            <token id="42" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="20" string="that on March 15 , 1988 , he was waiting at Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="on" />
            <token id="10" string="March" />
            <token id="11" string="15" />
            <token id="12" string="," />
            <token id="13" string="1988" />
            <token id="14" string="," />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="waiting" />
            <token id="18" string="at" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="21" string="attend a golf tournament" type="VP">
          <tokens>
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="22" string="him" type="NP">
          <tokens>
            <token id="49" string="him" />
          </tokens>
        </chunking>
        <chunking id="23" string="Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" type="NP">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
            <token id="23" string="for" />
            <token id="24" string="a" />
            <token id="25" string="connecting" />
            <token id="26" string="flight" />
            <token id="27" string="to" />
            <token id="28" string="Tucson" />
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="24" string="when" type="WHADVP">
          <tokens>
            <token id="41" string="when" />
          </tokens>
        </chunking>
        <chunking id="25" string="to attend a golf tournament" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="attend" />
            <token id="31" string="a" />
            <token id="32" string="golf" />
            <token id="33" string="tournament" />
          </tokens>
        </chunking>
        <chunking id="26" string="Los Angeles International Airport" type="NP">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
          </tokens>
        </chunking>
        <chunking id="27" string="Tucson" type="NP">
          <tokens>
            <token id="28" string="Tucson" />
          </tokens>
        </chunking>
        <chunking id="28" string="when Searle suddenly grabbed his shoulder and spun him around" type="SBAR">
          <tokens>
            <token id="41" string="when" />
            <token id="42" string="Searle" />
            <token id="43" string="suddenly" />
            <token id="44" string="grabbed" />
            <token id="45" string="his" />
            <token id="46" string="shoulder" />
            <token id="47" string="and" />
            <token id="48" string="spun" />
            <token id="49" string="him" />
            <token id="50" string="around" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">documents</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">documents</governor>
          <dependent id="3">court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="4">documents</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">waiting</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">March</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">waiting</governor>
          <dependent id="10">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">March</governor>
          <dependent id="11">15</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">March</governor>
          <dependent id="13">1988</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">waiting</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">waiting</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="17">waiting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Airport</governor>
          <dependent id="18">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Airport</governor>
          <dependent id="19">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Airport</governor>
          <dependent id="20">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Airport</governor>
          <dependent id="21">International</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">waiting</governor>
          <dependent id="22">Airport</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">flight</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">flight</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">flight</governor>
          <dependent id="25">connecting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">Airport</governor>
          <dependent id="26">flight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Tucson</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">flight</governor>
          <dependent id="28">Tucson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">attend</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">flight</governor>
          <dependent id="30">attend</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">tournament</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">tournament</governor>
          <dependent id="32">golf</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">attend</governor>
          <dependent id="33">tournament</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">said</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">making</governor>
          <dependent id="35">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">making</governor>
          <dependent id="36">innocently</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">said</governor>
          <dependent id="37">making</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">call</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">call</governor>
          <dependent id="39">phone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">making</governor>
          <dependent id="40">call</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="44">grabbed</governor>
          <dependent id="41">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">grabbed</governor>
          <dependent id="42">Searle</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="44">grabbed</governor>
          <dependent id="43">suddenly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="40">call</governor>
          <dependent id="44">grabbed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">shoulder</governor>
          <dependent id="45">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="44">grabbed</governor>
          <dependent id="46">shoulder</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="44">grabbed</governor>
          <dependent id="47">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="44">grabbed</governor>
          <dependent id="48">spun</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="48">spun</governor>
          <dependent id="49">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="48">spun</governor>
          <dependent id="50">around</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March 15 , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="March" />
            <token id="11" string="15" />
            <token id="12" string="," />
            <token id="13" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="Searle" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles International Airport" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="International" />
            <token id="22" string="Airport" />
          </tokens>
        </entity>
        <entity id="4" string="Tucson" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Tucson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Asked to identify himself, Morgan said he told the officer that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it.</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="wallet" lemma="wallet" stem="wallet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="attache" lemma="attache" stem="attach" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="retrieve" lemma="retrieve" stem="retriev" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Asked) (S (VP (TO to) (VP (VB identify) (NP (PRP himself))))))) (, ,) (NP (NNP Morgan)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD told) (NP (NP (DT the) (NN officer)) (SBAR (SBAR (IN that) (S (NP (PRP$ his) (NN wallet)) (VP (VBD was) (PP (IN in) (NP (DT an) (NN attache) (NN case))) (PP (IN about) (ADVP (NP (CD 40) (NNS feet)) (RB away)))))) (CC but) (SBAR (WHNP (DT that)) (S (NP (NNP Searle)) (VP (VBD refused) (S (VP (TO to) (VP (VB let) (S (NP (PRP him)) (VP (VB retrieve) (NP (PRP it)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to let him retrieve it" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="was in an attache case about 40 feet away" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="told the officer that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it" type="VP">
          <tokens>
            <token id="9" string="told" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="he told the officer that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it" type="SBAR">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="told" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="his wallet" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="wallet" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="himself" type="NP">
          <tokens>
            <token id="4" string="himself" />
          </tokens>
        </chunking>
        <chunking id="10" string="the officer that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="let him retrieve it" type="VP">
          <tokens>
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="an attache case" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="retrieve it" type="VP">
          <tokens>
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="said he told the officer that his wallet was in an attache case about 40 feet away but that Searle refused to let him retrieve it" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="he" />
            <token id="9" string="told" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="Searle" type="NP">
          <tokens>
            <token id="26" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="16" string="to identify himself" type="VP">
          <tokens>
            <token id="2" string="to" />
            <token id="3" string="identify" />
            <token id="4" string="himself" />
          </tokens>
        </chunking>
        <chunking id="17" string="the officer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="18" string="him" type="NP">
          <tokens>
            <token id="30" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="identify himself" type="VP">
          <tokens>
            <token id="3" string="identify" />
            <token id="4" string="himself" />
          </tokens>
        </chunking>
        <chunking id="20" string="40 feet" type="NP">
          <tokens>
            <token id="21" string="40" />
            <token id="22" string="feet" />
          </tokens>
        </chunking>
        <chunking id="21" string="refused to let him retrieve it" type="VP">
          <tokens>
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="22" string="Asked to identify himself" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="to" />
            <token id="3" string="identify" />
            <token id="4" string="himself" />
          </tokens>
        </chunking>
        <chunking id="23" string="Morgan" type="NP">
          <tokens>
            <token id="6" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="24" string="that Searle refused to let him retrieve it" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="Searle" />
            <token id="27" string="refused" />
            <token id="28" string="to" />
            <token id="29" string="let" />
            <token id="30" string="him" />
            <token id="31" string="retrieve" />
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="25" string="that his wallet was in an attache case about 40 feet away" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="his" />
            <token id="14" string="wallet" />
            <token id="15" string="was" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="attache" />
            <token id="19" string="case" />
            <token id="20" string="about" />
            <token id="21" string="40" />
            <token id="22" string="feet" />
            <token id="23" string="away" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="7">said</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="3">identify</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Asked</governor>
          <dependent id="3">identify</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">identify</governor>
          <dependent id="4">himself</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">Morgan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">told</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="9">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">told</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">case</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">wallet</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">case</governor>
          <dependent id="14">wallet</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">case</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">case</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">case</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">case</governor>
          <dependent id="18">attache</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">officer</governor>
          <dependent id="19">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">away</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">feet</governor>
          <dependent id="21">40</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="23">away</governor>
          <dependent id="22">feet</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">case</governor>
          <dependent id="23">away</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">case</governor>
          <dependent id="24">but</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">refused</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">refused</governor>
          <dependent id="26">Searle</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">case</governor>
          <dependent id="27">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">let</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">refused</governor>
          <dependent id="29">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">retrieve</governor>
          <dependent id="30">him</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">let</governor>
          <dependent id="31">retrieve</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">retrieve</governor>
          <dependent id="32">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Morgan" />
          </tokens>
        </entity>
        <entity id="3" string="40" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="40" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>When a bystander -- who would later testify for Morgan -- recognized the former player and tried to intervene, both men claimed that Searle warned the man to stay away.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bystander" lemma="bystander" stem="bystand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="recognized" lemma="recognize" stem="recogn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="player" lemma="player" stem="player" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="intervene" lemma="intervene" stem="interven" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="warned" lemma="warn" stem="warn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NP (DT a) (NN bystander)) (PRN (: --) (SBAR (WHNP (WP who)) (S (VP (MD would) (ADVP (RB later)) (VP (VB testify) (PP (IN for) (NP (NNP Morgan))))))) (: --))) (VP (VP (VBD recognized) (NP (DT the) (JJ former) (NN player))) (CC and) (VP (VBD tried) (S (VP (TO to) (VP (VB intervene)))))))) (, ,) (NP (DT both) (NNS men)) (VP (VBD claimed) (SBAR (IN that) (S (NP (NNP Searle)) (VP (VBD warned) (NP (DT the) (NN man) (S (VP (TO to) (VP (VB stay) (ADVP (RB away)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When a bystander -- who would later testify for Morgan -- recognized the former player and tried to intervene" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="a" />
            <token id="3" string="bystander" />
            <token id="4" string="--" />
            <token id="5" string="who" />
            <token id="6" string="would" />
            <token id="7" string="later" />
            <token id="8" string="testify" />
            <token id="9" string="for" />
            <token id="10" string="Morgan" />
            <token id="11" string="--" />
            <token id="12" string="recognized" />
            <token id="13" string="the" />
            <token id="14" string="former" />
            <token id="15" string="player" />
            <token id="16" string="and" />
            <token id="17" string="tried" />
            <token id="18" string="to" />
            <token id="19" string="intervene" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Searle warned the man to stay away" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="Searle" />
            <token id="26" string="warned" />
            <token id="27" string="the" />
            <token id="28" string="man" />
            <token id="29" string="to" />
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="3" string="the man to stay away" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="man" />
            <token id="29" string="to" />
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="4" string="Searle" type="NP">
          <tokens>
            <token id="25" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="5" string="the former player" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="former" />
            <token id="15" string="player" />
          </tokens>
        </chunking>
        <chunking id="6" string="tried to intervene" type="VP">
          <tokens>
            <token id="17" string="tried" />
            <token id="18" string="to" />
            <token id="19" string="intervene" />
          </tokens>
        </chunking>
        <chunking id="7" string="to stay away" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="8" string="a bystander -- who would later testify for Morgan --" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="bystander" />
            <token id="4" string="--" />
            <token id="5" string="who" />
            <token id="6" string="would" />
            <token id="7" string="later" />
            <token id="8" string="testify" />
            <token id="9" string="for" />
            <token id="10" string="Morgan" />
            <token id="11" string="--" />
          </tokens>
        </chunking>
        <chunking id="9" string="testify for Morgan" type="VP">
          <tokens>
            <token id="8" string="testify" />
            <token id="9" string="for" />
            <token id="10" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="10" string="to intervene" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="intervene" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="who would later testify for Morgan" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="would" />
            <token id="7" string="later" />
            <token id="8" string="testify" />
            <token id="9" string="for" />
            <token id="10" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="13" string="claimed that Searle warned the man to stay away" type="VP">
          <tokens>
            <token id="23" string="claimed" />
            <token id="24" string="that" />
            <token id="25" string="Searle" />
            <token id="26" string="warned" />
            <token id="27" string="the" />
            <token id="28" string="man" />
            <token id="29" string="to" />
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="14" string="a bystander" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="bystander" />
          </tokens>
        </chunking>
        <chunking id="15" string="recognized the former player and tried to intervene" type="VP">
          <tokens>
            <token id="12" string="recognized" />
            <token id="13" string="the" />
            <token id="14" string="former" />
            <token id="15" string="player" />
            <token id="16" string="and" />
            <token id="17" string="tried" />
            <token id="18" string="to" />
            <token id="19" string="intervene" />
          </tokens>
        </chunking>
        <chunking id="16" string="both men" type="NP">
          <tokens>
            <token id="21" string="both" />
            <token id="22" string="men" />
          </tokens>
        </chunking>
        <chunking id="17" string="Morgan" type="NP">
          <tokens>
            <token id="10" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="18" string="warned the man to stay away" type="VP">
          <tokens>
            <token id="26" string="warned" />
            <token id="27" string="the" />
            <token id="28" string="man" />
            <token id="29" string="to" />
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="19" string="stay away" type="VP">
          <tokens>
            <token id="30" string="stay" />
            <token id="31" string="away" />
          </tokens>
        </chunking>
        <chunking id="20" string="would later testify for Morgan" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="later" />
            <token id="8" string="testify" />
            <token id="9" string="for" />
            <token id="10" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="21" string="intervene" type="VP">
          <tokens>
            <token id="19" string="intervene" />
          </tokens>
        </chunking>
        <chunking id="22" string="recognized the former player" type="VP">
          <tokens>
            <token id="12" string="recognized" />
            <token id="13" string="the" />
            <token id="14" string="former" />
            <token id="15" string="player" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="12">recognized</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">bystander</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">recognized</governor>
          <dependent id="3">bystander</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">testify</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">testify</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">testify</governor>
          <dependent id="7">later</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">bystander</governor>
          <dependent id="8">testify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Morgan</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">testify</governor>
          <dependent id="10">Morgan</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">claimed</governor>
          <dependent id="12">recognized</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">player</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">player</governor>
          <dependent id="14">former</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">recognized</governor>
          <dependent id="15">player</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">recognized</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">recognized</governor>
          <dependent id="17">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">intervene</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">tried</governor>
          <dependent id="19">intervene</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">men</governor>
          <dependent id="21">both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">claimed</governor>
          <dependent id="22">men</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">warned</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">warned</governor>
          <dependent id="25">Searle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">claimed</governor>
          <dependent id="26">warned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">man</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">warned</governor>
          <dependent id="28">man</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">stay</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">man</governor>
          <dependent id="30">stay</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">stay</governor>
          <dependent id="31">away</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Minutes later, Morgan said, Searle grabbed him by the neck and they fell to the floor.</content>
      <tokens>
        <token id="1" string="Minutes" lemma="Minutes" stem="minut" pos="NNPS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="grabbed" lemma="grab" stem="grab" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="neck" lemma="neck" stem="neck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="fell" lemma="fall" stem="fell" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="floor" lemma="floor" stem="floor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNPS Minutes)) (ADVP (RB later)) (, ,) (NP (NNP Morgan)) (VP (VBD said))) (, ,) (S (NP (NNP Searle)) (VP (VBD grabbed) (NP (PRP him)) (PP (IN by) (NP (DT the) (NN neck))))) (CC and) (S (NP (PRP they)) (VP (VBD fell) (PP (TO to) (NP (DT the) (NN floor))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="the floor" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="floor" />
          </tokens>
        </chunking>
        <chunking id="3" string="Searle" type="NP">
          <tokens>
            <token id="7" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="4" string="grabbed him by the neck" type="VP">
          <tokens>
            <token id="8" string="grabbed" />
            <token id="9" string="him" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="neck" />
          </tokens>
        </chunking>
        <chunking id="5" string="Morgan" type="NP">
          <tokens>
            <token id="4" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="6" string="fell to the floor" type="VP">
          <tokens>
            <token id="15" string="fell" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="floor" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="the neck" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="neck" />
          </tokens>
        </chunking>
        <chunking id="10" string="Minutes" type="NP">
          <tokens>
            <token id="1" string="Minutes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="1">Minutes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">said</governor>
          <dependent id="2">later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">Morgan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">grabbed</governor>
          <dependent id="7">Searle</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">said</governor>
          <dependent id="8">grabbed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">grabbed</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">neck</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">neck</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">grabbed</governor>
          <dependent id="12">neck</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">said</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">fell</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">said</governor>
          <dependent id="15">fell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">floor</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">floor</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">fell</governor>
          <dependent id="18">floor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Minutes later" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Minutes" />
            <token id="2" string="later" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Searle" />
          </tokens>
        </entity>
        <entity id="3" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Morgan said the officer then put a knee in his back, wrenched his arms behind him and handcuffed him.</content>
      <tokens>
        <token id="1" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="knee" lemma="knee" stem="knee" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="wrenched" lemma="wrench" stem="wrench" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="arms" lemma="arm" stem="arm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="handcuffed" lemma="handcuff" stem="handcuf" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Morgan)) (VP (VBD said) (SBAR (S (NP (DT the) (NN officer)) (ADVP (RB then)) (VP (VP (VBD put) (NP (DT a) (NN knee)) (PP (IN in) (NP (PRP$ his) (NN back)))) (, ,) (VP (VBD wrenched) (NP (PRP$ his) (NNS arms)) (PP (IN behind) (NP (PRP him)))) (CC and) (VP (VBD handcuffed) (NP (PRP him))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wrenched his arms behind him" type="VP">
          <tokens>
            <token id="13" string="wrenched" />
            <token id="14" string="his" />
            <token id="15" string="arms" />
            <token id="16" string="behind" />
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="his back" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="3" string="his arms" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="arms" />
          </tokens>
        </chunking>
        <chunking id="4" string="Morgan" type="NP">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="5" string="put a knee in his back" type="VP">
          <tokens>
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="knee" />
            <token id="9" string="in" />
            <token id="10" string="his" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="6" string="said the officer then put a knee in his back , wrenched his arms behind him and handcuffed him" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="officer" />
            <token id="5" string="then" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="knee" />
            <token id="9" string="in" />
            <token id="10" string="his" />
            <token id="11" string="back" />
            <token id="12" string="," />
            <token id="13" string="wrenched" />
            <token id="14" string="his" />
            <token id="15" string="arms" />
            <token id="16" string="behind" />
            <token id="17" string="him" />
            <token id="18" string="and" />
            <token id="19" string="handcuffed" />
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="the officer then put a knee in his back , wrenched his arms behind him and handcuffed him" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officer" />
            <token id="5" string="then" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="knee" />
            <token id="9" string="in" />
            <token id="10" string="his" />
            <token id="11" string="back" />
            <token id="12" string="," />
            <token id="13" string="wrenched" />
            <token id="14" string="his" />
            <token id="15" string="arms" />
            <token id="16" string="behind" />
            <token id="17" string="him" />
            <token id="18" string="and" />
            <token id="19" string="handcuffed" />
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="the officer" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officer" />
          </tokens>
        </chunking>
        <chunking id="9" string="a knee" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="knee" />
          </tokens>
        </chunking>
        <chunking id="10" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="handcuffed him" type="VP">
          <tokens>
            <token id="19" string="handcuffed" />
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="put a knee in his back , wrenched his arms behind him and handcuffed him" type="VP">
          <tokens>
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="knee" />
            <token id="9" string="in" />
            <token id="10" string="his" />
            <token id="11" string="back" />
            <token id="12" string="," />
            <token id="13" string="wrenched" />
            <token id="14" string="his" />
            <token id="15" string="arms" />
            <token id="16" string="behind" />
            <token id="17" string="him" />
            <token id="18" string="and" />
            <token id="19" string="handcuffed" />
            <token id="20" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Morgan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">officer</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">put</governor>
          <dependent id="4">officer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">put</governor>
          <dependent id="5">then</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">knee</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">put</governor>
          <dependent id="8">knee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">back</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">back</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">put</governor>
          <dependent id="11">back</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">put</governor>
          <dependent id="13">wrenched</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">arms</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">wrenched</governor>
          <dependent id="15">arms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">him</governor>
          <dependent id="16">behind</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">wrenched</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">put</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">put</governor>
          <dependent id="19">handcuffed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">handcuffed</governor>
          <dependent id="20">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>He was taken to a small children&amp;apost;s nursery in the terminal and interrogated, but within minutes the officers had confirmed his identity, Morgan said.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="nursery" lemma="nursery" stem="nurseri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="terminal" lemma="terminal" stem="termin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="interrogated" lemma="interrogate" stem="interrog" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="identity" lemma="identity" stem="ident" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (PRP He)) (VP (VBD was) (VP (VP (VBN taken) (PP (TO to) (NP (NP (DT a) (JJ small) (NNS children) (POS 's)) (NN nursery))) (PP (IN in) (NP (DT the) (ADJP (JJ terminal))))) (CC and) (VP (VBN interrogated))))) (, ,) (CC but) (S (PP (IN within) (NP (NNS minutes))) (NP (DT the) (NNS officers)) (VP (VBD had) (VP (VBN confirmed) (NP (PRP$ his) (NN identity)))))) (, ,) (NP (NNP Morgan)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confirmed his identity" type="VP">
          <tokens>
            <token id="22" string="confirmed" />
            <token id="23" string="his" />
            <token id="24" string="identity" />
          </tokens>
        </chunking>
        <chunking id="2" string="a small children 's" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="small" />
            <token id="7" string="children" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="interrogated" type="VP">
          <tokens>
            <token id="14" string="interrogated" />
          </tokens>
        </chunking>
        <chunking id="4" string="minutes" type="NP">
          <tokens>
            <token id="18" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="5" string="his identity" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="identity" />
          </tokens>
        </chunking>
        <chunking id="6" string="taken to a small children 's nursery in the terminal and interrogated" type="VP">
          <tokens>
            <token id="3" string="taken" />
            <token id="4" string="to" />
            <token id="5" string="a" />
            <token id="6" string="small" />
            <token id="7" string="children" />
            <token id="8" string="'s" />
            <token id="9" string="nursery" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="terminal" />
            <token id="13" string="and" />
            <token id="14" string="interrogated" />
          </tokens>
        </chunking>
        <chunking id="7" string="the terminal" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="8" string="terminal" type="ADJP">
          <tokens>
            <token id="12" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="9" string="had confirmed his identity" type="VP">
          <tokens>
            <token id="21" string="had" />
            <token id="22" string="confirmed" />
            <token id="23" string="his" />
            <token id="24" string="identity" />
          </tokens>
        </chunking>
        <chunking id="10" string="Morgan" type="NP">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="11" string="a small children 's nursery" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="small" />
            <token id="7" string="children" />
            <token id="8" string="'s" />
            <token id="9" string="nursery" />
          </tokens>
        </chunking>
        <chunking id="12" string="taken to a small children 's nursery in the terminal" type="VP">
          <tokens>
            <token id="3" string="taken" />
            <token id="4" string="to" />
            <token id="5" string="a" />
            <token id="6" string="small" />
            <token id="7" string="children" />
            <token id="8" string="'s" />
            <token id="9" string="nursery" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="terminal" />
          </tokens>
        </chunking>
        <chunking id="13" string="the officers" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="officers" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="27" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="was taken to a small children 's nursery in the terminal and interrogated" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="taken" />
            <token id="4" string="to" />
            <token id="5" string="a" />
            <token id="6" string="small" />
            <token id="7" string="children" />
            <token id="8" string="'s" />
            <token id="9" string="nursery" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="terminal" />
            <token id="13" string="and" />
            <token id="14" string="interrogated" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">taken</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">taken</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="3">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">nursery</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">children</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">children</governor>
          <dependent id="6">small</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">nursery</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">children</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">taken</governor>
          <dependent id="9">nursery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">terminal</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">terminal</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">taken</governor>
          <dependent id="12">terminal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">taken</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">taken</governor>
          <dependent id="14">interrogated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">taken</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">minutes</governor>
          <dependent id="17">within</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">confirmed</governor>
          <dependent id="18">minutes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">officers</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">confirmed</governor>
          <dependent id="20">officers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">confirmed</governor>
          <dependent id="21">had</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">taken</governor>
          <dependent id="22">confirmed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">identity</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">confirmed</governor>
          <dependent id="24">identity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">Morgan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </entity>
        <entity id="2" string="minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="minutes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Searle then offered to free him if he would forget the matter, according to Morgan&amp;apost;s lawsuit.</content>
      <tokens>
        <token id="1" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="offered" lemma="offer" stem="offer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="forget" lemma="forget" stem="forget" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Searle)) (ADVP (RB then)) (VP (VBD offered) (S (VP (TO to) (VP (JJ free) (NP (PRP him)) (SBAR (IN if) (S (NP (PRP he)) (VP (MD would) (VP (VB forget) (NP (DT the) (NN matter))))))))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (NNP Morgan) (POS 's)) (NN lawsuit))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Morgan 's lawsuit" type="NP">
          <tokens>
            <token id="16" string="Morgan" />
            <token id="17" string="'s" />
            <token id="18" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="2" string="to free him if he would forget the matter" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="free" />
            <token id="6" string="him" />
            <token id="7" string="if" />
            <token id="8" string="he" />
            <token id="9" string="would" />
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
        <chunking id="3" string="Searle" type="NP">
          <tokens>
            <token id="1" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="4" string="if he would forget the matter" type="SBAR">
          <tokens>
            <token id="7" string="if" />
            <token id="8" string="he" />
            <token id="9" string="would" />
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
        <chunking id="5" string="forget the matter" type="VP">
          <tokens>
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
        <chunking id="6" string="free him if he would forget the matter" type="VP">
          <tokens>
            <token id="5" string="free" />
            <token id="6" string="him" />
            <token id="7" string="if" />
            <token id="8" string="he" />
            <token id="9" string="would" />
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="offered to free him if he would forget the matter , according to Morgan 's lawsuit" type="VP">
          <tokens>
            <token id="3" string="offered" />
            <token id="4" string="to" />
            <token id="5" string="free" />
            <token id="6" string="him" />
            <token id="7" string="if" />
            <token id="8" string="he" />
            <token id="9" string="would" />
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="," />
            <token id="14" string="according" />
            <token id="15" string="to" />
            <token id="16" string="Morgan" />
            <token id="17" string="'s" />
            <token id="18" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="10" string="Morgan 's" type="NP">
          <tokens>
            <token id="16" string="Morgan" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="would forget the matter" type="VP">
          <tokens>
            <token id="9" string="would" />
            <token id="10" string="forget" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
        <chunking id="12" string="the matter" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">offered</governor>
          <dependent id="1">Searle</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">offered</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">offered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">free</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">offered</governor>
          <dependent id="5">free</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">free</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">forget</governor>
          <dependent id="7">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">forget</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">forget</governor>
          <dependent id="9">would</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">free</governor>
          <dependent id="10">forget</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">matter</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">forget</governor>
          <dependent id="12">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">lawsuit</governor>
          <dependent id="14">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">according</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">lawsuit</governor>
          <dependent id="16">Morgan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Morgan</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">offered</governor>
          <dependent id="18">lawsuit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Instead, Morgan filed his complaint, in part, to discourage similar incidents from occurring, his attorneys said.</content>
      <tokens>
        <token id="1" string="Instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="filed" lemma="file" stem="file" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="discourage" lemma="discourage" stem="discourag" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="incidents" lemma="incident" stem="incid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="occurring" lemma="occur" stem="occur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Instead)) (PRN (, ,) (S (NP (NNP Morgan)) (VP (VBD filed) (NP (PRP$ his) (NN complaint)) (, ,) (PP (IN in) (NP (NN part))) (, ,) (S (VP (TO to) (VP (VB discourage) (NP (JJ similar) (NNS incidents)) (PP (IN from) (S (VP (VBG occurring))))))))) (, ,)) (NP (PRP$ his) (NNS attorneys)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to discourage similar incidents from occurring" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="discourage" />
            <token id="13" string="similar" />
            <token id="14" string="incidents" />
            <token id="15" string="from" />
            <token id="16" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="2" string="Morgan" type="NP">
          <tokens>
            <token id="3" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="3" string="part" type="NP">
          <tokens>
            <token id="9" string="part" />
          </tokens>
        </chunking>
        <chunking id="4" string="similar incidents" type="NP">
          <tokens>
            <token id="13" string="similar" />
            <token id="14" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="5" string="occurring" type="VP">
          <tokens>
            <token id="16" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="6" string="his attorneys" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="7" string="his complaint" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="filed his complaint , in part , to discourage similar incidents from occurring" type="VP">
          <tokens>
            <token id="4" string="filed" />
            <token id="5" string="his" />
            <token id="6" string="complaint" />
            <token id="7" string="," />
            <token id="8" string="in" />
            <token id="9" string="part" />
            <token id="10" string="," />
            <token id="11" string="to" />
            <token id="12" string="discourage" />
            <token id="13" string="similar" />
            <token id="14" string="incidents" />
            <token id="15" string="from" />
            <token id="16" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="10" string="discourage similar incidents from occurring" type="VP">
          <tokens>
            <token id="12" string="discourage" />
            <token id="13" string="similar" />
            <token id="14" string="incidents" />
            <token id="15" string="from" />
            <token id="16" string="occurring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="20">said</governor>
          <dependent id="1">Instead</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">filed</governor>
          <dependent id="3">Morgan</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">said</governor>
          <dependent id="4">filed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">complaint</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">filed</governor>
          <dependent id="6">complaint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">part</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">filed</governor>
          <dependent id="9">part</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">discourage</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">filed</governor>
          <dependent id="12">discourage</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">incidents</governor>
          <dependent id="13">similar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">discourage</governor>
          <dependent id="14">incidents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">occurring</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">discourage</governor>
          <dependent id="16">occurring</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">attorneys</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">attorneys</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;This happened to Joe Morgan, but it really is applicable to any black person who uses Los Angeles airport,&amp;quot; said Oakland attorney Edwin Wilson Jr., who also is black.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="applicable" lemma="applicable" stem="applic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="uses" lemma="use" stem="us" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="20" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="airport" lemma="airport" stem="airport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Oakland" lemma="Oakland" stem="oakland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Edwin" lemma="Edwin" stem="edwin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (DT This)) (VP (VBD happened) (PP (TO to) (NP (NNP Joe) (NNP Morgan))))) (, ,) (CC but) (S (NP (PRP it)) (ADVP (RB really)) (VP (VBZ is) (ADJP (JJ applicable) (PP (TO to) (NP (NP (DT any) (JJ black) (NN person)) (SBAR (WHNP (WP who)) (S (VP (VBZ uses) (NP (NNP Los) (NNP Angeles) (NN airport))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Oakland) (NN attorney) (NNP Edwin) (NNP Wilson) (NNP Jr.)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB also)) (VP (VBZ is) (ADJP (JJ black)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Los Angeles airport" type="NP">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="2" string="Oakland attorney Edwin Wilson Jr. , who also is black" type="NP">
          <tokens>
            <token id="25" string="Oakland" />
            <token id="26" string="attorney" />
            <token id="27" string="Edwin" />
            <token id="28" string="Wilson" />
            <token id="29" string="Jr." />
            <token id="30" string="," />
            <token id="31" string="who" />
            <token id="32" string="also" />
            <token id="33" string="is" />
            <token id="34" string="black" />
          </tokens>
        </chunking>
        <chunking id="3" string="black" type="ADJP">
          <tokens>
            <token id="34" string="black" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="who uses Los Angeles airport" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="uses" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="6" string="uses Los Angeles airport" type="VP">
          <tokens>
            <token id="18" string="uses" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="7" string="is applicable to any black person who uses Los Angeles airport" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="applicable" />
            <token id="13" string="to" />
            <token id="14" string="any" />
            <token id="15" string="black" />
            <token id="16" string="person" />
            <token id="17" string="who" />
            <token id="18" string="uses" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="8" string="Oakland attorney Edwin Wilson Jr." type="NP">
          <tokens>
            <token id="25" string="Oakland" />
            <token id="26" string="attorney" />
            <token id="27" string="Edwin" />
            <token id="28" string="Wilson" />
            <token id="29" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="9" string="is black" type="VP">
          <tokens>
            <token id="33" string="is" />
            <token id="34" string="black" />
          </tokens>
        </chunking>
        <chunking id="10" string="happened to Joe Morgan" type="VP">
          <tokens>
            <token id="3" string="happened" />
            <token id="4" string="to" />
            <token id="5" string="Joe" />
            <token id="6" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="11" string="who also is black" type="SBAR">
          <tokens>
            <token id="31" string="who" />
            <token id="32" string="also" />
            <token id="33" string="is" />
            <token id="34" string="black" />
          </tokens>
        </chunking>
        <chunking id="12" string="Joe Morgan" type="NP">
          <tokens>
            <token id="5" string="Joe" />
            <token id="6" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="13" string="applicable to any black person who uses Los Angeles airport" type="ADJP">
          <tokens>
            <token id="12" string="applicable" />
            <token id="13" string="to" />
            <token id="14" string="any" />
            <token id="15" string="black" />
            <token id="16" string="person" />
            <token id="17" string="who" />
            <token id="18" string="uses" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="14" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="15" string="any black person who uses Los Angeles airport" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="black" />
            <token id="16" string="person" />
            <token id="17" string="who" />
            <token id="18" string="uses" />
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
            <token id="21" string="airport" />
          </tokens>
        </chunking>
        <chunking id="16" string="any black person" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="black" />
            <token id="16" string="person" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">happened</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="3">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Morgan</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Morgan</governor>
          <dependent id="5">Joe</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">happened</governor>
          <dependent id="6">Morgan</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">happened</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">applicable</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">applicable</governor>
          <dependent id="10">really</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">applicable</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">happened</governor>
          <dependent id="12">applicable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">person</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">person</governor>
          <dependent id="14">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">person</governor>
          <dependent id="15">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">applicable</governor>
          <dependent id="16">person</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">uses</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">person</governor>
          <dependent id="18">uses</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">airport</governor>
          <dependent id="19">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">airport</governor>
          <dependent id="20">Angeles</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">uses</governor>
          <dependent id="21">airport</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Jr.</governor>
          <dependent id="25">Oakland</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Jr.</governor>
          <dependent id="26">attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Jr.</governor>
          <dependent id="27">Edwin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Jr.</governor>
          <dependent id="28">Wilson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="29">Jr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">black</governor>
          <dependent id="31">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">black</governor>
          <dependent id="32">also</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">black</governor>
          <dependent id="33">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">Jr.</governor>
          <dependent id="34">black</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Edwin Wilson Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Edwin" />
            <token id="28" string="Wilson" />
            <token id="29" string="Jr." />
          </tokens>
        </entity>
        <entity id="2" string="Joe Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Joe" />
            <token id="6" string="Morgan" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Los" />
            <token id="20" string="Angeles" />
          </tokens>
        </entity>
        <entity id="4" string="Oakland" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Oakland" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>&amp;quot;If it wasn&amp;apost;t Joe, this could have happened to me or my father or to any other black person.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="happened" lemma="happen" stem="happen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP it)) (VP (VBD was) (RB n't) (NP (NNP Joe))))) (, ,) (NP (DT this)) (VP (MD could) (VP (VB have) (VP (VBN happened) (PP (PP (TO to) (NP (NP (PRP me)) (CC or) (NP (PRP$ my) (NN father)))) (CC or) (PP (TO to) (NP (DT any) (JJ other) (JJ black) (NN person))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was n't Joe" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="n't" />
            <token id="6" string="Joe" />
          </tokens>
        </chunking>
        <chunking id="2" string="me or my father" type="NP">
          <tokens>
            <token id="13" string="me" />
            <token id="14" string="or" />
            <token id="15" string="my" />
            <token id="16" string="father" />
          </tokens>
        </chunking>
        <chunking id="3" string="have happened to me or my father or to any other black person" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="happened" />
            <token id="12" string="to" />
            <token id="13" string="me" />
            <token id="14" string="or" />
            <token id="15" string="my" />
            <token id="16" string="father" />
            <token id="17" string="or" />
            <token id="18" string="to" />
            <token id="19" string="any" />
            <token id="20" string="other" />
            <token id="21" string="black" />
            <token id="22" string="person" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="any other black person" type="NP">
          <tokens>
            <token id="19" string="any" />
            <token id="20" string="other" />
            <token id="21" string="black" />
            <token id="22" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="could have happened to me or my father or to any other black person" type="VP">
          <tokens>
            <token id="9" string="could" />
            <token id="10" string="have" />
            <token id="11" string="happened" />
            <token id="12" string="to" />
            <token id="13" string="me" />
            <token id="14" string="or" />
            <token id="15" string="my" />
            <token id="16" string="father" />
            <token id="17" string="or" />
            <token id="18" string="to" />
            <token id="19" string="any" />
            <token id="20" string="other" />
            <token id="21" string="black" />
            <token id="22" string="person" />
          </tokens>
        </chunking>
        <chunking id="8" string="If it was n't Joe" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="it" />
            <token id="4" string="was" />
            <token id="5" string="n't" />
            <token id="6" string="Joe" />
          </tokens>
        </chunking>
        <chunking id="9" string="this" type="NP">
          <tokens>
            <token id="8" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="my father" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="father" />
          </tokens>
        </chunking>
        <chunking id="11" string="Joe" type="NP">
          <tokens>
            <token id="6" string="Joe" />
          </tokens>
        </chunking>
        <chunking id="12" string="happened to me or my father or to any other black person" type="VP">
          <tokens>
            <token id="11" string="happened" />
            <token id="12" string="to" />
            <token id="13" string="me" />
            <token id="14" string="or" />
            <token id="15" string="my" />
            <token id="16" string="father" />
            <token id="17" string="or" />
            <token id="18" string="to" />
            <token id="19" string="any" />
            <token id="20" string="other" />
            <token id="21" string="black" />
            <token id="22" string="person" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">Joe</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">Joe</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">Joe</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">Joe</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">happened</governor>
          <dependent id="6">Joe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">happened</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">happened</governor>
          <dependent id="9">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">happened</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">happened</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">happened</governor>
          <dependent id="11">happened</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">happened</governor>
          <dependent id="11">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">me</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">happened</governor>
          <dependent id="13">me</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">happened</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">father</governor>
          <dependent id="15">my</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">me</governor>
          <dependent id="16">father</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">happened</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">person</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">person</governor>
          <dependent id="19">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">person</governor>
          <dependent id="20">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">person</governor>
          <dependent id="21">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">happened</governor>
          <dependent id="22">person</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joe" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Joe" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Searle, 42, denied the allegations but told The Times he could not discuss specifics of the case.</content>
      <tokens>
        <token id="1" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Times" lemma="Times" stem="time" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="discuss" lemma="discuss" stem="discuss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="specifics" lemma="specifics" stem="specif" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Searle)) (, ,) (NP (CD 42)) (, ,)) (VP (VP (VBD denied) (NP (DT the) (NNS allegations))) (CC but) (VP (VBD told) (NP (DT The) (NNPS Times)) (SBAR (S (NP (PRP he)) (VP (MD could) (RB not) (VP (VB discuss) (NP (NP (NNS specifics)) (PP (IN of) (NP (DT the) (NN case)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Searle" type="NP">
          <tokens>
            <token id="1" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Times" type="NP">
          <tokens>
            <token id="10" string="The" />
            <token id="11" string="Times" />
          </tokens>
        </chunking>
        <chunking id="4" string="told The Times he could not discuss specifics of the case" type="VP">
          <tokens>
            <token id="9" string="told" />
            <token id="10" string="The" />
            <token id="11" string="Times" />
            <token id="12" string="he" />
            <token id="13" string="could" />
            <token id="14" string="not" />
            <token id="15" string="discuss" />
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="denied the allegations" type="VP">
          <tokens>
            <token id="5" string="denied" />
            <token id="6" string="the" />
            <token id="7" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="6" string="he could not discuss specifics of the case" type="SBAR">
          <tokens>
            <token id="12" string="he" />
            <token id="13" string="could" />
            <token id="14" string="not" />
            <token id="15" string="discuss" />
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="discuss specifics of the case" type="VP">
          <tokens>
            <token id="15" string="discuss" />
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="the allegations" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="9" string="specifics of the case" type="NP">
          <tokens>
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="could not discuss specifics of the case" type="VP">
          <tokens>
            <token id="13" string="could" />
            <token id="14" string="not" />
            <token id="15" string="discuss" />
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="denied the allegations but told The Times he could not discuss specifics of the case" type="VP">
          <tokens>
            <token id="5" string="denied" />
            <token id="6" string="the" />
            <token id="7" string="allegations" />
            <token id="8" string="but" />
            <token id="9" string="told" />
            <token id="10" string="The" />
            <token id="11" string="Times" />
            <token id="12" string="he" />
            <token id="13" string="could" />
            <token id="14" string="not" />
            <token id="15" string="discuss" />
            <token id="16" string="specifics" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="12" string="Searle , 42 ," type="NP">
          <tokens>
            <token id="1" string="Searle" />
            <token id="2" string="," />
            <token id="3" string="42" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="42" type="NP">
          <tokens>
            <token id="3" string="42" />
          </tokens>
        </chunking>
        <chunking id="15" string="specifics" type="NP">
          <tokens>
            <token id="16" string="specifics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">denied</governor>
          <dependent id="1">Searle</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Searle</governor>
          <dependent id="3">42</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">denied</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">allegations</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">denied</governor>
          <dependent id="7">allegations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">denied</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">denied</governor>
          <dependent id="9">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Times</governor>
          <dependent id="10">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">told</governor>
          <dependent id="11">Times</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">discuss</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">discuss</governor>
          <dependent id="13">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">discuss</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">told</governor>
          <dependent id="15">discuss</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">discuss</governor>
          <dependent id="16">specifics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">case</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">case</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">specifics</governor>
          <dependent id="19">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="The Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="The" />
            <token id="11" string="Times" />
          </tokens>
        </entity>
        <entity id="3" string="42" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="42" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;quot;All I can say is that the guy is a great baseball player and appears to be a good announcer,&amp;quot; Searle said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="baseball" lemma="baseball" stem="basebal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="player" lemma="player" stem="player" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="appears" lemma="appear" stem="appear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="announcer" lemma="announcer" stem="announc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT All)) (SBAR (S (NP (PRP I)) (VP (MD can) (VP (VB say)))))) (VP (VBZ is) (SBAR (IN that) (S (NP (DT the) (NN guy)) (VP (VP (VBZ is) (NP (DT a) (JJ great) (NN baseball) (NN player))) (CC and) (VP (VBZ appears) (S (VP (TO to) (VP (VB be) (NP (DT a) (JJ good) (NN announcer))))))))))) (, ,) ('' '') (NP (NNP Searle)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="All" type="NP">
          <tokens>
            <token id="2" string="All" />
          </tokens>
        </chunking>
        <chunking id="2" string="to be a good announcer" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="3" string="Searle" type="NP">
          <tokens>
            <token id="24" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="4" string="is that the guy is a great baseball player and appears to be a good announcer" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="guy" />
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="baseball" />
            <token id="14" string="player" />
            <token id="15" string="and" />
            <token id="16" string="appears" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="say" type="VP">
          <tokens>
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="7" string="is a great baseball player and appears to be a good announcer" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="baseball" />
            <token id="14" string="player" />
            <token id="15" string="and" />
            <token id="16" string="appears" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="8" string="a great baseball player" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="baseball" />
            <token id="14" string="player" />
          </tokens>
        </chunking>
        <chunking id="9" string="that the guy is a great baseball player and appears to be a good announcer" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="guy" />
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="baseball" />
            <token id="14" string="player" />
            <token id="15" string="and" />
            <token id="16" string="appears" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="10" string="is a great baseball player" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="baseball" />
            <token id="14" string="player" />
          </tokens>
        </chunking>
        <chunking id="11" string="appears to be a good announcer" type="VP">
          <tokens>
            <token id="16" string="appears" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="12" string="the guy" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="guy" />
          </tokens>
        </chunking>
        <chunking id="13" string="All I can say" type="NP">
          <tokens>
            <token id="2" string="All" />
            <token id="3" string="I" />
            <token id="4" string="can" />
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="14" string="I can say" type="SBAR">
          <tokens>
            <token id="3" string="I" />
            <token id="4" string="can" />
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="15" string="be a good announcer" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="16" string="can say" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="17" string="a good announcer" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="good" />
            <token id="21" string="announcer" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="2">All</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">say</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">say</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">All</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">player</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">guy</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">player</governor>
          <dependent id="9">guy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">player</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">player</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">player</governor>
          <dependent id="12">great</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">player</governor>
          <dependent id="13">baseball</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">is</governor>
          <dependent id="14">player</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">player</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">player</governor>
          <dependent id="16">appears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">announcer</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">announcer</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">announcer</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">announcer</governor>
          <dependent id="20">good</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">appears</governor>
          <dependent id="21">announcer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">Searle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Searle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;I wish it didn&amp;apost;t happen.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wish" lemma="wish" stem="wish" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP wish) (SBAR (S (NP (PRP it)) (VP (VBD did) (RB n't) (VP (VB happen)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="it did n't happen" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="did" />
            <token id="6" string="n't" />
            <token id="7" string="happen" />
          </tokens>
        </chunking>
        <chunking id="2" string="happen" type="VP">
          <tokens>
            <token id="7" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="wish it did n't happen" type="VP">
          <tokens>
            <token id="3" string="wish" />
            <token id="4" string="it" />
            <token id="5" string="did" />
            <token id="6" string="n't" />
            <token id="7" string="happen" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="did n't happen" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="n't" />
            <token id="7" string="happen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wish</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wish</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">happen</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">happen</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">happen</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">wish</governor>
          <dependent id="7">happen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>He just sort of went out of control.&amp;quot;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB just)) (ADVP (NN sort) (IN of)) (VP (VBD went) (PRT (IN out)) (PP (IN of) (NP (NN control)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="control" type="NP">
          <tokens>
            <token id="8" string="control" />
          </tokens>
        </chunking>
        <chunking id="2" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="3" string="went out of control" type="VP">
          <tokens>
            <token id="5" string="went" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="control" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">went</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">went</governor>
          <dependent id="2">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">went</governor>
          <dependent id="3">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">sort</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">went</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">went</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">control</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">went</governor>
          <dependent id="8">control</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Assistant City Atty. Honey A. Lewis, who represents the officer and the Police Department, said Searle had acted properly and was merely asking Morgan to identify himself when Morgan suddenly became belligerent, spewing profanities and slapping the officer.</content>
      <tokens>
        <token id="1" string="Assistant" lemma="Assistant" stem="assistant" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="2" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Atty." lemma="Atty." stem="atty." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Honey" lemma="Honey" stem="honei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="A." lemma="A." stem="a." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="represents" lemma="represent" stem="repres" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="15" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="acted" lemma="act" stem="act" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="properly" lemma="properly" stem="properli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="asking" lemma="ask" stem="ask" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="belligerent" lemma="belligerent" stem="belliger" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="spewing" lemma="spew" stem="spew" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="profanities" lemma="profanity" stem="profan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="slapping" lemma="slapping" stem="slap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Assistant) (NNP City) (NNP Atty.) (NNP Honey) (NNP A.) (NNP Lewis)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ represents) (NP (NP (DT the) (NN officer)) (CC and) (NP (DT the) (NNP Police) (NNP Department)))))) (, ,)) (VP (VBD said) (SBAR (S (NP (NNP Searle)) (VP (VBD had) (VP (VP (VBN acted) (ADVP (RB properly))) (CC and) (VP (VBD was) (VP (ADVP (RB merely)) (VP (VBG asking) (S (NP (NNP Morgan)) (VP (TO to) (VP (VB identify) (NP (PRP himself)) (SBAR (WHADVP (WRB when)) (S (NP (NNP Morgan)) (ADVP (RB suddenly)) (VP (VBD became) (ADJP (JJ belligerent))))))))) (, ,) (VP (VBG spewing) (NP (NNS profanities) (CC and) (NN slapping))))) (NP (DT the) (NN officer))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when Morgan suddenly became belligerent" type="SBAR">
          <tokens>
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="2" string="Assistant City Atty. Honey A. Lewis" type="NP">
          <tokens>
            <token id="1" string="Assistant" />
            <token id="2" string="City" />
            <token id="3" string="Atty." />
            <token id="4" string="Honey" />
            <token id="5" string="A." />
            <token id="6" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Searle had acted properly and was merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping the officer" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="Searle" />
            <token id="19" string="had" />
            <token id="20" string="acted" />
            <token id="21" string="properly" />
            <token id="22" string="and" />
            <token id="23" string="was" />
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
            <token id="40" string="the" />
            <token id="41" string="officer" />
          </tokens>
        </chunking>
        <chunking id="4" string="became belligerent" type="VP">
          <tokens>
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="5" string="acted properly and was merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping the officer" type="VP">
          <tokens>
            <token id="20" string="acted" />
            <token id="21" string="properly" />
            <token id="22" string="and" />
            <token id="23" string="was" />
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
            <token id="40" string="the" />
            <token id="41" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="was merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
          </tokens>
        </chunking>
        <chunking id="7" string="Searle had acted properly and was merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping the officer" type="SBAR">
          <tokens>
            <token id="18" string="Searle" />
            <token id="19" string="had" />
            <token id="20" string="acted" />
            <token id="21" string="properly" />
            <token id="22" string="and" />
            <token id="23" string="was" />
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
            <token id="40" string="the" />
            <token id="41" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Police Department" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </chunking>
        <chunking id="9" string="himself" type="NP">
          <tokens>
            <token id="29" string="himself" />
          </tokens>
        </chunking>
        <chunking id="10" string="Searle" type="NP">
          <tokens>
            <token id="18" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="11" string="belligerent" type="ADJP">
          <tokens>
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="12" string="the officer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="13" string="represents the officer and the Police Department" type="VP">
          <tokens>
            <token id="9" string="represents" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </chunking>
        <chunking id="14" string="spewing profanities and slapping" type="VP">
          <tokens>
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
          </tokens>
        </chunking>
        <chunking id="15" string="when" type="WHADVP">
          <tokens>
            <token id="30" string="when" />
          </tokens>
        </chunking>
        <chunking id="16" string="identify himself when Morgan suddenly became belligerent" type="VP">
          <tokens>
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="17" string="acted properly" type="VP">
          <tokens>
            <token id="20" string="acted" />
            <token id="21" string="properly" />
          </tokens>
        </chunking>
        <chunking id="18" string="who represents the officer and the Police Department" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="represents" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </chunking>
        <chunking id="19" string="profanities and slapping" type="NP">
          <tokens>
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
          </tokens>
        </chunking>
        <chunking id="20" string="the officer and the Police Department" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </chunking>
        <chunking id="21" string="Morgan" type="NP">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="22" string="merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping" type="VP">
          <tokens>
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
          </tokens>
        </chunking>
        <chunking id="23" string="asking Morgan to identify himself when Morgan suddenly became belligerent" type="VP">
          <tokens>
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="24" string="to identify himself when Morgan suddenly became belligerent" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
          </tokens>
        </chunking>
        <chunking id="25" string="Assistant City Atty. Honey A. Lewis , who represents the officer and the Police Department ," type="NP">
          <tokens>
            <token id="1" string="Assistant" />
            <token id="2" string="City" />
            <token id="3" string="Atty." />
            <token id="4" string="Honey" />
            <token id="5" string="A." />
            <token id="6" string="Lewis" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="represents" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="26" string="had acted properly and was merely asking Morgan to identify himself when Morgan suddenly became belligerent , spewing profanities and slapping the officer" type="VP">
          <tokens>
            <token id="19" string="had" />
            <token id="20" string="acted" />
            <token id="21" string="properly" />
            <token id="22" string="and" />
            <token id="23" string="was" />
            <token id="24" string="merely" />
            <token id="25" string="asking" />
            <token id="26" string="Morgan" />
            <token id="27" string="to" />
            <token id="28" string="identify" />
            <token id="29" string="himself" />
            <token id="30" string="when" />
            <token id="31" string="Morgan" />
            <token id="32" string="suddenly" />
            <token id="33" string="became" />
            <token id="34" string="belligerent" />
            <token id="35" string="," />
            <token id="36" string="spewing" />
            <token id="37" string="profanities" />
            <token id="38" string="and" />
            <token id="39" string="slapping" />
            <token id="40" string="the" />
            <token id="41" string="officer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="6">Lewis</governor>
          <dependent id="1">Assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lewis</governor>
          <dependent id="2">City</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lewis</governor>
          <dependent id="3">Atty.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lewis</governor>
          <dependent id="4">Honey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lewis</governor>
          <dependent id="5">A.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="6">Lewis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">represents</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Lewis</governor>
          <dependent id="9">represents</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">represents</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">officer</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Department</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Department</governor>
          <dependent id="14">Police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">officer</governor>
          <dependent id="15">Department</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">acted</governor>
          <dependent id="18">Searle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">acted</governor>
          <dependent id="19">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="20">acted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">acted</governor>
          <dependent id="21">properly</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">acted</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">asking</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">asking</governor>
          <dependent id="24">merely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">acted</governor>
          <dependent id="25">asking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">asking</governor>
          <dependent id="26">Morgan</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">identify</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">asking</governor>
          <dependent id="28">identify</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">identify</governor>
          <dependent id="29">himself</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">became</governor>
          <dependent id="30">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">became</governor>
          <dependent id="31">Morgan</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">became</governor>
          <dependent id="32">suddenly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">identify</governor>
          <dependent id="33">became</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">became</governor>
          <dependent id="34">belligerent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">asking</governor>
          <dependent id="36">spewing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">spewing</governor>
          <dependent id="37">profanities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">profanities</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">profanities</governor>
          <dependent id="39">slapping</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">officer</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">acted</governor>
          <dependent id="41">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Honey A. Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Honey" />
            <token id="5" string="A." />
            <token id="6" string="Lewis" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Searle" />
          </tokens>
        </entity>
        <entity id="3" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Morgan" />
          </tokens>
        </entity>
        <entity id="4" string="Assistant" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Assistant" />
          </tokens>
        </entity>
        <entity id="5" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>&amp;quot;My argument is that Mr. Morgan overreacted,&amp;quot; Lewis said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="argument" lemma="argument" stem="argument" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="overreacted" lemma="overreact" stem="overreact" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ My) (NN argument)) (VP (VBZ is) (SBAR (IN that) (S (NP (NNP Mr.) (NNP Morgan)) (VP (VBD overreacted)))))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is that Mr. Morgan overreacted" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="that" />
            <token id="6" string="Mr." />
            <token id="7" string="Morgan" />
            <token id="8" string="overreacted" />
          </tokens>
        </chunking>
        <chunking id="2" string="overreacted" type="VP">
          <tokens>
            <token id="8" string="overreacted" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lewis" type="NP">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="4" string="My argument" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="argument" />
          </tokens>
        </chunking>
        <chunking id="5" string="that Mr. Morgan overreacted" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="Mr." />
            <token id="7" string="Morgan" />
            <token id="8" string="overreacted" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Morgan" type="NP">
          <tokens>
            <token id="6" string="Mr." />
            <token id="7" string="Morgan" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">argument</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">argument</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">overreacted</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Morgan</governor>
          <dependent id="6">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">overreacted</governor>
          <dependent id="7">Morgan</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="8">overreacted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Morgan" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;If he had cooperated, none of this would have happened.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="cooperated" lemma="cooperate" stem="cooper" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="none" lemma="none" stem="none" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="happened" lemma="happen" stem="happen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP he)) (VP (VBD had) (VP (VBN cooperated))))) (, ,) (NP (NP (NN none)) (PP (IN of) (NP (DT this)))) (VP (MD would) (VP (VB have) (VP (VBN happened)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="none of this" type="NP">
          <tokens>
            <token id="7" string="none" />
            <token id="8" string="of" />
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="have happened" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="happened" />
          </tokens>
        </chunking>
        <chunking id="3" string="none" type="NP">
          <tokens>
            <token id="7" string="none" />
          </tokens>
        </chunking>
        <chunking id="4" string="cooperated" type="VP">
          <tokens>
            <token id="5" string="cooperated" />
          </tokens>
        </chunking>
        <chunking id="5" string="had cooperated" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="cooperated" />
          </tokens>
        </chunking>
        <chunking id="6" string="would have happened" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="have" />
            <token id="12" string="happened" />
          </tokens>
        </chunking>
        <chunking id="7" string="If he had cooperated" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="he" />
            <token id="4" string="had" />
            <token id="5" string="cooperated" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="happened" type="VP">
          <tokens>
            <token id="12" string="happened" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">cooperated</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">cooperated</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">cooperated</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">happened</governor>
          <dependent id="5">cooperated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">happened</governor>
          <dependent id="7">none</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">this</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">none</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">happened</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">happened</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">happened</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>I think he had a bruised ego, and he was offended because the officer hadn&amp;apost;t recognized him.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="bruised" lemma="bruised" stem="bruis" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="ego" lemma="ego" stem="ego" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="offended" lemma="offend" stem="offend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="recognized" lemma="recognize" stem="recogn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP he)) (VP (VBD had) (NP (DT a) (JJ bruised) (NN ego))))))) (, ,) (CC and) (S (NP (PRP he)) (VP (VBD was) (VP (VBN offended) (SBAR (IN because) (S (NP (NP (DT the) (NN officer)) (SBAR (S (VP (VBD had) (RB n't))))) (VP (VBD recognized) (NP (PRP him)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="recognized him" type="VP">
          <tokens>
            <token id="18" string="recognized" />
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="the officer" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="officer" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="had a bruised ego" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="a" />
            <token id="6" string="bruised" />
            <token id="7" string="ego" />
          </tokens>
        </chunking>
        <chunking id="6" string="offended because the officer had n't recognized him" type="VP">
          <tokens>
            <token id="12" string="offended" />
            <token id="13" string="because" />
            <token id="14" string="the" />
            <token id="15" string="officer" />
            <token id="16" string="had" />
            <token id="17" string="n't" />
            <token id="18" string="recognized" />
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="a bruised ego" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="bruised" />
            <token id="7" string="ego" />
          </tokens>
        </chunking>
        <chunking id="8" string="was offended because the officer had n't recognized him" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="offended" />
            <token id="13" string="because" />
            <token id="14" string="the" />
            <token id="15" string="officer" />
            <token id="16" string="had" />
            <token id="17" string="n't" />
            <token id="18" string="recognized" />
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="because the officer had n't recognized him" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="the" />
            <token id="15" string="officer" />
            <token id="16" string="had" />
            <token id="17" string="n't" />
            <token id="18" string="recognized" />
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="the officer had n't" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="officer" />
            <token id="16" string="had" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="11" string="had n't" type="SBAR">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="he had a bruised ego" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="had" />
            <token id="5" string="a" />
            <token id="6" string="bruised" />
            <token id="7" string="ego" />
          </tokens>
        </chunking>
        <chunking id="14" string="think he had a bruised ego" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="he" />
            <token id="4" string="had" />
            <token id="5" string="a" />
            <token id="6" string="bruised" />
            <token id="7" string="ego" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">ego</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">ego</governor>
          <dependent id="6">bruised</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="7">ego</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">think</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">offended</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">offended</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">think</governor>
          <dependent id="12">offended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">recognized</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">officer</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">recognized</governor>
          <dependent id="15">officer</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">officer</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">had</governor>
          <dependent id="17">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">offended</governor>
          <dependent id="18">recognized</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">recognized</governor>
          <dependent id="19">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>According to Searle&amp;apost;s sworn court deposition, the incident began after he and Woessner, working together as members of an airport anti-drug task force, had arrested a passenger as a suspected drug courier.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="sworn" lemma="swear" stem="sworn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="deposition" lemma="deposition" stem="deposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Woessner" lemma="Woessner" stem="woessner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="airport" lemma="airport" stem="airport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="anti-drug" lemma="anti-drug" stem="anti-drug" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="task" lemma="task" stem="task" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="passenger" lemma="passenger" stem="passeng" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (NP (NNP Searle) (POS 's)) (VBN sworn) (NN court) (NN deposition)))) (, ,) (NP (DT the) (NN incident)) (VP (VBD began) (SBAR (IN after) (S (NP (PRP he) (CC and) (NNP Woessner)) (, ,) (S (VP (VBG working) (ADVP (RB together)) (PP (IN as) (NP (NP (NNS members)) (PP (IN of) (NP (DT an) (NN airport) (JJ anti-drug) (NN task) (NN force))))))) (, ,) (VP (VBD had) (VP (VBN arrested) (NP (DT a) (NN passenger)) (PP (IN as) (NP (DT a) (VBN suspected) (NN drug) (NN courier)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="after he and Woessner , working together as members of an airport anti-drug task force , had arrested a passenger as a suspected drug courier" type="SBAR">
          <tokens>
            <token id="12" string="after" />
            <token id="13" string="he" />
            <token id="14" string="and" />
            <token id="15" string="Woessner" />
            <token id="16" string="," />
            <token id="17" string="working" />
            <token id="18" string="together" />
            <token id="19" string="as" />
            <token id="20" string="members" />
            <token id="21" string="of" />
            <token id="22" string="an" />
            <token id="23" string="airport" />
            <token id="24" string="anti-drug" />
            <token id="25" string="task" />
            <token id="26" string="force" />
            <token id="27" string="," />
            <token id="28" string="had" />
            <token id="29" string="arrested" />
            <token id="30" string="a" />
            <token id="31" string="passenger" />
            <token id="32" string="as" />
            <token id="33" string="a" />
            <token id="34" string="suspected" />
            <token id="35" string="drug" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="2" string="Searle 's" type="NP">
          <tokens>
            <token id="3" string="Searle" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="he and Woessner" type="NP">
          <tokens>
            <token id="13" string="he" />
            <token id="14" string="and" />
            <token id="15" string="Woessner" />
          </tokens>
        </chunking>
        <chunking id="4" string="working together as members of an airport anti-drug task force" type="VP">
          <tokens>
            <token id="17" string="working" />
            <token id="18" string="together" />
            <token id="19" string="as" />
            <token id="20" string="members" />
            <token id="21" string="of" />
            <token id="22" string="an" />
            <token id="23" string="airport" />
            <token id="24" string="anti-drug" />
            <token id="25" string="task" />
            <token id="26" string="force" />
          </tokens>
        </chunking>
        <chunking id="5" string="members" type="NP">
          <tokens>
            <token id="20" string="members" />
          </tokens>
        </chunking>
        <chunking id="6" string="an airport anti-drug task force" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="airport" />
            <token id="24" string="anti-drug" />
            <token id="25" string="task" />
            <token id="26" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="a suspected drug courier" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="suspected" />
            <token id="35" string="drug" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="8" string="Searle 's sworn court deposition" type="NP">
          <tokens>
            <token id="3" string="Searle" />
            <token id="4" string="'s" />
            <token id="5" string="sworn" />
            <token id="6" string="court" />
            <token id="7" string="deposition" />
          </tokens>
        </chunking>
        <chunking id="9" string="members of an airport anti-drug task force" type="NP">
          <tokens>
            <token id="20" string="members" />
            <token id="21" string="of" />
            <token id="22" string="an" />
            <token id="23" string="airport" />
            <token id="24" string="anti-drug" />
            <token id="25" string="task" />
            <token id="26" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="began after he and Woessner , working together as members of an airport anti-drug task force , had arrested a passenger as a suspected drug courier" type="VP">
          <tokens>
            <token id="11" string="began" />
            <token id="12" string="after" />
            <token id="13" string="he" />
            <token id="14" string="and" />
            <token id="15" string="Woessner" />
            <token id="16" string="," />
            <token id="17" string="working" />
            <token id="18" string="together" />
            <token id="19" string="as" />
            <token id="20" string="members" />
            <token id="21" string="of" />
            <token id="22" string="an" />
            <token id="23" string="airport" />
            <token id="24" string="anti-drug" />
            <token id="25" string="task" />
            <token id="26" string="force" />
            <token id="27" string="," />
            <token id="28" string="had" />
            <token id="29" string="arrested" />
            <token id="30" string="a" />
            <token id="31" string="passenger" />
            <token id="32" string="as" />
            <token id="33" string="a" />
            <token id="34" string="suspected" />
            <token id="35" string="drug" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="11" string="the incident" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="incident" />
          </tokens>
        </chunking>
        <chunking id="12" string="had arrested a passenger as a suspected drug courier" type="VP">
          <tokens>
            <token id="28" string="had" />
            <token id="29" string="arrested" />
            <token id="30" string="a" />
            <token id="31" string="passenger" />
            <token id="32" string="as" />
            <token id="33" string="a" />
            <token id="34" string="suspected" />
            <token id="35" string="drug" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="13" string="arrested a passenger as a suspected drug courier" type="VP">
          <tokens>
            <token id="29" string="arrested" />
            <token id="30" string="a" />
            <token id="31" string="passenger" />
            <token id="32" string="as" />
            <token id="33" string="a" />
            <token id="34" string="suspected" />
            <token id="35" string="drug" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="14" string="a passenger" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="passenger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="7">deposition</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">deposition</governor>
          <dependent id="3">Searle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Searle</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">deposition</governor>
          <dependent id="5">sworn</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">deposition</governor>
          <dependent id="6">court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">began</governor>
          <dependent id="7">deposition</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">incident</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">began</governor>
          <dependent id="10">incident</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">began</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">arrested</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">arrested</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">he</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">he</governor>
          <dependent id="15">Woessner</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">arrested</governor>
          <dependent id="17">working</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">working</governor>
          <dependent id="18">together</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">members</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">working</governor>
          <dependent id="20">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">force</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">force</governor>
          <dependent id="22">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">force</governor>
          <dependent id="23">airport</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">force</governor>
          <dependent id="24">anti-drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">force</governor>
          <dependent id="25">task</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">members</governor>
          <dependent id="26">force</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">arrested</governor>
          <dependent id="28">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">began</governor>
          <dependent id="29">arrested</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">passenger</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">arrested</governor>
          <dependent id="31">passenger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">courier</governor>
          <dependent id="32">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">courier</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">courier</governor>
          <dependent id="34">suspected</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">courier</governor>
          <dependent id="35">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">arrested</governor>
          <dependent id="36">courier</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Woessner" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Woessner" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Searle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>They said he was using an alias.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="alias" lemma="alias" stem="alia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG using) (NP (DT an) (NN alias))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="he was using an alias" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="was" />
            <token id="5" string="using" />
            <token id="6" string="an" />
            <token id="7" string="alias" />
          </tokens>
        </chunking>
        <chunking id="3" string="using an alias" type="VP">
          <tokens>
            <token id="5" string="using" />
            <token id="6" string="an" />
            <token id="7" string="alias" />
          </tokens>
        </chunking>
        <chunking id="4" string="was using an alias" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="using" />
            <token id="6" string="an" />
            <token id="7" string="alias" />
          </tokens>
        </chunking>
        <chunking id="5" string="said he was using an alias" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="was" />
            <token id="5" string="using" />
            <token id="6" string="an" />
            <token id="7" string="alias" />
          </tokens>
        </chunking>
        <chunking id="6" string="an alias" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="alias" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">using</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">using</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">using</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">alias</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">using</governor>
          <dependent id="7">alias</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Although the officers found no drugs in his possession, Searle said they discovered that the passenger was holding a second plane ticket, and they began looking for his companion.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="possession" lemma="possession" stem="possess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="discovered" lemma="discover" stem="discov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="passenger" lemma="passenger" stem="passeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="holding" lemma="hold" stem="hold" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="plane" lemma="plane" stem="plane" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="ticket" lemma="ticket" stem="ticket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="companion" lemma="companion" stem="companion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN Although) (S (NP (DT the) (NNS officers)) (VP (VBD found) (NP (DT no) (NNS drugs)) (PP (IN in) (NP (PRP$ his) (NN possession)))))) (, ,) (NP (NNP Searle)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD discovered) (SBAR (IN that) (S (NP (DT the) (NN passenger)) (VP (VBD was) (VP (VBG holding) (NP (DT a) (JJ second) (NN plane) (NN ticket))))))))))) (, ,) (CC and) (S (NP (PRP they)) (VP (VBD began) (S (VP (VBG looking) (PP (IN for) (NP (PRP$ his) (NN companion))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they discovered that the passenger was holding a second plane ticket" type="SBAR">
          <tokens>
            <token id="13" string="they" />
            <token id="14" string="discovered" />
            <token id="15" string="that" />
            <token id="16" string="the" />
            <token id="17" string="passenger" />
            <token id="18" string="was" />
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="2" string="Searle" type="NP">
          <tokens>
            <token id="11" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="3" string="a second plane ticket" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="4" string="looking for his companion" type="VP">
          <tokens>
            <token id="28" string="looking" />
            <token id="29" string="for" />
            <token id="30" string="his" />
            <token id="31" string="companion" />
          </tokens>
        </chunking>
        <chunking id="5" string="found no drugs in his possession" type="VP">
          <tokens>
            <token id="4" string="found" />
            <token id="5" string="no" />
            <token id="6" string="drugs" />
            <token id="7" string="in" />
            <token id="8" string="his" />
            <token id="9" string="possession" />
          </tokens>
        </chunking>
        <chunking id="6" string="the passenger" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="7" string="was holding a second plane ticket" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="8" string="his possession" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="possession" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="holding a second plane ticket" type="VP">
          <tokens>
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="11" string="no drugs" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="his companion" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="companion" />
          </tokens>
        </chunking>
        <chunking id="13" string="Although the officers found no drugs in his possession" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="the" />
            <token id="3" string="officers" />
            <token id="4" string="found" />
            <token id="5" string="no" />
            <token id="6" string="drugs" />
            <token id="7" string="in" />
            <token id="8" string="his" />
            <token id="9" string="possession" />
          </tokens>
        </chunking>
        <chunking id="14" string="said they discovered that the passenger was holding a second plane ticket" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="they" />
            <token id="14" string="discovered" />
            <token id="15" string="that" />
            <token id="16" string="the" />
            <token id="17" string="passenger" />
            <token id="18" string="was" />
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="15" string="the officers" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="officers" />
          </tokens>
        </chunking>
        <chunking id="16" string="began looking for his companion" type="VP">
          <tokens>
            <token id="27" string="began" />
            <token id="28" string="looking" />
            <token id="29" string="for" />
            <token id="30" string="his" />
            <token id="31" string="companion" />
          </tokens>
        </chunking>
        <chunking id="17" string="discovered that the passenger was holding a second plane ticket" type="VP">
          <tokens>
            <token id="14" string="discovered" />
            <token id="15" string="that" />
            <token id="16" string="the" />
            <token id="17" string="passenger" />
            <token id="18" string="was" />
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="18" string="that the passenger was holding a second plane ticket" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="the" />
            <token id="17" string="passenger" />
            <token id="18" string="was" />
            <token id="19" string="holding" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="plane" />
            <token id="23" string="ticket" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">found</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">officers</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">found</governor>
          <dependent id="3">officers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">said</governor>
          <dependent id="4">found</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">drugs</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">found</governor>
          <dependent id="6">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">possession</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">possession</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">found</governor>
          <dependent id="9">possession</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Searle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">discovered</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="14">discovered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">holding</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">passenger</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">holding</governor>
          <dependent id="17">passenger</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">holding</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">discovered</governor>
          <dependent id="19">holding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">ticket</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">ticket</governor>
          <dependent id="21">second</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">ticket</governor>
          <dependent id="22">plane</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">holding</governor>
          <dependent id="23">ticket</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">said</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">began</governor>
          <dependent id="26">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">said</governor>
          <dependent id="27">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">began</governor>
          <dependent id="28">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">companion</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">companion</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">looking</governor>
          <dependent id="31">companion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Searle" />
          </tokens>
        </entity>
        <entity id="3" string="a second" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Since the passenger was black and indicated that his companion &amp;quot;looked like me,&amp;quot; the officer began looking for a black man who was nervous-looking or having &amp;quot;other characteristics of a narcotics courier.&amp;quot;</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="passenger" lemma="passenger" stem="passeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="indicated" lemma="indicate" stem="indic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="companion" lemma="companion" stem="companion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="looked" lemma="look" stem="look" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="nervous-looking" lemma="nervous-looking" stem="nervous-look" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="characteristics" lemma="characteristic" stem="characterist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="courier" lemma="courier" stem="courier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Since) (S (NP (DT the) (NN passenger)) (VP (VP (VBD was) (ADJP (JJ black))) (CC and) (VP (VBD indicated) (SBAR (IN that) (S (NP (PRP$ his) (NN companion)) (`` ``) (VP (VBD looked) (PP (IN like) (NP (PRP me)))))))))) (, ,) ('' '') (NP (DT the) (NN officer)) (VP (VBD began) (S (VP (VP (VBG looking) (PP (IN for) (NP (NP (DT a) (JJ black) (NN man)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADJP (JJ nervous-looking)))))))) (CC or) (VP (VBG having) (NP (NP (`` ``) (JJ other) (NNS characteristics)) (PP (IN of) (NP (DT a) (NNS narcotics) (NN courier)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="looking for a black man who was nervous-looking" type="VP">
          <tokens>
            <token id="20" string="looking" />
            <token id="21" string="for" />
            <token id="22" string="a" />
            <token id="23" string="black" />
            <token id="24" string="man" />
            <token id="25" string="who" />
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
          </tokens>
        </chunking>
        <chunking id="2" string="indicated that his companion `` looked like me" type="VP">
          <tokens>
            <token id="7" string="indicated" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="companion" />
            <token id="11" string="&quot;" />
            <token id="12" string="looked" />
            <token id="13" string="like" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="Since the passenger was black and indicated that his companion `` looked like me" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="the" />
            <token id="3" string="passenger" />
            <token id="4" string="was" />
            <token id="5" string="black" />
            <token id="6" string="and" />
            <token id="7" string="indicated" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="companion" />
            <token id="11" string="&quot;" />
            <token id="12" string="looked" />
            <token id="13" string="like" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="was black" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="black" />
          </tokens>
        </chunking>
        <chunking id="5" string="looked like me" type="VP">
          <tokens>
            <token id="12" string="looked" />
            <token id="13" string="like" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="the passenger" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` other characteristics" type="NP">
          <tokens>
            <token id="30" string="&quot;" />
            <token id="31" string="other" />
            <token id="32" string="characteristics" />
          </tokens>
        </chunking>
        <chunking id="8" string="black" type="ADJP">
          <tokens>
            <token id="5" string="black" />
          </tokens>
        </chunking>
        <chunking id="9" string="that his companion `` looked like me" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="companion" />
            <token id="11" string="&quot;" />
            <token id="12" string="looked" />
            <token id="13" string="like" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="the officer" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="officer" />
          </tokens>
        </chunking>
        <chunking id="11" string="looking for a black man who was nervous-looking or having `` other characteristics of a narcotics courier" type="VP">
          <tokens>
            <token id="20" string="looking" />
            <token id="21" string="for" />
            <token id="22" string="a" />
            <token id="23" string="black" />
            <token id="24" string="man" />
            <token id="25" string="who" />
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
            <token id="28" string="or" />
            <token id="29" string="having" />
            <token id="30" string="&quot;" />
            <token id="31" string="other" />
            <token id="32" string="characteristics" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="narcotics" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="12" string="nervous-looking" type="ADJP">
          <tokens>
            <token id="27" string="nervous-looking" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` other characteristics of a narcotics courier" type="NP">
          <tokens>
            <token id="30" string="&quot;" />
            <token id="31" string="other" />
            <token id="32" string="characteristics" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="narcotics" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="14" string="having `` other characteristics of a narcotics courier" type="VP">
          <tokens>
            <token id="29" string="having" />
            <token id="30" string="&quot;" />
            <token id="31" string="other" />
            <token id="32" string="characteristics" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="narcotics" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="15" string="began looking for a black man who was nervous-looking or having `` other characteristics of a narcotics courier" type="VP">
          <tokens>
            <token id="19" string="began" />
            <token id="20" string="looking" />
            <token id="21" string="for" />
            <token id="22" string="a" />
            <token id="23" string="black" />
            <token id="24" string="man" />
            <token id="25" string="who" />
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
            <token id="28" string="or" />
            <token id="29" string="having" />
            <token id="30" string="&quot;" />
            <token id="31" string="other" />
            <token id="32" string="characteristics" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="narcotics" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="16" string="who was nervous-looking" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
          </tokens>
        </chunking>
        <chunking id="17" string="his companion" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="companion" />
          </tokens>
        </chunking>
        <chunking id="18" string="me" type="NP">
          <tokens>
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="19" string="was black and indicated that his companion `` looked like me" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="black" />
            <token id="6" string="and" />
            <token id="7" string="indicated" />
            <token id="8" string="that" />
            <token id="9" string="his" />
            <token id="10" string="companion" />
            <token id="11" string="&quot;" />
            <token id="12" string="looked" />
            <token id="13" string="like" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="20" string="a narcotics courier" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="narcotics" />
            <token id="36" string="courier" />
          </tokens>
        </chunking>
        <chunking id="21" string="a black man who was nervous-looking" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="black" />
            <token id="24" string="man" />
            <token id="25" string="who" />
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
          </tokens>
        </chunking>
        <chunking id="22" string="a black man" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="black" />
            <token id="24" string="man" />
          </tokens>
        </chunking>
        <chunking id="23" string="was nervous-looking" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="nervous-looking" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">black</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">passenger</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">black</governor>
          <dependent id="3">passenger</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">black</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">began</governor>
          <dependent id="5">black</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">black</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">black</governor>
          <dependent id="7">indicated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">looked</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">companion</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">looked</governor>
          <dependent id="10">companion</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">indicated</governor>
          <dependent id="12">looked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">me</governor>
          <dependent id="13">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">looked</governor>
          <dependent id="14">me</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">officer</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">began</governor>
          <dependent id="18">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">began</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">began</governor>
          <dependent id="20">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">man</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">man</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">man</governor>
          <dependent id="23">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">looking</governor>
          <dependent id="24">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">nervous-looking</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">nervous-looking</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">man</governor>
          <dependent id="27">nervous-looking</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">looking</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">looking</governor>
          <dependent id="29">having</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">characteristics</governor>
          <dependent id="31">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">having</governor>
          <dependent id="32">characteristics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">courier</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">courier</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">courier</governor>
          <dependent id="35">narcotics</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">characteristics</governor>
          <dependent id="36">courier</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>When they spotted Morgan, Searle said, he tried to speak to him but Morgan started screaming profanities and &amp;quot;making animal noises&amp;quot; and hit him in the chest with a wild swing.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="spotted" lemma="spot" stem="spot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Searle" lemma="Searle" stem="searl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="speak" lemma="speak" stem="speak" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="screaming" lemma="scream" stem="scream" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="profanities" lemma="profanity" stem="profan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="animal" lemma="animal" stem="anim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="noises" lemma="noise" stem="nois" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="hit" lemma="hit" stem="hit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="chest" lemma="chest" stem="chest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="wild" lemma="wild" stem="wild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="swing" lemma="swing" stem="swing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (WHADVP (WRB When)) (S (NP (PRP they)) (VP (VBD spotted) (SBAR (S (NP (NNP Morgan) (, ,) (NNP Searle)) (VP (VBD said))))))) (, ,) (NP (PRP he)) (VP (VBD tried) (S (VP (TO to) (VP (VB speak) (PP (TO to) (NP (PRP him)))))))) (CC but) (S (NP (NNP Morgan)) (VP (VP (VBD started) (S (VP (VP (VBG screaming) (NP (NNS profanities))) (CC and) (VP (`` ``) (VBG making) (NP (NN animal) (NNS noises)))))) ('' '') (CC and) (VP (VBD hit) (NP (PRP him)) (PP (IN in) (NP (NP (DT the) (NN chest)) (PP (IN with) (NP (DT a) (JJ wild) (NN swing)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hit him in the chest with a wild swing" type="VP">
          <tokens>
            <token id="27" string="hit" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="chest" />
            <token id="32" string="with" />
            <token id="33" string="a" />
            <token id="34" string="wild" />
            <token id="35" string="swing" />
          </tokens>
        </chunking>
        <chunking id="2" string="the chest" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="chest" />
          </tokens>
        </chunking>
        <chunking id="3" string="started screaming profanities and `` making animal noises" type="VP">
          <tokens>
            <token id="17" string="started" />
            <token id="18" string="screaming" />
            <token id="19" string="profanities" />
            <token id="20" string="and" />
            <token id="21" string="&quot;" />
            <token id="22" string="making" />
            <token id="23" string="animal" />
            <token id="24" string="noises" />
          </tokens>
        </chunking>
        <chunking id="4" string="When they spotted Morgan , Searle said" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="they" />
            <token id="3" string="spotted" />
            <token id="4" string="Morgan" />
            <token id="5" string="," />
            <token id="6" string="Searle" />
            <token id="7" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="tried to speak to him" type="VP">
          <tokens>
            <token id="10" string="tried" />
            <token id="11" string="to" />
            <token id="12" string="speak" />
            <token id="13" string="to" />
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="screaming profanities and `` making animal noises" type="VP">
          <tokens>
            <token id="18" string="screaming" />
            <token id="19" string="profanities" />
            <token id="20" string="and" />
            <token id="21" string="&quot;" />
            <token id="22" string="making" />
            <token id="23" string="animal" />
            <token id="24" string="noises" />
          </tokens>
        </chunking>
        <chunking id="7" string="to speak to him" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="speak" />
            <token id="13" string="to" />
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="`` making animal noises" type="VP">
          <tokens>
            <token id="21" string="&quot;" />
            <token id="22" string="making" />
            <token id="23" string="animal" />
            <token id="24" string="noises" />
          </tokens>
        </chunking>
        <chunking id="10" string="spotted Morgan , Searle said" type="VP">
          <tokens>
            <token id="3" string="spotted" />
            <token id="4" string="Morgan" />
            <token id="5" string="," />
            <token id="6" string="Searle" />
            <token id="7" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="Morgan , Searle" type="NP">
          <tokens>
            <token id="4" string="Morgan" />
            <token id="5" string="," />
            <token id="6" string="Searle" />
          </tokens>
        </chunking>
        <chunking id="14" string="started screaming profanities and `` making animal noises '' and hit him in the chest with a wild swing" type="VP">
          <tokens>
            <token id="17" string="started" />
            <token id="18" string="screaming" />
            <token id="19" string="profanities" />
            <token id="20" string="and" />
            <token id="21" string="&quot;" />
            <token id="22" string="making" />
            <token id="23" string="animal" />
            <token id="24" string="noises" />
            <token id="25" string="&quot;" />
            <token id="26" string="and" />
            <token id="27" string="hit" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="chest" />
            <token id="32" string="with" />
            <token id="33" string="a" />
            <token id="34" string="wild" />
            <token id="35" string="swing" />
          </tokens>
        </chunking>
        <chunking id="15" string="speak to him" type="VP">
          <tokens>
            <token id="12" string="speak" />
            <token id="13" string="to" />
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="profanities" type="NP">
          <tokens>
            <token id="19" string="profanities" />
          </tokens>
        </chunking>
        <chunking id="17" string="Morgan" type="NP">
          <tokens>
            <token id="16" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="18" string="a wild swing" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="wild" />
            <token id="35" string="swing" />
          </tokens>
        </chunking>
        <chunking id="19" string="the chest with a wild swing" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="chest" />
            <token id="32" string="with" />
            <token id="33" string="a" />
            <token id="34" string="wild" />
            <token id="35" string="swing" />
          </tokens>
        </chunking>
        <chunking id="20" string="screaming profanities" type="VP">
          <tokens>
            <token id="18" string="screaming" />
            <token id="19" string="profanities" />
          </tokens>
        </chunking>
        <chunking id="21" string="animal noises" type="NP">
          <tokens>
            <token id="23" string="animal" />
            <token id="24" string="noises" />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="said" type="VP">
          <tokens>
            <token id="7" string="said" />
          </tokens>
        </chunking>
        <chunking id="24" string="Morgan , Searle said" type="SBAR">
          <tokens>
            <token id="4" string="Morgan" />
            <token id="5" string="," />
            <token id="6" string="Searle" />
            <token id="7" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">spotted</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">spotted</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">tried</governor>
          <dependent id="3">spotted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Searle</governor>
          <dependent id="4">Morgan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">Searle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">spotted</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">tried</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">speak</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">tried</governor>
          <dependent id="12">speak</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">him</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">speak</governor>
          <dependent id="14">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">tried</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">started</governor>
          <dependent id="16">Morgan</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">tried</governor>
          <dependent id="17">started</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">started</governor>
          <dependent id="18">screaming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">screaming</governor>
          <dependent id="19">profanities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">screaming</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">screaming</governor>
          <dependent id="22">making</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">noises</governor>
          <dependent id="23">animal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">making</governor>
          <dependent id="24">noises</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">started</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">started</governor>
          <dependent id="27">hit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">hit</governor>
          <dependent id="28">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">chest</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">chest</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">hit</governor>
          <dependent id="31">chest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">swing</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">swing</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">swing</governor>
          <dependent id="34">wild</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">chest</governor>
          <dependent id="35">swing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Searle" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Searle" />
          </tokens>
        </entity>
        <entity id="2" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>In his suit, Morgan denies that and contends that he suffered &amp;quot;acute physical and emotional distress and embarrassment&amp;quot; after the incident and expressed concern about damage to his reputation.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Morgan" lemma="Morgan" stem="morgan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="denies" lemma="deny" stem="deni" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="contends" lemma="contend" stem="contend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="acute" lemma="acute" stem="acut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="distress" lemma="distress" stem="distress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="embarrassment" lemma="embarrassment" stem="embarrass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="expressed" lemma="express" stem="express" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (PRP$ his) (NN suit))) (, ,) (NP (NNP Morgan)) (VP (VP (VBZ denies) (ADVP (IN that))) (CC and) (VP (VBZ contends) (SBAR (IN that) (S (NP (PRP he)) (VP (VP (VBD suffered) (`` ``) (NP (NP (JJ acute) (ADJP (JJ physical) (CC and) (JJ emotional)) (NN distress)) (CC and) (NP (NN embarrassment))) ('' '') (PP (IN after) (NP (DT the) (NN incident)))) (CC and) (VP (VBD expressed) (NP (NN concern)) (PP (IN about) (NP (NN damage))) (PP (TO to) (NP (PRP$ his) (NN reputation))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="damage" type="NP">
          <tokens>
            <token id="29" string="damage" />
          </tokens>
        </chunking>
        <chunking id="2" string="embarrassment" type="NP">
          <tokens>
            <token id="20" string="embarrassment" />
          </tokens>
        </chunking>
        <chunking id="3" string="denies that" type="VP">
          <tokens>
            <token id="6" string="denies" />
            <token id="7" string="that" />
          </tokens>
        </chunking>
        <chunking id="4" string="his suit" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="suit" />
          </tokens>
        </chunking>
        <chunking id="5" string="contends that he suffered `` acute physical and emotional distress and embarrassment '' after the incident and expressed concern about damage to his reputation" type="VP">
          <tokens>
            <token id="9" string="contends" />
            <token id="10" string="that" />
            <token id="11" string="he" />
            <token id="12" string="suffered" />
            <token id="13" string="&quot;" />
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
            <token id="21" string="&quot;" />
            <token id="22" string="after" />
            <token id="23" string="the" />
            <token id="24" string="incident" />
            <token id="25" string="and" />
            <token id="26" string="expressed" />
            <token id="27" string="concern" />
            <token id="28" string="about" />
            <token id="29" string="damage" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="6" string="acute physical and emotional distress and embarrassment" type="NP">
          <tokens>
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
          </tokens>
        </chunking>
        <chunking id="7" string="his reputation" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="8" string="physical and emotional" type="ADJP">
          <tokens>
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
          </tokens>
        </chunking>
        <chunking id="9" string="concern" type="NP">
          <tokens>
            <token id="27" string="concern" />
          </tokens>
        </chunking>
        <chunking id="10" string="suffered `` acute physical and emotional distress and embarrassment '' after the incident" type="VP">
          <tokens>
            <token id="12" string="suffered" />
            <token id="13" string="&quot;" />
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
            <token id="21" string="&quot;" />
            <token id="22" string="after" />
            <token id="23" string="the" />
            <token id="24" string="incident" />
          </tokens>
        </chunking>
        <chunking id="11" string="acute physical and emotional distress" type="NP">
          <tokens>
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
          </tokens>
        </chunking>
        <chunking id="12" string="Morgan" type="NP">
          <tokens>
            <token id="5" string="Morgan" />
          </tokens>
        </chunking>
        <chunking id="13" string="suffered `` acute physical and emotional distress and embarrassment '' after the incident and expressed concern about damage to his reputation" type="VP">
          <tokens>
            <token id="12" string="suffered" />
            <token id="13" string="&quot;" />
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
            <token id="21" string="&quot;" />
            <token id="22" string="after" />
            <token id="23" string="the" />
            <token id="24" string="incident" />
            <token id="25" string="and" />
            <token id="26" string="expressed" />
            <token id="27" string="concern" />
            <token id="28" string="about" />
            <token id="29" string="damage" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="14" string="denies that and contends that he suffered `` acute physical and emotional distress and embarrassment '' after the incident and expressed concern about damage to his reputation" type="VP">
          <tokens>
            <token id="6" string="denies" />
            <token id="7" string="that" />
            <token id="8" string="and" />
            <token id="9" string="contends" />
            <token id="10" string="that" />
            <token id="11" string="he" />
            <token id="12" string="suffered" />
            <token id="13" string="&quot;" />
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
            <token id="21" string="&quot;" />
            <token id="22" string="after" />
            <token id="23" string="the" />
            <token id="24" string="incident" />
            <token id="25" string="and" />
            <token id="26" string="expressed" />
            <token id="27" string="concern" />
            <token id="28" string="about" />
            <token id="29" string="damage" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="that he suffered `` acute physical and emotional distress and embarrassment '' after the incident and expressed concern about damage to his reputation" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="he" />
            <token id="12" string="suffered" />
            <token id="13" string="&quot;" />
            <token id="14" string="acute" />
            <token id="15" string="physical" />
            <token id="16" string="and" />
            <token id="17" string="emotional" />
            <token id="18" string="distress" />
            <token id="19" string="and" />
            <token id="20" string="embarrassment" />
            <token id="21" string="&quot;" />
            <token id="22" string="after" />
            <token id="23" string="the" />
            <token id="24" string="incident" />
            <token id="25" string="and" />
            <token id="26" string="expressed" />
            <token id="27" string="concern" />
            <token id="28" string="about" />
            <token id="29" string="damage" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="17" string="the incident" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="incident" />
          </tokens>
        </chunking>
        <chunking id="18" string="expressed concern about damage to his reputation" type="VP">
          <tokens>
            <token id="26" string="expressed" />
            <token id="27" string="concern" />
            <token id="28" string="about" />
            <token id="29" string="damage" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="reputation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">suit</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">suit</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">denies</governor>
          <dependent id="3">suit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">denies</governor>
          <dependent id="5">Morgan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">denies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">denies</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">denies</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">denies</governor>
          <dependent id="9">contends</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">suffered</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">suffered</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">contends</governor>
          <dependent id="12">suffered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">distress</governor>
          <dependent id="14">acute</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">distress</governor>
          <dependent id="15">physical</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">physical</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">physical</governor>
          <dependent id="17">emotional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">suffered</governor>
          <dependent id="18">distress</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">distress</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">distress</governor>
          <dependent id="20">embarrassment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">incident</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">incident</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">suffered</governor>
          <dependent id="24">incident</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">suffered</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">suffered</governor>
          <dependent id="26">expressed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">expressed</governor>
          <dependent id="27">concern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">damage</governor>
          <dependent id="28">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">expressed</governor>
          <dependent id="29">damage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">reputation</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">reputation</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">expressed</governor>
          <dependent id="32">reputation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morgan" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Morgan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="false">
      <content>RELATED STORY: C14</content>
      <tokens>
        <token id="1" string="RELATED" lemma="related" stem="related" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="STORY" lemma="story" stem="story" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="C14" lemma="c14" stem="c14" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (JJ RELATED) (NN STORY)) (: :) (NP (NN C14))))</syntactictree>
      <chunkings>
        <chunking id="1" string="C14" type="NP">
          <tokens>
            <token id="4" string="C14" />
          </tokens>
        </chunking>
        <chunking id="2" string="RELATED STORY : C14" type="NP">
          <tokens>
            <token id="1" string="RELATED" />
            <token id="2" string="STORY" />
            <token id="3" string=":" />
            <token id="4" string="C14" />
          </tokens>
        </chunking>
        <chunking id="3" string="RELATED STORY" type="NP">
          <tokens>
            <token id="1" string="RELATED" />
            <token id="2" string="STORY" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">STORY</governor>
          <dependent id="1">RELATED</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">STORY</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">STORY</governor>
          <dependent id="4">C14</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="9-10-11-12" string="Los Angeles International Airport" id_sentence="1" />
      <mentions>
        <mention ids_tokens="25-26" string="Los Angeles" id_sentence="2" />
        <mention ids_tokens="22-23" string="Los Angeles" id_sentence="6" />
        <mention ids_tokens="26-27" string="Los Angeles" id_sentence="21" />
        <mention ids_tokens="19-20" string="Los Angeles" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="16-17" string="Clayton Searle" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="Searle" id_sentence="2" />
        <mention ids_tokens="34" string="him" id_sentence="2" />
        <mention ids_tokens="23" string="Searle" id_sentence="3" />
        <mention ids_tokens="25" string="his" id_sentence="3" />
        <mention ids_tokens="29" string="him" id_sentence="3" />
        <mention ids_tokens="31" string="his" id_sentence="3" />
        <mention ids_tokens="2" string="his" id_sentence="4" />
        <mention ids_tokens="14" string="him" id_sentence="4" />
        <mention ids_tokens="4" string="Searle" id_sentence="5" />
        <mention ids_tokens="6" string="his" id_sentence="5" />
        <mention ids_tokens="17" string="Searle" id_sentence="6" />
        <mention ids_tokens="23" string="he" id_sentence="7" />
        <mention ids_tokens="14" string="you" id_sentence="9" />
        <mention ids_tokens="21" string="I" id_sentence="14" />
        <mention ids_tokens="25" string="you" id_sentence="14" />
        <mention ids_tokens="1" string="He" id_sentence="17" />
        <mention ids_tokens="2" string="Searle" id_sentence="26" />
        <mention ids_tokens="11" string="Searle" id_sentence="27" />
        <mention ids_tokens="42" string="Searle" id_sentence="31" />
        <mention ids_tokens="45" string="his" id_sentence="31" />
        <mention ids_tokens="49" string="him" id_sentence="31" />
        <mention ids_tokens="26" string="Searle" id_sentence="32" />
        <mention ids_tokens="30" string="him" id_sentence="32" />
        <mention ids_tokens="25" string="Searle" id_sentence="33" />
        <mention ids_tokens="7" string="Searle" id_sentence="34" />
        <mention ids_tokens="9" string="him" id_sentence="34" />
        <mention ids_tokens="1" string="Searle" id_sentence="37" />
        <mention ids_tokens="6" string="him" id_sentence="37" />
        <mention ids_tokens="8" string="he" id_sentence="37" />
        <mention ids_tokens="1-3" string="Searle , 42" id_sentence="41" />
        <mention ids_tokens="1" string="Searle" id_sentence="41" />
        <mention ids_tokens="12" string="he" id_sentence="41" />
        <mention ids_tokens="3" string="I" id_sentence="42" />
        <mention ids_tokens="24" string="Searle" id_sentence="42" />
        <mention ids_tokens="2" string="I" id_sentence="43" />
        <mention ids_tokens="18" string="Searle" id_sentence="45" />
        <mention ids_tokens="3-4" string="Searle's" id_sentence="49" />
        <mention ids_tokens="13" string="he" id_sentence="49" />
        <mention ids_tokens="3" string="he" id_sentence="50" />
        <mention ids_tokens="8" string="his" id_sentence="51" />
        <mention ids_tokens="11" string="Searle" id_sentence="51" />
        <mention ids_tokens="30" string="his" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="3" type="PRONOMINAL">
      <referenced ids_tokens="2" string="they" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12" string="them" id_sentence="2" />
        <mention ids_tokens="6" string="their" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22" string="his fellow narcotics officer" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10-11" string="the officer" id_sentence="4" />
        <mention ids_tokens="3-4" string="the officer" id_sentence="35" />
        <mention ids_tokens="10" string="his" id_sentence="35" />
        <mention ids_tokens="14" string="his" id_sentence="35" />
        <mention ids_tokens="17" string="him" id_sentence="35" />
        <mention ids_tokens="20" string="him" id_sentence="35" />
        <mention ids_tokens="10-11" string="the officer" id_sentence="45" />
        <mention ids_tokens="40-41" string="the officer" id_sentence="45" />
        <mention ids_tokens="17-18" string="the officer" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="25-26-27-28-29-30-31-32-33-34-35-36" string="the likely companion of the suspected drug courier who stood handcuffed nearby" id_sentence="1" />
      <mentions>
        <mention ids_tokens="30-31" string="his companion" id_sentence="51" />
        <mention ids_tokens="9-10" string="his companion" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="19-20-21" string="the terminal floor" id_sentence="3" />
      <mentions>
        <mention ids_tokens="17-18" string="the floor" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="15" string="DEA" id_sentence="26" />
      <mentions>
        <mention ids_tokens="6-12" string="his partner from the Drug Enforcement Administration" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The 46-year-old Morgan" id_sentence="6" />
      <mentions>
        <mention ids_tokens="15-27" string="the suspected drug courier they had arrested on that March day in 1988" id_sentence="5" />
        <mention ids_tokens="29-35" string="Joe Morgan , the former Cincinnati Reds" id_sentence="5" />
        <mention ids_tokens="29-30" string="Joe Morgan" id_sentence="5" />
        <mention ids_tokens="15-16" string="Joe Morgan" id_sentence="7" />
        <mention ids_tokens="19" string="he" id_sentence="7" />
        <mention ids_tokens="2" string="Morgan" id_sentence="8" />
        <mention ids_tokens="9" string="Morgan" id_sentence="21" />
        <mention ids_tokens="1" string="Morgan" id_sentence="22" />
        <mention ids_tokens="9" string="his" id_sentence="22" />
        <mention ids_tokens="9-10" string="Morgan's" id_sentence="23" />
        <mention ids_tokens="26" string="Morgan" id_sentence="24" />
        <mention ids_tokens="5" string="Morgan" id_sentence="28" />
        <mention ids_tokens="13" string="he" id_sentence="28" />
        <mention ids_tokens="7" string="him" id_sentence="29" />
        <mention ids_tokens="1" string="Morgan" id_sentence="30" />
        <mention ids_tokens="6" string="he" id_sentence="31" />
        <mention ids_tokens="15" string="he" id_sentence="31" />
        <mention ids_tokens="4" string="himself" id_sentence="32" />
        <mention ids_tokens="6" string="Morgan" id_sentence="32" />
        <mention ids_tokens="8" string="he" id_sentence="32" />
        <mention ids_tokens="13" string="his" id_sentence="32" />
        <mention ids_tokens="10" string="Morgan" id_sentence="33" />
        <mention ids_tokens="4" string="Morgan" id_sentence="34" />
        <mention ids_tokens="1" string="Morgan" id_sentence="35" />
        <mention ids_tokens="1" string="He" id_sentence="36" />
        <mention ids_tokens="23" string="his" id_sentence="36" />
        <mention ids_tokens="26" string="Morgan" id_sentence="36" />
        <mention ids_tokens="16-17" string="Morgan's" id_sentence="37" />
        <mention ids_tokens="3" string="Morgan" id_sentence="38" />
        <mention ids_tokens="5" string="his" id_sentence="38" />
        <mention ids_tokens="18" string="his" id_sentence="38" />
        <mention ids_tokens="5-6" string="Joe Morgan" id_sentence="39" />
        <mention ids_tokens="6" string="Joe" id_sentence="40" />
        <mention ids_tokens="26" string="Morgan" id_sentence="45" />
        <mention ids_tokens="29" string="himself" id_sentence="45" />
        <mention ids_tokens="31" string="Morgan" id_sentence="45" />
        <mention ids_tokens="6-7" string="Mr. Morgan" id_sentence="46" />
        <mention ids_tokens="3" string="he" id_sentence="47" />
        <mention ids_tokens="3" string="he" id_sentence="48" />
        <mention ids_tokens="10" string="he" id_sentence="48" />
        <mention ids_tokens="4-6" string="Morgan , Searle" id_sentence="53" />
        <mention ids_tokens="4" string="Morgan" id_sentence="53" />
        <mention ids_tokens="9" string="he" id_sentence="53" />
        <mention ids_tokens="14" string="him" id_sentence="53" />
        <mention ids_tokens="16" string="Morgan" id_sentence="53" />
        <mention ids_tokens="2" string="his" id_sentence="54" />
        <mention ids_tokens="5" string="Morgan" id_sentence="54" />
        <mention ids_tokens="11" string="he" id_sentence="54" />
        <mention ids_tokens="31" string="his" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="12" type="LIST">
      <referenced ids_tokens="8-9-10-11-12-13" string="an Oakland businessman and baseball broadcaster" id_sentence="6" />
      <mentions>
        <mention ids_tokens="7" string="our" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="13" type="LIST">
      <referenced ids_tokens="17-18-19-20-21-22-23" string="Searle and the city of Los Angeles" id_sentence="6" />
      <mentions>
        <mention ids_tokens="13" string="they" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="40-41-42-43-44-45-46-47-48-49-50-51-52-53-54" string="a certain &quot; profile &quot; that narcotics officers think a drug courier should look like" id_sentence="6" />
      <mentions>
        <mention ids_tokens="13-16" string="the drug courier profile" id_sentence="8" />
        <mention ids_tokens="7-10" string="the drug courier profile" id_sentence="10" />
        <mention ids_tokens="18-19" string="the profile" id_sentence="14" />
        <mention ids_tokens="2" string="It" id_sentence="15" />
        <mention ids_tokens="1" string="It" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="46-47" string="narcotics officers" id_sentence="6" />
      <mentions>
        <mention ids_tokens="19-20" string="the officers" id_sentence="36" />
        <mention ids_tokens="2-3" string="the officers" id_sentence="51" />
        <mention ids_tokens="13" string="they" id_sentence="51" />
        <mention ids_tokens="26" string="they" id_sentence="51" />
        <mention ids_tokens="2" string="they" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="5-6" string="no drugs" id_sentence="51" />
      <mentions>
        <mention ids_tokens="22" string="drugs" id_sentence="8" />
        <mention ids_tokens="17" string="drugs" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The Morgan case" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="9" />
        <mention ids_tokens="9-11" string="Morgan's case" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="1-2" string="Last year" id_sentence="12" />
      <mentions>
        <mention ids_tokens="5-6" string="this year" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="4-5-6-7" string="the U.S. Supreme Court" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2-3" string="the court" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="10-11" string="government agents" id_sentence="12" />
      <mentions>
        <mention ids_tokens="6" string="we" id_sentence="14" />
        <mention ids_tokens="13" string="we" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24" string="airline passengers who look and act like drug couriers" id_sentence="12" />
      <mentions>
        <mention ids_tokens="8" string="them" id_sentence="14" />
        <mention ids_tokens="15" string="them" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="29-30-31-32" string="Los Angeles Police Department" id_sentence="14" />
      <mentions>
        <mention ids_tokens="6-7" string="Police Department" id_sentence="26" />
        <mention ids_tokens="13-15" string="the Police Department" id_sentence="45" />
        <mention ids_tokens="14-15" string="Police Department" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="29-30-31-32-33-34-35" string="Los Angeles Police Department Cmdr. William Booth" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="Booth" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="1-2" string="Frank Schults" id_sentence="19" />
      <mentions>
        <mention ids_tokens="29" string="he" id_sentence="20" />
        <mention ids_tokens="4" string="Schults" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27" string="the Morgan lawsuit , which is scheduled to go to trial for a second time next month in Los Angeles" id_sentence="21" />
      <mentions>
        <mention ids_tokens="16-18" string="Morgan's lawsuit" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="the Morgan lawsuit" id_sentence="21" />
      <mentions>
        <mention ids_tokens="22-23" string="the lawsuit" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="8" string="Judge" id_sentence="24" />
      <mentions>
        <mention ids_tokens="17-18" string="the judge" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="11-12" string="William Woessner" id_sentence="26" />
      <mentions>
        <mention ids_tokens="15" string="Woessner" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="5" string="this" id_sentence="27" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="28" />
        <mention ids_tokens="10" string="I" id_sentence="28" />
        <mention ids_tokens="1" string="I" id_sentence="29" />
        <mention ids_tokens="4" string="I" id_sentence="29" />
        <mention ids_tokens="13" string="me" id_sentence="40" />
        <mention ids_tokens="15" string="my" id_sentence="40" />
        <mention ids_tokens="2" string="My" id_sentence="46" />
        <mention ids_tokens="1" string="I" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="19-20-21-22-23-24-25-26-27-28-29-30-31-32-33" string="Los Angeles International Airport for a connecting flight to Tucson to attend a golf tournament" id_sentence="31" />
      <mentions>
        <mention ids_tokens="19-21" string="Los Angeles airport" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="17-18-19" string="an attache case" id_sentence="32" />
      <mentions>
        <mention ids_tokens="18-19" string="the case" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="21-22" string="both men" id_sentence="33" />
      <mentions>
        <mention ids_tokens="14" string="they" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="2" string="This" id_sentence="39" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="3" string="42" id_sentence="41" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="8-9" string="the guy" id_sentence="42" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="4-5-6" string="Honey A. Lewis" id_sentence="45" />
      <mentions>
        <mention ids_tokens="11" string="Lewis" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="19" string="profanities" id_sentence="53" />
      <mentions>
        <mention ids_tokens="37-39" string="profanities and slapping" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="46" type="LIST">
      <referenced ids_tokens="13-14-15" string="he and Woessner" id_sentence="49" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="30-31" string="a passenger" id_sentence="49" />
      <mentions>
        <mention ids_tokens="16-17" string="the passenger" id_sentence="51" />
        <mention ids_tokens="2-3" string="the passenger" id_sentence="52" />
        <mention ids_tokens="9" string="his" id_sentence="52" />
        <mention ids_tokens="14" string="me" id_sentence="52" />
        <mention ids_tokens="28" string="him" id_sentence="53" />
      </mentions>
    </coreference>
  </coreferences>
</document>
