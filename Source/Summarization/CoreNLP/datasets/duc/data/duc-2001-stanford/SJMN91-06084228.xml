<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06084228">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>SPEED TRAP; By Charlie Francis with Jeff Coplon  St. Martin&amp;apost;s, 306 pp., $18.95; CHARLIE Francis, testifying in 1988 in Toronto at a federal inquiry about the use of performance-enhancing drugs in sports, seemed a mad scientist, something on the order of Dr. Frankenstein.</content>
      <tokens>
        <token id="1" string="SPEED" lemma="speed" stem="speed" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="TRAP" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Jeff" lemma="Jeff" stem="jeff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Coplon" lemma="Coplon" stem="coplon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="306" lemma="306" stem="306" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="pp." lemma="pp." stem="pp." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="18.95" lemma="18.95" stem="18.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="19" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="CHARLIE" lemma="CHARLIE" stem="charlie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="testifying" lemma="testify" stem="testifi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="sports" lemma="sport" stem="sport" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="Frankenstein" lemma="Frankenstein" stem="frankenstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (VP (VB SPEED) (NP (NP (NP (NN TRAP)) (PRN (: ;) (PP (IN By) (NP (NP (NNP Charlie) (NNP Francis)) (PP (IN with) (NP (NNP Jeff) (NNP Coplon))))) (NP (NP (NNP St.) (NNP Martin) (POS 's)) (, ,) (NP (CD 306) (NN pp.)) (, ,) (NP ($ $) (CD 18.95))))) (: ;) (NP (NNP CHARLIE) (NNP Francis)) (, ,) (VP (VBG testifying) (PP (IN in) (NP (NP (CD 1988)) (PP (IN in) (NP (NNP Toronto))))) (PP (IN at) (NP (NP (DT a) (JJ federal) (NN inquiry)) (PP (IN about) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (JJ performance-enhancing) (NNS drugs)) (PP (IN in) (NP (NNS sports))))))))))))) (, ,) (VP (VBD seemed)) (NP (NP (DT a) (JJ mad) (NN scientist)) (, ,) (NP (NP (NN something)) (PP (IN on) (NP (NP (DT the) (NN order)) (PP (IN of) (NP (NNP Dr.) (NNP Frankenstein))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the order" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="order" />
          </tokens>
        </chunking>
        <chunking id="2" string="seemed" type="VP">
          <tokens>
            <token id="41" string="seemed" />
          </tokens>
        </chunking>
        <chunking id="3" string="sports" type="NP">
          <tokens>
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dr. Frankenstein" type="NP">
          <tokens>
            <token id="51" string="Dr." />
            <token id="52" string="Frankenstein" />
          </tokens>
        </chunking>
        <chunking id="5" string="St. Martin 's" type="NP">
          <tokens>
            <token id="10" string="St." />
            <token id="11" string="Martin" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="CHARLIE Francis" type="NP">
          <tokens>
            <token id="20" string="CHARLIE" />
            <token id="21" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="7" string="TRAP ; By Charlie Francis with Jeff Coplon St. Martin 's , 306 pp. , $ 18.95" type="NP">
          <tokens>
            <token id="2" string="TRAP" />
            <token id="3" string=";" />
            <token id="4" string="By" />
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
            <token id="7" string="with" />
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
            <token id="10" string="St." />
            <token id="11" string="Martin" />
            <token id="12" string="'s" />
            <token id="13" string="," />
            <token id="14" string="306" />
            <token id="15" string="pp." />
            <token id="16" string="," />
            <token id="17" string="$" />
            <token id="18" string="18.95" />
          </tokens>
        </chunking>
        <chunking id="8" string="something" type="NP">
          <tokens>
            <token id="46" string="something" />
          </tokens>
        </chunking>
        <chunking id="9" string="1988" type="NP">
          <tokens>
            <token id="25" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="the order of Dr. Frankenstein" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="order" />
            <token id="50" string="of" />
            <token id="51" string="Dr." />
            <token id="52" string="Frankenstein" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jeff Coplon" type="NP">
          <tokens>
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
          </tokens>
        </chunking>
        <chunking id="12" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="the use" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="use" />
          </tokens>
        </chunking>
        <chunking id="14" string="Toronto" type="NP">
          <tokens>
            <token id="27" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="15" string="SPEED TRAP ; By Charlie Francis with Jeff Coplon St. Martin 's , 306 pp. , $ 18.95 ; CHARLIE Francis , testifying in 1988 in Toronto at a federal inquiry about the use of performance-enhancing drugs in sports" type="VP">
          <tokens>
            <token id="1" string="SPEED" />
            <token id="2" string="TRAP" />
            <token id="3" string=";" />
            <token id="4" string="By" />
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
            <token id="7" string="with" />
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
            <token id="10" string="St." />
            <token id="11" string="Martin" />
            <token id="12" string="'s" />
            <token id="13" string="," />
            <token id="14" string="306" />
            <token id="15" string="pp." />
            <token id="16" string="," />
            <token id="17" string="$" />
            <token id="18" string="18.95" />
            <token id="19" string=";" />
            <token id="20" string="CHARLIE" />
            <token id="21" string="Francis" />
            <token id="22" string="," />
            <token id="23" string="testifying" />
            <token id="24" string="in" />
            <token id="25" string="1988" />
            <token id="26" string="in" />
            <token id="27" string="Toronto" />
            <token id="28" string="at" />
            <token id="29" string="a" />
            <token id="30" string="federal" />
            <token id="31" string="inquiry" />
            <token id="32" string="about" />
            <token id="33" string="the" />
            <token id="34" string="use" />
            <token id="35" string="of" />
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="16" string="a federal inquiry" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="federal" />
            <token id="31" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="17" string="306 pp." type="NP">
          <tokens>
            <token id="14" string="306" />
            <token id="15" string="pp." />
          </tokens>
        </chunking>
        <chunking id="18" string="Charlie Francis" type="NP">
          <tokens>
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="19" string="TRAP" type="NP">
          <tokens>
            <token id="2" string="TRAP" />
          </tokens>
        </chunking>
        <chunking id="20" string="Charlie Francis with Jeff Coplon" type="NP">
          <tokens>
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
            <token id="7" string="with" />
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
          </tokens>
        </chunking>
        <chunking id="21" string="the use of performance-enhancing drugs in sports" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="use" />
            <token id="35" string="of" />
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="22" string="$ 18.95" type="NP">
          <tokens>
            <token id="17" string="$" />
            <token id="18" string="18.95" />
          </tokens>
        </chunking>
        <chunking id="23" string="a mad scientist" type="NP">
          <tokens>
            <token id="42" string="a" />
            <token id="43" string="mad" />
            <token id="44" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="24" string="performance-enhancing drugs in sports" type="NP">
          <tokens>
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="25" string="TRAP ; By Charlie Francis with Jeff Coplon St. Martin 's , 306 pp. , $ 18.95 ; CHARLIE Francis , testifying in 1988 in Toronto at a federal inquiry about the use of performance-enhancing drugs in sports" type="NP">
          <tokens>
            <token id="2" string="TRAP" />
            <token id="3" string=";" />
            <token id="4" string="By" />
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
            <token id="7" string="with" />
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
            <token id="10" string="St." />
            <token id="11" string="Martin" />
            <token id="12" string="'s" />
            <token id="13" string="," />
            <token id="14" string="306" />
            <token id="15" string="pp." />
            <token id="16" string="," />
            <token id="17" string="$" />
            <token id="18" string="18.95" />
            <token id="19" string=";" />
            <token id="20" string="CHARLIE" />
            <token id="21" string="Francis" />
            <token id="22" string="," />
            <token id="23" string="testifying" />
            <token id="24" string="in" />
            <token id="25" string="1988" />
            <token id="26" string="in" />
            <token id="27" string="Toronto" />
            <token id="28" string="at" />
            <token id="29" string="a" />
            <token id="30" string="federal" />
            <token id="31" string="inquiry" />
            <token id="32" string="about" />
            <token id="33" string="the" />
            <token id="34" string="use" />
            <token id="35" string="of" />
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="26" string="testifying in 1988 in Toronto at a federal inquiry about the use of performance-enhancing drugs in sports" type="VP">
          <tokens>
            <token id="23" string="testifying" />
            <token id="24" string="in" />
            <token id="25" string="1988" />
            <token id="26" string="in" />
            <token id="27" string="Toronto" />
            <token id="28" string="at" />
            <token id="29" string="a" />
            <token id="30" string="federal" />
            <token id="31" string="inquiry" />
            <token id="32" string="about" />
            <token id="33" string="the" />
            <token id="34" string="use" />
            <token id="35" string="of" />
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="27" string="1988 in Toronto" type="NP">
          <tokens>
            <token id="25" string="1988" />
            <token id="26" string="in" />
            <token id="27" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="28" string="a federal inquiry about the use of performance-enhancing drugs in sports" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="federal" />
            <token id="31" string="inquiry" />
            <token id="32" string="about" />
            <token id="33" string="the" />
            <token id="34" string="use" />
            <token id="35" string="of" />
            <token id="36" string="performance-enhancing" />
            <token id="37" string="drugs" />
            <token id="38" string="in" />
            <token id="39" string="sports" />
          </tokens>
        </chunking>
        <chunking id="29" string="a mad scientist , something on the order of Dr. Frankenstein" type="NP">
          <tokens>
            <token id="42" string="a" />
            <token id="43" string="mad" />
            <token id="44" string="scientist" />
            <token id="45" string="," />
            <token id="46" string="something" />
            <token id="47" string="on" />
            <token id="48" string="the" />
            <token id="49" string="order" />
            <token id="50" string="of" />
            <token id="51" string="Dr." />
            <token id="52" string="Frankenstein" />
          </tokens>
        </chunking>
        <chunking id="30" string="St. Martin 's , 306 pp. , $ 18.95" type="NP">
          <tokens>
            <token id="10" string="St." />
            <token id="11" string="Martin" />
            <token id="12" string="'s" />
            <token id="13" string="," />
            <token id="14" string="306" />
            <token id="15" string="pp." />
            <token id="16" string="," />
            <token id="17" string="$" />
            <token id="18" string="18.95" />
          </tokens>
        </chunking>
        <chunking id="31" string="something on the order of Dr. Frankenstein" type="NP">
          <tokens>
            <token id="46" string="something" />
            <token id="47" string="on" />
            <token id="48" string="the" />
            <token id="49" string="order" />
            <token id="50" string="of" />
            <token id="51" string="Dr." />
            <token id="52" string="Frankenstein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="41">seemed</governor>
          <dependent id="1">SPEED</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">SPEED</governor>
          <dependent id="2">TRAP</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Francis</governor>
          <dependent id="4">By</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Francis</governor>
          <dependent id="5">Charlie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Martin</governor>
          <dependent id="6">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Coplon</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Coplon</governor>
          <dependent id="8">Jeff</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Francis</governor>
          <dependent id="9">Coplon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Martin</governor>
          <dependent id="10">St.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">TRAP</governor>
          <dependent id="11">Martin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Martin</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">pp.</governor>
          <dependent id="14">306</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Martin</governor>
          <dependent id="15">pp.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">18.95</governor>
          <dependent id="17">$</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Martin</governor>
          <dependent id="18">18.95</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Francis</governor>
          <dependent id="20">CHARLIE</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">TRAP</governor>
          <dependent id="21">Francis</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">TRAP</governor>
          <dependent id="23">testifying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">1988</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">testifying</governor>
          <dependent id="25">1988</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Toronto</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">1988</governor>
          <dependent id="27">Toronto</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">inquiry</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">inquiry</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">inquiry</governor>
          <dependent id="30">federal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">testifying</governor>
          <dependent id="31">inquiry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">use</governor>
          <dependent id="32">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">use</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">inquiry</governor>
          <dependent id="34">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">drugs</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">drugs</governor>
          <dependent id="36">performance-enhancing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">use</governor>
          <dependent id="37">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">sports</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">drugs</governor>
          <dependent id="39">sports</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">seemed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">scientist</governor>
          <dependent id="42">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">scientist</governor>
          <dependent id="43">mad</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">seemed</governor>
          <dependent id="44">scientist</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="44">scientist</governor>
          <dependent id="46">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">order</governor>
          <dependent id="47">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">order</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">something</governor>
          <dependent id="49">order</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">Frankenstein</governor>
          <dependent id="50">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Frankenstein</governor>
          <dependent id="51">Dr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">order</governor>
          <dependent id="52">Frankenstein</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="37" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="Frankenstein" type="PERSON" score="0.0">
          <tokens>
            <token id="52" string="Frankenstein" />
          </tokens>
        </entity>
        <entity id="4" string="306" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="306" />
          </tokens>
        </entity>
        <entity id="5" string="Charlie Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Charlie" />
            <token id="6" string="Francis" />
          </tokens>
        </entity>
        <entity id="6" string="Jeff Coplon St. Martin" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jeff" />
            <token id="9" string="Coplon" />
            <token id="10" string="St." />
            <token id="11" string="Martin" />
          </tokens>
        </entity>
        <entity id="7" string="CHARLIE Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="CHARLIE" />
            <token id="21" string="Francis" />
          </tokens>
        </entity>
        <entity id="8" string="$ 18.95" type="MONEY" score="0.0">
          <tokens>
            <token id="17" string="$" />
            <token id="18" string="18.95" />
          </tokens>
        </entity>
        <entity id="9" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Francis, the Canadian national sprint coach, knew the polysyllabic names and complex characteristics of steroids -- furazabol, stanozolol, Dianabol -- as if they were members of his family.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="5" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="sprint" lemma="sprint" stem="sprint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="polysyllabic" lemma="polysyllabic" stem="polysyllab" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="complex" lemma="complex" stem="complex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="characteristics" lemma="characteristic" stem="characterist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="furazabol" lemma="furazabol" stem="furazabol" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Dianabol" lemma="Dianabol" stem="dianabol" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Francis)) (, ,) (NP (DT the) (JJ Canadian) (JJ national) (NN sprint) (NN coach)) (, ,)) (VP (VBD knew) (NP (NP (DT the) (JJ polysyllabic) (NNS names) (CC and) (NN complex) (NNS characteristics)) (PP (IN of) (NP (NP (NNS steroids)) (PRN (: --) (NP (NP (NN furazabol)) (, ,) (NP (NN stanozolol)) (, ,) (NP (NNP Dianabol))) (: --))))) (SBAR (IN as) (IN if) (S (NP (PRP they)) (VP (VBD were) (NP (NP (NNS members)) (PP (IN of) (NP (PRP$ his) (NN family)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Canadian national sprint coach" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Canadian" />
            <token id="5" string="national" />
            <token id="6" string="sprint" />
            <token id="7" string="coach" />
          </tokens>
        </chunking>
        <chunking id="2" string="the polysyllabic names and complex characteristics" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="polysyllabic" />
            <token id="12" string="names" />
            <token id="13" string="and" />
            <token id="14" string="complex" />
            <token id="15" string="characteristics" />
          </tokens>
        </chunking>
        <chunking id="3" string="Francis , the Canadian national sprint coach ," type="NP">
          <tokens>
            <token id="1" string="Francis" />
            <token id="2" string="," />
            <token id="3" string="the" />
            <token id="4" string="Canadian" />
            <token id="5" string="national" />
            <token id="6" string="sprint" />
            <token id="7" string="coach" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="steroids -- furazabol , stanozolol , Dianabol --" type="NP">
          <tokens>
            <token id="17" string="steroids" />
            <token id="18" string="--" />
            <token id="19" string="furazabol" />
            <token id="20" string="," />
            <token id="21" string="stanozolol" />
            <token id="22" string="," />
            <token id="23" string="Dianabol" />
            <token id="24" string="--" />
          </tokens>
        </chunking>
        <chunking id="5" string="stanozolol" type="NP">
          <tokens>
            <token id="21" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="6" string="knew the polysyllabic names and complex characteristics of steroids -- furazabol , stanozolol , Dianabol -- as if they were members of his family" type="VP">
          <tokens>
            <token id="9" string="knew" />
            <token id="10" string="the" />
            <token id="11" string="polysyllabic" />
            <token id="12" string="names" />
            <token id="13" string="and" />
            <token id="14" string="complex" />
            <token id="15" string="characteristics" />
            <token id="16" string="of" />
            <token id="17" string="steroids" />
            <token id="18" string="--" />
            <token id="19" string="furazabol" />
            <token id="20" string="," />
            <token id="21" string="stanozolol" />
            <token id="22" string="," />
            <token id="23" string="Dianabol" />
            <token id="24" string="--" />
            <token id="25" string="as" />
            <token id="26" string="if" />
            <token id="27" string="they" />
            <token id="28" string="were" />
            <token id="29" string="members" />
            <token id="30" string="of" />
            <token id="31" string="his" />
            <token id="32" string="family" />
          </tokens>
        </chunking>
        <chunking id="7" string="furazabol" type="NP">
          <tokens>
            <token id="19" string="furazabol" />
          </tokens>
        </chunking>
        <chunking id="8" string="as if they were members of his family" type="SBAR">
          <tokens>
            <token id="25" string="as" />
            <token id="26" string="if" />
            <token id="27" string="they" />
            <token id="28" string="were" />
            <token id="29" string="members" />
            <token id="30" string="of" />
            <token id="31" string="his" />
            <token id="32" string="family" />
          </tokens>
        </chunking>
        <chunking id="9" string="members of his family" type="NP">
          <tokens>
            <token id="29" string="members" />
            <token id="30" string="of" />
            <token id="31" string="his" />
            <token id="32" string="family" />
          </tokens>
        </chunking>
        <chunking id="10" string="the polysyllabic names and complex characteristics of steroids -- furazabol , stanozolol , Dianabol --" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="polysyllabic" />
            <token id="12" string="names" />
            <token id="13" string="and" />
            <token id="14" string="complex" />
            <token id="15" string="characteristics" />
            <token id="16" string="of" />
            <token id="17" string="steroids" />
            <token id="18" string="--" />
            <token id="19" string="furazabol" />
            <token id="20" string="," />
            <token id="21" string="stanozolol" />
            <token id="22" string="," />
            <token id="23" string="Dianabol" />
            <token id="24" string="--" />
          </tokens>
        </chunking>
        <chunking id="11" string="Dianabol" type="NP">
          <tokens>
            <token id="23" string="Dianabol" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="27" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="14" string="furazabol , stanozolol , Dianabol" type="NP">
          <tokens>
            <token id="19" string="furazabol" />
            <token id="20" string="," />
            <token id="21" string="stanozolol" />
            <token id="22" string="," />
            <token id="23" string="Dianabol" />
          </tokens>
        </chunking>
        <chunking id="15" string="members" type="NP">
          <tokens>
            <token id="29" string="members" />
          </tokens>
        </chunking>
        <chunking id="16" string="were members of his family" type="VP">
          <tokens>
            <token id="28" string="were" />
            <token id="29" string="members" />
            <token id="30" string="of" />
            <token id="31" string="his" />
            <token id="32" string="family" />
          </tokens>
        </chunking>
        <chunking id="17" string="steroids" type="NP">
          <tokens>
            <token id="17" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="18" string="his family" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="family" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">knew</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">coach</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">coach</governor>
          <dependent id="4">Canadian</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">coach</governor>
          <dependent id="5">national</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">coach</governor>
          <dependent id="6">sprint</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Francis</governor>
          <dependent id="7">coach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">knew</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">names</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">names</governor>
          <dependent id="11">polysyllabic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">knew</governor>
          <dependent id="12">names</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">names</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">characteristics</governor>
          <dependent id="14">complex</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">names</governor>
          <dependent id="15">characteristics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">steroids</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">names</governor>
          <dependent id="17">steroids</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">steroids</governor>
          <dependent id="19">furazabol</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">furazabol</governor>
          <dependent id="21">stanozolol</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">furazabol</governor>
          <dependent id="23">Dianabol</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">members</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="25">as</governor>
          <dependent id="26">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">members</governor>
          <dependent id="27">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">members</governor>
          <dependent id="28">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">knew</governor>
          <dependent id="29">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">family</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">family</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">members</governor>
          <dependent id="32">family</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
        <entity id="2" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="Canadian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>And although he spoke of his athletes as if they were family members, too, he made it plain, under oath, that he had given them every steroid combination imaginable, his experiments all carefully calibrated, charted and analyzed.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="spoke" lemma="speak" stem="spoke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="plain" lemma="plain" stem="plain" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="oath" lemma="oath" stem="oath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="combination" lemma="combination" stem="combin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="imaginable" lemma="imaginable" stem="imagin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="experiments" lemma="experiment" stem="experi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="carefully" lemma="carefully" stem="carefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="calibrated" lemma="calibrate" stem="calibr" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="charted" lemma="chart" stem="chart" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="analyzed" lemma="analyze" stem="analyz" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (IN although) (S (NP (PRP he)) (VP (VBD spoke) (PP (IN of) (NP (PRP$ his) (NNS athletes))) (SBAR (IN as) (IN if) (S (NP (PRP they)) (VP (VBD were) (NP (NN family) (NNS members)) (, ,) (ADVP (RB too)))))))) (, ,) (NP (PRP he)) (VP (VBD made) (NP (PRP it)) (ADVP (RB plain)) (, ,) (PP (IN under) (NP (NN oath))) (, ,) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD had) (VP (VBN given) (NP (PRP them)) (NP (NP (DT every) (NN steroid) (NN combination)) (ADJP (JJ imaginable))) (, ,) (NP (NP (NP (PRP$ his) (NNS experiments)) (NP (DT all)) (ADJP (RB carefully) (VBN calibrated))) (, ,) (VP (VBN charted) (CC and) (VBN analyzed)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were family members , too" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="family" />
            <token id="13" string="members" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="2" string="although he spoke of his athletes as if they were family members , too" type="SBAR">
          <tokens>
            <token id="2" string="although" />
            <token id="3" string="he" />
            <token id="4" string="spoke" />
            <token id="5" string="of" />
            <token id="6" string="his" />
            <token id="7" string="athletes" />
            <token id="8" string="as" />
            <token id="9" string="if" />
            <token id="10" string="they" />
            <token id="11" string="were" />
            <token id="12" string="family" />
            <token id="13" string="members" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="3" string="family members" type="NP">
          <tokens>
            <token id="12" string="family" />
            <token id="13" string="members" />
          </tokens>
        </chunking>
        <chunking id="4" string="all" type="NP">
          <tokens>
            <token id="37" string="all" />
          </tokens>
        </chunking>
        <chunking id="5" string="his experiments all carefully calibrated , charted and analyzed" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
            <token id="40" string="," />
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="6" string="his athletes" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="7" string="as if they were family members , too" type="SBAR">
          <tokens>
            <token id="8" string="as" />
            <token id="9" string="if" />
            <token id="10" string="they" />
            <token id="11" string="were" />
            <token id="12" string="family" />
            <token id="13" string="members" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="8" string="had given them every steroid combination imaginable , his experiments all carefully calibrated , charted and analyzed" type="VP">
          <tokens>
            <token id="27" string="had" />
            <token id="28" string="given" />
            <token id="29" string="them" />
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
            <token id="33" string="imaginable" />
            <token id="34" string="," />
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
            <token id="40" string="," />
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="9" string="spoke of his athletes as if they were family members , too" type="VP">
          <tokens>
            <token id="4" string="spoke" />
            <token id="5" string="of" />
            <token id="6" string="his" />
            <token id="7" string="athletes" />
            <token id="8" string="as" />
            <token id="9" string="if" />
            <token id="10" string="they" />
            <token id="11" string="were" />
            <token id="12" string="family" />
            <token id="13" string="members" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="charted and analyzed" type="VP">
          <tokens>
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="12" string="made it plain , under oath , that he had given them every steroid combination imaginable , his experiments all carefully calibrated , charted and analyzed" type="VP">
          <tokens>
            <token id="18" string="made" />
            <token id="19" string="it" />
            <token id="20" string="plain" />
            <token id="21" string="," />
            <token id="22" string="under" />
            <token id="23" string="oath" />
            <token id="24" string="," />
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="given" />
            <token id="29" string="them" />
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
            <token id="33" string="imaginable" />
            <token id="34" string="," />
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
            <token id="40" string="," />
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="13" string="them" type="NP">
          <tokens>
            <token id="29" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="every steroid combination imaginable" type="NP">
          <tokens>
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
            <token id="33" string="imaginable" />
          </tokens>
        </chunking>
        <chunking id="15" string="his experiments all carefully calibrated" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
          </tokens>
        </chunking>
        <chunking id="16" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="17" string="that he had given them every steroid combination imaginable , his experiments all carefully calibrated , charted and analyzed" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="given" />
            <token id="29" string="them" />
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
            <token id="33" string="imaginable" />
            <token id="34" string="," />
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
            <token id="40" string="," />
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="18" string="given them every steroid combination imaginable , his experiments all carefully calibrated , charted and analyzed" type="VP">
          <tokens>
            <token id="28" string="given" />
            <token id="29" string="them" />
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
            <token id="33" string="imaginable" />
            <token id="34" string="," />
            <token id="35" string="his" />
            <token id="36" string="experiments" />
            <token id="37" string="all" />
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
            <token id="40" string="," />
            <token id="41" string="charted" />
            <token id="42" string="and" />
            <token id="43" string="analyzed" />
          </tokens>
        </chunking>
        <chunking id="19" string="every steroid combination" type="NP">
          <tokens>
            <token id="30" string="every" />
            <token id="31" string="steroid" />
            <token id="32" string="combination" />
          </tokens>
        </chunking>
        <chunking id="20" string="oath" type="NP">
          <tokens>
            <token id="23" string="oath" />
          </tokens>
        </chunking>
        <chunking id="21" string="imaginable" type="ADJP">
          <tokens>
            <token id="33" string="imaginable" />
          </tokens>
        </chunking>
        <chunking id="22" string="his experiments" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="experiments" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="carefully calibrated" type="ADJP">
          <tokens>
            <token id="38" string="carefully" />
            <token id="39" string="calibrated" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="18">made</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">spoke</governor>
          <dependent id="2">although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">spoke</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">made</governor>
          <dependent id="4">spoke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">athletes</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">athletes</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spoke</governor>
          <dependent id="7">athletes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">members</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">as</governor>
          <dependent id="9">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">members</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">members</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">members</governor>
          <dependent id="12">family</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">spoke</governor>
          <dependent id="13">members</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">members</governor>
          <dependent id="15">too</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">made</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">made</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">made</governor>
          <dependent id="20">plain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">oath</governor>
          <dependent id="22">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">made</governor>
          <dependent id="23">oath</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">given</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">given</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">given</governor>
          <dependent id="27">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">made</governor>
          <dependent id="28">given</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="28">given</governor>
          <dependent id="29">them</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">combination</governor>
          <dependent id="30">every</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">combination</governor>
          <dependent id="31">steroid</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">given</governor>
          <dependent id="32">combination</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">combination</governor>
          <dependent id="33">imaginable</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">experiments</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">given</governor>
          <dependent id="36">experiments</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">experiments</governor>
          <dependent id="37">all</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">calibrated</governor>
          <dependent id="38">carefully</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">experiments</governor>
          <dependent id="39">calibrated</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="36">experiments</governor>
          <dependent id="41">charted</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">charted</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">charted</governor>
          <dependent id="43">analyzed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>His system had worked remarkably.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="worked" lemma="work" stem="work" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="remarkably" lemma="remarkably" stem="remark" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ His) (NN system)) (VP (VBD had) (VP (VBN worked) (ADVP (RB remarkably)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="His system" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="system" />
          </tokens>
        </chunking>
        <chunking id="2" string="worked remarkably" type="VP">
          <tokens>
            <token id="4" string="worked" />
            <token id="5" string="remarkably" />
          </tokens>
        </chunking>
        <chunking id="3" string="had worked remarkably" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="worked" />
            <token id="5" string="remarkably" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">system</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">worked</governor>
          <dependent id="2">system</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">worked</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">worked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">worked</governor>
          <dependent id="5">remarkably</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>On Sept. 24, 1988, Francis&amp;apost; most famous pupil, Ben Johnson, who immigrated to Toronto from Jamaica as a scrawny 14-year-old, ran 100 meters in 9.79 seconds at the Olympics in Seoul, South Korea.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Sept." lemma="Sept." stem="sept." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="famous" lemma="famous" stem="famou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="pupil" lemma="pupil" stem="pupil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="immigrated" lemma="immigrate" stem="immigr" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Jamaica" lemma="Jamaica" stem="jamaica" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="scrawny" lemma="scrawny" stem="scrawni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="14-year-old" lemma="14-year-old" stem="14-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="9.79" lemma="9.79" stem="9.79" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="32" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="33" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="Korea" lemma="Korea" stem="korea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NP (NNP Sept.) (CD 24)) (, ,) (NP (CD 1988)) (, ,) (NP (NNP Francis)) ('' '))) (NP (NP (ADJP (RBS most) (JJ famous)) (NN pupil)) (, ,) (NP (NNP Ben) (NNP Johnson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD immigrated) (PP (TO to) (NP (NNP Toronto))) (PP (IN from) (NP (NNP Jamaica))) (PP (IN as) (NP (DT a) (JJ scrawny) (JJ 14-year-old)))))) (, ,)) (VP (VBD ran) (NP (CD 100) (NNS meters)) (PP (IN in) (NP (NP (CD 9.79) (NNS seconds)) (PP (IN at) (NP (DT the) (NNPS Olympics))))) (PP (IN in) (NP (NP (NNP Seoul)) (, ,) (NP (NNP South) (NNP Korea))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sept. 24" type="NP">
          <tokens>
            <token id="2" string="Sept." />
            <token id="3" string="24" />
          </tokens>
        </chunking>
        <chunking id="2" string="immigrated to Toronto from Jamaica as a scrawny 14-year-old" type="VP">
          <tokens>
            <token id="17" string="immigrated" />
            <token id="18" string="to" />
            <token id="19" string="Toronto" />
            <token id="20" string="from" />
            <token id="21" string="Jamaica" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="scrawny" />
            <token id="25" string="14-year-old" />
          </tokens>
        </chunking>
        <chunking id="3" string="ran 100 meters in 9.79 seconds at the Olympics in Seoul , South Korea" type="VP">
          <tokens>
            <token id="27" string="ran" />
            <token id="28" string="100" />
            <token id="29" string="meters" />
            <token id="30" string="in" />
            <token id="31" string="9.79" />
            <token id="32" string="seconds" />
            <token id="33" string="at" />
            <token id="34" string="the" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="4" string="most famous" type="ADJP">
          <tokens>
            <token id="9" string="most" />
            <token id="10" string="famous" />
          </tokens>
        </chunking>
        <chunking id="5" string="9.79 seconds" type="NP">
          <tokens>
            <token id="31" string="9.79" />
            <token id="32" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="6" string="most famous pupil , Ben Johnson , who immigrated to Toronto from Jamaica as a scrawny 14-year-old ," type="NP">
          <tokens>
            <token id="9" string="most" />
            <token id="10" string="famous" />
            <token id="11" string="pupil" />
            <token id="12" string="," />
            <token id="13" string="Ben" />
            <token id="14" string="Johnson" />
            <token id="15" string="," />
            <token id="16" string="who" />
            <token id="17" string="immigrated" />
            <token id="18" string="to" />
            <token id="19" string="Toronto" />
            <token id="20" string="from" />
            <token id="21" string="Jamaica" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="scrawny" />
            <token id="25" string="14-year-old" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="1988" type="NP">
          <tokens>
            <token id="5" string="1988" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ben Johnson" type="NP">
          <tokens>
            <token id="13" string="Ben" />
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="9" string="Seoul , South Korea" type="NP">
          <tokens>
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="10" string="100 meters" type="NP">
          <tokens>
            <token id="28" string="100" />
            <token id="29" string="meters" />
          </tokens>
        </chunking>
        <chunking id="11" string="Seoul" type="NP">
          <tokens>
            <token id="37" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="12" string="most famous pupil" type="NP">
          <tokens>
            <token id="9" string="most" />
            <token id="10" string="famous" />
            <token id="11" string="pupil" />
          </tokens>
        </chunking>
        <chunking id="13" string="9.79 seconds at the Olympics" type="NP">
          <tokens>
            <token id="31" string="9.79" />
            <token id="32" string="seconds" />
            <token id="33" string="at" />
            <token id="34" string="the" />
            <token id="35" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Olympics" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="15" string="South Korea" type="NP">
          <tokens>
            <token id="39" string="South" />
            <token id="40" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="16" string="Francis" type="NP">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="17" string="Sept. 24 , 1988 , Francis '" type="NP">
          <tokens>
            <token id="2" string="Sept." />
            <token id="3" string="24" />
            <token id="4" string="," />
            <token id="5" string="1988" />
            <token id="6" string="," />
            <token id="7" string="Francis" />
            <token id="8" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="who immigrated to Toronto from Jamaica as a scrawny 14-year-old" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="immigrated" />
            <token id="18" string="to" />
            <token id="19" string="Toronto" />
            <token id="20" string="from" />
            <token id="21" string="Jamaica" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="scrawny" />
            <token id="25" string="14-year-old" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jamaica" type="NP">
          <tokens>
            <token id="21" string="Jamaica" />
          </tokens>
        </chunking>
        <chunking id="20" string="a scrawny 14-year-old" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="scrawny" />
            <token id="25" string="14-year-old" />
          </tokens>
        </chunking>
        <chunking id="21" string="Toronto" type="NP">
          <tokens>
            <token id="19" string="Toronto" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Sept.</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">ran</governor>
          <dependent id="2">Sept.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Sept.</governor>
          <dependent id="3">24</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Sept.</governor>
          <dependent id="5">1988</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Sept.</governor>
          <dependent id="7">Francis</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">famous</governor>
          <dependent id="9">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">pupil</governor>
          <dependent id="10">famous</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">ran</governor>
          <dependent id="11">pupil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Johnson</governor>
          <dependent id="13">Ben</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">pupil</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">immigrated</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">pupil</governor>
          <dependent id="17">immigrated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Toronto</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">immigrated</governor>
          <dependent id="19">Toronto</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Jamaica</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">immigrated</governor>
          <dependent id="21">Jamaica</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">14-year-old</governor>
          <dependent id="22">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">14-year-old</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">14-year-old</governor>
          <dependent id="24">scrawny</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">immigrated</governor>
          <dependent id="25">14-year-old</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">ran</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">meters</governor>
          <dependent id="28">100</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">ran</governor>
          <dependent id="29">meters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">seconds</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">seconds</governor>
          <dependent id="31">9.79</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">ran</governor>
          <dependent id="32">seconds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Olympics</governor>
          <dependent id="33">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Olympics</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">seconds</governor>
          <dependent id="35">Olympics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Seoul</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">ran</governor>
          <dependent id="37">Seoul</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Korea</governor>
          <dependent id="39">South</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">Seoul</governor>
          <dependent id="40">Korea</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Ben" />
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="100" />
          </tokens>
        </entity>
        <entity id="3" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Seoul" />
          </tokens>
        </entity>
        <entity id="4" string="South Korea" type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="South" />
            <token id="40" string="Korea" />
          </tokens>
        </entity>
        <entity id="5" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </entity>
        <entity id="6" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="35" string="Olympics" />
          </tokens>
        </entity>
        <entity id="7" string="9.79 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="31" string="9.79" />
            <token id="32" string="seconds" />
          </tokens>
        </entity>
        <entity id="8" string="Jamaica" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Jamaica" />
          </tokens>
        </entity>
        <entity id="9" string="Sept. 24 , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Sept." />
            <token id="3" string="24" />
            <token id="4" string="," />
            <token id="5" string="1988" />
          </tokens>
        </entity>
        <entity id="10" string="14-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="14-year-old" />
          </tokens>
        </entity>
        <entity id="11" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The time was a world record and gave Johnson the gold medal, ahead of the defending champion, U.S. star Carl Lewis.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ahead" lemma="ahead" stem="ahead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="defending" lemma="defend" stem="defend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN time)) (VP (VP (VBD was) (NP (DT a) (NN world) (NN record))) (CC and) (VP (VBD gave) (NP (NNP Johnson)) (NP (DT the) (NN gold) (NN medal))) (, ,) (PP (RB ahead) (IN of) (NP (NP (DT the) (VBG defending) (NN champion)) (, ,) (NP (NNP U.S.) (NN star) (NNP Carl) (NNP Lewis))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="the gold medal" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="gold" />
            <token id="12" string="medal" />
          </tokens>
        </chunking>
        <chunking id="3" string="a world record" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="world" />
            <token id="6" string="record" />
          </tokens>
        </chunking>
        <chunking id="4" string="The time" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="U.S. star Carl Lewis" type="NP">
          <tokens>
            <token id="20" string="U.S." />
            <token id="21" string="star" />
            <token id="22" string="Carl" />
            <token id="23" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="6" string="gave Johnson the gold medal" type="VP">
          <tokens>
            <token id="8" string="gave" />
            <token id="9" string="Johnson" />
            <token id="10" string="the" />
            <token id="11" string="gold" />
            <token id="12" string="medal" />
          </tokens>
        </chunking>
        <chunking id="7" string="was a world record" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="world" />
            <token id="6" string="record" />
          </tokens>
        </chunking>
        <chunking id="8" string="the defending champion , U.S. star Carl Lewis" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="defending" />
            <token id="18" string="champion" />
            <token id="19" string="," />
            <token id="20" string="U.S." />
            <token id="21" string="star" />
            <token id="22" string="Carl" />
            <token id="23" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="9" string="the defending champion" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="defending" />
            <token id="18" string="champion" />
          </tokens>
        </chunking>
        <chunking id="10" string="was a world record and gave Johnson the gold medal , ahead of the defending champion , U.S. star Carl Lewis" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="world" />
            <token id="6" string="record" />
            <token id="7" string="and" />
            <token id="8" string="gave" />
            <token id="9" string="Johnson" />
            <token id="10" string="the" />
            <token id="11" string="gold" />
            <token id="12" string="medal" />
            <token id="13" string="," />
            <token id="14" string="ahead" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="defending" />
            <token id="18" string="champion" />
            <token id="19" string="," />
            <token id="20" string="U.S." />
            <token id="21" string="star" />
            <token id="22" string="Carl" />
            <token id="23" string="Lewis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">time</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">record</governor>
          <dependent id="2">time</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">record</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">record</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">record</governor>
          <dependent id="5">world</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">record</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">record</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">record</governor>
          <dependent id="8">gave</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="8">gave</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">medal</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">medal</governor>
          <dependent id="11">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">gave</governor>
          <dependent id="12">medal</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">champion</governor>
          <dependent id="14">ahead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">champion</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">champion</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">champion</governor>
          <dependent id="17">defending</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">record</governor>
          <dependent id="18">champion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lewis</governor>
          <dependent id="20">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lewis</governor>
          <dependent id="21">star</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lewis</governor>
          <dependent id="22">Carl</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">champion</governor>
          <dependent id="23">Lewis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Carl" />
            <token id="23" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>But the Francis system, like all systems, was not foolproof.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="4" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="systems" lemma="system" stem="system" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="foolproof" lemma="foolproof" stem="foolproof" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NNP Francis) (NN system)) (, ,) (PP (IN like) (NP (DT all) (NNS systems))) (, ,) (VP (VBD was) (RB not) (ADJP (JJ foolproof))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was not foolproof" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="not" />
            <token id="12" string="foolproof" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Francis system" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Francis" />
            <token id="4" string="system" />
          </tokens>
        </chunking>
        <chunking id="3" string="foolproof" type="ADJP">
          <tokens>
            <token id="12" string="foolproof" />
          </tokens>
        </chunking>
        <chunking id="4" string="all systems" type="NP">
          <tokens>
            <token id="7" string="all" />
            <token id="8" string="systems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">foolproof</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">system</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">system</governor>
          <dependent id="3">Francis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">foolproof</governor>
          <dependent id="4">system</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">systems</governor>
          <dependent id="6">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">systems</governor>
          <dependent id="7">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">foolproof</governor>
          <dependent id="8">systems</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">foolproof</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">foolproof</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">foolproof</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>&amp;quot;About 42 hours after my life&amp;apost;s greatest moment,&amp;quot; Francis writes on the first page of his confessional, &amp;quot;Speed Trap,&amp;quot; his &amp;quot;nightmare began.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="About" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="greatest" lemma="greatest" stem="greatest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="18" string="page" lemma="page" stem="page" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="confessional" lemma="confessional" stem="confession" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="Trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="nightmare" lemma="nightmare" stem="nightmar" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN About) (NP (NP (CD 42) (NNS hours)) (PP (IN after) (NP (NP (PRP$ my) (NN life) (POS 's)) (JJS greatest) (NN moment))))) (PRN (, ,) ('' '') (S (NP (NNP Francis)) (VP (VBZ writes) (PP (IN on) (NP (NP (DT the) (JJ first) (NN page)) (PP (IN of) (NP (PRP$ his) (NN confessional))))))) (, ,)) (NP (NP (`` ``) (NN Speed) (NN Trap) (, ,) ('' '')) (NP (PRP$ his) (`` ``) (NN nightmare))) (VP (VBD began)) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Speed Trap , '' his `` nightmare" type="NP">
          <tokens>
            <token id="23" string="&quot;" />
            <token id="24" string="Speed" />
            <token id="25" string="Trap" />
            <token id="26" string="," />
            <token id="27" string="&quot;" />
            <token id="28" string="his" />
            <token id="29" string="&quot;" />
            <token id="30" string="nightmare" />
          </tokens>
        </chunking>
        <chunking id="2" string="began" type="VP">
          <tokens>
            <token id="31" string="began" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Speed Trap , ''" type="NP">
          <tokens>
            <token id="23" string="&quot;" />
            <token id="24" string="Speed" />
            <token id="25" string="Trap" />
            <token id="26" string="," />
            <token id="27" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="my life 's" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="life" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="his `` nightmare" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="&quot;" />
            <token id="30" string="nightmare" />
          </tokens>
        </chunking>
        <chunking id="6" string="42 hours after my life 's greatest moment" type="NP">
          <tokens>
            <token id="3" string="42" />
            <token id="4" string="hours" />
            <token id="5" string="after" />
            <token id="6" string="my" />
            <token id="7" string="life" />
            <token id="8" string="'s" />
            <token id="9" string="greatest" />
            <token id="10" string="moment" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first page of his confessional" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="first" />
            <token id="18" string="page" />
            <token id="19" string="of" />
            <token id="20" string="his" />
            <token id="21" string="confessional" />
          </tokens>
        </chunking>
        <chunking id="8" string="42 hours" type="NP">
          <tokens>
            <token id="3" string="42" />
            <token id="4" string="hours" />
          </tokens>
        </chunking>
        <chunking id="9" string="his confessional" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="confessional" />
          </tokens>
        </chunking>
        <chunking id="10" string="Francis" type="NP">
          <tokens>
            <token id="13" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="11" string="writes on the first page of his confessional" type="VP">
          <tokens>
            <token id="14" string="writes" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="first" />
            <token id="18" string="page" />
            <token id="19" string="of" />
            <token id="20" string="his" />
            <token id="21" string="confessional" />
          </tokens>
        </chunking>
        <chunking id="12" string="my life 's greatest moment" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="life" />
            <token id="8" string="'s" />
            <token id="9" string="greatest" />
            <token id="10" string="moment" />
          </tokens>
        </chunking>
        <chunking id="13" string="the first page" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="first" />
            <token id="18" string="page" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">hours</governor>
          <dependent id="2">About</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">hours</governor>
          <dependent id="3">42</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">began</governor>
          <dependent id="4">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">moment</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">life</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">moment</governor>
          <dependent id="7">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">life</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">moment</governor>
          <dependent id="9">greatest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">hours</governor>
          <dependent id="10">moment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">writes</governor>
          <dependent id="13">Francis</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="31">began</governor>
          <dependent id="14">writes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">page</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">page</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">page</governor>
          <dependent id="17">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">writes</governor>
          <dependent id="18">page</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">confessional</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">confessional</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">page</governor>
          <dependent id="21">confessional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Trap</governor>
          <dependent id="24">Speed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">began</governor>
          <dependent id="25">Trap</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">nightmare</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">Trap</governor>
          <dependent id="30">nightmare</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">began</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="17" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="About 42 hours" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="About" />
            <token id="3" string="42" />
            <token id="4" string="hours" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>; Johnson, the world&amp;apost;s fastest man, had tested positive for illegal steroid use.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NNP Johnson)) (, ,) (NP (NP (DT the) (NN world) (POS 's)) (JJS fastest) (NN man))) (, ,) (VP (VBD had) (VP (VBN tested) (ADJP (JJ positive)) (PP (IN for) (NP (JJ illegal) (NN steroid) (NN use))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal steroid use" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="steroid" />
            <token id="16" string="use" />
          </tokens>
        </chunking>
        <chunking id="3" string="the world 's fastest man" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="fastest" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="4" string="tested positive for illegal steroid use" type="VP">
          <tokens>
            <token id="11" string="tested" />
            <token id="12" string="positive" />
            <token id="13" string="for" />
            <token id="14" string="illegal" />
            <token id="15" string="steroid" />
            <token id="16" string="use" />
          </tokens>
        </chunking>
        <chunking id="5" string="Johnson , the world 's fastest man" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="fastest" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="6" string="positive" type="ADJP">
          <tokens>
            <token id="12" string="positive" />
          </tokens>
        </chunking>
        <chunking id="7" string="had tested positive for illegal steroid use" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="tested" />
            <token id="12" string="positive" />
            <token id="13" string="for" />
            <token id="14" string="illegal" />
            <token id="15" string="steroid" />
            <token id="16" string="use" />
          </tokens>
        </chunking>
        <chunking id="8" string="the world 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">tested</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">world</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">man</governor>
          <dependent id="5">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">world</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">man</governor>
          <dependent id="7">fastest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Johnson</governor>
          <dependent id="8">man</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">tested</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">tested</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">tested</governor>
          <dependent id="12">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">use</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">use</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">use</governor>
          <dependent id="15">steroid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">tested</governor>
          <dependent id="16">use</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Suddenly he was the world&amp;apost;s fastest cheat.</content>
      <tokens>
        <token id="1" string="Suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="cheat" lemma="cheat" stem="cheat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Suddenly)) (NP (PRP he)) (VP (VBD was) (NP (NP (DT the) (NN world) (POS 's)) (JJS fastest)) (S (VP (VB cheat)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cheat" type="VP">
          <tokens>
            <token id="8" string="cheat" />
          </tokens>
        </chunking>
        <chunking id="2" string="was the world 's fastest cheat" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="fastest" />
            <token id="8" string="cheat" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="4" string="the world 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the world 's fastest" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="fastest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">world</governor>
          <dependent id="1">Suddenly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">world</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">world</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">world</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">world</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">world</governor>
          <dependent id="7">fastest</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">world</governor>
          <dependent id="8">cheat</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Millions of dollars worth of endorsements shriveled up.</content>
      <tokens>
        <token id="1" string="Millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="dollars" lemma="dollar" stem="dollar" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="worth" lemma="worth" stem="worth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="endorsements" lemma="endorsement" stem="endors" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="shriveled" lemma="shrivel" stem="shrivel" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Millions)) (PP (IN of) (NP (NP (NNS dollars) (NN worth)) (PP (IN of) (NP (NNS endorsements)))))) (VP (VBD shriveled) (PRT (RP up))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Millions" type="NP">
          <tokens>
            <token id="1" string="Millions" />
          </tokens>
        </chunking>
        <chunking id="2" string="Millions of dollars worth of endorsements" type="NP">
          <tokens>
            <token id="1" string="Millions" />
            <token id="2" string="of" />
            <token id="3" string="dollars" />
            <token id="4" string="worth" />
            <token id="5" string="of" />
            <token id="6" string="endorsements" />
          </tokens>
        </chunking>
        <chunking id="3" string="endorsements" type="NP">
          <tokens>
            <token id="6" string="endorsements" />
          </tokens>
        </chunking>
        <chunking id="4" string="dollars worth of endorsements" type="NP">
          <tokens>
            <token id="3" string="dollars" />
            <token id="4" string="worth" />
            <token id="5" string="of" />
            <token id="6" string="endorsements" />
          </tokens>
        </chunking>
        <chunking id="5" string="dollars worth" type="NP">
          <tokens>
            <token id="3" string="dollars" />
            <token id="4" string="worth" />
          </tokens>
        </chunking>
        <chunking id="6" string="shriveled up" type="VP">
          <tokens>
            <token id="7" string="shriveled" />
            <token id="8" string="up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">shriveled</governor>
          <dependent id="1">Millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">worth</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">worth</governor>
          <dependent id="3">dollars</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Millions</governor>
          <dependent id="4">worth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">endorsements</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">worth</governor>
          <dependent id="6">endorsements</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">shriveled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">shriveled</governor>
          <dependent id="8">up</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>His gold medal was revoked, and his world record was, too.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="revoked" lemma="revoke" stem="revok" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ His) (NN gold) (NN medal)) (VP (VBD was) (VP (VBN revoked)))) (, ,) (CC and) (S (NP (PRP$ his) (NN world) (NN record)) (VP (VBD was)) (, ,) (ADVP (RB too))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="His gold medal" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="gold" />
            <token id="3" string="medal" />
          </tokens>
        </chunking>
        <chunking id="2" string="was" type="VP">
          <tokens>
            <token id="11" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="his world record" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="4" string="was revoked" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="revoked" />
          </tokens>
        </chunking>
        <chunking id="5" string="revoked" type="VP">
          <tokens>
            <token id="5" string="revoked" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">medal</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">medal</governor>
          <dependent id="2">gold</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">revoked</governor>
          <dependent id="3">medal</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">revoked</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">revoked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">revoked</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">record</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">record</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">was</governor>
          <dependent id="10">record</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">revoked</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">was</governor>
          <dependent id="13">too</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Because Johnson was caught, the Canadians were embarrassed.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Canadians" lemma="Canadians" stem="canadian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="embarrassed" lemma="embarrassed" stem="embarrass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (NNP Johnson)) (VP (VBD was) (VP (VBN caught))))) (, ,) (NP (DT the) (NNPS Canadians)) (VP (VBD were) (ADJP (JJ embarrassed))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were embarrassed" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Canadians" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Canadians" />
          </tokens>
        </chunking>
        <chunking id="4" string="caught" type="VP">
          <tokens>
            <token id="4" string="caught" />
          </tokens>
        </chunking>
        <chunking id="5" string="embarrassed" type="ADJP">
          <tokens>
            <token id="9" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="6" string="Because Johnson was caught" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="Johnson" />
            <token id="3" string="was" />
            <token id="4" string="caught" />
          </tokens>
        </chunking>
        <chunking id="7" string="was caught" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="caught" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">caught</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">caught</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">caught</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">embarrassed</governor>
          <dependent id="4">caught</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Canadians</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">embarrassed</governor>
          <dependent id="7">Canadians</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">embarrassed</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">embarrassed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canadians" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Canadians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Because they were embarrassed, they conducted a federal inquiry.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="embarrassed" lemma="embarrassed" stem="embarrass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="conducted" lemma="conduct" stem="conduct" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (PRP they)) (VP (VBD were) (ADJP (JJ embarrassed))))) (, ,) (NP (PRP they)) (VP (VBD conducted) (NP (DT a) (JJ federal) (NN inquiry))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were embarrassed" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="conducted a federal inquiry" type="VP">
          <tokens>
            <token id="7" string="conducted" />
            <token id="8" string="a" />
            <token id="9" string="federal" />
            <token id="10" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="4" string="Because they were embarrassed" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="they" />
            <token id="3" string="were" />
            <token id="4" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="5" string="embarrassed" type="ADJP">
          <tokens>
            <token id="4" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="6" string="a federal inquiry" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="federal" />
            <token id="10" string="inquiry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">embarrassed</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">embarrassed</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">embarrassed</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">conducted</governor>
          <dependent id="4">embarrassed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">conducted</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">conducted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">inquiry</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">inquiry</governor>
          <dependent id="9">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">conducted</governor>
          <dependent id="10">inquiry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Because they held an inquiry, Francis had to testify.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (PRP they)) (VP (VBD held) (NP (DT an) (NN inquiry))))) (, ,) (NP (NNP Francis)) (VP (VBD had) (S (VP (TO to) (VP (VB testify))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an inquiry" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="2" string="Because they held an inquiry" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="they" />
            <token id="3" string="held" />
            <token id="4" string="an" />
            <token id="5" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="had to testify" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="to" />
            <token id="10" string="testify" />
          </tokens>
        </chunking>
        <chunking id="5" string="Francis" type="NP">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="6" string="to testify" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="testify" />
          </tokens>
        </chunking>
        <chunking id="7" string="held an inquiry" type="VP">
          <tokens>
            <token id="3" string="held" />
            <token id="4" string="an" />
            <token id="5" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="8" string="testify" type="VP">
          <tokens>
            <token id="10" string="testify" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">held</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">held</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">had</governor>
          <dependent id="3">held</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">inquiry</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">held</governor>
          <dependent id="5">inquiry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">had</governor>
          <dependent id="7">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">testify</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">had</governor>
          <dependent id="10">testify</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>And because of that testimony, we have &amp;quot;Speed Trap,&amp;quot; an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="elaboration" lemma="elaboration" stem="elabor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="remarkable" lemma="remarkable" stem="remark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="path" lemma="path" stem="path" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (PP (IN because) (PP (IN of) (NP (DT that) (NN testimony)))) (, ,) (NP (PRP we)) (VP (VBP have) (NP (`` ``) (NP (NN Speed) (NN Trap)) (, ,) ('' '') (NP (NP (DT an) (NN elaboration)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (NNP Francis)) (VP (VBD said) (PP (IN at) (NP (NP (DT the) (NN inquiry)) (CC and) (NP (NP (DT a) (NN history)) (PP (IN of) (NP (PRP$ his) (JJ remarkable) (NN path)))))) (PP (IN through) (NP (NP (DT the) (NN world)) (PP (IN of) (NP (NN track) (CC and) (NN field)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that testimony" type="NP">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="2" string="have `` Speed Trap , '' an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="&quot;" />
            <token id="10" string="Speed" />
            <token id="11" string="Trap" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="an" />
            <token id="15" string="elaboration" />
            <token id="16" string="of" />
            <token id="17" string="what" />
            <token id="18" string="Francis" />
            <token id="19" string="said" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
            <token id="30" string="through" />
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="3" string="a history" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="history" />
          </tokens>
        </chunking>
        <chunking id="4" string="what Francis said at the inquiry and a history of his remarkable path through the world of track and field" type="SBAR">
          <tokens>
            <token id="17" string="what" />
            <token id="18" string="Francis" />
            <token id="19" string="said" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
            <token id="30" string="through" />
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="5" string="the inquiry and a history of his remarkable path" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="world" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="7" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="`` Speed Trap , '' an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field" type="NP">
          <tokens>
            <token id="9" string="&quot;" />
            <token id="10" string="Speed" />
            <token id="11" string="Trap" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="an" />
            <token id="15" string="elaboration" />
            <token id="16" string="of" />
            <token id="17" string="what" />
            <token id="18" string="Francis" />
            <token id="19" string="said" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
            <token id="30" string="through" />
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="9" string="an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="elaboration" />
            <token id="16" string="of" />
            <token id="17" string="what" />
            <token id="18" string="Francis" />
            <token id="19" string="said" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
            <token id="30" string="through" />
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="10" string="the world of track and field" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="11" string="track and field" type="NP">
          <tokens>
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="12" string="said at the inquiry and a history of his remarkable path through the world of track and field" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
            <token id="30" string="through" />
            <token id="31" string="the" />
            <token id="32" string="world" />
            <token id="33" string="of" />
            <token id="34" string="track" />
            <token id="35" string="and" />
            <token id="36" string="field" />
          </tokens>
        </chunking>
        <chunking id="13" string="Francis" type="NP">
          <tokens>
            <token id="18" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="14" string="his remarkable path" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
          </tokens>
        </chunking>
        <chunking id="15" string="the inquiry" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="16" string="a history of his remarkable path" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="history" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="remarkable" />
            <token id="29" string="path" />
          </tokens>
        </chunking>
        <chunking id="17" string="an elaboration" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="elaboration" />
          </tokens>
        </chunking>
        <chunking id="18" string="Speed Trap" type="NP">
          <tokens>
            <token id="10" string="Speed" />
            <token id="11" string="Trap" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">have</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">testimony</governor>
          <dependent id="2">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">testimony</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">testimony</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">have</governor>
          <dependent id="5">testimony</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">have</governor>
          <dependent id="7">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Trap</governor>
          <dependent id="10">Speed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">have</governor>
          <dependent id="11">Trap</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">elaboration</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Trap</governor>
          <dependent id="15">elaboration</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">said</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">said</governor>
          <dependent id="17">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Francis</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">elaboration</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">inquiry</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">inquiry</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">said</governor>
          <dependent id="22">inquiry</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">inquiry</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">history</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">inquiry</governor>
          <dependent id="25">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">path</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">path</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">path</governor>
          <dependent id="28">remarkable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">history</governor>
          <dependent id="29">path</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">world</governor>
          <dependent id="30">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">world</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">said</governor>
          <dependent id="32">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">track</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">world</governor>
          <dependent id="34">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">track</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">track</governor>
          <dependent id="36">field</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>He argues, essentially, that to be a world-class sprinter, you must use steroids -- he makes this argument even as Johnson attempts a comeback for the 1992 Olympic Games in Barcelona, Spain, without them.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="argues" lemma="argue" stem="argu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="essentially" lemma="essentially" stem="essenti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="world-class" lemma="world-class" stem="world-class" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="argument" lemma="argument" stem="argument" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="attempts" lemma="attempt" stem="attempt" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="comeback" lemma="comeback" stem="comeback" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="1992" lemma="1992" stem="1992" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="32" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Barcelona" lemma="Barcelona" stem="barcelona" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Spain" lemma="Spain" stem="spain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ argues) (, ,) (ADVP (RB essentially)) (, ,) (SBAR (IN that) (S (S (VP (TO to) (VP (VB be) (NP (DT a) (JJ world-class) (NN sprinter))))) (, ,) (NP (PRP you)) (VP (MD must) (VP (VB use) (NP (NNS steroids)))))))) (: --) (S (NP (PRP he)) (VP (VBZ makes) (NP (DT this) (NN argument)) (SBAR (RB even) (IN as) (S (NP (NNP Johnson)) (VP (VBZ attempts) (NP (NP (DT a) (NN comeback)) (PP (IN for) (NP (NP (DT the) (CD 1992) (NNP Olympic) (NNPS Games)) (PP (IN in) (NP (NNP Barcelona) (, ,) (NNP Spain) (, ,)))))) (PP (IN without) (NP (PRP them)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="even as Johnson attempts a comeback for the 1992 Olympic Games in Barcelona , Spain , without them" type="SBAR">
          <tokens>
            <token id="22" string="even" />
            <token id="23" string="as" />
            <token id="24" string="Johnson" />
            <token id="25" string="attempts" />
            <token id="26" string="a" />
            <token id="27" string="comeback" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
            <token id="33" string="in" />
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
            <token id="38" string="without" />
            <token id="39" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="a comeback for the 1992 Olympic Games in Barcelona , Spain ," type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="comeback" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
            <token id="33" string="in" />
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="be a world-class sprinter" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="world-class" />
            <token id="11" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="5" string="use steroids" type="VP">
          <tokens>
            <token id="15" string="use" />
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="39" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="a comeback" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be a world-class sprinter" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="world-class" />
            <token id="11" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="9" string="a world-class sprinter" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="world-class" />
            <token id="11" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="10" string="that to be a world-class sprinter , you must use steroids" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="world-class" />
            <token id="11" string="sprinter" />
            <token id="12" string="," />
            <token id="13" string="you" />
            <token id="14" string="must" />
            <token id="15" string="use" />
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="11" string="must use steroids" type="VP">
          <tokens>
            <token id="14" string="must" />
            <token id="15" string="use" />
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="12" string="Barcelona , Spain ," type="NP">
          <tokens>
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="the 1992 Olympic Games" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="14" string="steroids" type="NP">
          <tokens>
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="15" string="makes this argument even as Johnson attempts a comeback for the 1992 Olympic Games in Barcelona , Spain , without them" type="VP">
          <tokens>
            <token id="19" string="makes" />
            <token id="20" string="this" />
            <token id="21" string="argument" />
            <token id="22" string="even" />
            <token id="23" string="as" />
            <token id="24" string="Johnson" />
            <token id="25" string="attempts" />
            <token id="26" string="a" />
            <token id="27" string="comeback" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
            <token id="33" string="in" />
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
            <token id="38" string="without" />
            <token id="39" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="this argument" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="argument" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 1992 Olympic Games in Barcelona , Spain ," type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
            <token id="33" string="in" />
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="argues , essentially , that to be a world-class sprinter , you must use steroids" type="VP">
          <tokens>
            <token id="2" string="argues" />
            <token id="3" string="," />
            <token id="4" string="essentially" />
            <token id="5" string="," />
            <token id="6" string="that" />
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="world-class" />
            <token id="11" string="sprinter" />
            <token id="12" string="," />
            <token id="13" string="you" />
            <token id="14" string="must" />
            <token id="15" string="use" />
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="21" string="attempts a comeback for the 1992 Olympic Games in Barcelona , Spain , without them" type="VP">
          <tokens>
            <token id="25" string="attempts" />
            <token id="26" string="a" />
            <token id="27" string="comeback" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="1992" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
            <token id="33" string="in" />
            <token id="34" string="Barcelona" />
            <token id="35" string="," />
            <token id="36" string="Spain" />
            <token id="37" string="," />
            <token id="38" string="without" />
            <token id="39" string="them" />
          </tokens>
        </chunking>
        <chunking id="22" string="you" type="NP">
          <tokens>
            <token id="13" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">argues</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">argues</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">argues</governor>
          <dependent id="4">essentially</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">use</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">sprinter</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">sprinter</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">sprinter</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">sprinter</governor>
          <dependent id="10">world-class</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">use</governor>
          <dependent id="11">sprinter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">use</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">use</governor>
          <dependent id="14">must</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">argues</governor>
          <dependent id="15">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">use</governor>
          <dependent id="16">steroids</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">makes</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">argues</governor>
          <dependent id="19">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">argument</governor>
          <dependent id="20">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">makes</governor>
          <dependent id="21">argument</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">attempts</governor>
          <dependent id="22">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">attempts</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">attempts</governor>
          <dependent id="24">Johnson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">makes</governor>
          <dependent id="25">attempts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">comeback</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">attempts</governor>
          <dependent id="27">comeback</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Games</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">Games</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">Games</governor>
          <dependent id="30">1992</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Games</governor>
          <dependent id="31">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">comeback</governor>
          <dependent id="32">Games</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Spain</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Spain</governor>
          <dependent id="34">Barcelona</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">Games</governor>
          <dependent id="36">Spain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">them</governor>
          <dependent id="38">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">attempts</governor>
          <dependent id="39">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Barcelona" type="LOCATION" score="0.0">
          <tokens>
            <token id="34" string="Barcelona" />
          </tokens>
        </entity>
        <entity id="3" string="1992" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="1992" />
          </tokens>
        </entity>
        <entity id="4" string="Olympic Games" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </entity>
        <entity id="5" string="Spain" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Spain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Steroids do not make a runner run faster, Francis explains, but they enable a runner to train harder.</content>
      <tokens>
        <token id="1" string="Steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="run" lemma="run" stem="run" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="faster" lemma="faster" stem="faster" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="explains" lemma="explain" stem="explain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="enable" lemma="enable" stem="enabl" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="train" lemma="train" stem="train" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="harder" lemma="harder" stem="harder" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Steroids)) (VP (VBP do) (RB not) (VP (VB make) (SBAR (S (NP (DT a) (NN runner)) (VP (VBP run) (ADVP (RBR faster)))))))) (PRN (, ,) (NP (NNP Francis)) (VP (VBZ explains)) (, ,)) (CC but) (S (NP (PRP they)) (VP (VBP enable) (S (NP (DT a) (NN runner)) (VP (TO to) (VP (VB train) (ADJP (JJR harder))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run faster" type="VP">
          <tokens>
            <token id="7" string="run" />
            <token id="8" string="faster" />
          </tokens>
        </chunking>
        <chunking id="2" string="make a runner run faster" type="VP">
          <tokens>
            <token id="4" string="make" />
            <token id="5" string="a" />
            <token id="6" string="runner" />
            <token id="7" string="run" />
            <token id="8" string="faster" />
          </tokens>
        </chunking>
        <chunking id="3" string="train harder" type="VP">
          <tokens>
            <token id="19" string="train" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="4" string="a runner" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="runner" />
          </tokens>
        </chunking>
        <chunking id="5" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="6" string="harder" type="ADJP">
          <tokens>
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="7" string="Francis" type="NP">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="8" string="to train harder" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="train" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="9" string="explains" type="VP">
          <tokens>
            <token id="11" string="explains" />
          </tokens>
        </chunking>
        <chunking id="10" string="do not make a runner run faster" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="not" />
            <token id="4" string="make" />
            <token id="5" string="a" />
            <token id="6" string="runner" />
            <token id="7" string="run" />
            <token id="8" string="faster" />
          </tokens>
        </chunking>
        <chunking id="11" string="enable a runner to train harder" type="VP">
          <tokens>
            <token id="15" string="enable" />
            <token id="16" string="a" />
            <token id="17" string="runner" />
            <token id="18" string="to" />
            <token id="19" string="train" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="12" string="Steroids" type="NP">
          <tokens>
            <token id="1" string="Steroids" />
          </tokens>
        </chunking>
        <chunking id="13" string="a runner run faster" type="SBAR">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="runner" />
            <token id="7" string="run" />
            <token id="8" string="faster" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">make</governor>
          <dependent id="1">Steroids</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">make</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">make</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">runner</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">run</governor>
          <dependent id="6">runner</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">make</governor>
          <dependent id="7">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">run</governor>
          <dependent id="8">faster</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">explains</governor>
          <dependent id="10">Francis</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">make</governor>
          <dependent id="11">explains</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">make</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">enable</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">make</governor>
          <dependent id="15">enable</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">runner</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">enable</governor>
          <dependent id="17">runner</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">train</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">enable</governor>
          <dependent id="19">train</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">train</governor>
          <dependent id="20">harder</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The desire for speed comes with incredible costs, and they are the trap.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="desire" lemma="desire" stem="desir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="incredible" lemma="incredible" stem="incred" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="costs" lemma="cost" stem="cost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN desire)) (PP (IN for) (NP (NN speed)))) (VP (VBZ comes) (PP (IN with) (NP (JJ incredible) (NNS costs))))) (, ,) (CC and) (S (NP (PRP they)) (VP (VBP are) (NP (DT the) (NN trap)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="The desire for speed" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="desire" />
            <token id="3" string="for" />
            <token id="4" string="speed" />
          </tokens>
        </chunking>
        <chunking id="3" string="incredible costs" type="NP">
          <tokens>
            <token id="7" string="incredible" />
            <token id="8" string="costs" />
          </tokens>
        </chunking>
        <chunking id="4" string="are the trap" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="the" />
            <token id="14" string="trap" />
          </tokens>
        </chunking>
        <chunking id="5" string="The desire" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="desire" />
          </tokens>
        </chunking>
        <chunking id="6" string="the trap" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="trap" />
          </tokens>
        </chunking>
        <chunking id="7" string="comes with incredible costs" type="VP">
          <tokens>
            <token id="5" string="comes" />
            <token id="6" string="with" />
            <token id="7" string="incredible" />
            <token id="8" string="costs" />
          </tokens>
        </chunking>
        <chunking id="8" string="speed" type="NP">
          <tokens>
            <token id="4" string="speed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">desire</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">comes</governor>
          <dependent id="2">desire</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">speed</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">desire</governor>
          <dependent id="4">speed</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">costs</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">costs</governor>
          <dependent id="7">incredible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">comes</governor>
          <dependent id="8">costs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">comes</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">trap</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">trap</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">trap</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">comes</governor>
          <dependent id="14">trap</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>By encouraging his athletes to use steroids -- and Francis maintains that they all wanted to do so and knew about steroids before the coach brought the subject up -- Francis argues that he is simply helping to create a level playing field.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="encouraging" lemma="encourage" stem="encourag" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="maintains" lemma="maintain" stem="maintain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="brought" lemma="bring" stem="brought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="argues" lemma="argue" stem="argu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="helping" lemma="help" stem="help" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="create" lemma="create" stem="creat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="playing" lemma="playing" stem="plai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (S (VP (VBG encouraging) (NP (PRP$ his) (NNS athletes)) (S (VP (TO to) (VP (VB use) (NP (NNS steroids)))))))) (PRN (: --) (CC and) (S (NP (NNP Francis)) (VP (VBZ maintains) (SBAR (IN that) (S (NP (PRP they)) (ADVP (DT all)) (VP (VP (VBD wanted) (S (VP (TO to) (VP (VB do) (ADVP (RB so)))))) (CC and) (VP (VBD knew) (PP (IN about) (NP (NNS steroids))) (SBAR (IN before) (S (NP (DT the) (NN coach)) (VP (VBD brought) (ADVP (NP (DT the) (NN subject)) (RB up))))))))))) (: --)) (NP (NNP Francis)) (VP (VBZ argues) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ is) (ADVP (RB simply)) (VP (VBG helping) (S (VP (TO to) (VP (VB create) (NP (DT a) (NN level) (NN playing) (NN field)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his athletes" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="2" string="do so" type="VP">
          <tokens>
            <token id="17" string="do" />
            <token id="18" string="so" />
          </tokens>
        </chunking>
        <chunking id="3" string="argues that he is simply helping to create a level playing field" type="VP">
          <tokens>
            <token id="32" string="argues" />
            <token id="33" string="that" />
            <token id="34" string="he" />
            <token id="35" string="is" />
            <token id="36" string="simply" />
            <token id="37" string="helping" />
            <token id="38" string="to" />
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="4" string="that they all wanted to do so and knew about steroids before the coach brought the subject up" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="they" />
            <token id="14" string="all" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="do" />
            <token id="18" string="so" />
            <token id="19" string="and" />
            <token id="20" string="knew" />
            <token id="21" string="about" />
            <token id="22" string="steroids" />
            <token id="23" string="before" />
            <token id="24" string="the" />
            <token id="25" string="coach" />
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="brought the subject up" type="VP">
          <tokens>
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="6" string="use steroids" type="VP">
          <tokens>
            <token id="6" string="use" />
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="7" string="that he is simply helping to create a level playing field" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="he" />
            <token id="35" string="is" />
            <token id="36" string="simply" />
            <token id="37" string="helping" />
            <token id="38" string="to" />
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="8" string="a level playing field" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="9" string="maintains that they all wanted to do so and knew about steroids before the coach brought the subject up" type="VP">
          <tokens>
            <token id="11" string="maintains" />
            <token id="12" string="that" />
            <token id="13" string="they" />
            <token id="14" string="all" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="do" />
            <token id="18" string="so" />
            <token id="19" string="and" />
            <token id="20" string="knew" />
            <token id="21" string="about" />
            <token id="22" string="steroids" />
            <token id="23" string="before" />
            <token id="24" string="the" />
            <token id="25" string="coach" />
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="10" string="create a level playing field" type="VP">
          <tokens>
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="11" string="is simply helping to create a level playing field" type="VP">
          <tokens>
            <token id="35" string="is" />
            <token id="36" string="simply" />
            <token id="37" string="helping" />
            <token id="38" string="to" />
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="12" string="the subject" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="subject" />
          </tokens>
        </chunking>
        <chunking id="13" string="steroids" type="NP">
          <tokens>
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="34" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the coach" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="coach" />
          </tokens>
        </chunking>
        <chunking id="16" string="to do so" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="do" />
            <token id="18" string="so" />
          </tokens>
        </chunking>
        <chunking id="17" string="helping to create a level playing field" type="VP">
          <tokens>
            <token id="37" string="helping" />
            <token id="38" string="to" />
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
        <chunking id="18" string="wanted to do so" type="VP">
          <tokens>
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="do" />
            <token id="18" string="so" />
          </tokens>
        </chunking>
        <chunking id="19" string="to use steroids" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="use" />
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="20" string="knew about steroids before the coach brought the subject up" type="VP">
          <tokens>
            <token id="20" string="knew" />
            <token id="21" string="about" />
            <token id="22" string="steroids" />
            <token id="23" string="before" />
            <token id="24" string="the" />
            <token id="25" string="coach" />
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="21" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="22" string="wanted to do so and knew about steroids before the coach brought the subject up" type="VP">
          <tokens>
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="do" />
            <token id="18" string="so" />
            <token id="19" string="and" />
            <token id="20" string="knew" />
            <token id="21" string="about" />
            <token id="22" string="steroids" />
            <token id="23" string="before" />
            <token id="24" string="the" />
            <token id="25" string="coach" />
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="23" string="encouraging his athletes to use steroids" type="VP">
          <tokens>
            <token id="2" string="encouraging" />
            <token id="3" string="his" />
            <token id="4" string="athletes" />
            <token id="5" string="to" />
            <token id="6" string="use" />
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="24" string="Francis" type="NP">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="25" string="before the coach brought the subject up" type="SBAR">
          <tokens>
            <token id="23" string="before" />
            <token id="24" string="the" />
            <token id="25" string="coach" />
            <token id="26" string="brought" />
            <token id="27" string="the" />
            <token id="28" string="subject" />
            <token id="29" string="up" />
          </tokens>
        </chunking>
        <chunking id="26" string="to create a level playing field" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="create" />
            <token id="40" string="a" />
            <token id="41" string="level" />
            <token id="42" string="playing" />
            <token id="43" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">encouraging</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">argues</governor>
          <dependent id="2">encouraging</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">athletes</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">encouraging</governor>
          <dependent id="4">athletes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">use</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">encouraging</governor>
          <dependent id="6">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">use</governor>
          <dependent id="7">steroids</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">maintains</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">maintains</governor>
          <dependent id="10">Francis</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="32">argues</governor>
          <dependent id="11">maintains</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">wanted</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">wanted</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">wanted</governor>
          <dependent id="14">all</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">maintains</governor>
          <dependent id="15">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">do</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">wanted</governor>
          <dependent id="17">do</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">do</governor>
          <dependent id="18">so</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">wanted</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">wanted</governor>
          <dependent id="20">knew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">steroids</governor>
          <dependent id="21">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">knew</governor>
          <dependent id="22">steroids</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">brought</governor>
          <dependent id="23">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">coach</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">brought</governor>
          <dependent id="25">coach</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">knew</governor>
          <dependent id="26">brought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">subject</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="29">up</governor>
          <dependent id="28">subject</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">brought</governor>
          <dependent id="29">up</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">argues</governor>
          <dependent id="31">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">argues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">helping</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">helping</governor>
          <dependent id="34">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">helping</governor>
          <dependent id="35">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">helping</governor>
          <dependent id="36">simply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">argues</governor>
          <dependent id="37">helping</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">create</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">helping</governor>
          <dependent id="39">create</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">field</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">field</governor>
          <dependent id="41">level</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">field</governor>
          <dependent id="42">playing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">create</governor>
          <dependent id="43">field</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>We learn that the use of performance-enhancing drugs is nothing new in the world of sports -- that cocaine and arsenic and codeine were used by athletes in the 1896 Olympic Games.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="learn" lemma="learn" stem="learn" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sports" lemma="sport" stem="sport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="cocaine" lemma="cocaine" stem="cocain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="arsenic" lemma="arsenic" stem="arsen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="codeine" lemma="codeine" stem="codein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="1896" lemma="1896" stem="1896" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="31" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="32" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP learn) (SBAR (IN that) (S (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ performance-enhancing) (NNS drugs)))) (VP (VBZ is) (ADJP (NN nothing) (JJ new) (PP (IN in) (NP (NP (DT the) (NN world)) (PP (IN of) (NP (NNS sports)))))) (: --) (SBAR (IN that) (S (NP (NP (NN cocaine) (CC and) (NN arsenic)) (CC and) (NP (NN codeine))) (VP (VBD were) (VP (VBN used) (PP (IN by) (NP (NP (NNS athletes)) (PP (IN in) (NP (DT the) (CD 1896) (NNP Olympic) (NNPS Games))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="nothing new in the world of sports" type="ADJP">
          <tokens>
            <token id="10" string="nothing" />
            <token id="11" string="new" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="of" />
            <token id="16" string="sports" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the use of performance-enhancing drugs is nothing new in the world of sports -- that cocaine and arsenic and codeine were used by athletes in the 1896 Olympic Games" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="use" />
            <token id="6" string="of" />
            <token id="7" string="performance-enhancing" />
            <token id="8" string="drugs" />
            <token id="9" string="is" />
            <token id="10" string="nothing" />
            <token id="11" string="new" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="of" />
            <token id="16" string="sports" />
            <token id="17" string="--" />
            <token id="18" string="that" />
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
            <token id="22" string="and" />
            <token id="23" string="codeine" />
            <token id="24" string="were" />
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="3" string="sports" type="NP">
          <tokens>
            <token id="16" string="sports" />
          </tokens>
        </chunking>
        <chunking id="4" string="athletes in the 1896 Olympic Games" type="NP">
          <tokens>
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="5" string="the world" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="world" />
          </tokens>
        </chunking>
        <chunking id="6" string="were used by athletes in the 1896 Olympic Games" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="cocaine and arsenic and codeine" type="NP">
          <tokens>
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
            <token id="22" string="and" />
            <token id="23" string="codeine" />
          </tokens>
        </chunking>
        <chunking id="9" string="athletes" type="NP">
          <tokens>
            <token id="27" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="10" string="is nothing new in the world of sports -- that cocaine and arsenic and codeine were used by athletes in the 1896 Olympic Games" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="nothing" />
            <token id="11" string="new" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="of" />
            <token id="16" string="sports" />
            <token id="17" string="--" />
            <token id="18" string="that" />
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
            <token id="22" string="and" />
            <token id="23" string="codeine" />
            <token id="24" string="were" />
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="11" string="codeine" type="NP">
          <tokens>
            <token id="23" string="codeine" />
          </tokens>
        </chunking>
        <chunking id="12" string="used by athletes in the 1896 Olympic Games" type="VP">
          <tokens>
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="13" string="that cocaine and arsenic and codeine were used by athletes in the 1896 Olympic Games" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
            <token id="22" string="and" />
            <token id="23" string="codeine" />
            <token id="24" string="were" />
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="14" string="the use of performance-enhancing drugs" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="use" />
            <token id="6" string="of" />
            <token id="7" string="performance-enhancing" />
            <token id="8" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="15" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="7" string="performance-enhancing" />
            <token id="8" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="16" string="learn that the use of performance-enhancing drugs is nothing new in the world of sports -- that cocaine and arsenic and codeine were used by athletes in the 1896 Olympic Games" type="VP">
          <tokens>
            <token id="2" string="learn" />
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="use" />
            <token id="6" string="of" />
            <token id="7" string="performance-enhancing" />
            <token id="8" string="drugs" />
            <token id="9" string="is" />
            <token id="10" string="nothing" />
            <token id="11" string="new" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="of" />
            <token id="16" string="sports" />
            <token id="17" string="--" />
            <token id="18" string="that" />
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
            <token id="22" string="and" />
            <token id="23" string="codeine" />
            <token id="24" string="were" />
            <token id="25" string="used" />
            <token id="26" string="by" />
            <token id="27" string="athletes" />
            <token id="28" string="in" />
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="17" string="the 1896 Olympic Games" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="1896" />
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </chunking>
        <chunking id="18" string="the use" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="use" />
          </tokens>
        </chunking>
        <chunking id="19" string="the world of sports" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="of" />
            <token id="16" string="sports" />
          </tokens>
        </chunking>
        <chunking id="20" string="cocaine and arsenic" type="NP">
          <tokens>
            <token id="19" string="cocaine" />
            <token id="20" string="and" />
            <token id="21" string="arsenic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">learn</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">learn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">new</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">use</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">new</governor>
          <dependent id="5">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">drugs</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">drugs</governor>
          <dependent id="7">performance-enhancing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">use</governor>
          <dependent id="8">drugs</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">new</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="11">new</governor>
          <dependent id="10">nothing</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">learn</governor>
          <dependent id="11">new</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">world</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">world</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">new</governor>
          <dependent id="14">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">sports</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">world</governor>
          <dependent id="16">sports</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">used</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">used</governor>
          <dependent id="19">cocaine</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">cocaine</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">cocaine</governor>
          <dependent id="21">arsenic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">cocaine</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">cocaine</governor>
          <dependent id="23">codeine</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">used</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">new</governor>
          <dependent id="25">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">athletes</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">used</governor>
          <dependent id="27">athletes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Games</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">Games</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">Games</governor>
          <dependent id="30">1896</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Games</governor>
          <dependent id="31">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">athletes</governor>
          <dependent id="32">Games</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="1896" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="1896" />
          </tokens>
        </entity>
        <entity id="3" string="Olympic Games" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="Olympic" />
            <token id="32" string="Games" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>We learn that Johnson harmed his own world-record times by raising his hand jubilantly as he approached the finish line.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="learn" lemma="learn" stem="learn" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="harmed" lemma="harm" stem="harm" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="world-record" lemma="world-record" stem="world-record" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="raising" lemma="raise" stem="rais" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="jubilantly" lemma="jubilantly" stem="jubilantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="approached" lemma="approach" stem="approach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP learn) (SBAR (IN that) (S (NP (NNP Johnson)) (VP (VBD harmed) (NP (PRP$ his) (JJ own) (JJ world-record) (NNS times)) (PP (IN by) (S (VP (VBG raising) (NP (PRP$ his) (NN hand)) (ADVP (RB jubilantly)) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD approached) (NP (DT the) (NN finish) (NN line)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="learn that Johnson harmed his own world-record times by raising his hand jubilantly as he approached the finish line" type="VP">
          <tokens>
            <token id="2" string="learn" />
            <token id="3" string="that" />
            <token id="4" string="Johnson" />
            <token id="5" string="harmed" />
            <token id="6" string="his" />
            <token id="7" string="own" />
            <token id="8" string="world-record" />
            <token id="9" string="times" />
            <token id="10" string="by" />
            <token id="11" string="raising" />
            <token id="12" string="his" />
            <token id="13" string="hand" />
            <token id="14" string="jubilantly" />
            <token id="15" string="as" />
            <token id="16" string="he" />
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="approached the finish line" type="VP">
          <tokens>
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="4" string="harmed his own world-record times by raising his hand jubilantly as he approached the finish line" type="VP">
          <tokens>
            <token id="5" string="harmed" />
            <token id="6" string="his" />
            <token id="7" string="own" />
            <token id="8" string="world-record" />
            <token id="9" string="times" />
            <token id="10" string="by" />
            <token id="11" string="raising" />
            <token id="12" string="his" />
            <token id="13" string="hand" />
            <token id="14" string="jubilantly" />
            <token id="15" string="as" />
            <token id="16" string="he" />
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="5" string="raising his hand jubilantly as he approached the finish line" type="VP">
          <tokens>
            <token id="11" string="raising" />
            <token id="12" string="his" />
            <token id="13" string="hand" />
            <token id="14" string="jubilantly" />
            <token id="15" string="as" />
            <token id="16" string="he" />
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Johnson harmed his own world-record times by raising his hand jubilantly as he approached the finish line" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="Johnson" />
            <token id="5" string="harmed" />
            <token id="6" string="his" />
            <token id="7" string="own" />
            <token id="8" string="world-record" />
            <token id="9" string="times" />
            <token id="10" string="by" />
            <token id="11" string="raising" />
            <token id="12" string="his" />
            <token id="13" string="hand" />
            <token id="14" string="jubilantly" />
            <token id="15" string="as" />
            <token id="16" string="he" />
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="7" string="his hand" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="hand" />
          </tokens>
        </chunking>
        <chunking id="8" string="as he approached the finish line" type="SBAR">
          <tokens>
            <token id="15" string="as" />
            <token id="16" string="he" />
            <token id="17" string="approached" />
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="9" string="his own world-record times" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="own" />
            <token id="8" string="world-record" />
            <token id="9" string="times" />
          </tokens>
        </chunking>
        <chunking id="10" string="the finish line" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="finish" />
            <token id="20" string="line" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">learn</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">learn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">harmed</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">harmed</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">learn</governor>
          <dependent id="5">harmed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">times</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">times</governor>
          <dependent id="7">own</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">times</governor>
          <dependent id="8">world-record</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">harmed</governor>
          <dependent id="9">times</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">raising</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">harmed</governor>
          <dependent id="11">raising</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">hand</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">raising</governor>
          <dependent id="13">hand</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">raising</governor>
          <dependent id="14">jubilantly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">approached</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">approached</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">raising</governor>
          <dependent id="17">approached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">line</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">line</governor>
          <dependent id="19">finish</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">approached</governor>
          <dependent id="20">line</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>We learn that if athletes take steroids on their own, independent of an official (but still illicit, of course) program, it&amp;apost;s called &amp;quot;free-lancing.&amp;quot;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="learn" lemma="learn" stem="learn" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="illicit" lemma="illicit" stem="illicit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="free-lancing" lemma="free-lancing" stem="free-lanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP learn) (SBAR (IN that) (S (SBAR (IN if) (S (NP (NNS athletes)) (VP (VBP take) (NP (NNS steroids)) (PP (IN on) (NP (PRP$ their) (JJ own))) (, ,) (ADJP (JJ independent) (PP (IN of) (NP (DT an) (NN official) (PRN (-LRB- -LRB-) (CC but) (ADVP (RB still)) (NP (NP (JJ illicit)) (, ,) (PP (IN of) (NP (NN course)))) (-RRB- -RRB-)) (NN program))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (VP (VBN called) (S (`` ``) (NP (NN free-lancing)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="illicit , of course" type="NP">
          <tokens>
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s called `` free-lancing" type="VP">
          <tokens>
            <token id="27" string="'s" />
            <token id="28" string="called" />
            <token id="29" string="&quot;" />
            <token id="30" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="3" string="free-lancing" type="NP">
          <tokens>
            <token id="30" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="4" string="their own" type="NP">
          <tokens>
            <token id="9" string="their" />
            <token id="10" string="own" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="athletes" type="NP">
          <tokens>
            <token id="5" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="8" string="called `` free-lancing" type="VP">
          <tokens>
            <token id="28" string="called" />
            <token id="29" string="&quot;" />
            <token id="30" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="9" string="take steroids on their own , independent of an official -LRB- but still illicit , of course -RRB- program" type="VP">
          <tokens>
            <token id="6" string="take" />
            <token id="7" string="steroids" />
            <token id="8" string="on" />
            <token id="9" string="their" />
            <token id="10" string="own" />
            <token id="11" string="," />
            <token id="12" string="independent" />
            <token id="13" string="of" />
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
          </tokens>
        </chunking>
        <chunking id="10" string="illicit" type="NP">
          <tokens>
            <token id="19" string="illicit" />
          </tokens>
        </chunking>
        <chunking id="11" string="independent of an official -LRB- but still illicit , of course -RRB- program" type="ADJP">
          <tokens>
            <token id="12" string="independent" />
            <token id="13" string="of" />
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
          </tokens>
        </chunking>
        <chunking id="12" string="course" type="NP">
          <tokens>
            <token id="22" string="course" />
          </tokens>
        </chunking>
        <chunking id="13" string="that if athletes take steroids on their own , independent of an official -LRB- but still illicit , of course -RRB- program , it 's called `` free-lancing" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="if" />
            <token id="5" string="athletes" />
            <token id="6" string="take" />
            <token id="7" string="steroids" />
            <token id="8" string="on" />
            <token id="9" string="their" />
            <token id="10" string="own" />
            <token id="11" string="," />
            <token id="12" string="independent" />
            <token id="13" string="of" />
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
            <token id="25" string="," />
            <token id="26" string="it" />
            <token id="27" string="'s" />
            <token id="28" string="called" />
            <token id="29" string="&quot;" />
            <token id="30" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="14" string="if athletes take steroids on their own , independent of an official -LRB- but still illicit , of course -RRB- program" type="SBAR">
          <tokens>
            <token id="4" string="if" />
            <token id="5" string="athletes" />
            <token id="6" string="take" />
            <token id="7" string="steroids" />
            <token id="8" string="on" />
            <token id="9" string="their" />
            <token id="10" string="own" />
            <token id="11" string="," />
            <token id="12" string="independent" />
            <token id="13" string="of" />
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
          </tokens>
        </chunking>
        <chunking id="15" string="steroids" type="NP">
          <tokens>
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="16" string="learn that if athletes take steroids on their own , independent of an official -LRB- but still illicit , of course -RRB- program , it 's called `` free-lancing" type="VP">
          <tokens>
            <token id="2" string="learn" />
            <token id="3" string="that" />
            <token id="4" string="if" />
            <token id="5" string="athletes" />
            <token id="6" string="take" />
            <token id="7" string="steroids" />
            <token id="8" string="on" />
            <token id="9" string="their" />
            <token id="10" string="own" />
            <token id="11" string="," />
            <token id="12" string="independent" />
            <token id="13" string="of" />
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
            <token id="25" string="," />
            <token id="26" string="it" />
            <token id="27" string="'s" />
            <token id="28" string="called" />
            <token id="29" string="&quot;" />
            <token id="30" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="17" string="an official -LRB- but still illicit , of course -RRB- program" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="official" />
            <token id="16" string="(" />
            <token id="17" string="but" />
            <token id="18" string="still" />
            <token id="19" string="illicit" />
            <token id="20" string="," />
            <token id="21" string="of" />
            <token id="22" string="course" />
            <token id="23" string=")" />
            <token id="24" string="program" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">learn</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">learn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">called</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">take</governor>
          <dependent id="4">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">take</governor>
          <dependent id="5">athletes</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">called</governor>
          <dependent id="6">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">take</governor>
          <dependent id="7">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">own</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">own</governor>
          <dependent id="9">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">take</governor>
          <dependent id="10">own</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">take</governor>
          <dependent id="12">independent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">program</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">program</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">program</governor>
          <dependent id="15">official</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">illicit</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">illicit</governor>
          <dependent id="18">still</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">program</governor>
          <dependent id="19">illicit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">course</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">illicit</governor>
          <dependent id="22">course</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">independent</governor>
          <dependent id="24">program</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">called</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">called</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">learn</governor>
          <dependent id="28">called</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">called</governor>
          <dependent id="30">free-lancing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>That&amp;apost;s one of Francis&amp;apost; theories for why Johnson got caught.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="theories" lemma="theory" stem="theori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (NP (NP (CD one)) (PP (IN of) (NP (NP (NNP Francis) (POS ')) (NNS theories))) (PP (IN for) (SBAR (WHADVP (WRB why)) (S (NP (NNP Johnson)) (VP (VBD got) (VP (VBN caught)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="Francis ' theories" type="NP">
          <tokens>
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="theories" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s one of Francis ' theories for why Johnson got caught" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="theories" />
            <token id="8" string="for" />
            <token id="9" string="why" />
            <token id="10" string="Johnson" />
            <token id="11" string="got" />
            <token id="12" string="caught" />
          </tokens>
        </chunking>
        <chunking id="6" string="why" type="WHADVP">
          <tokens>
            <token id="9" string="why" />
          </tokens>
        </chunking>
        <chunking id="7" string="caught" type="VP">
          <tokens>
            <token id="12" string="caught" />
          </tokens>
        </chunking>
        <chunking id="8" string="why Johnson got caught" type="SBAR">
          <tokens>
            <token id="9" string="why" />
            <token id="10" string="Johnson" />
            <token id="11" string="got" />
            <token id="12" string="caught" />
          </tokens>
        </chunking>
        <chunking id="9" string="one of Francis ' theories for why Johnson got caught" type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="theories" />
            <token id="8" string="for" />
            <token id="9" string="why" />
            <token id="10" string="Johnson" />
            <token id="11" string="got" />
            <token id="12" string="caught" />
          </tokens>
        </chunking>
        <chunking id="10" string="Francis '" type="NP">
          <tokens>
            <token id="5" string="Francis" />
            <token id="6" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="got caught" type="VP">
          <tokens>
            <token id="11" string="got" />
            <token id="12" string="caught" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">one</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">one</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">theories</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">theories</governor>
          <dependent id="5">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Francis</governor>
          <dependent id="6">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">one</governor>
          <dependent id="7">theories</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">caught</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">caught</governor>
          <dependent id="9">why</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">caught</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">caught</governor>
          <dependent id="11">got</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">one</governor>
          <dependent id="12">caught</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>But, Francis says, there is no logical reason for Johnson to have been caught.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="logical" lemma="logical" stem="logic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PRN (, ,) (NP (NNP Francis)) (VP (VBZ says)) (, ,)) (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ logical) (NN reason)) (PP (IN for) (NP (NNP Johnson))) (S (VP (TO to) (VP (VB have) (VP (VBN been) (VP (VBN caught)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="6" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="4" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="no logical reason for Johnson to have been caught" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="logical" />
            <token id="10" string="reason" />
            <token id="11" string="for" />
            <token id="12" string="Johnson" />
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="been" />
            <token id="16" string="caught" />
          </tokens>
        </chunking>
        <chunking id="5" string="Francis" type="NP">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="6" string="been caught" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="caught" />
          </tokens>
        </chunking>
        <chunking id="7" string="have been caught" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="been" />
            <token id="16" string="caught" />
          </tokens>
        </chunking>
        <chunking id="8" string="caught" type="VP">
          <tokens>
            <token id="16" string="caught" />
          </tokens>
        </chunking>
        <chunking id="9" string="no logical reason" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="logical" />
            <token id="10" string="reason" />
          </tokens>
        </chunking>
        <chunking id="10" string="is no logical reason for Johnson to have been caught" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="no" />
            <token id="9" string="logical" />
            <token id="10" string="reason" />
            <token id="11" string="for" />
            <token id="12" string="Johnson" />
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="been" />
            <token id="16" string="caught" />
          </tokens>
        </chunking>
        <chunking id="11" string="to have been caught" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="been" />
            <token id="16" string="caught" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">is</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">says</governor>
          <dependent id="3">Francis</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">is</governor>
          <dependent id="4">says</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="7">is</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">reason</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">reason</governor>
          <dependent id="9">logical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">is</governor>
          <dependent id="10">reason</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Johnson</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">reason</governor>
          <dependent id="12">Johnson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">caught</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">caught</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">caught</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">reason</governor>
          <dependent id="16">caught</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>After all, he had never been caught before.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (DT all))) (, ,) (NP (PRP he)) (VP (VBD had) (ADVP (RB never)) (VP (VBN been) (VP (VBN caught) (ADVP (RB before))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="2" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="had never been caught before" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="never" />
            <token id="7" string="been" />
            <token id="8" string="caught" />
            <token id="9" string="before" />
          </tokens>
        </chunking>
        <chunking id="3" string="been caught before" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="caught" />
            <token id="9" string="before" />
          </tokens>
        </chunking>
        <chunking id="4" string="caught before" type="VP">
          <tokens>
            <token id="8" string="caught" />
            <token id="9" string="before" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">all</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">caught</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">caught</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">caught</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">caught</governor>
          <dependent id="6">never</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">caught</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">caught</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">caught</governor>
          <dependent id="9">before</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>No one of Johnson&amp;apost;s standing had been caught before.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="standing" lemma="standing" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT No) (NN one)) (PP (IN of) (NP (NP (NNP Johnson) (POS 's)) (NN standing)))) (VP (VBD had) (VP (VBN been) (VP (VBN caught) (ADVP (RB before))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="been caught before" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="caught" />
            <token id="10" string="before" />
          </tokens>
        </chunking>
        <chunking id="3" string="caught before" type="VP">
          <tokens>
            <token id="9" string="caught" />
            <token id="10" string="before" />
          </tokens>
        </chunking>
        <chunking id="4" string="No one of Johnson 's standing" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
            <token id="3" string="of" />
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
            <token id="6" string="standing" />
          </tokens>
        </chunking>
        <chunking id="5" string="had been caught before" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="been" />
            <token id="9" string="caught" />
            <token id="10" string="before" />
          </tokens>
        </chunking>
        <chunking id="6" string="Johnson 's standing" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
            <token id="6" string="standing" />
          </tokens>
        </chunking>
        <chunking id="7" string="Johnson 's" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">caught</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">standing</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">standing</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Johnson</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">one</governor>
          <dependent id="6">standing</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">caught</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">caught</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">caught</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">caught</governor>
          <dependent id="10">before</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Francis offers theories for the positive test result -- free-lancing, sabotage, a screw-up by the team doctor -- but there is no clear answer.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="offers" lemma="offer" stem="offer" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="theories" lemma="theory" stem="theori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="free-lancing" lemma="free-lancing" stem="free-lanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sabotage" lemma="sabotage" stem="sabotag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="screw-up" lemma="screw-up" stem="screw-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Francis)) (VP (VBZ offers) (NP (NNS theories)) (PP (IN for) (NP (DT the) (JJ positive) (NN test) (NN result))) (: --) (NP (NP (NN free-lancing)) (, ,) (NP (NN sabotage)) (, ,) (NP (NP (DT a) (NN screw-up)) (PP (IN by) (NP (DT the) (NN team) (NN doctor))))))) (: --) (CC but) (S (NP (EX there)) (VP (VBZ is) (NP (DT no) (JJ clear) (NN answer)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="free-lancing" type="NP">
          <tokens>
            <token id="10" string="free-lancing" />
          </tokens>
        </chunking>
        <chunking id="2" string="offers theories for the positive test result -- free-lancing , sabotage , a screw-up by the team doctor" type="VP">
          <tokens>
            <token id="2" string="offers" />
            <token id="3" string="theories" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="positive" />
            <token id="7" string="test" />
            <token id="8" string="result" />
            <token id="9" string="--" />
            <token id="10" string="free-lancing" />
            <token id="11" string="," />
            <token id="12" string="sabotage" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="screw-up" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="team" />
            <token id="19" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="3" string="a screw-up by the team doctor" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="screw-up" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="team" />
            <token id="19" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="4" string="no clear answer" type="NP">
          <tokens>
            <token id="24" string="no" />
            <token id="25" string="clear" />
            <token id="26" string="answer" />
          </tokens>
        </chunking>
        <chunking id="5" string="there" type="NP">
          <tokens>
            <token id="22" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="a screw-up" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="screw-up" />
          </tokens>
        </chunking>
        <chunking id="7" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="8" string="sabotage" type="NP">
          <tokens>
            <token id="12" string="sabotage" />
          </tokens>
        </chunking>
        <chunking id="9" string="theories" type="NP">
          <tokens>
            <token id="3" string="theories" />
          </tokens>
        </chunking>
        <chunking id="10" string="is no clear answer" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="no" />
            <token id="25" string="clear" />
            <token id="26" string="answer" />
          </tokens>
        </chunking>
        <chunking id="11" string="free-lancing , sabotage , a screw-up by the team doctor" type="NP">
          <tokens>
            <token id="10" string="free-lancing" />
            <token id="11" string="," />
            <token id="12" string="sabotage" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="screw-up" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="team" />
            <token id="19" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="12" string="the team doctor" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="team" />
            <token id="19" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="13" string="the positive test result" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="positive" />
            <token id="7" string="test" />
            <token id="8" string="result" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">offers</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">offers</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">offers</governor>
          <dependent id="3">theories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">result</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">result</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">result</governor>
          <dependent id="6">positive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">result</governor>
          <dependent id="7">test</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">offers</governor>
          <dependent id="8">result</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">offers</governor>
          <dependent id="10">free-lancing</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">free-lancing</governor>
          <dependent id="12">sabotage</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">screw-up</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">free-lancing</governor>
          <dependent id="15">screw-up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">doctor</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">doctor</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">doctor</governor>
          <dependent id="18">team</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">screw-up</governor>
          <dependent id="19">doctor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">offers</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="23">is</governor>
          <dependent id="22">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">offers</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">answer</governor>
          <dependent id="24">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">answer</governor>
          <dependent id="25">clear</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">is</governor>
          <dependent id="26">answer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>For all its candor, answers and revelations are not forthcoming in &amp;quot;Speed Trap.&amp;quot;</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="candor" lemma="candor" stem="candor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="revelations" lemma="revelation" stem="revel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="forthcoming" lemma="forthcoming" stem="forthcom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (DT all) (PRP$ its) (NN candor))) (, ,) (NP (NNS answers) (CC and) (NNS revelations)) (VP (VBP are) (RB not) (ADJP (JJ forthcoming)) (PP (IN in) (`` ``) (NP (NN Speed) (NN Trap)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="are not forthcoming in `` Speed Trap" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="not" />
            <token id="11" string="forthcoming" />
            <token id="12" string="in" />
            <token id="13" string="&quot;" />
            <token id="14" string="Speed" />
            <token id="15" string="Trap" />
          </tokens>
        </chunking>
        <chunking id="2" string="forthcoming" type="ADJP">
          <tokens>
            <token id="11" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="3" string="answers and revelations" type="NP">
          <tokens>
            <token id="6" string="answers" />
            <token id="7" string="and" />
            <token id="8" string="revelations" />
          </tokens>
        </chunking>
        <chunking id="4" string="Speed Trap" type="NP">
          <tokens>
            <token id="14" string="Speed" />
            <token id="15" string="Trap" />
          </tokens>
        </chunking>
        <chunking id="5" string="all its candor" type="NP">
          <tokens>
            <token id="2" string="all" />
            <token id="3" string="its" />
            <token id="4" string="candor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">candor</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="4">candor</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">candor</governor>
          <dependent id="3">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">forthcoming</governor>
          <dependent id="4">candor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">forthcoming</governor>
          <dependent id="6">answers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">answers</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">answers</governor>
          <dependent id="8">revelations</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">forthcoming</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">forthcoming</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">forthcoming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Trap</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Trap</governor>
          <dependent id="14">Speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">forthcoming</governor>
          <dependent id="15">Trap</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Francis, without naming names, convinces us that steroid usage is rampant, but he tells us what that means to him only in a technical sense.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="naming" lemma="name" stem="name" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="convinces" lemma="convince" stem="convinc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="usage" lemma="usage" stem="usag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="rampant" lemma="rampant" stem="rampant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="means" lemma="mean" stem="mean" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="technical" lemma="technical" stem="technic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Francis)) (, ,) (PP (IN without) (S (VP (VBG naming) (NP (NNS names))))) (, ,) (VP (VBZ convinces) (NP (PRP us)) (SBAR (IN that) (S (NP (NN steroid) (NN usage)) (VP (VBZ is) (ADJP (JJ rampant))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBZ tells) (NP (PRP us)) (SBAR (WHNP (WP what)) (S (NP (DT that)) (VP (VBZ means) (PP (TO to) (NP (PRP him))) (PP (ADVP (RB only)) (IN in) (NP (DT a) (JJ technical) (NN sense)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="naming names" type="VP">
          <tokens>
            <token id="4" string="naming" />
            <token id="5" string="names" />
          </tokens>
        </chunking>
        <chunking id="2" string="that steroid usage is rampant" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="steroid" />
            <token id="11" string="usage" />
            <token id="12" string="is" />
            <token id="13" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="3" string="what that means to him only in a technical sense" type="SBAR">
          <tokens>
            <token id="19" string="what" />
            <token id="20" string="that" />
            <token id="21" string="means" />
            <token id="22" string="to" />
            <token id="23" string="him" />
            <token id="24" string="only" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="technical" />
            <token id="28" string="sense" />
          </tokens>
        </chunking>
        <chunking id="4" string="a technical sense" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="technical" />
            <token id="28" string="sense" />
          </tokens>
        </chunking>
        <chunking id="5" string="convinces us that steroid usage is rampant" type="VP">
          <tokens>
            <token id="7" string="convinces" />
            <token id="8" string="us" />
            <token id="9" string="that" />
            <token id="10" string="steroid" />
            <token id="11" string="usage" />
            <token id="12" string="is" />
            <token id="13" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="6" string="tells us what that means to him only in a technical sense" type="VP">
          <tokens>
            <token id="17" string="tells" />
            <token id="18" string="us" />
            <token id="19" string="what" />
            <token id="20" string="that" />
            <token id="21" string="means" />
            <token id="22" string="to" />
            <token id="23" string="him" />
            <token id="24" string="only" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="technical" />
            <token id="28" string="sense" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="means to him only in a technical sense" type="VP">
          <tokens>
            <token id="21" string="means" />
            <token id="22" string="to" />
            <token id="23" string="him" />
            <token id="24" string="only" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="technical" />
            <token id="28" string="sense" />
          </tokens>
        </chunking>
        <chunking id="9" string="that" type="NP">
          <tokens>
            <token id="20" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="11" string="rampant" type="ADJP">
          <tokens>
            <token id="13" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="12" string="names" type="NP">
          <tokens>
            <token id="5" string="names" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="us" type="NP">
          <tokens>
            <token id="8" string="us" />
          </tokens>
        </chunking>
        <chunking id="15" string="is rampant" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="16" string="steroid usage" type="NP">
          <tokens>
            <token id="10" string="steroid" />
            <token id="11" string="usage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">convinces</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">naming</governor>
          <dependent id="3">without</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">convinces</governor>
          <dependent id="4">naming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">naming</governor>
          <dependent id="5">names</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">convinces</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">convinces</governor>
          <dependent id="8">us</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">rampant</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">usage</governor>
          <dependent id="10">steroid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">rampant</governor>
          <dependent id="11">usage</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">rampant</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">convinces</governor>
          <dependent id="13">rampant</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">convinces</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">tells</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">convinces</governor>
          <dependent id="17">tells</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">tells</governor>
          <dependent id="18">us</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">means</governor>
          <dependent id="19">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">means</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">tells</governor>
          <dependent id="21">means</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">him</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">means</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">sense</governor>
          <dependent id="24">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">sense</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">sense</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">sense</governor>
          <dependent id="27">technical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">means</governor>
          <dependent id="28">sense</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The book lacks a strong sense of character development.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="lacks" lemma="lack" stem="lack" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="development" lemma="development" stem="develop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN book)) (VP (VBZ lacks) (NP (NP (DT a) (JJ strong) (NN sense)) (PP (IN of) (NP (NN character) (NN development))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The book" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="book" />
          </tokens>
        </chunking>
        <chunking id="2" string="a strong sense of character development" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="strong" />
            <token id="6" string="sense" />
            <token id="7" string="of" />
            <token id="8" string="character" />
            <token id="9" string="development" />
          </tokens>
        </chunking>
        <chunking id="3" string="character development" type="NP">
          <tokens>
            <token id="8" string="character" />
            <token id="9" string="development" />
          </tokens>
        </chunking>
        <chunking id="4" string="lacks a strong sense of character development" type="VP">
          <tokens>
            <token id="3" string="lacks" />
            <token id="4" string="a" />
            <token id="5" string="strong" />
            <token id="6" string="sense" />
            <token id="7" string="of" />
            <token id="8" string="character" />
            <token id="9" string="development" />
          </tokens>
        </chunking>
        <chunking id="5" string="a strong sense" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="strong" />
            <token id="6" string="sense" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">book</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">lacks</governor>
          <dependent id="2">book</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">lacks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sense</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">sense</governor>
          <dependent id="5">strong</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">lacks</governor>
          <dependent id="6">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">development</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">development</governor>
          <dependent id="8">character</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sense</governor>
          <dependent id="9">development</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>It does not take any moral stand; it lacks passion.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="moral" lemma="moral" stem="moral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="lacks" lemma="lack" stem="lack" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="passion" lemma="passion" stem="passion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ does) (RB not) (VP (VB take) (NP (DT any) (JJ moral) (NN stand))))) (: ;) (S (NP (PRP it)) (VP (VBZ lacks) (NP (NN passion)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any moral stand" type="NP">
          <tokens>
            <token id="5" string="any" />
            <token id="6" string="moral" />
            <token id="7" string="stand" />
          </tokens>
        </chunking>
        <chunking id="2" string="take any moral stand" type="VP">
          <tokens>
            <token id="4" string="take" />
            <token id="5" string="any" />
            <token id="6" string="moral" />
            <token id="7" string="stand" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="does not take any moral stand" type="VP">
          <tokens>
            <token id="2" string="does" />
            <token id="3" string="not" />
            <token id="4" string="take" />
            <token id="5" string="any" />
            <token id="6" string="moral" />
            <token id="7" string="stand" />
          </tokens>
        </chunking>
        <chunking id="6" string="lacks passion" type="VP">
          <tokens>
            <token id="10" string="lacks" />
            <token id="11" string="passion" />
          </tokens>
        </chunking>
        <chunking id="7" string="passion" type="NP">
          <tokens>
            <token id="11" string="passion" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">take</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">take</governor>
          <dependent id="2">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">take</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">stand</governor>
          <dependent id="5">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">stand</governor>
          <dependent id="6">moral</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">take</governor>
          <dependent id="7">stand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">lacks</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">take</governor>
          <dependent id="10">lacks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">lacks</governor>
          <dependent id="11">passion</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>How did Francis feel violating the rules?</content>
      <tokens>
        <token id="1" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="violating" lemma="violate" stem="violat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHADVP (WRB How)) (SQ (VBD did) (NP (NNP Francis)) (VP (VB feel) (S (VP (VBG violating) (NP (DT the) (NNS rules)))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Francis" type="NP">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="2" string="violating the rules" type="VP">
          <tokens>
            <token id="5" string="violating" />
            <token id="6" string="the" />
            <token id="7" string="rules" />
          </tokens>
        </chunking>
        <chunking id="3" string="feel violating the rules" type="VP">
          <tokens>
            <token id="4" string="feel" />
            <token id="5" string="violating" />
            <token id="6" string="the" />
            <token id="7" string="rules" />
          </tokens>
        </chunking>
        <chunking id="4" string="the rules" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="rules" />
          </tokens>
        </chunking>
        <chunking id="5" string="How" type="WHADVP">
          <tokens>
            <token id="1" string="How" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">feel</governor>
          <dependent id="1">How</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">feel</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">feel</governor>
          <dependent id="3">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">feel</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">feel</governor>
          <dependent id="5">violating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">rules</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">violating</governor>
          <dependent id="7">rules</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>What drove him?</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WDT What)) (SQ (VP (VBD drove) (NP (PRP him)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="drove him" type="VP">
          <tokens>
            <token id="2" string="drove" />
            <token id="3" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">drove</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">drove</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">drove</governor>
          <dependent id="3">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>What did he really feel toward Johnson?</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP What)) (SQ (VBD did) (NP (PRP he)) (VP (ADVP (RB really)) (VBP feel) (PP (IN toward) (NP (NNP Johnson))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="really feel toward Johnson" type="VP">
          <tokens>
            <token id="4" string="really" />
            <token id="5" string="feel" />
            <token id="6" string="toward" />
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="5">feel</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">feel</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">feel</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">feel</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">feel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Johnson</governor>
          <dependent id="6">toward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">feel</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>; After a two-year ban, Johnson is running again without Francis&amp;apost; coaching.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="two-year" lemma="two-year" stem="two-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="coaching" lemma="coaching" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN After) (NP (DT a) (JJ two-year) (NN ban))) (, ,) (NP (NNP Johnson)) (VP (VBZ is) (VP (VBG running) (ADVP (RB again)) (PP (IN without) (NP (NP (NNP Francis) (POS ')) (NN coaching))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="is running again without Francis ' coaching" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="running" />
            <token id="10" string="again" />
            <token id="11" string="without" />
            <token id="12" string="Francis" />
            <token id="13" string="'" />
            <token id="14" string="coaching" />
          </tokens>
        </chunking>
        <chunking id="3" string="Francis ' coaching" type="NP">
          <tokens>
            <token id="12" string="Francis" />
            <token id="13" string="'" />
            <token id="14" string="coaching" />
          </tokens>
        </chunking>
        <chunking id="4" string="Francis '" type="NP">
          <tokens>
            <token id="12" string="Francis" />
            <token id="13" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="a two-year ban" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="two-year" />
            <token id="5" string="ban" />
          </tokens>
        </chunking>
        <chunking id="6" string="running again without Francis ' coaching" type="VP">
          <tokens>
            <token id="9" string="running" />
            <token id="10" string="again" />
            <token id="11" string="without" />
            <token id="12" string="Francis" />
            <token id="13" string="'" />
            <token id="14" string="coaching" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">ban</governor>
          <dependent id="2">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ban</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">ban</governor>
          <dependent id="4">two-year</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">running</governor>
          <dependent id="5">ban</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">running</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">running</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">running</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">running</governor>
          <dependent id="10">again</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">coaching</governor>
          <dependent id="11">without</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">coaching</governor>
          <dependent id="12">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Francis</governor>
          <dependent id="13">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">running</governor>
          <dependent id="14">coaching</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="two-year" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="two-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>The early word is that he is still extremely fast, probably one of the fastest men in the world -- but no longer the fastest.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="extremely" lemma="extremely" stem="extrem" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ early) (NN word)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ is) (ADVP (RB still)) (ADVP (RB extremely) (RB fast)) (, ,) (NP (NP (NP (RB probably) (CD one)) (PP (IN of) (NP (NP (DT the) (JJS fastest) (NNS men)) (PP (IN in) (NP (DT the) (NN world)))))) (: --) (CC but) (NP (ADVP (RB no) (RBR longer)) (DT the) (JJS fastest))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="probably one of the fastest men in the world -- but no longer the fastest" type="NP">
          <tokens>
            <token id="12" string="probably" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
            <token id="21" string="--" />
            <token id="22" string="but" />
            <token id="23" string="no" />
            <token id="24" string="longer" />
            <token id="25" string="the" />
            <token id="26" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="2" string="probably one of the fastest men in the world" type="NP">
          <tokens>
            <token id="12" string="probably" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
          </tokens>
        </chunking>
        <chunking id="3" string="no longer the fastest" type="NP">
          <tokens>
            <token id="23" string="no" />
            <token id="24" string="longer" />
            <token id="25" string="the" />
            <token id="26" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="4" string="is still extremely fast , probably one of the fastest men in the world -- but no longer the fastest" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="still" />
            <token id="9" string="extremely" />
            <token id="10" string="fast" />
            <token id="11" string="," />
            <token id="12" string="probably" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
            <token id="21" string="--" />
            <token id="22" string="but" />
            <token id="23" string="no" />
            <token id="24" string="longer" />
            <token id="25" string="the" />
            <token id="26" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="5" string="The early word" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="early" />
            <token id="3" string="word" />
          </tokens>
        </chunking>
        <chunking id="6" string="probably one" type="NP">
          <tokens>
            <token id="12" string="probably" />
            <token id="13" string="one" />
          </tokens>
        </chunking>
        <chunking id="7" string="the fastest men" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
          </tokens>
        </chunking>
        <chunking id="8" string="is that he is still extremely fast , probably one of the fastest men in the world -- but no longer the fastest" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="is" />
            <token id="8" string="still" />
            <token id="9" string="extremely" />
            <token id="10" string="fast" />
            <token id="11" string="," />
            <token id="12" string="probably" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
            <token id="21" string="--" />
            <token id="22" string="but" />
            <token id="23" string="no" />
            <token id="24" string="longer" />
            <token id="25" string="the" />
            <token id="26" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="the world" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="world" />
          </tokens>
        </chunking>
        <chunking id="11" string="the fastest men in the world" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he is still extremely fast , probably one of the fastest men in the world -- but no longer the fastest" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="is" />
            <token id="8" string="still" />
            <token id="9" string="extremely" />
            <token id="10" string="fast" />
            <token id="11" string="," />
            <token id="12" string="probably" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="fastest" />
            <token id="17" string="men" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="world" />
            <token id="21" string="--" />
            <token id="22" string="but" />
            <token id="23" string="no" />
            <token id="24" string="longer" />
            <token id="25" string="the" />
            <token id="26" string="fastest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">word</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">word</governor>
          <dependent id="2">early</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">word</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">one</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">one</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">one</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">one</governor>
          <dependent id="8">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">fast</governor>
          <dependent id="9">extremely</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">one</governor>
          <dependent id="10">fast</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">one</governor>
          <dependent id="12">probably</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="13">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">men</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">men</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">men</governor>
          <dependent id="16">fastest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">one</governor>
          <dependent id="17">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">world</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">world</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">men</governor>
          <dependent id="20">world</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">one</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">longer</governor>
          <dependent id="23">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">fastest</governor>
          <dependent id="24">longer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">fastest</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">one</governor>
          <dependent id="26">fastest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Francis would have us believe that without steroids, Johnson cannot be the fastest.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Francis)) (VP (MD would) (VP (VB have) (S (NP (PRP us)) (VP (VB believe) (NP (DT that)) (PP (IN without) (NP (NNS steroids)))))))) (, ,) (NP (NNP Johnson)) (VP (MD can) (RB not) (VP (VB be) (NP (DT the) (JJS fastest)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the fastest" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="4" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="5" string="would have us believe that without steroids" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="have" />
            <token id="4" string="us" />
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="without" />
            <token id="8" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="6" string="believe that without steroids" type="VP">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="without" />
            <token id="8" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="7" string="have us believe that without steroids" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="us" />
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="without" />
            <token id="8" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="8" string="steroids" type="NP">
          <tokens>
            <token id="8" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="9" string="be the fastest" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="the" />
            <token id="15" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="10" string="us" type="NP">
          <tokens>
            <token id="4" string="us" />
          </tokens>
        </chunking>
        <chunking id="11" string="can not be the fastest" type="VP">
          <tokens>
            <token id="11" string="can" />
            <token id="12" string="not" />
            <token id="13" string="be" />
            <token id="14" string="the" />
            <token id="15" string="fastest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">have</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">fastest</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">believe</governor>
          <dependent id="4">us</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">have</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">believe</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">steroids</governor>
          <dependent id="7">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">believe</governor>
          <dependent id="8">steroids</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">fastest</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">fastest</governor>
          <dependent id="11">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">fastest</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">fastest</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">fastest</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">fastest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>(Johnson disagrees.)</content>
      <tokens>
        <token id="1" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="disagrees" lemma="disagree" stem="disagre" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (-LRB- -LRB-) (NP (NNP Johnson)) (VP (VBZ disagrees)) (. .) (-RRB- -RRB-)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="disagrees" type="VP">
          <tokens>
            <token id="3" string="disagrees" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">disagrees</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">disagrees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>; At the end of &amp;quot;Speed Trap,&amp;quot; Francis says that steroids cannot be simply banned -- their use is too prevalent, they can be disguised too easily and they work too well.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="prevalent" lemma="prevalent" stem="preval" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="disguised" lemma="disguise" stem="disguis" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="easily" lemma="easily" stem="easili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="work" lemma="work" stem="work" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (`` ``) (NN Speed) (NN Trap) (, ,) ('' ''))))) (NP (NNP Francis)) (VP (VBZ says) (SBAR (IN that) (S (NP (NNS steroids)) (VP (MD can) (RB not) (VP (VB be) (VP (ADVP (RB simply)) (VBN banned)))))))) (: --) (S (NP (PRP$ their) (NN use)) (VP (VBZ is) (ADJP (RB too) (JJ prevalent)))) (, ,) (S (NP (PRP they)) (VP (MD can) (VP (VB be) (VP (VBN disguised) (ADVP (RB too) (RB easily)))))) (CC and) (S (NP (PRP they)) (VP (VBP work) (ADVP (RB too) (RB well)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that steroids can not be simply banned" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="steroids" />
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="be" />
            <token id="18" string="simply" />
            <token id="19" string="banned" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="simply banned" type="VP">
          <tokens>
            <token id="18" string="simply" />
            <token id="19" string="banned" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` Speed Trap , ''" type="NP">
          <tokens>
            <token id="6" string="&quot;" />
            <token id="7" string="Speed" />
            <token id="8" string="Trap" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="is too prevalent" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="too" />
            <token id="25" string="prevalent" />
          </tokens>
        </chunking>
        <chunking id="6" string="can not be simply banned" type="VP">
          <tokens>
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="be" />
            <token id="18" string="simply" />
            <token id="19" string="banned" />
          </tokens>
        </chunking>
        <chunking id="7" string="can be disguised too easily" type="VP">
          <tokens>
            <token id="28" string="can" />
            <token id="29" string="be" />
            <token id="30" string="disguised" />
            <token id="31" string="too" />
            <token id="32" string="easily" />
          </tokens>
        </chunking>
        <chunking id="8" string="too prevalent" type="ADJP">
          <tokens>
            <token id="24" string="too" />
            <token id="25" string="prevalent" />
          </tokens>
        </chunking>
        <chunking id="9" string="be simply banned" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="simply" />
            <token id="19" string="banned" />
          </tokens>
        </chunking>
        <chunking id="10" string="work too well" type="VP">
          <tokens>
            <token id="35" string="work" />
            <token id="36" string="too" />
            <token id="37" string="well" />
          </tokens>
        </chunking>
        <chunking id="11" string="disguised too easily" type="VP">
          <tokens>
            <token id="30" string="disguised" />
            <token id="31" string="too" />
            <token id="32" string="easily" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="27" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="be disguised too easily" type="VP">
          <tokens>
            <token id="29" string="be" />
            <token id="30" string="disguised" />
            <token id="31" string="too" />
            <token id="32" string="easily" />
          </tokens>
        </chunking>
        <chunking id="14" string="Francis" type="NP">
          <tokens>
            <token id="11" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="15" string="says that steroids can not be simply banned" type="VP">
          <tokens>
            <token id="12" string="says" />
            <token id="13" string="that" />
            <token id="14" string="steroids" />
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="be" />
            <token id="18" string="simply" />
            <token id="19" string="banned" />
          </tokens>
        </chunking>
        <chunking id="16" string="the end of `` Speed Trap , ''" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="end" />
            <token id="5" string="of" />
            <token id="6" string="&quot;" />
            <token id="7" string="Speed" />
            <token id="8" string="Trap" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="17" string="their use" type="NP">
          <tokens>
            <token id="21" string="their" />
            <token id="22" string="use" />
          </tokens>
        </chunking>
        <chunking id="18" string="steroids" type="NP">
          <tokens>
            <token id="14" string="steroids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">end</governor>
          <dependent id="2">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">end</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">says</governor>
          <dependent id="4">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Trap</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Trap</governor>
          <dependent id="7">Speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">end</governor>
          <dependent id="8">Trap</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="11">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">banned</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">banned</governor>
          <dependent id="14">steroids</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">banned</governor>
          <dependent id="15">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">banned</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">banned</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">banned</governor>
          <dependent id="18">simply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">says</governor>
          <dependent id="19">banned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">use</governor>
          <dependent id="21">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">prevalent</governor>
          <dependent id="22">use</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">prevalent</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">prevalent</governor>
          <dependent id="24">too</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">says</governor>
          <dependent id="25">prevalent</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">disguised</governor>
          <dependent id="27">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">disguised</governor>
          <dependent id="28">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">disguised</governor>
          <dependent id="29">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">says</governor>
          <dependent id="30">disguised</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">easily</governor>
          <dependent id="31">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">disguised</governor>
          <dependent id="32">easily</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">says</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">work</governor>
          <dependent id="34">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">says</governor>
          <dependent id="35">work</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">well</governor>
          <dependent id="36">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">work</governor>
          <dependent id="37">well</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>The dangers have been exaggerated, Francis says.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="dangers" lemma="danger" stem="danger" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="exaggerated" lemma="exaggerate" stem="exagger" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS dangers)) (VP (VBP have) (VP (VBN been) (VP (VBN exaggerated))))) (, ,) (NP (NNP Francis)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been exaggerated" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="exaggerated" />
          </tokens>
        </chunking>
        <chunking id="2" string="have been exaggerated" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="exaggerated" />
          </tokens>
        </chunking>
        <chunking id="3" string="exaggerated" type="VP">
          <tokens>
            <token id="5" string="exaggerated" />
          </tokens>
        </chunking>
        <chunking id="4" string="says" type="VP">
          <tokens>
            <token id="8" string="says" />
          </tokens>
        </chunking>
        <chunking id="5" string="Francis" type="NP">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="6" string="The dangers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="dangers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">dangers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">exaggerated</governor>
          <dependent id="2">dangers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">exaggerated</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">exaggerated</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="5">exaggerated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>People who want running to be a &amp;quot;natural&amp;quot; sport are naive.</content>
      <tokens>
        <token id="1" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="naive" lemma="naive" stem="naiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS People)) (SBAR (WHNP (WP who)) (S (VP (VBP want) (S (VP (VBG running) (S (VP (TO to) (VP (VB be) (NP (DT a) (`` ``) (JJ natural) ('' '') (NN sport))))))))))) (VP (VBP are) (ADJP (JJ naive))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="People who want running to be a `` natural '' sport" type="NP">
          <tokens>
            <token id="1" string="People" />
            <token id="2" string="who" />
            <token id="3" string="want" />
            <token id="4" string="running" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` natural '' sport" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="3" string="who want running to be a `` natural '' sport" type="SBAR">
          <tokens>
            <token id="2" string="who" />
            <token id="3" string="want" />
            <token id="4" string="running" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="4" string="be a `` natural '' sport" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="5" string="running to be a `` natural '' sport" type="VP">
          <tokens>
            <token id="4" string="running" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="6" string="are naive" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="naive" />
          </tokens>
        </chunking>
        <chunking id="7" string="People" type="NP">
          <tokens>
            <token id="1" string="People" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be a `` natural '' sport" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="9" string="want running to be a `` natural '' sport" type="VP">
          <tokens>
            <token id="3" string="want" />
            <token id="4" string="running" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="&quot;" />
            <token id="9" string="natural" />
            <token id="10" string="&quot;" />
            <token id="11" string="sport" />
          </tokens>
        </chunking>
        <chunking id="10" string="naive" type="ADJP">
          <tokens>
            <token id="13" string="naive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">naive</governor>
          <dependent id="1">People</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">want</governor>
          <dependent id="2">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">People</governor>
          <dependent id="3">want</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">want</governor>
          <dependent id="4">running</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">sport</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">sport</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">sport</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">sport</governor>
          <dependent id="9">natural</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">running</governor>
          <dependent id="11">sport</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">naive</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">naive</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;We ceased being natural ages ago, the moment we stopped running barefoot on dirt paths,&amp;quot; Francis writes.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="ceased" lemma="cease" stem="ceas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ages" lemma="age" stem="ag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="barefoot" lemma="barefoot" stem="barefoot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="dirt" lemma="dirt" stem="dirt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="paths" lemma="path" stem="path" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VP (VBD ceased) (S (VP (VBG being) (ADVP (NP (JJ natural) (NNS ages)) (RB ago))))) (, ,) (NP (NP (DT the) (NN moment)) (SBAR (S (NP (PRP we)) (VP (VBD stopped) (S (VP (VBG running) (NP (NN barefoot)) (PP (IN on) (NP (NN dirt) (NNS paths))))))))))) (, ,) ('' '') (NP (NNP Francis)) (VP (VBZ writes)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the moment we stopped running barefoot on dirt paths" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="moment" />
            <token id="11" string="we" />
            <token id="12" string="stopped" />
            <token id="13" string="running" />
            <token id="14" string="barefoot" />
            <token id="15" string="on" />
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
        <chunking id="2" string="natural ages" type="NP">
          <tokens>
            <token id="5" string="natural" />
            <token id="6" string="ages" />
          </tokens>
        </chunking>
        <chunking id="3" string="barefoot" type="NP">
          <tokens>
            <token id="14" string="barefoot" />
          </tokens>
        </chunking>
        <chunking id="4" string="being natural ages ago" type="VP">
          <tokens>
            <token id="4" string="being" />
            <token id="5" string="natural" />
            <token id="6" string="ages" />
            <token id="7" string="ago" />
          </tokens>
        </chunking>
        <chunking id="5" string="stopped running barefoot on dirt paths" type="VP">
          <tokens>
            <token id="12" string="stopped" />
            <token id="13" string="running" />
            <token id="14" string="barefoot" />
            <token id="15" string="on" />
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="11" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="ceased being natural ages ago , the moment we stopped running barefoot on dirt paths" type="VP">
          <tokens>
            <token id="3" string="ceased" />
            <token id="4" string="being" />
            <token id="5" string="natural" />
            <token id="6" string="ages" />
            <token id="7" string="ago" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="moment" />
            <token id="11" string="we" />
            <token id="12" string="stopped" />
            <token id="13" string="running" />
            <token id="14" string="barefoot" />
            <token id="15" string="on" />
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
        <chunking id="9" string="the moment" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="moment" />
          </tokens>
        </chunking>
        <chunking id="10" string="ceased being natural ages ago" type="VP">
          <tokens>
            <token id="3" string="ceased" />
            <token id="4" string="being" />
            <token id="5" string="natural" />
            <token id="6" string="ages" />
            <token id="7" string="ago" />
          </tokens>
        </chunking>
        <chunking id="11" string="we stopped running barefoot on dirt paths" type="SBAR">
          <tokens>
            <token id="11" string="we" />
            <token id="12" string="stopped" />
            <token id="13" string="running" />
            <token id="14" string="barefoot" />
            <token id="15" string="on" />
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
        <chunking id="12" string="Francis" type="NP">
          <tokens>
            <token id="20" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="13" string="dirt paths" type="NP">
          <tokens>
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
        <chunking id="14" string="writes" type="VP">
          <tokens>
            <token id="21" string="writes" />
          </tokens>
        </chunking>
        <chunking id="15" string="running barefoot on dirt paths" type="VP">
          <tokens>
            <token id="13" string="running" />
            <token id="14" string="barefoot" />
            <token id="15" string="on" />
            <token id="16" string="dirt" />
            <token id="17" string="paths" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">ceased</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">writes</governor>
          <dependent id="3">ceased</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">ceased</governor>
          <dependent id="4">being</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">ages</governor>
          <dependent id="5">natural</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">ago</governor>
          <dependent id="6">ages</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">being</governor>
          <dependent id="7">ago</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">moment</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">ceased</governor>
          <dependent id="10">moment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">stopped</governor>
          <dependent id="11">we</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">moment</governor>
          <dependent id="12">stopped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">stopped</governor>
          <dependent id="13">running</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">running</governor>
          <dependent id="14">barefoot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">paths</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">paths</governor>
          <dependent id="16">dirt</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">running</governor>
          <dependent id="17">paths</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">writes</governor>
          <dependent id="20">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">writes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>&amp;quot;It is a formidable challenge to distinguish between nature and artifice, a task I would leave to the philosophers.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="formidable" lemma="formidable" stem="formid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="distinguish" lemma="distinguish" stem="distinguish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="nature" lemma="nature" stem="natur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="artifice" lemma="artifice" stem="artific" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="task" lemma="task" stem="task" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="leave" lemma="leave" stem="leav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="philosophers" lemma="philosopher" stem="philosoph" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ is) (NP (DT a) (JJ formidable) (NN challenge) (S (VP (TO to) (VP (VB distinguish) (PP (IN between) (NP (NP (NN nature) (CC and) (NN artifice)) (, ,) (NP (NP (DT a) (NN task)) (SBAR (S (NP (PRP I)) (VP (MD would) (VP (VB leave) (PP (TO to) (NP (DT the) (NNS philosophers))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="would leave to the philosophers" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="2" string="nature and artifice , a task I would leave to the philosophers" type="NP">
          <tokens>
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="3" string="to distinguish between nature and artifice , a task I would leave to the philosophers" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="distinguish" />
            <token id="9" string="between" />
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="4" string="nature and artifice" type="NP">
          <tokens>
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="16" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="leave to the philosophers" type="VP">
          <tokens>
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="8" string="is a formidable challenge to distinguish between nature and artifice , a task I would leave to the philosophers" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="formidable" />
            <token id="6" string="challenge" />
            <token id="7" string="to" />
            <token id="8" string="distinguish" />
            <token id="9" string="between" />
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="9" string="I would leave to the philosophers" type="SBAR">
          <tokens>
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="10" string="a task I would leave to the philosophers" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="11" string="a formidable challenge to distinguish between nature and artifice , a task I would leave to the philosophers" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="formidable" />
            <token id="6" string="challenge" />
            <token id="7" string="to" />
            <token id="8" string="distinguish" />
            <token id="9" string="between" />
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="12" string="distinguish between nature and artifice , a task I would leave to the philosophers" type="VP">
          <tokens>
            <token id="8" string="distinguish" />
            <token id="9" string="between" />
            <token id="10" string="nature" />
            <token id="11" string="and" />
            <token id="12" string="artifice" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="task" />
            <token id="16" string="I" />
            <token id="17" string="would" />
            <token id="18" string="leave" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
        <chunking id="13" string="a task" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="task" />
          </tokens>
        </chunking>
        <chunking id="14" string="the philosophers" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="philosophers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">challenge</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">challenge</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">challenge</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">challenge</governor>
          <dependent id="5">formidable</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">challenge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">distinguish</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">challenge</governor>
          <dependent id="8">distinguish</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">nature</governor>
          <dependent id="9">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">distinguish</governor>
          <dependent id="10">nature</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">nature</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">nature</governor>
          <dependent id="12">artifice</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">task</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">nature</governor>
          <dependent id="15">task</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">leave</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">leave</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">task</governor>
          <dependent id="18">leave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">philosophers</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">philosophers</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">leave</governor>
          <dependent id="21">philosophers</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>; But &amp;quot;Speed Trap&amp;quot; left me wishing Francis had at least tried his hand at philosophy.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Trap" lemma="trap" stem="trap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="wishing" lemma="wish" stem="wish" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (CC But) (NP (`` ``) (NN Speed) (NN Trap) ('' '')) (VP (VBD left) (S (NP (PRP me)) (VP (VBG wishing) (SBAR (S (NP (NNP Francis)) (VP (VBD had) (VP (ADVP (IN at) (JJS least)) (VBD tried) (NP (PRP$ his) (NN hand)) (PP (IN at) (NP (NN philosophy)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Francis had at least tried his hand at philosophy" type="SBAR">
          <tokens>
            <token id="10" string="Francis" />
            <token id="11" string="had" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="tried" />
            <token id="15" string="his" />
            <token id="16" string="hand" />
            <token id="17" string="at" />
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` Speed Trap ''" type="NP">
          <tokens>
            <token id="3" string="&quot;" />
            <token id="4" string="Speed" />
            <token id="5" string="Trap" />
            <token id="6" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="Francis" type="NP">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="4" string="wishing Francis had at least tried his hand at philosophy" type="VP">
          <tokens>
            <token id="9" string="wishing" />
            <token id="10" string="Francis" />
            <token id="11" string="had" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="tried" />
            <token id="15" string="his" />
            <token id="16" string="hand" />
            <token id="17" string="at" />
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="5" string="his hand" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="hand" />
          </tokens>
        </chunking>
        <chunking id="6" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="at least tried his hand at philosophy" type="VP">
          <tokens>
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="tried" />
            <token id="15" string="his" />
            <token id="16" string="hand" />
            <token id="17" string="at" />
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="8" string="philosophy" type="NP">
          <tokens>
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="9" string="had at least tried his hand at philosophy" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="tried" />
            <token id="15" string="his" />
            <token id="16" string="hand" />
            <token id="17" string="at" />
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="10" string="left me wishing Francis had at least tried his hand at philosophy" type="VP">
          <tokens>
            <token id="7" string="left" />
            <token id="8" string="me" />
            <token id="9" string="wishing" />
            <token id="10" string="Francis" />
            <token id="11" string="had" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="tried" />
            <token id="15" string="his" />
            <token id="16" string="hand" />
            <token id="17" string="at" />
            <token id="18" string="philosophy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">left</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Trap</governor>
          <dependent id="4">Speed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">left</governor>
          <dependent id="5">Trap</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">left</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">wishing</governor>
          <dependent id="8">me</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">left</governor>
          <dependent id="9">wishing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">tried</governor>
          <dependent id="10">Francis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">tried</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">tried</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">at</governor>
          <dependent id="13">least</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">wishing</governor>
          <dependent id="14">tried</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">hand</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">tried</governor>
          <dependent id="16">hand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">philosophy</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">tried</governor>
          <dependent id="18">philosophy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Isn&amp;apost;t that everyone&amp;apost;s responsibility?</content>
      <tokens>
        <token id="1" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="responsibility" lemma="responsibility" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBZ Is) (RB n't) (ADVP (IN that)) (NP (NP (NN everyone) (POS 's)) (NN responsibility))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="everyone 's" type="NP">
          <tokens>
            <token id="4" string="everyone" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone 's responsibility" type="NP">
          <tokens>
            <token id="4" string="everyone" />
            <token id="5" string="'s" />
            <token id="6" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="3" string="Is n't that everyone 's responsibility" type="VP">
          <tokens>
            <token id="1" string="Is" />
            <token id="2" string="n't" />
            <token id="3" string="that" />
            <token id="4" string="everyone" />
            <token id="5" string="'s" />
            <token id="6" string="responsibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cop">
          <governor id="6">responsibility</governor>
          <dependent id="1">Is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">responsibility</governor>
          <dependent id="2">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">responsibility</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">responsibility</governor>
          <dependent id="4">everyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">everyone</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">responsibility</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>To ask why we do the things we do?</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB ask) (SBAR (WHADVP (WRB why)) (S (NP (PRP we)) (VP (VBP do) (NP (DT the) (NNS things)))))))) (NP (PRP we)) (VP (VBP do)) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do the things" type="VP">
          <tokens>
            <token id="5" string="do" />
            <token id="6" string="the" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="2" string="why" type="WHADVP">
          <tokens>
            <token id="3" string="why" />
          </tokens>
        </chunking>
        <chunking id="3" string="do" type="VP">
          <tokens>
            <token id="9" string="do" />
          </tokens>
        </chunking>
        <chunking id="4" string="why we do the things" type="SBAR">
          <tokens>
            <token id="3" string="why" />
            <token id="4" string="we" />
            <token id="5" string="do" />
            <token id="6" string="the" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="5" string="To ask why we do the things" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="ask" />
            <token id="3" string="why" />
            <token id="4" string="we" />
            <token id="5" string="do" />
            <token id="6" string="the" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="6" string="the things" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="7" string="ask why we do the things" type="VP">
          <tokens>
            <token id="2" string="ask" />
            <token id="3" string="why" />
            <token id="4" string="we" />
            <token id="5" string="do" />
            <token id="6" string="the" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">ask</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">do</governor>
          <dependent id="2">ask</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">do</governor>
          <dependent id="3">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">do</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">ask</governor>
          <dependent id="5">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">things</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">do</governor>
          <dependent id="7">things</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">do</governor>
          <dependent id="8">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">do</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;But I was a sprint coach, and I had a different job,&amp;quot; he concludes.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="sprint" lemma="sprint" stem="sprint" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="concludes" lemma="conclude" stem="conclud" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (CC But) (NP (PRP I)) (VP (VBD was) (NP (DT a) (NN sprint) (NN coach)))) (, ,) (CC and) (S (NP (PRP I)) (VP (VBD had) (NP (DT a) (JJ different) (NN job))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ concludes)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a sprint coach" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="sprint" />
            <token id="7" string="coach" />
          </tokens>
        </chunking>
        <chunking id="2" string="had a different job" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="concludes" type="VP">
          <tokens>
            <token id="18" string="concludes" />
          </tokens>
        </chunking>
        <chunking id="5" string="was a sprint coach" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="a" />
            <token id="6" string="sprint" />
            <token id="7" string="coach" />
          </tokens>
        </chunking>
        <chunking id="6" string="a different job" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">coach</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">coach</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">coach</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">coach</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">coach</governor>
          <dependent id="6">sprint</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">concludes</governor>
          <dependent id="7">coach</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">coach</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">had</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">coach</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">job</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">job</governor>
          <dependent id="13">different</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">had</governor>
          <dependent id="14">job</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">concludes</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">concludes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>&amp;quot;To help a few gifted people run as fast as they could.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="gifted" lemma="gifted" stem="gift" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="run" lemma="run" stem="run" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (S (VP (TO To) (VP (VB help) (NP (DT a) (JJ few) (JJ gifted) (NNS people)))))) (VP (VBP run) (ADVP (ADVP (RB as) (RB fast)) (SBAR (IN as) (S (NP (PRP they)) (VP (MD could)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="To help a few gifted people" type="NP">
          <tokens>
            <token id="2" string="To" />
            <token id="3" string="help" />
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="gifted" />
            <token id="7" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="help a few gifted people" type="VP">
          <tokens>
            <token id="3" string="help" />
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="gifted" />
            <token id="7" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="could" type="VP">
          <tokens>
            <token id="13" string="could" />
          </tokens>
        </chunking>
        <chunking id="5" string="run as fast as they could" type="VP">
          <tokens>
            <token id="8" string="run" />
            <token id="9" string="as" />
            <token id="10" string="fast" />
            <token id="11" string="as" />
            <token id="12" string="they" />
            <token id="13" string="could" />
          </tokens>
        </chunking>
        <chunking id="6" string="as they could" type="SBAR">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="they" />
            <token id="13" string="could" />
          </tokens>
        </chunking>
        <chunking id="7" string="a few gifted people" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="gifted" />
            <token id="7" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">help</governor>
          <dependent id="2">To</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">run</governor>
          <dependent id="3">help</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">people</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">people</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">people</governor>
          <dependent id="6">gifted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">help</governor>
          <dependent id="7">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">fast</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">run</governor>
          <dependent id="10">fast</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">could</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">could</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">fast</governor>
          <dependent id="13">could</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>; They ran fast, all right.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (PRP They)) (VP (VBD ran) (ADVP (RB fast)) (, ,) (ADVP (DT all) (NN right))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="ran fast , all right" type="VP">
          <tokens>
            <token id="3" string="ran" />
            <token id="4" string="fast" />
            <token id="5" string="," />
            <token id="6" string="all" />
            <token id="7" string="right" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">ran</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">ran</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">ran</governor>
          <dependent id="4">fast</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">right</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">ran</governor>
          <dependent id="7">right</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>But he never seems to have asked himself: Is it worth it?</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="worth" lemma="worth" stem="worth" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (ADVP (RB never)) (VP (VBZ seems) (S (VP (TO to) (VP (VB have) (VP (VBN asked) (S (NP (PRP himself))) (: :) (SQ (VBZ Is) (NP (PRP it)) (PP (IN worth) (NP (PRP it))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="asked himself : Is it worth it" type="VP">
          <tokens>
            <token id="7" string="asked" />
            <token id="8" string="himself" />
            <token id="9" string=":" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="worth" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="have asked himself : Is it worth it" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="asked" />
            <token id="8" string="himself" />
            <token id="9" string=":" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="worth" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="seems to have asked himself : Is it worth it" type="VP">
          <tokens>
            <token id="4" string="seems" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="asked" />
            <token id="8" string="himself" />
            <token id="9" string=":" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="worth" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="himself" type="NP">
          <tokens>
            <token id="8" string="himself" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have asked himself : Is it worth it" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="asked" />
            <token id="8" string="himself" />
            <token id="9" string=":" />
            <token id="10" string="Is" />
            <token id="11" string="it" />
            <token id="12" string="worth" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">seems</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">seems</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">seems</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">asked</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">asked</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">seems</governor>
          <dependent id="7">asked</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">asked</governor>
          <dependent id="8">himself</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">asked</governor>
          <dependent id="10">Is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">Is</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">it</governor>
          <dependent id="12">worth</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Is</governor>
          <dependent id="13">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="false">
      <content>(box)</content>
      <tokens>
        <token id="1" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)))</syntactictree>
      <chunkings>
        <chunking id="1" string="box" type="NP">
          <tokens>
            <token id="2" string="box" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">box</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="a sprint coach" id_sentence="48" />
      <mentions>
        <mention ids_tokens="4-5" string="everyone's" id_sentence="46" />
        <mention ids_tokens="2-7" string="To help a few gifted people" id_sentence="49" />
        <mention ids_tokens="2" string="he" id_sentence="51" />
        <mention ids_tokens="8" string="himself" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="Charlie Francis with Jeff Coplon" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-7" string="Francis , the Canadian national sprint coach" id_sentence="2" />
        <mention ids_tokens="1" string="Francis" id_sentence="2" />
        <mention ids_tokens="3-7" string="the Canadian national sprint coach" id_sentence="2" />
        <mention ids_tokens="31" string="his" id_sentence="2" />
        <mention ids_tokens="3" string="he" id_sentence="3" />
        <mention ids_tokens="6" string="his" id_sentence="3" />
        <mention ids_tokens="17" string="he" id_sentence="3" />
        <mention ids_tokens="26" string="he" id_sentence="3" />
        <mention ids_tokens="35" string="his" id_sentence="3" />
        <mention ids_tokens="1" string="His" id_sentence="4" />
        <mention ids_tokens="7" string="Francis" id_sentence="5" />
        <mention ids_tokens="3" string="Francis" id_sentence="7" />
        <mention ids_tokens="6" string="my" id_sentence="8" />
        <mention ids_tokens="13" string="Francis" id_sentence="8" />
        <mention ids_tokens="20" string="his" id_sentence="8" />
        <mention ids_tokens="28" string="his" id_sentence="8" />
        <mention ids_tokens="7" string="Francis" id_sentence="15" />
        <mention ids_tokens="18" string="Francis" id_sentence="16" />
        <mention ids_tokens="27" string="his" id_sentence="16" />
        <mention ids_tokens="1" string="He" id_sentence="17" />
        <mention ids_tokens="18" string="he" id_sentence="17" />
        <mention ids_tokens="10" string="Francis" id_sentence="18" />
        <mention ids_tokens="10" string="Francis" id_sentence="20" />
        <mention ids_tokens="24-25" string="the coach" id_sentence="20" />
        <mention ids_tokens="31" string="Francis" id_sentence="20" />
        <mention ids_tokens="3" string="Francis" id_sentence="25" />
        <mention ids_tokens="4" string="he" id_sentence="26" />
        <mention ids_tokens="1" string="Francis" id_sentence="28" />
        <mention ids_tokens="1" string="Francis" id_sentence="30" />
        <mention ids_tokens="16" string="he" id_sentence="30" />
        <mention ids_tokens="23" string="him" id_sentence="30" />
        <mention ids_tokens="3" string="Francis" id_sentence="33" />
        <mention ids_tokens="3" string="him" id_sentence="34" />
        <mention ids_tokens="3" string="he" id_sentence="35" />
        <mention ids_tokens="12-13" string="Francis'" id_sentence="36" />
        <mention ids_tokens="1" string="Francis" id_sentence="38" />
        <mention ids_tokens="11" string="Francis" id_sentence="40" />
        <mention ids_tokens="7" string="Francis" id_sentence="41" />
        <mention ids_tokens="20" string="Francis" id_sentence="43" />
        <mention ids_tokens="10" string="Francis" id_sentence="45" />
        <mention ids_tokens="15" string="his" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="25-26-27" string="1988 in Toronto" id_sentence="1" />
      <mentions>
        <mention ids_tokens="5" string="1988" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="a different job" id_sentence="48" />
      <mentions>
        <mention ids_tokens="11" string="it" id_sentence="51" />
        <mention ids_tokens="13" string="it" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38-39" string="the use of performance-enhancing drugs in sports" id_sentence="1" />
      <mentions>
        <mention ids_tokens="4-8" string="the use of performance-enhancing drugs" id_sentence="21" />
        <mention ids_tokens="21-22" string="their use" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="36-37-38-39" string="performance-enhancing drugs in sports" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7-8" string="performance-enhancing drugs" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7" string="a few gifted people" id_sentence="49" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23-24" string="steroids -- furazabol , stanozolol , Dianabol --" id_sentence="2" />
      <mentions>
        <mention ids_tokens="16" string="steroids" id_sentence="17" />
        <mention ids_tokens="1" string="Steroids" id_sentence="18" />
        <mention ids_tokens="7" string="steroids" id_sentence="20" />
        <mention ids_tokens="22" string="steroids" id_sentence="20" />
        <mention ids_tokens="7" string="steroids" id_sentence="23" />
        <mention ids_tokens="8" string="steroids" id_sentence="38" />
        <mention ids_tokens="14" string="steroids" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23" string="furazabol , stanozolol , Dianabol" id_sentence="2" />
      <mentions>
        <mention ids_tokens="19" string="it" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="12-13" string="family members" id_sentence="3" />
      <mentions>
        <mention ids_tokens="27" string="they" id_sentence="2" />
        <mention ids_tokens="29-32" string="members of his family" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="6-7" string="his athletes" id_sentence="3" />
      <mentions>
        <mention ids_tokens="13" string="they" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="13-14" string="Ben Johnson" id_sentence="5" />
      <mentions>
        <mention ids_tokens="9" string="Johnson" id_sentence="6" />
        <mention ids_tokens="2-8" string="Johnson , the world's fastest man" id_sentence="9" />
        <mention ids_tokens="2" string="Johnson" id_sentence="9" />
        <mention ids_tokens="4-8" string="the world's fastest man" id_sentence="9" />
        <mention ids_tokens="2" string="he" id_sentence="10" />
        <mention ids_tokens="1" string="His" id_sentence="12" />
        <mention ids_tokens="8" string="his" id_sentence="12" />
        <mention ids_tokens="2" string="Johnson" id_sentence="13" />
        <mention ids_tokens="24" string="Johnson" id_sentence="17" />
        <mention ids_tokens="4" string="Johnson" id_sentence="22" />
        <mention ids_tokens="6" string="his" id_sentence="22" />
        <mention ids_tokens="12" string="his" id_sentence="22" />
        <mention ids_tokens="16" string="he" id_sentence="22" />
        <mention ids_tokens="10" string="Johnson" id_sentence="24" />
        <mention ids_tokens="12" string="Johnson" id_sentence="25" />
        <mention ids_tokens="7" string="Johnson" id_sentence="35" />
        <mention ids_tokens="7" string="Johnson" id_sentence="36" />
        <mention ids_tokens="6" string="he" id_sentence="37" />
        <mention ids_tokens="10" string="Johnson" id_sentence="38" />
        <mention ids_tokens="2" string="Johnson" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a world record" id_sentence="6" />
      <mentions>
        <mention ids_tokens="8-10" string="his world record" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="the gold medal" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1-3" string="His gold medal" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26-27-28-29-30" string="&quot; Speed Trap , &quot; his &quot; nightmare" id_sentence="8" />
      <mentions>
        <mention ids_tokens="9-36" string="&quot; Speed Trap , &quot; an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field" id_sentence="16" />
        <mention ids_tokens="10-11" string="Speed Trap" id_sentence="16" />
        <mention ids_tokens="14-36" string="an elaboration of what Francis said at the inquiry and a history of his remarkable path through the world of track and field" id_sentence="16" />
        <mention ids_tokens="13-14" string="the trap" id_sentence="19" />
        <mention ids_tokens="14-15" string="Speed Trap" id_sentence="29" />
        <mention ids_tokens="6-10" string="&quot; Speed Trap , &quot;" id_sentence="40" />
        <mention ids_tokens="3-6" string="&quot; Speed Trap &quot;" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the world 's" id_sentence="9" />
      <mentions>
        <mention ids_tokens="19-20" string="the world" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="Millions of dollars worth of endorsements" id_sentence="11" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="14" />
        <mention ids_tokens="6" string="they" id_sentence="14" />
        <mention ids_tokens="2" string="they" id_sentence="15" />
        <mention ids_tokens="39" string="them" id_sentence="17" />
        <mention ids_tokens="14" string="they" id_sentence="18" />
        <mention ids_tokens="11" string="they" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="4-5" string="an inquiry" id_sentence="15" />
      <mentions>
        <mention ids_tokens="21-22" string="the inquiry" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="5-6" string="a runner" id_sentence="18" />
      <mentions>
        <mention ids_tokens="3" string="his" id_sentence="20" />
        <mention ids_tokens="34" string="he" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="24" type="PRONOMINAL">
      <referenced ids_tokens="1" string="We" id_sentence="21" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32" string="athletes in the 1896 Olympic Games" id_sentence="21" />
      <mentions>
        <mention ids_tokens="5" string="athletes" id_sentence="23" />
        <mention ids_tokens="9" string="their" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="the positive test result" id_sentence="28" />
      <mentions>
        <mention ids_tokens="3" string="its" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The book" id_sentence="31" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="32" />
        <mention ids_tokens="9" string="it" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26" string="no longer the fastest" id_sentence="37" />
      <mentions>
        <mention ids_tokens="14-15" string="the fastest" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="34" type="PRONOMINAL">
      <referenced ids_tokens="21" string="their" id_sentence="40" />
      <mentions>
        <mention ids_tokens="11" string="we" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11" string="People who want running to be a &quot; natural &quot; sport" id_sentence="42" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="43" />
        <mention ids_tokens="16" string="I" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="20-21" string="the philosophers" id_sentence="44" />
      <mentions>
        <mention ids_tokens="4" string="we" id_sentence="47" />
        <mention ids_tokens="8" string="we" id_sentence="47" />
      </mentions>
    </coreference>
  </coreferences>
</document>
