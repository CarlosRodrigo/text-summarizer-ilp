<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06187248">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Fire long ago destroyed the house where Clarence Thomas spent his boyhood.</content>
      <tokens>
        <token id="1" string="Fire" lemma="fire" stem="fire" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="destroyed" lemma="destroy" stem="destroi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="boyhood" lemma="boyhood" stem="boyhood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Fire)) (ADVP (RB long) (RB ago)) (VP (VBD destroyed) (NP (DT the) (NN house)) (SBAR (WHADVP (WRB where)) (S (NP (NNP Clarence) (NNP Thomas)) (VP (VBD spent) (NP (PRP$ his) (NN boyhood)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="where Clarence Thomas spent his boyhood" type="SBAR">
          <tokens>
            <token id="7" string="where" />
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="spent" />
            <token id="11" string="his" />
            <token id="12" string="boyhood" />
          </tokens>
        </chunking>
        <chunking id="2" string="Fire" type="NP">
          <tokens>
            <token id="1" string="Fire" />
          </tokens>
        </chunking>
        <chunking id="3" string="spent his boyhood" type="VP">
          <tokens>
            <token id="10" string="spent" />
            <token id="11" string="his" />
            <token id="12" string="boyhood" />
          </tokens>
        </chunking>
        <chunking id="4" string="destroyed the house where Clarence Thomas spent his boyhood" type="VP">
          <tokens>
            <token id="4" string="destroyed" />
            <token id="5" string="the" />
            <token id="6" string="house" />
            <token id="7" string="where" />
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="spent" />
            <token id="11" string="his" />
            <token id="12" string="boyhood" />
          </tokens>
        </chunking>
        <chunking id="5" string="the house" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="house" />
          </tokens>
        </chunking>
        <chunking id="6" string="where" type="WHADVP">
          <tokens>
            <token id="7" string="where" />
          </tokens>
        </chunking>
        <chunking id="7" string="his boyhood" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="boyhood" />
          </tokens>
        </chunking>
        <chunking id="8" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">destroyed</governor>
          <dependent id="1">Fire</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">ago</governor>
          <dependent id="2">long</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">destroyed</governor>
          <dependent id="3">ago</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">destroyed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">house</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">destroyed</governor>
          <dependent id="6">house</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">spent</governor>
          <dependent id="7">where</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Thomas</governor>
          <dependent id="8">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">spent</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">destroyed</governor>
          <dependent id="10">spent</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">boyhood</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">spent</governor>
          <dependent id="12">boyhood</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>But nearby, down a woodsy, one-lane, white-sand road outside Savannah, Ga., sits a reminder of what might have been -- the tired cottage where his sister still lives, by a broad, shining marsh called Moon River.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="nearby" lemma="nearby" stem="nearbi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="down" lemma="down" stem="down" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="woodsy" lemma="woodsy" stem="woodsi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="one-lane" lemma="one-lane" stem="one-lan" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="white-sand" lemma="white-sand" stem="white-sand" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Ga." lemma="Ga." stem="ga." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sits" lemma="sit" stem="sit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="reminder" lemma="reminder" stem="remind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tired" lemma="tired" stem="tire" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="cottage" lemma="cottage" stem="cottag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="broad" lemma="broad" stem="broad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="shining" lemma="shine" stem="shine" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="marsh" lemma="marsh" stem="marsh" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="43" string="River" lemma="River" stem="river" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (CC But) (ADVP (RB nearby)) (VP (PRN (, ,) (PP (IN down) (NP (NP (DT a) (JJ woodsy) (, ,) (JJ one-lane) (, ,) (JJ white-sand) (NN road)) (PP (IN outside) (NP (NNP Savannah) (, ,) (NNP Ga.))))) (, ,)) (VBZ sits) (NP (NP (DT a) (NN reminder)) (PP (IN of) (NP (SBAR (WHNP (WP what)) (S (VP (MD might) (VP (VB have) (VP (VBN been)))))) (: --) (NP (NP (DT the) (JJ tired) (NN cottage)) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ his) (NN sister)) (VP (ADVP (RB still)) (VBZ lives) (, ,) (PP (IN by) (NP (DT a) (JJ broad))) (, ,) (S (VP (VBG shining) (NP (NP (JJ marsh)) (VP (VBN called))))))))))))) (NP (NNP Moon) (NNP River)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his sister" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="sister" />
          </tokens>
        </chunking>
        <chunking id="2" string="Savannah , Ga." type="NP">
          <tokens>
            <token id="13" string="Savannah" />
            <token id="14" string="," />
            <token id="15" string="Ga." />
          </tokens>
        </chunking>
        <chunking id="3" string="the tired cottage" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="tired" />
            <token id="28" string="cottage" />
          </tokens>
        </chunking>
        <chunking id="4" string="the tired cottage where his sister still lives , by a broad , shining marsh called" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="tired" />
            <token id="28" string="cottage" />
            <token id="29" string="where" />
            <token id="30" string="his" />
            <token id="31" string="sister" />
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="5" string="might have been" type="VP">
          <tokens>
            <token id="22" string="might" />
            <token id="23" string="have" />
            <token id="24" string="been" />
          </tokens>
        </chunking>
        <chunking id="6" string="been" type="VP">
          <tokens>
            <token id="24" string="been" />
          </tokens>
        </chunking>
        <chunking id="7" string="called" type="VP">
          <tokens>
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="8" string=", down a woodsy , one-lane , white-sand road outside Savannah , Ga. , sits a reminder of what might have been -- the tired cottage where his sister still lives , by a broad , shining marsh called" type="VP">
          <tokens>
            <token id="3" string="," />
            <token id="4" string="down" />
            <token id="5" string="a" />
            <token id="6" string="woodsy" />
            <token id="7" string="," />
            <token id="8" string="one-lane" />
            <token id="9" string="," />
            <token id="10" string="white-sand" />
            <token id="11" string="road" />
            <token id="12" string="outside" />
            <token id="13" string="Savannah" />
            <token id="14" string="," />
            <token id="15" string="Ga." />
            <token id="16" string="," />
            <token id="17" string="sits" />
            <token id="18" string="a" />
            <token id="19" string="reminder" />
            <token id="20" string="of" />
            <token id="21" string="what" />
            <token id="22" string="might" />
            <token id="23" string="have" />
            <token id="24" string="been" />
            <token id="25" string="--" />
            <token id="26" string="the" />
            <token id="27" string="tired" />
            <token id="28" string="cottage" />
            <token id="29" string="where" />
            <token id="30" string="his" />
            <token id="31" string="sister" />
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="9" string="a reminder" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="reminder" />
          </tokens>
        </chunking>
        <chunking id="10" string="have been" type="VP">
          <tokens>
            <token id="23" string="have" />
            <token id="24" string="been" />
          </tokens>
        </chunking>
        <chunking id="11" string="a woodsy , one-lane , white-sand road" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="woodsy" />
            <token id="7" string="," />
            <token id="8" string="one-lane" />
            <token id="9" string="," />
            <token id="10" string="white-sand" />
            <token id="11" string="road" />
          </tokens>
        </chunking>
        <chunking id="12" string="what might have been -- the tired cottage where his sister still lives , by a broad , shining marsh called" type="NP">
          <tokens>
            <token id="21" string="what" />
            <token id="22" string="might" />
            <token id="23" string="have" />
            <token id="24" string="been" />
            <token id="25" string="--" />
            <token id="26" string="the" />
            <token id="27" string="tired" />
            <token id="28" string="cottage" />
            <token id="29" string="where" />
            <token id="30" string="his" />
            <token id="31" string="sister" />
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="13" string="shining marsh called" type="VP">
          <tokens>
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="14" string="Moon River" type="NP">
          <tokens>
            <token id="42" string="Moon" />
            <token id="43" string="River" />
          </tokens>
        </chunking>
        <chunking id="15" string="a broad" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="broad" />
          </tokens>
        </chunking>
        <chunking id="16" string="still lives , by a broad , shining marsh called" type="VP">
          <tokens>
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="17" string="marsh called" type="NP">
          <tokens>
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="18" string="what might have been" type="SBAR">
          <tokens>
            <token id="21" string="what" />
            <token id="22" string="might" />
            <token id="23" string="have" />
            <token id="24" string="been" />
          </tokens>
        </chunking>
        <chunking id="19" string="where his sister still lives , by a broad , shining marsh called" type="SBAR">
          <tokens>
            <token id="29" string="where" />
            <token id="30" string="his" />
            <token id="31" string="sister" />
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="20" string="a woodsy , one-lane , white-sand road outside Savannah , Ga." type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="woodsy" />
            <token id="7" string="," />
            <token id="8" string="one-lane" />
            <token id="9" string="," />
            <token id="10" string="white-sand" />
            <token id="11" string="road" />
            <token id="12" string="outside" />
            <token id="13" string="Savannah" />
            <token id="14" string="," />
            <token id="15" string="Ga." />
          </tokens>
        </chunking>
        <chunking id="21" string="where" type="WHADVP">
          <tokens>
            <token id="29" string="where" />
          </tokens>
        </chunking>
        <chunking id="22" string="a reminder of what might have been -- the tired cottage where his sister still lives , by a broad , shining marsh called" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="reminder" />
            <token id="20" string="of" />
            <token id="21" string="what" />
            <token id="22" string="might" />
            <token id="23" string="have" />
            <token id="24" string="been" />
            <token id="25" string="--" />
            <token id="26" string="the" />
            <token id="27" string="tired" />
            <token id="28" string="cottage" />
            <token id="29" string="where" />
            <token id="30" string="his" />
            <token id="31" string="sister" />
            <token id="32" string="still" />
            <token id="33" string="lives" />
            <token id="34" string="," />
            <token id="35" string="by" />
            <token id="36" string="a" />
            <token id="37" string="broad" />
            <token id="38" string="," />
            <token id="39" string="shining" />
            <token id="40" string="marsh" />
            <token id="41" string="called" />
          </tokens>
        </chunking>
        <chunking id="23" string="marsh" type="NP">
          <tokens>
            <token id="40" string="marsh" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="17">sits</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">sits</governor>
          <dependent id="2">nearby</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">road</governor>
          <dependent id="4">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">road</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">road</governor>
          <dependent id="6">woodsy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">road</governor>
          <dependent id="8">one-lane</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">road</governor>
          <dependent id="10">white-sand</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">sits</governor>
          <dependent id="11">road</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ga.</governor>
          <dependent id="12">outside</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ga.</governor>
          <dependent id="13">Savannah</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">road</governor>
          <dependent id="15">Ga.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">sits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">reminder</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">sits</governor>
          <dependent id="19">reminder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">cottage</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">been</governor>
          <dependent id="21">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">been</governor>
          <dependent id="22">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">been</governor>
          <dependent id="23">have</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">cottage</governor>
          <dependent id="24">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">cottage</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">cottage</governor>
          <dependent id="27">tired</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">reminder</governor>
          <dependent id="28">cottage</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">lives</governor>
          <dependent id="29">where</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">sister</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">lives</governor>
          <dependent id="31">sister</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">lives</governor>
          <dependent id="32">still</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">cottage</governor>
          <dependent id="33">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">broad</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">broad</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">lives</governor>
          <dependent id="37">broad</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">lives</governor>
          <dependent id="39">shining</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">shining</governor>
          <dependent id="40">marsh</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="40">marsh</governor>
          <dependent id="41">called</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">River</governor>
          <dependent id="42">Moon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">sits</governor>
          <dependent id="43">River</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ga." type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Ga." />
          </tokens>
        </entity>
        <entity id="2" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Savannah" />
          </tokens>
        </entity>
        <entity id="3" string="Moon River" type="LOCATION" score="0.0">
          <tokens>
            <token id="42" string="Moon" />
            <token id="43" string="River" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Down shore sits the defunct packing factory where his family and most of the rest of the people in the semirural cluster of houses and trailer-homes known as Pin Point used to pick the meat from crabs and chop the heads off shrimp.</content>
      <tokens>
        <token id="1" string="Down" lemma="down" stem="down" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="shore" lemma="shore" stem="shore" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sits" lemma="sit" stem="sit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="defunct" lemma="defunct" stem="defunct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="packing" lemma="packing" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="factory" lemma="factory" stem="factori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="rest" lemma="rest" stem="rest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="semirural" lemma="semirural" stem="semirur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="cluster" lemma="cluster" stem="cluster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="houses" lemma="house" stem="hous" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="trailer-homes" lemma="trailer-home" stem="trailer-hom" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Pin" lemma="pin" stem="pin" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="Point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="pick" lemma="pick" stem="pick" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="crabs" lemma="crab" stem="crab" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="chop" lemma="chop" stem="chop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="heads" lemma="head" stem="head" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="shrimp" lemma="shrimp" stem="shrimp" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN Down) (NP (NN shore))) (VP (VBZ sits)) (NP (NP (DT the) (JJ defunct) (NN packing) (NN factory)) (SBAR (WHADVP (WRB where)) (S (NP (NP (PRP$ his) (NN family)) (CC and) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NN rest)) (PP (IN of) (NP (NP (DT the) (NNS people)) (PP (IN in) (NP (NP (DT the) (JJ semirural) (NN cluster)) (PP (IN of) (NP (NNS houses) (CC and) (NNS trailer-homes))))))))))) (VP (VBN known) (PP (IN as) (NP (NP (NN Pin) (NN Point)) (VP (VBN used) (S (VP (TO to) (VP (VP (VB pick) (NP (DT the) (NN meat)) (PP (IN from) (NP (NNS crabs)))) (CC and) (VP (VB chop) (NP (DT the) (NNS heads)) (PP (IN off) (NP (NN shrimp)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sits" type="VP">
          <tokens>
            <token id="3" string="sits" />
          </tokens>
        </chunking>
        <chunking id="2" string="most of the rest of the people in the semirural cluster of houses and trailer-homes" type="NP">
          <tokens>
            <token id="12" string="most" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="3" string="Pin Point" type="NP">
          <tokens>
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
          </tokens>
        </chunking>
        <chunking id="4" string="shore" type="NP">
          <tokens>
            <token id="2" string="shore" />
          </tokens>
        </chunking>
        <chunking id="5" string="used to pick the meat from crabs and chop the heads off shrimp" type="VP">
          <tokens>
            <token id="31" string="used" />
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="6" string="chop the heads off shrimp" type="VP">
          <tokens>
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="7" string="his family and most of the rest of the people in the semirural cluster of houses and trailer-homes" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="family" />
            <token id="11" string="and" />
            <token id="12" string="most" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="8" string="most" type="NP">
          <tokens>
            <token id="12" string="most" />
          </tokens>
        </chunking>
        <chunking id="9" string="the semirural cluster of houses and trailer-homes" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="10" string="the heads" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="heads" />
          </tokens>
        </chunking>
        <chunking id="11" string="known as Pin Point used to pick the meat from crabs and chop the heads off shrimp" type="VP">
          <tokens>
            <token id="27" string="known" />
            <token id="28" string="as" />
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
            <token id="31" string="used" />
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="12" string="the rest of the people in the semirural cluster of houses and trailer-homes" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="13" string="the rest" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rest" />
          </tokens>
        </chunking>
        <chunking id="14" string="the semirural cluster" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
          </tokens>
        </chunking>
        <chunking id="15" string="shrimp" type="NP">
          <tokens>
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="16" string="pick the meat from crabs" type="VP">
          <tokens>
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
          </tokens>
        </chunking>
        <chunking id="17" string="houses and trailer-homes" type="NP">
          <tokens>
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="18" string="the meat" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="meat" />
          </tokens>
        </chunking>
        <chunking id="19" string="to pick the meat from crabs and chop the heads off shrimp" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="20" string="where his family and most of the rest of the people in the semirural cluster of houses and trailer-homes known as Pin Point used to pick the meat from crabs and chop the heads off shrimp" type="SBAR">
          <tokens>
            <token id="8" string="where" />
            <token id="9" string="his" />
            <token id="10" string="family" />
            <token id="11" string="and" />
            <token id="12" string="most" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
            <token id="27" string="known" />
            <token id="28" string="as" />
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
            <token id="31" string="used" />
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="21" string="the people" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="22" string="Pin Point used to pick the meat from crabs and chop the heads off shrimp" type="NP">
          <tokens>
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
            <token id="31" string="used" />
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="23" string="crabs" type="NP">
          <tokens>
            <token id="37" string="crabs" />
          </tokens>
        </chunking>
        <chunking id="24" string="the defunct packing factory where his family and most of the rest of the people in the semirural cluster of houses and trailer-homes known as Pin Point used to pick the meat from crabs and chop the heads off shrimp" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="defunct" />
            <token id="6" string="packing" />
            <token id="7" string="factory" />
            <token id="8" string="where" />
            <token id="9" string="his" />
            <token id="10" string="family" />
            <token id="11" string="and" />
            <token id="12" string="most" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
            <token id="27" string="known" />
            <token id="28" string="as" />
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
            <token id="31" string="used" />
            <token id="32" string="to" />
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="25" string="pick the meat from crabs and chop the heads off shrimp" type="VP">
          <tokens>
            <token id="33" string="pick" />
            <token id="34" string="the" />
            <token id="35" string="meat" />
            <token id="36" string="from" />
            <token id="37" string="crabs" />
            <token id="38" string="and" />
            <token id="39" string="chop" />
            <token id="40" string="the" />
            <token id="41" string="heads" />
            <token id="42" string="off" />
            <token id="43" string="shrimp" />
          </tokens>
        </chunking>
        <chunking id="26" string="the people in the semirural cluster of houses and trailer-homes" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="semirural" />
            <token id="22" string="cluster" />
            <token id="23" string="of" />
            <token id="24" string="houses" />
            <token id="25" string="and" />
            <token id="26" string="trailer-homes" />
          </tokens>
        </chunking>
        <chunking id="27" string="where" type="WHADVP">
          <tokens>
            <token id="8" string="where" />
          </tokens>
        </chunking>
        <chunking id="28" string="the defunct packing factory" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="defunct" />
            <token id="6" string="packing" />
            <token id="7" string="factory" />
          </tokens>
        </chunking>
        <chunking id="29" string="his family" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">shore</governor>
          <dependent id="1">Down</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sits</governor>
          <dependent id="2">shore</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">factory</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">factory</governor>
          <dependent id="5">defunct</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">factory</governor>
          <dependent id="6">packing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">sits</governor>
          <dependent id="7">factory</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">known</governor>
          <dependent id="8">where</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">family</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">known</governor>
          <dependent id="10">family</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">family</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">family</governor>
          <dependent id="12">most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">rest</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">rest</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">most</governor>
          <dependent id="15">rest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">people</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">people</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rest</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">cluster</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">cluster</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">cluster</governor>
          <dependent id="21">semirural</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">people</governor>
          <dependent id="22">cluster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">houses</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">cluster</governor>
          <dependent id="24">houses</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">houses</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">houses</governor>
          <dependent id="26">trailer-homes</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">factory</governor>
          <dependent id="27">known</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Point</governor>
          <dependent id="28">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Point</governor>
          <dependent id="29">Pin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">known</governor>
          <dependent id="30">Point</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="30">Point</governor>
          <dependent id="31">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">pick</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">used</governor>
          <dependent id="33">pick</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">meat</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">pick</governor>
          <dependent id="35">meat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">crabs</governor>
          <dependent id="36">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">pick</governor>
          <dependent id="37">crabs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">pick</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">pick</governor>
          <dependent id="39">chop</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">heads</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">chop</governor>
          <dependent id="41">heads</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">shrimp</governor>
          <dependent id="42">off</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">chop</governor>
          <dependent id="43">shrimp</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pin Point" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Pin" />
            <token id="30" string="Point" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>There, in the segregated black Georgia of four decades past, began the toughening of Clarence Thomas, nominee to the United States Supreme Court.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="segregated" lemma="segregate" stem="segreg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="toughening" lemma="toughening" stem="toughen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="18" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="24" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB There)) (, ,) (PP (IN in) (NP (NP (DT the) (VBN segregated) (JJ black) (NNP Georgia)) (PP (IN of) (ADJP (NP (CD four) (NNS decades)) (JJ past))))) (, ,) (VP (VBD began) (NP (NP (DT the) (NN toughening)) (PP (IN of) (NP (NP (NNP Clarence) (NNP Thomas)) (, ,) (NP (NN nominee))))) (PP (TO to) (NP (DT the) (NNP United) (NNPS States) (NNP Supreme) (NNP Court)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the toughening of Clarence Thomas , nominee" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="toughening" />
            <token id="16" string="of" />
            <token id="17" string="Clarence" />
            <token id="18" string="Thomas" />
            <token id="19" string="," />
            <token id="20" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="2" string="the segregated black Georgia" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="segregated" />
            <token id="6" string="black" />
            <token id="7" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="3" string="four decades" type="NP">
          <tokens>
            <token id="9" string="four" />
            <token id="10" string="decades" />
          </tokens>
        </chunking>
        <chunking id="4" string="began the toughening of Clarence Thomas , nominee to the United States Supreme Court" type="VP">
          <tokens>
            <token id="13" string="began" />
            <token id="14" string="the" />
            <token id="15" string="toughening" />
            <token id="16" string="of" />
            <token id="17" string="Clarence" />
            <token id="18" string="Thomas" />
            <token id="19" string="," />
            <token id="20" string="nominee" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="four decades past" type="ADJP">
          <tokens>
            <token id="9" string="four" />
            <token id="10" string="decades" />
            <token id="11" string="past" />
          </tokens>
        </chunking>
        <chunking id="6" string="nominee" type="NP">
          <tokens>
            <token id="20" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="7" string="the United States Supreme Court" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="8" string="the segregated black Georgia of four decades past" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="segregated" />
            <token id="6" string="black" />
            <token id="7" string="Georgia" />
            <token id="8" string="of" />
            <token id="9" string="four" />
            <token id="10" string="decades" />
            <token id="11" string="past" />
          </tokens>
        </chunking>
        <chunking id="9" string="the toughening" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="toughening" />
          </tokens>
        </chunking>
        <chunking id="10" string="Clarence Thomas , nominee" type="NP">
          <tokens>
            <token id="17" string="Clarence" />
            <token id="18" string="Thomas" />
            <token id="19" string="," />
            <token id="20" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="11" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="17" string="Clarence" />
            <token id="18" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="13">began</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Georgia</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Georgia</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Georgia</governor>
          <dependent id="5">segregated</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Georgia</governor>
          <dependent id="6">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">began</governor>
          <dependent id="7">Georgia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">past</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">decades</governor>
          <dependent id="9">four</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="11">past</governor>
          <dependent id="10">decades</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">Georgia</governor>
          <dependent id="11">past</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">began</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">toughening</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">began</governor>
          <dependent id="15">toughening</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Thomas</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Thomas</governor>
          <dependent id="17">Clarence</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">toughening</governor>
          <dependent id="18">Thomas</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Thomas</governor>
          <dependent id="20">nominee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Court</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Court</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Court</governor>
          <dependent id="23">United</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Court</governor>
          <dependent id="24">States</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Court</governor>
          <dependent id="25">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">began</governor>
          <dependent id="26">Court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="United" />
            <token id="24" string="States" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="four decades" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="four" />
            <token id="10" string="decades" />
          </tokens>
        </entity>
        <entity id="3" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="past" />
          </tokens>
        </entity>
        <entity id="4" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Georgia" />
          </tokens>
        </entity>
        <entity id="5" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Clarence" />
            <token id="18" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Abandoned by his father, driven by his hard-eyed grandfather and a band of nuns sent south to teach black children, young Clarence learned sharecropping and scholarship, hard labor and the Latin mass, and how to survive the walk home through black Savannah in his Catholic school uniform.</content>
      <tokens>
        <token id="1" string="Abandoned" lemma="abandon" stem="abandon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="driven" lemma="drive" stem="driven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="hard-eyed" lemma="hard-eyed" stem="hard-ei" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="band" lemma="band" stem="band" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="nuns" lemma="nun" stem="nun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="south" lemma="south" stem="south" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="teach" lemma="teach" stem="teach" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="learned" lemma="learn" stem="learn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="sharecropping" lemma="sharecropping" stem="sharecrop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="scholarship" lemma="scholarship" stem="scholarship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="labor" lemma="labor" stem="labor" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Latin" lemma="Latin" stem="latin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="mass" lemma="mass" stem="mass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="walk" lemma="walk" stem="walk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="47" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Catholic" lemma="catholic" stem="cathol" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="50" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="uniform" lemma="uniform" stem="uniform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VP (VBN Abandoned) (PP (IN by) (NP (PRP$ his) (NN father)))) (, ,) (VP (VBN driven) (PP (IN by) (NP (NP (PRP$ his) (JJ hard-eyed) (NN grandfather)) (CC and) (NP (NP (DT a) (NN band)) (PP (IN of) (NP (NP (NNS nuns)) (VP (VBN sent) (ADVP (RB south))))))))) (S (VP (TO to) (VP (VB teach) (NP (JJ black) (NNS children))))))) (, ,) (NP (JJ young) (NNP Clarence)) (VP (VBD learned) (NP (NP (NN sharecropping) (CC and) (NN scholarship)) (, ,) (NP (NP (JJ hard) (NN labor)) (CC and) (NP (DT the) (NNP Latin) (NN mass))) (, ,) (CC and) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB survive) (NP (DT the) (NN walk) (NN home)) (PP (IN through) (NP (JJ black) (NNP Savannah))) (PP (IN in) (NP (PRP$ his) (JJ Catholic) (NN school) (NN uniform))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a band" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="band" />
          </tokens>
        </chunking>
        <chunking id="2" string="black children" type="NP">
          <tokens>
            <token id="20" string="black" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="his hard-eyed grandfather" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="hard-eyed" />
            <token id="10" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="4" string="his Catholic school uniform" type="NP">
          <tokens>
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
        <chunking id="5" string="to teach black children" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="teach" />
            <token id="20" string="black" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="sent south" type="VP">
          <tokens>
            <token id="16" string="sent" />
            <token id="17" string="south" />
          </tokens>
        </chunking>
        <chunking id="7" string="how to survive the walk home through black Savannah in his Catholic school uniform" type="SBAR">
          <tokens>
            <token id="38" string="how" />
            <token id="39" string="to" />
            <token id="40" string="survive" />
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
            <token id="44" string="through" />
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
            <token id="47" string="in" />
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
        <chunking id="8" string="to survive the walk home through black Savannah in his Catholic school uniform" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="survive" />
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
            <token id="44" string="through" />
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
            <token id="47" string="in" />
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
        <chunking id="9" string="young Clarence" type="NP">
          <tokens>
            <token id="23" string="young" />
            <token id="24" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="10" string="sharecropping and scholarship" type="NP">
          <tokens>
            <token id="26" string="sharecropping" />
            <token id="27" string="and" />
            <token id="28" string="scholarship" />
          </tokens>
        </chunking>
        <chunking id="11" string="nuns" type="NP">
          <tokens>
            <token id="15" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Latin mass" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Latin" />
            <token id="35" string="mass" />
          </tokens>
        </chunking>
        <chunking id="13" string="a band of nuns sent south" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="band" />
            <token id="14" string="of" />
            <token id="15" string="nuns" />
            <token id="16" string="sent" />
            <token id="17" string="south" />
          </tokens>
        </chunking>
        <chunking id="14" string="driven by his hard-eyed grandfather and a band of nuns sent south" type="VP">
          <tokens>
            <token id="6" string="driven" />
            <token id="7" string="by" />
            <token id="8" string="his" />
            <token id="9" string="hard-eyed" />
            <token id="10" string="grandfather" />
            <token id="11" string="and" />
            <token id="12" string="a" />
            <token id="13" string="band" />
            <token id="14" string="of" />
            <token id="15" string="nuns" />
            <token id="16" string="sent" />
            <token id="17" string="south" />
          </tokens>
        </chunking>
        <chunking id="15" string="survive the walk home through black Savannah in his Catholic school uniform" type="VP">
          <tokens>
            <token id="40" string="survive" />
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
            <token id="44" string="through" />
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
            <token id="47" string="in" />
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
        <chunking id="16" string="teach black children" type="VP">
          <tokens>
            <token id="19" string="teach" />
            <token id="20" string="black" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="17" string="hard labor" type="NP">
          <tokens>
            <token id="30" string="hard" />
            <token id="31" string="labor" />
          </tokens>
        </chunking>
        <chunking id="18" string="his hard-eyed grandfather and a band of nuns sent south" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="hard-eyed" />
            <token id="10" string="grandfather" />
            <token id="11" string="and" />
            <token id="12" string="a" />
            <token id="13" string="band" />
            <token id="14" string="of" />
            <token id="15" string="nuns" />
            <token id="16" string="sent" />
            <token id="17" string="south" />
          </tokens>
        </chunking>
        <chunking id="19" string="Abandoned by his father , driven by his hard-eyed grandfather and a band of nuns sent south to teach black children" type="VP">
          <tokens>
            <token id="1" string="Abandoned" />
            <token id="2" string="by" />
            <token id="3" string="his" />
            <token id="4" string="father" />
            <token id="5" string="," />
            <token id="6" string="driven" />
            <token id="7" string="by" />
            <token id="8" string="his" />
            <token id="9" string="hard-eyed" />
            <token id="10" string="grandfather" />
            <token id="11" string="and" />
            <token id="12" string="a" />
            <token id="13" string="band" />
            <token id="14" string="of" />
            <token id="15" string="nuns" />
            <token id="16" string="sent" />
            <token id="17" string="south" />
            <token id="18" string="to" />
            <token id="19" string="teach" />
            <token id="20" string="black" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="20" string="how" type="WHADVP">
          <tokens>
            <token id="38" string="how" />
          </tokens>
        </chunking>
        <chunking id="21" string="Abandoned by his father" type="VP">
          <tokens>
            <token id="1" string="Abandoned" />
            <token id="2" string="by" />
            <token id="3" string="his" />
            <token id="4" string="father" />
          </tokens>
        </chunking>
        <chunking id="22" string="nuns sent south" type="NP">
          <tokens>
            <token id="15" string="nuns" />
            <token id="16" string="sent" />
            <token id="17" string="south" />
          </tokens>
        </chunking>
        <chunking id="23" string="black Savannah" type="NP">
          <tokens>
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="24" string="his father" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="father" />
          </tokens>
        </chunking>
        <chunking id="25" string="sharecropping and scholarship , hard labor and the Latin mass , and how to survive the walk home through black Savannah in his Catholic school uniform" type="NP">
          <tokens>
            <token id="26" string="sharecropping" />
            <token id="27" string="and" />
            <token id="28" string="scholarship" />
            <token id="29" string="," />
            <token id="30" string="hard" />
            <token id="31" string="labor" />
            <token id="32" string="and" />
            <token id="33" string="the" />
            <token id="34" string="Latin" />
            <token id="35" string="mass" />
            <token id="36" string="," />
            <token id="37" string="and" />
            <token id="38" string="how" />
            <token id="39" string="to" />
            <token id="40" string="survive" />
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
            <token id="44" string="through" />
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
            <token id="47" string="in" />
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
        <chunking id="26" string="hard labor and the Latin mass" type="NP">
          <tokens>
            <token id="30" string="hard" />
            <token id="31" string="labor" />
            <token id="32" string="and" />
            <token id="33" string="the" />
            <token id="34" string="Latin" />
            <token id="35" string="mass" />
          </tokens>
        </chunking>
        <chunking id="27" string="the walk home" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
          </tokens>
        </chunking>
        <chunking id="28" string="learned sharecropping and scholarship , hard labor and the Latin mass , and how to survive the walk home through black Savannah in his Catholic school uniform" type="VP">
          <tokens>
            <token id="25" string="learned" />
            <token id="26" string="sharecropping" />
            <token id="27" string="and" />
            <token id="28" string="scholarship" />
            <token id="29" string="," />
            <token id="30" string="hard" />
            <token id="31" string="labor" />
            <token id="32" string="and" />
            <token id="33" string="the" />
            <token id="34" string="Latin" />
            <token id="35" string="mass" />
            <token id="36" string="," />
            <token id="37" string="and" />
            <token id="38" string="how" />
            <token id="39" string="to" />
            <token id="40" string="survive" />
            <token id="41" string="the" />
            <token id="42" string="walk" />
            <token id="43" string="home" />
            <token id="44" string="through" />
            <token id="45" string="black" />
            <token id="46" string="Savannah" />
            <token id="47" string="in" />
            <token id="48" string="his" />
            <token id="49" string="Catholic" />
            <token id="50" string="school" />
            <token id="51" string="uniform" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="25">learned</governor>
          <dependent id="1">Abandoned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">father</governor>
          <dependent id="2">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">father</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Abandoned</governor>
          <dependent id="4">father</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Abandoned</governor>
          <dependent id="6">driven</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">grandfather</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">grandfather</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">grandfather</governor>
          <dependent id="9">hard-eyed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">driven</governor>
          <dependent id="10">grandfather</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">grandfather</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">band</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">grandfather</governor>
          <dependent id="13">band</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">nuns</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">band</governor>
          <dependent id="15">nuns</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">nuns</governor>
          <dependent id="16">sent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">sent</governor>
          <dependent id="17">south</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">teach</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Abandoned</governor>
          <dependent id="19">teach</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">children</governor>
          <dependent id="20">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">teach</governor>
          <dependent id="21">children</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">Clarence</governor>
          <dependent id="23">young</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">learned</governor>
          <dependent id="24">Clarence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">learned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">learned</governor>
          <dependent id="26">sharecropping</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">sharecropping</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">sharecropping</governor>
          <dependent id="28">scholarship</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">labor</governor>
          <dependent id="30">hard</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">sharecropping</governor>
          <dependent id="31">labor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">labor</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">mass</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">mass</governor>
          <dependent id="34">Latin</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">labor</governor>
          <dependent id="35">mass</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">sharecropping</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">survive</governor>
          <dependent id="38">how</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">survive</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">sharecropping</governor>
          <dependent id="40">survive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">home</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">home</governor>
          <dependent id="42">walk</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">survive</governor>
          <dependent id="43">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Savannah</governor>
          <dependent id="44">through</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">Savannah</governor>
          <dependent id="45">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">survive</governor>
          <dependent id="46">Savannah</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">uniform</governor>
          <dependent id="47">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="51">uniform</governor>
          <dependent id="48">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">uniform</governor>
          <dependent id="49">Catholic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">uniform</governor>
          <dependent id="50">school</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">survive</governor>
          <dependent id="51">uniform</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="labor" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="31" string="labor" />
          </tokens>
        </entity>
        <entity id="2" string="Catholic" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="49" string="Catholic" />
          </tokens>
        </entity>
        <entity id="3" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="46" string="Savannah" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>From these roots, he might have become one of any number of bright, activist black men to rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall, the retiring justice whose Supreme Court seat Thomas might take.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="roots" lemma="root" stem="root" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="bright" lemma="bright" stem="bright" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="activist" lemma="activist" stem="activist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rise" lemma="rise" stem="rise" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="24" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="aggressive" lemma="aggressive" stem="aggress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="31" string="agenda" lemma="agenda" stem="agenda" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="Thurgood" lemma="Thurgood" stem="thurgood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="44" string="Marshall" lemma="Marshall" stem="marshal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="47" string="retiring" lemma="retire" stem="retir" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="48" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="49" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="50" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="51" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="52" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="53" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="54" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="55" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (DT these) (NNS roots))) (, ,) (NP (PRP he)) (VP (MD might) (VP (VB have) (VP (VBN become) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (JJ bright) (, ,) (JJ activist) (JJ black) (NNS men)))))) (S (VP (TO to) (VP (VB rise) (ADVP (IN out) (PP (IN of) (NP (NP (NNP Southern) (NN poverty)) (CC and) (NP (NN press))))) (NP (NP (DT a) (ADJP (RB politically) (JJ aggressive)) (JJ liberal) (NN agenda)) (PP (IN of) (NP (NP (JJ civil) (NNS rights)) (CC and) (NP (JJ affirmative) (NN action))))) (: --) (SBAR (IN as) (S (VP (VBD did) (NP (NNS men)) (PP (IN like) (NP (NP (NNP Thurgood) (NNP Marshall)) (, ,) (NP (NP (DT the) (VBG retiring) (NN justice)) (SBAR (WP$ whose) (S (NP (NNP Supreme) (NNP Court) (NN seat) (NNP Thomas)) (VP (MD might) (VP (VB take))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the retiring justice" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
          </tokens>
        </chunking>
        <chunking id="2" string="Supreme Court seat Thomas" type="NP">
          <tokens>
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="Southern poverty and press" type="NP">
          <tokens>
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
          </tokens>
        </chunking>
        <chunking id="5" string="a politically aggressive liberal agenda" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
          </tokens>
        </chunking>
        <chunking id="6" string="civil rights and affirmative action" type="NP">
          <tokens>
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thurgood Marshall" type="NP">
          <tokens>
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="NP">
          <tokens>
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="9" string="rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="20" string="rise" />
            <token id="21" string="out" />
            <token id="22" string="of" />
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
            <token id="38" string="--" />
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="10" string="take" type="VP">
          <tokens>
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="11" string="any number" type="NP">
          <tokens>
            <token id="11" string="any" />
            <token id="12" string="number" />
          </tokens>
        </chunking>
        <chunking id="12" string="bright , activist black men" type="NP">
          <tokens>
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
          </tokens>
        </chunking>
        <chunking id="13" string="these roots" type="NP">
          <tokens>
            <token id="2" string="these" />
            <token id="3" string="roots" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the retiring justice whose Supreme Court seat Thomas might take" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="16" string="become one of any number of bright , activist black men to rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="8" string="become" />
            <token id="9" string="one" />
            <token id="10" string="of" />
            <token id="11" string="any" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
            <token id="19" string="to" />
            <token id="20" string="rise" />
            <token id="21" string="out" />
            <token id="22" string="of" />
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
            <token id="38" string="--" />
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="17" string="did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="18" string="a politically aggressive liberal agenda of civil rights and affirmative action" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
          </tokens>
        </chunking>
        <chunking id="19" string="as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="SBAR">
          <tokens>
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="20" string="might take" type="VP">
          <tokens>
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="21" string="to rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="rise" />
            <token id="21" string="out" />
            <token id="22" string="of" />
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
            <token id="38" string="--" />
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="22" string="politically aggressive" type="ADJP">
          <tokens>
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
          </tokens>
        </chunking>
        <chunking id="23" string="might have become one of any number of bright , activist black men to rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="6" string="might" />
            <token id="7" string="have" />
            <token id="8" string="become" />
            <token id="9" string="one" />
            <token id="10" string="of" />
            <token id="11" string="any" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
            <token id="19" string="to" />
            <token id="20" string="rise" />
            <token id="21" string="out" />
            <token id="22" string="of" />
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
            <token id="38" string="--" />
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="24" string="civil rights" type="NP">
          <tokens>
            <token id="33" string="civil" />
            <token id="34" string="rights" />
          </tokens>
        </chunking>
        <chunking id="25" string="any number of bright , activist black men" type="NP">
          <tokens>
            <token id="11" string="any" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
          </tokens>
        </chunking>
        <chunking id="26" string="one of any number of bright , activist black men" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="of" />
            <token id="11" string="any" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
          </tokens>
        </chunking>
        <chunking id="27" string="men" type="NP">
          <tokens>
            <token id="41" string="men" />
          </tokens>
        </chunking>
        <chunking id="28" string="have become one of any number of bright , activist black men to rise out of Southern poverty and press a politically aggressive liberal agenda of civil rights and affirmative action -- as did men like Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="become" />
            <token id="9" string="one" />
            <token id="10" string="of" />
            <token id="11" string="any" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="bright" />
            <token id="15" string="," />
            <token id="16" string="activist" />
            <token id="17" string="black" />
            <token id="18" string="men" />
            <token id="19" string="to" />
            <token id="20" string="rise" />
            <token id="21" string="out" />
            <token id="22" string="of" />
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
            <token id="25" string="and" />
            <token id="26" string="press" />
            <token id="27" string="a" />
            <token id="28" string="politically" />
            <token id="29" string="aggressive" />
            <token id="30" string="liberal" />
            <token id="31" string="agenda" />
            <token id="32" string="of" />
            <token id="33" string="civil" />
            <token id="34" string="rights" />
            <token id="35" string="and" />
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
            <token id="38" string="--" />
            <token id="39" string="as" />
            <token id="40" string="did" />
            <token id="41" string="men" />
            <token id="42" string="like" />
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="retiring" />
            <token id="48" string="justice" />
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="29" string="affirmative action" type="NP">
          <tokens>
            <token id="36" string="affirmative" />
            <token id="37" string="action" />
          </tokens>
        </chunking>
        <chunking id="30" string="whose Supreme Court seat Thomas might take" type="SBAR">
          <tokens>
            <token id="49" string="whose" />
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
            <token id="52" string="seat" />
            <token id="53" string="Thomas" />
            <token id="54" string="might" />
            <token id="55" string="take" />
          </tokens>
        </chunking>
        <chunking id="31" string="press" type="NP">
          <tokens>
            <token id="26" string="press" />
          </tokens>
        </chunking>
        <chunking id="32" string="Southern poverty" type="NP">
          <tokens>
            <token id="23" string="Southern" />
            <token id="24" string="poverty" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">roots</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">roots</governor>
          <dependent id="2">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">become</governor>
          <dependent id="3">roots</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">become</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">become</governor>
          <dependent id="6">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">become</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">become</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">number</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">number</governor>
          <dependent id="11">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">one</governor>
          <dependent id="12">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">men</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">men</governor>
          <dependent id="14">bright</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">men</governor>
          <dependent id="16">activist</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">men</governor>
          <dependent id="17">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">number</governor>
          <dependent id="18">men</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">rise</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">become</governor>
          <dependent id="20">rise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">poverty</governor>
          <dependent id="21">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">out</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">poverty</governor>
          <dependent id="23">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">rise</governor>
          <dependent id="24">poverty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">poverty</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">poverty</governor>
          <dependent id="26">press</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">agenda</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">aggressive</governor>
          <dependent id="28">politically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">agenda</governor>
          <dependent id="29">aggressive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">agenda</governor>
          <dependent id="30">liberal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">rise</governor>
          <dependent id="31">agenda</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">rights</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">rights</governor>
          <dependent id="33">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">agenda</governor>
          <dependent id="34">rights</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">rights</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">action</governor>
          <dependent id="36">affirmative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">rights</governor>
          <dependent id="37">action</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">did</governor>
          <dependent id="39">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">rise</governor>
          <dependent id="40">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">did</governor>
          <dependent id="41">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">Marshall</governor>
          <dependent id="42">like</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Marshall</governor>
          <dependent id="43">Thurgood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">did</governor>
          <dependent id="44">Marshall</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">justice</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">justice</governor>
          <dependent id="47">retiring</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="44">Marshall</governor>
          <dependent id="48">justice</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="55">take</governor>
          <dependent id="49">whose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">Thomas</governor>
          <dependent id="50">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">Thomas</governor>
          <dependent id="51">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">Thomas</governor>
          <dependent id="52">seat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="55">take</governor>
          <dependent id="53">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="55">take</governor>
          <dependent id="54">might</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="48">justice</governor>
          <dependent id="55">take</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="50" string="Supreme" />
            <token id="51" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="53" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Thurgood Marshall" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Thurgood" />
            <token id="44" string="Marshall" />
          </tokens>
        </entity>
        <entity id="5" string="Southern" type="MISC" score="0.0">
          <tokens>
            <token id="23" string="Southern" />
          </tokens>
        </entity>
        <entity id="6" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="30" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Instead, Thomas, now 43, became something else -- a hybrid product of harsh Southern history and baby-boom ambition, a proponent of personal strength over dependence, of individualism over government activism.</content>
      <tokens>
        <token id="1" string="Instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="43" lemma="43" stem="43" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="hybrid" lemma="hybrid" stem="hybrid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="product" lemma="product" stem="product" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="harsh" lemma="harsh" stem="harsh" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Southern" lemma="southern" stem="southern" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="baby-boom" lemma="baby-boom" stem="baby-boom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="ambition" lemma="ambition" stem="ambit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="proponent" lemma="proponent" stem="propon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="strength" lemma="strength" stem="strength" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="dependence" lemma="dependence" stem="depend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="individualism" lemma="individualism" stem="individu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="activism" lemma="activism" stem="activ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Instead)) (, ,) (NP (NP (NNP Thomas)) (, ,) (ADVP (RB now) (NP (CD 43))) (, ,)) (VP (VBD became) (NP (NP (NP (NN something) (RB else)) (: --) (NP (NP (DT a) (NN hybrid) (NN product)) (PP (IN of) (NP (JJ harsh) (JJ Southern) (NN history))))) (CC and) (NP (NP (NP (JJ baby-boom) (NN ambition)) (, ,) (NP (NP (DT a) (NN proponent)) (PP (IN of) (NP (NP (JJ personal) (NN strength)) (PP (IN over) (NP (NN dependence)))))) (, ,)) (PP (IN of) (NP (NN individualism))))) (PP (IN over) (NP (NN government) (NN activism)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="a proponent" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="proponent" />
          </tokens>
        </chunking>
        <chunking id="3" string="individualism" type="NP">
          <tokens>
            <token id="32" string="individualism" />
          </tokens>
        </chunking>
        <chunking id="4" string="a hybrid product" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="hybrid" />
            <token id="14" string="product" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas , now 43 ," type="NP">
          <tokens>
            <token id="3" string="Thomas" />
            <token id="4" string="," />
            <token id="5" string="now" />
            <token id="6" string="43" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="harsh Southern history" type="NP">
          <tokens>
            <token id="16" string="harsh" />
            <token id="17" string="Southern" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="7" string="baby-boom ambition , a proponent of personal strength over dependence , of individualism" type="NP">
          <tokens>
            <token id="20" string="baby-boom" />
            <token id="21" string="ambition" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="proponent" />
            <token id="25" string="of" />
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
            <token id="30" string="," />
            <token id="31" string="of" />
            <token id="32" string="individualism" />
          </tokens>
        </chunking>
        <chunking id="8" string="became something else -- a hybrid product of harsh Southern history and baby-boom ambition , a proponent of personal strength over dependence , of individualism over government activism" type="VP">
          <tokens>
            <token id="8" string="became" />
            <token id="9" string="something" />
            <token id="10" string="else" />
            <token id="11" string="--" />
            <token id="12" string="a" />
            <token id="13" string="hybrid" />
            <token id="14" string="product" />
            <token id="15" string="of" />
            <token id="16" string="harsh" />
            <token id="17" string="Southern" />
            <token id="18" string="history" />
            <token id="19" string="and" />
            <token id="20" string="baby-boom" />
            <token id="21" string="ambition" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="proponent" />
            <token id="25" string="of" />
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
            <token id="30" string="," />
            <token id="31" string="of" />
            <token id="32" string="individualism" />
            <token id="33" string="over" />
            <token id="34" string="government" />
            <token id="35" string="activism" />
          </tokens>
        </chunking>
        <chunking id="9" string="a hybrid product of harsh Southern history" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="hybrid" />
            <token id="14" string="product" />
            <token id="15" string="of" />
            <token id="16" string="harsh" />
            <token id="17" string="Southern" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="10" string="personal strength" type="NP">
          <tokens>
            <token id="26" string="personal" />
            <token id="27" string="strength" />
          </tokens>
        </chunking>
        <chunking id="11" string="something else -- a hybrid product of harsh Southern history and baby-boom ambition , a proponent of personal strength over dependence , of individualism" type="NP">
          <tokens>
            <token id="9" string="something" />
            <token id="10" string="else" />
            <token id="11" string="--" />
            <token id="12" string="a" />
            <token id="13" string="hybrid" />
            <token id="14" string="product" />
            <token id="15" string="of" />
            <token id="16" string="harsh" />
            <token id="17" string="Southern" />
            <token id="18" string="history" />
            <token id="19" string="and" />
            <token id="20" string="baby-boom" />
            <token id="21" string="ambition" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="proponent" />
            <token id="25" string="of" />
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
            <token id="30" string="," />
            <token id="31" string="of" />
            <token id="32" string="individualism" />
          </tokens>
        </chunking>
        <chunking id="12" string="baby-boom ambition , a proponent of personal strength over dependence ," type="NP">
          <tokens>
            <token id="20" string="baby-boom" />
            <token id="21" string="ambition" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="proponent" />
            <token id="25" string="of" />
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
            <token id="30" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="a proponent of personal strength over dependence" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="proponent" />
            <token id="25" string="of" />
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
          </tokens>
        </chunking>
        <chunking id="14" string="baby-boom ambition" type="NP">
          <tokens>
            <token id="20" string="baby-boom" />
            <token id="21" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="15" string="dependence" type="NP">
          <tokens>
            <token id="29" string="dependence" />
          </tokens>
        </chunking>
        <chunking id="16" string="something else -- a hybrid product of harsh Southern history" type="NP">
          <tokens>
            <token id="9" string="something" />
            <token id="10" string="else" />
            <token id="11" string="--" />
            <token id="12" string="a" />
            <token id="13" string="hybrid" />
            <token id="14" string="product" />
            <token id="15" string="of" />
            <token id="16" string="harsh" />
            <token id="17" string="Southern" />
            <token id="18" string="history" />
          </tokens>
        </chunking>
        <chunking id="17" string="something else" type="NP">
          <tokens>
            <token id="9" string="something" />
            <token id="10" string="else" />
          </tokens>
        </chunking>
        <chunking id="18" string="government activism" type="NP">
          <tokens>
            <token id="34" string="government" />
            <token id="35" string="activism" />
          </tokens>
        </chunking>
        <chunking id="19" string="43" type="NP">
          <tokens>
            <token id="6" string="43" />
          </tokens>
        </chunking>
        <chunking id="20" string="personal strength over dependence" type="NP">
          <tokens>
            <token id="26" string="personal" />
            <token id="27" string="strength" />
            <token id="28" string="over" />
            <token id="29" string="dependence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">became</governor>
          <dependent id="1">Instead</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">became</governor>
          <dependent id="3">Thomas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">Thomas</governor>
          <dependent id="5">now</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">now</governor>
          <dependent id="6">43</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">became</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">became</governor>
          <dependent id="9">something</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">something</governor>
          <dependent id="10">else</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">product</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">product</governor>
          <dependent id="13">hybrid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">something</governor>
          <dependent id="14">product</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">history</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">history</governor>
          <dependent id="16">harsh</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">history</governor>
          <dependent id="17">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">product</governor>
          <dependent id="18">history</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">something</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">ambition</governor>
          <dependent id="20">baby-boom</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">something</governor>
          <dependent id="21">ambition</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">proponent</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">ambition</governor>
          <dependent id="24">proponent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">strength</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">strength</governor>
          <dependent id="26">personal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">proponent</governor>
          <dependent id="27">strength</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">dependence</governor>
          <dependent id="28">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">strength</governor>
          <dependent id="29">dependence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">individualism</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">ambition</governor>
          <dependent id="32">individualism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">activism</governor>
          <dependent id="33">over</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">activism</governor>
          <dependent id="34">government</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">became</governor>
          <dependent id="35">activism</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Southern" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Southern" />
          </tokens>
        </entity>
        <entity id="4" string="43" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="43" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>By the time he arrived in Washington with the Reagan administration, he had developed into a rare breed -- a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="arrived" lemma="arrive" stem="arriv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="developed" lemma="develop" stem="develop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="breed" lemma="breed" stem="breed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="24" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="impressive" lemma="impressive" stem="impress" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="28" string="presidents" lemma="president" stem="presid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="35" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="highest" lemma="highest" stem="highest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="land" lemma="land" stem="land" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN By) (NP (DT the) (NN time))) (NP (PRP he)) (VP (VBD arrived) (PP (IN in) (NP (NNP Washington))) (PP (IN with) (NP (DT the) (NNP Reagan) (NN administration))))) (, ,) (NP (PRP he)) (VP (VBD had) (VP (VBN developed) (PP (IN into) (NP (NP (DT a) (JJ rare) (NN breed)) (: --) (NP (NP (DT a) (JJ black) (JJ conservative)) (RRC (ADJP (RB so) (JJ impressive) (PP (TO to) (NP (JJ Republican) (NNS presidents)))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (VP (VBN set) (PP (IN on) (NP (DT the) (NN road))) (PP (TO to) (NP (NP (DT the) (JJS highest) (NN court)) (PP (IN in) (NP (DT the) (NN land))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was set on the road to the highest court in the land" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="2" string="the land" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="3" string="had developed into a rare breed -- a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="developed" />
            <token id="16" string="into" />
            <token id="17" string="a" />
            <token id="18" string="rare" />
            <token id="19" string="breed" />
            <token id="20" string="--" />
            <token id="21" string="a" />
            <token id="22" string="black" />
            <token id="23" string="conservative" />
            <token id="24" string="so" />
            <token id="25" string="impressive" />
            <token id="26" string="to" />
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="4" string="a rare breed -- a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="rare" />
            <token id="19" string="breed" />
            <token id="20" string="--" />
            <token id="21" string="a" />
            <token id="22" string="black" />
            <token id="23" string="conservative" />
            <token id="24" string="so" />
            <token id="25" string="impressive" />
            <token id="26" string="to" />
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="5" string="a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="black" />
            <token id="23" string="conservative" />
            <token id="24" string="so" />
            <token id="25" string="impressive" />
            <token id="26" string="to" />
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="6" string="the road" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="road" />
          </tokens>
        </chunking>
        <chunking id="7" string="a rare breed" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="rare" />
            <token id="19" string="breed" />
          </tokens>
        </chunking>
        <chunking id="8" string="the highest court" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
          </tokens>
        </chunking>
        <chunking id="9" string="a black conservative" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="black" />
            <token id="23" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="10" string="the highest court in the land" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="11" string="Washington" type="NP">
          <tokens>
            <token id="7" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="12" string="developed into a rare breed -- a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land" type="VP">
          <tokens>
            <token id="15" string="developed" />
            <token id="16" string="into" />
            <token id="17" string="a" />
            <token id="18" string="rare" />
            <token id="19" string="breed" />
            <token id="20" string="--" />
            <token id="21" string="a" />
            <token id="22" string="black" />
            <token id="23" string="conservative" />
            <token id="24" string="so" />
            <token id="25" string="impressive" />
            <token id="26" string="to" />
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="13" string="that he was set on the road to the highest court in the land" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="14" string="the time" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
          </tokens>
        </chunking>
        <chunking id="15" string="arrived in Washington with the Reagan administration" type="VP">
          <tokens>
            <token id="5" string="arrived" />
            <token id="6" string="in" />
            <token id="7" string="Washington" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="administration" />
          </tokens>
        </chunking>
        <chunking id="16" string="so impressive to Republican presidents" type="ADJP">
          <tokens>
            <token id="24" string="so" />
            <token id="25" string="impressive" />
            <token id="26" string="to" />
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
          </tokens>
        </chunking>
        <chunking id="17" string="Republican presidents" type="NP">
          <tokens>
            <token id="27" string="Republican" />
            <token id="28" string="presidents" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="set on the road to the highest court in the land" type="VP">
          <tokens>
            <token id="32" string="set" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="road" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="highest" />
            <token id="39" string="court" />
            <token id="40" string="in" />
            <token id="41" string="the" />
            <token id="42" string="land" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Reagan administration" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="administration" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">time</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">time</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arrived</governor>
          <dependent id="3">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">arrived</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">developed</governor>
          <dependent id="5">arrived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Washington</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arrived</governor>
          <dependent id="7">Washington</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">administration</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">administration</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">administration</governor>
          <dependent id="10">Reagan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arrived</governor>
          <dependent id="11">administration</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">developed</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">developed</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">developed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">breed</governor>
          <dependent id="16">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">breed</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">breed</governor>
          <dependent id="18">rare</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">developed</governor>
          <dependent id="19">breed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">conservative</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">conservative</governor>
          <dependent id="22">black</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">breed</governor>
          <dependent id="23">conservative</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">impressive</governor>
          <dependent id="24">so</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">conservative</governor>
          <dependent id="25">impressive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">presidents</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">presidents</governor>
          <dependent id="27">Republican</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">impressive</governor>
          <dependent id="28">presidents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">set</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">set</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">set</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">impressive</governor>
          <dependent id="32">set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">road</governor>
          <dependent id="33">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">road</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">set</governor>
          <dependent id="35">road</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">court</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">court</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">court</governor>
          <dependent id="38">highest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">set</governor>
          <dependent id="39">court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">land</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">land</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">court</governor>
          <dependent id="42">land</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="23" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="27" string="Republican" />
          </tokens>
        </entity>
        <entity id="4" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>But he was so disturbing to traditional liberals that they are eager to deprive him of Senate confirmation in September.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="disturbing" lemma="disturbing" stem="disturb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="liberals" lemma="liberal" stem="liber" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="eager" lemma="eager" stem="eager" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="deprive" lemma="deprive" stem="depriv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="18" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (VP (VBD was) (ADJP (RB so) (JJ disturbing) (PP (TO to) (NP (JJ traditional) (NNS liberals)))) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP are) (ADJP (JJ eager) (S (VP (TO to) (VP (VB deprive) (NP (NP (PRP him)) (PP (IN of) (NP (NNP Senate) (NN confirmation)))) (PP (IN in) (NP (NNP September))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="so disturbing to traditional liberals" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="disturbing" />
            <token id="6" string="to" />
            <token id="7" string="traditional" />
            <token id="8" string="liberals" />
          </tokens>
        </chunking>
        <chunking id="2" string="are eager to deprive him of Senate confirmation in September" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="eager" />
            <token id="13" string="to" />
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="3" string="Senate confirmation" type="NP">
          <tokens>
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="4" string="September" type="NP">
          <tokens>
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="5" string="that they are eager to deprive him of Senate confirmation in September" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="are" />
            <token id="12" string="eager" />
            <token id="13" string="to" />
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="15" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="deprive him of Senate confirmation in September" type="VP">
          <tokens>
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="8" string="him of Senate confirmation" type="NP">
          <tokens>
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="to deprive him of Senate confirmation in September" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="11" string="was so disturbing to traditional liberals that they are eager to deprive him of Senate confirmation in September" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="so" />
            <token id="5" string="disturbing" />
            <token id="6" string="to" />
            <token id="7" string="traditional" />
            <token id="8" string="liberals" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="are" />
            <token id="12" string="eager" />
            <token id="13" string="to" />
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="traditional liberals" type="NP">
          <tokens>
            <token id="7" string="traditional" />
            <token id="8" string="liberals" />
          </tokens>
        </chunking>
        <chunking id="14" string="eager to deprive him of Senate confirmation in September" type="ADJP">
          <tokens>
            <token id="12" string="eager" />
            <token id="13" string="to" />
            <token id="14" string="deprive" />
            <token id="15" string="him" />
            <token id="16" string="of" />
            <token id="17" string="Senate" />
            <token id="18" string="confirmation" />
            <token id="19" string="in" />
            <token id="20" string="September" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">disturbing</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">disturbing</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">disturbing</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">disturbing</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">disturbing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">liberals</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">liberals</governor>
          <dependent id="7">traditional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">disturbing</governor>
          <dependent id="8">liberals</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">eager</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">eager</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">eager</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">disturbing</governor>
          <dependent id="12">eager</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">deprive</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">eager</governor>
          <dependent id="14">deprive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">deprive</governor>
          <dependent id="15">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">confirmation</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">confirmation</governor>
          <dependent id="17">Senate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">him</governor>
          <dependent id="18">confirmation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">September</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">deprive</governor>
          <dependent id="20">September</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="September" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="September" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Historically, trying to predict Supreme Court nominees has been extremely risky.</content>
      <tokens>
        <token id="1" string="Historically" lemma="Historically" stem="histor" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="predict" lemma="predict" stem="predict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="8" string="nominees" lemma="nominee" stem="nomine" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="extremely" lemma="extremely" stem="extrem" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="risky" lemma="risky" stem="riski" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Historically)) (, ,) (S (VP (VBG trying) (S (VP (TO to) (VP (VB predict) (NP (NNP Supreme) (NNP Court) (NNS nominees))))))) (VP (VBZ has) (VP (VBN been) (ADJP (RB extremely) (JJ risky)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been extremely risky" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="extremely" />
            <token id="12" string="risky" />
          </tokens>
        </chunking>
        <chunking id="2" string="extremely risky" type="ADJP">
          <tokens>
            <token id="11" string="extremely" />
            <token id="12" string="risky" />
          </tokens>
        </chunking>
        <chunking id="3" string="Supreme Court nominees" type="NP">
          <tokens>
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
            <token id="8" string="nominees" />
          </tokens>
        </chunking>
        <chunking id="4" string="predict Supreme Court nominees" type="VP">
          <tokens>
            <token id="5" string="predict" />
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
            <token id="8" string="nominees" />
          </tokens>
        </chunking>
        <chunking id="5" string="Historically" type="NP">
          <tokens>
            <token id="1" string="Historically" />
          </tokens>
        </chunking>
        <chunking id="6" string="to predict Supreme Court nominees" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="predict" />
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
            <token id="8" string="nominees" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been extremely risky" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="been" />
            <token id="11" string="extremely" />
            <token id="12" string="risky" />
          </tokens>
        </chunking>
        <chunking id="8" string="trying to predict Supreme Court nominees" type="VP">
          <tokens>
            <token id="3" string="trying" />
            <token id="4" string="to" />
            <token id="5" string="predict" />
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
            <token id="8" string="nominees" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">risky</governor>
          <dependent id="1">Historically</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">risky</governor>
          <dependent id="3">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">predict</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">trying</governor>
          <dependent id="5">predict</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">nominees</governor>
          <dependent id="6">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">nominees</governor>
          <dependent id="7">Court</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">predict</governor>
          <dependent id="8">nominees</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">risky</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">risky</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">risky</governor>
          <dependent id="11">extremely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">risky</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Supreme" />
            <token id="7" string="Court" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Still, many liberals are convinced that Thomas&amp;apost; past clearly shows his future.</content>
      <tokens>
        <token id="1" string="Still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="liberals" lemma="liberal" stem="liber" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="convinced" lemma="convince" stem="convinc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="clearly" lemma="clearly" stem="clearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Still)) (, ,) (NP (JJ many) (NNS liberals)) (VP (VBP are) (ADJP (VBN convinced) (SBAR (IN that) (S (NP (NP (NNP Thomas) (POS ')) (JJ past)) (ADVP (RB clearly)) (VP (VBZ shows) (NP (PRP$ his) (NN future))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shows his future" type="VP">
          <tokens>
            <token id="12" string="shows" />
            <token id="13" string="his" />
            <token id="14" string="future" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas '" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="many liberals" type="NP">
          <tokens>
            <token id="3" string="many" />
            <token id="4" string="liberals" />
          </tokens>
        </chunking>
        <chunking id="4" string="convinced that Thomas ' past clearly shows his future" type="ADJP">
          <tokens>
            <token id="6" string="convinced" />
            <token id="7" string="that" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="past" />
            <token id="11" string="clearly" />
            <token id="12" string="shows" />
            <token id="13" string="his" />
            <token id="14" string="future" />
          </tokens>
        </chunking>
        <chunking id="5" string="that Thomas ' past clearly shows his future" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="past" />
            <token id="11" string="clearly" />
            <token id="12" string="shows" />
            <token id="13" string="his" />
            <token id="14" string="future" />
          </tokens>
        </chunking>
        <chunking id="6" string="his future" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="future" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas ' past" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="past" />
          </tokens>
        </chunking>
        <chunking id="8" string="are convinced that Thomas ' past clearly shows his future" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="convinced" />
            <token id="7" string="that" />
            <token id="8" string="Thomas" />
            <token id="9" string="'" />
            <token id="10" string="past" />
            <token id="11" string="clearly" />
            <token id="12" string="shows" />
            <token id="13" string="his" />
            <token id="14" string="future" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">convinced</governor>
          <dependent id="1">Still</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">liberals</governor>
          <dependent id="3">many</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">convinced</governor>
          <dependent id="4">liberals</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">convinced</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">convinced</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">shows</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">shows</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thomas</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Thomas</governor>
          <dependent id="10">past</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">shows</governor>
          <dependent id="11">clearly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">convinced</governor>
          <dependent id="12">shows</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">future</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">shows</governor>
          <dependent id="14">future</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="past" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="future" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>He would, they say, oppose abortion rights, school busing plans and affirmative action programs.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="oppose" lemma="oppose" stem="oppos" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="busing" lemma="busing" stem="buse" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="plans" lemma="plan" stem="plan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="programs" lemma="program" stem="program" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (NP (PRP He)) (VP (MD would))) (, ,) (S (NP (PRP they)) (VP (VBP say)))) (, ,) (VP (VBP oppose)) (NP (NP (NN abortion) (NNS rights)) (, ,) (NP (NP (NN school) (NN busing) (NNS plans)) (CC and) (NP (JJ affirmative) (NN action) (NNS programs)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="school busing plans and affirmative action programs" type="NP">
          <tokens>
            <token id="11" string="school" />
            <token id="12" string="busing" />
            <token id="13" string="plans" />
            <token id="14" string="and" />
            <token id="15" string="affirmative" />
            <token id="16" string="action" />
            <token id="17" string="programs" />
          </tokens>
        </chunking>
        <chunking id="3" string="would" type="VP">
          <tokens>
            <token id="2" string="would" />
          </tokens>
        </chunking>
        <chunking id="4" string="abortion rights , school busing plans and affirmative action programs" type="NP">
          <tokens>
            <token id="8" string="abortion" />
            <token id="9" string="rights" />
            <token id="10" string="," />
            <token id="11" string="school" />
            <token id="12" string="busing" />
            <token id="13" string="plans" />
            <token id="14" string="and" />
            <token id="15" string="affirmative" />
            <token id="16" string="action" />
            <token id="17" string="programs" />
          </tokens>
        </chunking>
        <chunking id="5" string="abortion rights" type="NP">
          <tokens>
            <token id="8" string="abortion" />
            <token id="9" string="rights" />
          </tokens>
        </chunking>
        <chunking id="6" string="oppose" type="VP">
          <tokens>
            <token id="7" string="oppose" />
          </tokens>
        </chunking>
        <chunking id="7" string="affirmative action programs" type="NP">
          <tokens>
            <token id="15" string="affirmative" />
            <token id="16" string="action" />
            <token id="17" string="programs" />
          </tokens>
        </chunking>
        <chunking id="8" string="say" type="VP">
          <tokens>
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="9" string="school busing plans" type="NP">
          <tokens>
            <token id="11" string="school" />
            <token id="12" string="busing" />
            <token id="13" string="plans" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">would</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">oppose</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">say</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">would</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">oppose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">rights</governor>
          <dependent id="8">abortion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">oppose</governor>
          <dependent id="9">rights</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">plans</governor>
          <dependent id="11">school</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">plans</governor>
          <dependent id="12">busing</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">rights</governor>
          <dependent id="13">plans</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">plans</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">programs</governor>
          <dependent id="15">affirmative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">programs</governor>
          <dependent id="16">action</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">plans</governor>
          <dependent id="17">programs</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>He would also weaken the wall separating government and religion and further restrict the rights of criminal suspects and defendants.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="weaken" lemma="weaken" stem="weaken" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="wall" lemma="wall" stem="wall" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="separating" lemma="separate" stem="separ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="religion" lemma="religion" stem="religion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="further" lemma="further" stem="further" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="restrict" lemma="restrict" stem="restrict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (MD would) (ADVP (RB also)) (VP (VB weaken) (NP (DT the) (NN wall)) (S (VP (VBG separating) (S (NP (NP (NN government) (CC and) (NN religion)) (CC and) (NP (JJ further))) (VP (VB restrict) (NP (NP (DT the) (NNS rights)) (PP (IN of) (NP (JJ criminal) (NNS suspects) (CC and) (NNS defendants)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="criminal suspects and defendants" type="NP">
          <tokens>
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="2" string="restrict the rights of criminal suspects and defendants" type="VP">
          <tokens>
            <token id="13" string="restrict" />
            <token id="14" string="the" />
            <token id="15" string="rights" />
            <token id="16" string="of" />
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="the rights of criminal suspects and defendants" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rights" />
            <token id="16" string="of" />
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="4" string="the rights" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="5" string="government and religion and further" type="NP">
          <tokens>
            <token id="8" string="government" />
            <token id="9" string="and" />
            <token id="10" string="religion" />
            <token id="11" string="and" />
            <token id="12" string="further" />
          </tokens>
        </chunking>
        <chunking id="6" string="weaken the wall separating government and religion and further restrict the rights of criminal suspects and defendants" type="VP">
          <tokens>
            <token id="4" string="weaken" />
            <token id="5" string="the" />
            <token id="6" string="wall" />
            <token id="7" string="separating" />
            <token id="8" string="government" />
            <token id="9" string="and" />
            <token id="10" string="religion" />
            <token id="11" string="and" />
            <token id="12" string="further" />
            <token id="13" string="restrict" />
            <token id="14" string="the" />
            <token id="15" string="rights" />
            <token id="16" string="of" />
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="7" string="government and religion" type="NP">
          <tokens>
            <token id="8" string="government" />
            <token id="9" string="and" />
            <token id="10" string="religion" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="the wall" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="wall" />
          </tokens>
        </chunking>
        <chunking id="10" string="further" type="NP">
          <tokens>
            <token id="12" string="further" />
          </tokens>
        </chunking>
        <chunking id="11" string="would also weaken the wall separating government and religion and further restrict the rights of criminal suspects and defendants" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="also" />
            <token id="4" string="weaken" />
            <token id="5" string="the" />
            <token id="6" string="wall" />
            <token id="7" string="separating" />
            <token id="8" string="government" />
            <token id="9" string="and" />
            <token id="10" string="religion" />
            <token id="11" string="and" />
            <token id="12" string="further" />
            <token id="13" string="restrict" />
            <token id="14" string="the" />
            <token id="15" string="rights" />
            <token id="16" string="of" />
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="12" string="separating government and religion and further restrict the rights of criminal suspects and defendants" type="VP">
          <tokens>
            <token id="7" string="separating" />
            <token id="8" string="government" />
            <token id="9" string="and" />
            <token id="10" string="religion" />
            <token id="11" string="and" />
            <token id="12" string="further" />
            <token id="13" string="restrict" />
            <token id="14" string="the" />
            <token id="15" string="rights" />
            <token id="16" string="of" />
            <token id="17" string="criminal" />
            <token id="18" string="suspects" />
            <token id="19" string="and" />
            <token id="20" string="defendants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">weaken</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">weaken</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">weaken</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">weaken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">wall</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">weaken</governor>
          <dependent id="6">wall</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">weaken</governor>
          <dependent id="7">separating</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">restrict</governor>
          <dependent id="8">government</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">government</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">government</governor>
          <dependent id="10">religion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">government</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">government</governor>
          <dependent id="12">further</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">separating</governor>
          <dependent id="13">restrict</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">rights</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">restrict</governor>
          <dependent id="15">rights</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">suspects</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">suspects</governor>
          <dependent id="17">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rights</governor>
          <dependent id="18">suspects</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">suspects</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">suspects</governor>
          <dependent id="20">defendants</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Not surprisingly, Thomas&amp;apost; many friends and supporters draw different conclusions.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="surprisingly" lemma="surprisingly" stem="surprisingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="supporters" lemma="supporter" stem="support" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="draw" lemma="draw" stem="draw" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="conclusions" lemma="conclusion" stem="conclus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Not) (RB surprisingly)) (, ,) (NP (NP (NNP Thomas) (POS ')) (JJ many) (NNS friends) (CC and) (NNS supporters)) (VP (VBP draw) (NP (JJ different) (NNS conclusions))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="draw different conclusions" type="VP">
          <tokens>
            <token id="10" string="draw" />
            <token id="11" string="different" />
            <token id="12" string="conclusions" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' many friends and supporters" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="'" />
            <token id="6" string="many" />
            <token id="7" string="friends" />
            <token id="8" string="and" />
            <token id="9" string="supporters" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="different conclusions" type="NP">
          <tokens>
            <token id="11" string="different" />
            <token id="12" string="conclusions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="2">surprisingly</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">draw</governor>
          <dependent id="2">surprisingly</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">friends</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Thomas</governor>
          <dependent id="5">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">friends</governor>
          <dependent id="6">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">draw</governor>
          <dependent id="7">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">friends</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">friends</governor>
          <dependent id="9">supporters</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">draw</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">conclusions</governor>
          <dependent id="11">different</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">draw</governor>
          <dependent id="12">conclusions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>They see him as an independent spirit, a probable centrist on a court that has been steering rightward for several years.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="7" string="spirit" lemma="spirit" stem="spirit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="probable" lemma="probable" stem="probabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="centrist" lemma="centrist" stem="centrist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="steering" lemma="steer" stem="steer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="rightward" lemma="rightward" stem="rightward" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP see) (NP (PRP him)) (PP (IN as) (NP (NP (DT an) (JJ independent) (NN spirit)) (, ,) (NP (NP (DT a) (JJ probable) (JJ centrist)) (PP (IN on) (NP (NP (DT a) (NN court)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBG steering) (NP (NP (JJ rightward)) (PP (IN for) (NP (JJ several) (NNS years))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a court that has been steering rightward for several years" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="court" />
            <token id="15" string="that" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="see him as an independent spirit , a probable centrist on a court that has been steering rightward for several years" type="VP">
          <tokens>
            <token id="2" string="see" />
            <token id="3" string="him" />
            <token id="4" string="as" />
            <token id="5" string="an" />
            <token id="6" string="independent" />
            <token id="7" string="spirit" />
            <token id="8" string="," />
            <token id="9" string="a" />
            <token id="10" string="probable" />
            <token id="11" string="centrist" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="court" />
            <token id="15" string="that" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="steering rightward for several years" type="VP">
          <tokens>
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="rightward for several years" type="NP">
          <tokens>
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="several years" type="NP">
          <tokens>
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="a probable centrist" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="probable" />
            <token id="11" string="centrist" />
          </tokens>
        </chunking>
        <chunking id="9" string="an independent spirit" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="independent" />
            <token id="7" string="spirit" />
          </tokens>
        </chunking>
        <chunking id="10" string="a court" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="court" />
          </tokens>
        </chunking>
        <chunking id="11" string="been steering rightward for several years" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="a probable centrist on a court that has been steering rightward for several years" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="probable" />
            <token id="11" string="centrist" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="court" />
            <token id="15" string="that" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="13" string="an independent spirit , a probable centrist on a court that has been steering rightward for several years" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="independent" />
            <token id="7" string="spirit" />
            <token id="8" string="," />
            <token id="9" string="a" />
            <token id="10" string="probable" />
            <token id="11" string="centrist" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="court" />
            <token id="15" string="that" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="has been steering rightward for several years" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="15" string="that has been steering rightward for several years" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="steering" />
            <token id="19" string="rightward" />
            <token id="20" string="for" />
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="16" string="rightward" type="NP">
          <tokens>
            <token id="19" string="rightward" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">see</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">see</governor>
          <dependent id="3">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">spirit</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">spirit</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">spirit</governor>
          <dependent id="6">independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">see</governor>
          <dependent id="7">spirit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">centrist</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">centrist</governor>
          <dependent id="10">probable</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">spirit</governor>
          <dependent id="11">centrist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">court</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">court</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">centrist</governor>
          <dependent id="14">court</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">steering</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">steering</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">steering</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">court</governor>
          <dependent id="18">steering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">steering</governor>
          <dependent id="19">rightward</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">years</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">years</governor>
          <dependent id="21">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">rightward</governor>
          <dependent id="22">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="independent" />
          </tokens>
        </entity>
        <entity id="2" string="several years" type="DURATION" score="0.0">
          <tokens>
            <token id="21" string="several" />
            <token id="22" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="centrist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="centrist" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The Georgia beginning; But any attempt to understand the potential successor to the revered Thurgood Marshall must begin in Georgia.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="beginning" lemma="beginning" stem="begin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="understand" lemma="understand" stem="understand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="potential" lemma="potential" stem="potenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="successor" lemma="successor" stem="successor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="revered" lemma="revered" stem="rever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="Thurgood" lemma="Thurgood" stem="thurgood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Marshall" lemma="Marshall" stem="marshal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Georgia) (NN beginning)) (: ;) (S (CC But) (NP (DT any) (NN attempt) (S (VP (TO to) (VP (VB understand) (NP (DT the) (JJ potential) (NN successor)) (PP (TO to) (NP (DT the) (JJ revered) (NNP Thurgood) (NNP Marshall))))))) (VP (MD must) (VP (VB begin) (PP (IN in) (NP (NNP Georgia)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the potential successor" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="potential" />
            <token id="12" string="successor" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Georgia beginning" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Georgia" />
            <token id="3" string="beginning" />
          </tokens>
        </chunking>
        <chunking id="3" string="understand the potential successor to the revered Thurgood Marshall" type="VP">
          <tokens>
            <token id="9" string="understand" />
            <token id="10" string="the" />
            <token id="11" string="potential" />
            <token id="12" string="successor" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="revered" />
            <token id="16" string="Thurgood" />
            <token id="17" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="4" string="the revered Thurgood Marshall" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="revered" />
            <token id="16" string="Thurgood" />
            <token id="17" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="5" string="must begin in Georgia" type="VP">
          <tokens>
            <token id="18" string="must" />
            <token id="19" string="begin" />
            <token id="20" string="in" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="6" string="begin in Georgia" type="VP">
          <tokens>
            <token id="19" string="begin" />
            <token id="20" string="in" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="7" string="Georgia" type="NP">
          <tokens>
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="8" string="to understand the potential successor to the revered Thurgood Marshall" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="understand" />
            <token id="10" string="the" />
            <token id="11" string="potential" />
            <token id="12" string="successor" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="revered" />
            <token id="16" string="Thurgood" />
            <token id="17" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="9" string="any attempt to understand the potential successor to the revered Thurgood Marshall" type="NP">
          <tokens>
            <token id="6" string="any" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="understand" />
            <token id="10" string="the" />
            <token id="11" string="potential" />
            <token id="12" string="successor" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="revered" />
            <token id="16" string="Thurgood" />
            <token id="17" string="Marshall" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">beginning</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">beginning</governor>
          <dependent id="2">Georgia</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">begin</governor>
          <dependent id="3">beginning</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">begin</governor>
          <dependent id="5">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">attempt</governor>
          <dependent id="6">any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">begin</governor>
          <dependent id="7">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">understand</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">attempt</governor>
          <dependent id="9">understand</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">successor</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">successor</governor>
          <dependent id="11">potential</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">understand</governor>
          <dependent id="12">successor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Marshall</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Marshall</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Marshall</governor>
          <dependent id="15">revered</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Marshall</governor>
          <dependent id="16">Thurgood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">understand</governor>
          <dependent id="17">Marshall</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">begin</governor>
          <dependent id="18">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">begin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Georgia</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">begin</governor>
          <dependent id="21">Georgia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Georgia" />
          </tokens>
        </entity>
        <entity id="2" string="Thurgood Marshall" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Thurgood" />
            <token id="17" string="Marshall" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>There, just the other day, Leola Williams, Thomas&amp;apost; mother, talked about how the force of family worked on her son.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Leola" lemma="Leola" stem="leola" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="talked" lemma="talk" stem="talk" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="worked" lemma="work" stem="work" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB There)) (, ,) (NP (NP (RB just) (DT the) (JJ other) (NN day)) (, ,) (NP (NP (NNP Leola) (NNP Williams)) (, ,) (NP (NP (NNP Thomas) (POS ')) (NN mother))) (, ,)) (VP (VBD talked) (PP (IN about) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT the) (NN force)) (PP (IN of) (NP (NN family)))) (VP (VBD worked) (PP (IN on) (NP (PRP$ her) (NN son)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="talked about how the force of family worked on her son" type="VP">
          <tokens>
            <token id="15" string="talked" />
            <token id="16" string="about" />
            <token id="17" string="how" />
            <token id="18" string="the" />
            <token id="19" string="force" />
            <token id="20" string="of" />
            <token id="21" string="family" />
            <token id="22" string="worked" />
            <token id="23" string="on" />
            <token id="24" string="her" />
            <token id="25" string="son" />
          </tokens>
        </chunking>
        <chunking id="2" string="the force" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="just the other day , Leola Williams , Thomas ' mother ," type="NP">
          <tokens>
            <token id="3" string="just" />
            <token id="4" string="the" />
            <token id="5" string="other" />
            <token id="6" string="day" />
            <token id="7" string="," />
            <token id="8" string="Leola" />
            <token id="9" string="Williams" />
            <token id="10" string="," />
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="mother" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas '" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="Leola Williams , Thomas ' mother" type="NP">
          <tokens>
            <token id="8" string="Leola" />
            <token id="9" string="Williams" />
            <token id="10" string="," />
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="how" type="WHADVP">
          <tokens>
            <token id="17" string="how" />
          </tokens>
        </chunking>
        <chunking id="7" string="the force of family" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="force" />
            <token id="20" string="of" />
            <token id="21" string="family" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thomas ' mother" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="'" />
            <token id="13" string="mother" />
          </tokens>
        </chunking>
        <chunking id="9" string="Leola Williams" type="NP">
          <tokens>
            <token id="8" string="Leola" />
            <token id="9" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="10" string="family" type="NP">
          <tokens>
            <token id="21" string="family" />
          </tokens>
        </chunking>
        <chunking id="11" string="just the other day" type="NP">
          <tokens>
            <token id="3" string="just" />
            <token id="4" string="the" />
            <token id="5" string="other" />
            <token id="6" string="day" />
          </tokens>
        </chunking>
        <chunking id="12" string="worked on her son" type="VP">
          <tokens>
            <token id="22" string="worked" />
            <token id="23" string="on" />
            <token id="24" string="her" />
            <token id="25" string="son" />
          </tokens>
        </chunking>
        <chunking id="13" string="her son" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="son" />
          </tokens>
        </chunking>
        <chunking id="14" string="how the force of family worked on her son" type="SBAR">
          <tokens>
            <token id="17" string="how" />
            <token id="18" string="the" />
            <token id="19" string="force" />
            <token id="20" string="of" />
            <token id="21" string="family" />
            <token id="22" string="worked" />
            <token id="23" string="on" />
            <token id="24" string="her" />
            <token id="25" string="son" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="15">talked</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">day</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">day</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">day</governor>
          <dependent id="5">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">talked</governor>
          <dependent id="6">day</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Williams</governor>
          <dependent id="8">Leola</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">day</governor>
          <dependent id="9">Williams</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">mother</governor>
          <dependent id="11">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Thomas</governor>
          <dependent id="12">'</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Williams</governor>
          <dependent id="13">mother</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">talked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">worked</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">worked</governor>
          <dependent id="17">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">force</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">worked</governor>
          <dependent id="19">force</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">family</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">force</governor>
          <dependent id="21">family</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">talked</governor>
          <dependent id="22">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">son</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">son</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">worked</governor>
          <dependent id="25">son</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the other day" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="other" />
            <token id="6" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="Leola Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Leola" />
            <token id="9" string="Williams" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>&amp;quot;Clarence was surrounded by all our older parents.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="surrounded" lemma="surround" stem="surround" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="older" lemma="older" stem="older" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Clarence)) (VP (VBD was) (VP (VBN surrounded) (PP (IN by) (NP (DT all) (PRP$ our) (ADJP (JJR older)) (NNS parents))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all our older parents" type="NP">
          <tokens>
            <token id="6" string="all" />
            <token id="7" string="our" />
            <token id="8" string="older" />
            <token id="9" string="parents" />
          </tokens>
        </chunking>
        <chunking id="2" string="was surrounded by all our older parents" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="surrounded" />
            <token id="5" string="by" />
            <token id="6" string="all" />
            <token id="7" string="our" />
            <token id="8" string="older" />
            <token id="9" string="parents" />
          </tokens>
        </chunking>
        <chunking id="3" string="surrounded by all our older parents" type="VP">
          <tokens>
            <token id="4" string="surrounded" />
            <token id="5" string="by" />
            <token id="6" string="all" />
            <token id="7" string="our" />
            <token id="8" string="older" />
            <token id="9" string="parents" />
          </tokens>
        </chunking>
        <chunking id="4" string="older" type="ADJP">
          <tokens>
            <token id="8" string="older" />
          </tokens>
        </chunking>
        <chunking id="5" string="Clarence" type="NP">
          <tokens>
            <token id="2" string="Clarence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">surrounded</governor>
          <dependent id="2">Clarence</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">surrounded</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">surrounded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">parents</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="9">parents</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">parents</governor>
          <dependent id="7">our</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">parents</governor>
          <dependent id="8">older</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">surrounded</governor>
          <dependent id="9">parents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>He saw how our family and other people struggled to make a living.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="struggled" lemma="struggle" stem="struggl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD saw) (SBAR (WHADVP (WRB how)) (S (NP (NP (PRP$ our) (NN family)) (CC and) (NP (JJ other) (NNS people))) (VP (VBD struggled) (S (VP (TO to) (VP (VB make) (NP (DT a) (NN living))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="saw how our family and other people struggled to make a living" type="VP">
          <tokens>
            <token id="2" string="saw" />
            <token id="3" string="how" />
            <token id="4" string="our" />
            <token id="5" string="family" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="people" />
            <token id="9" string="struggled" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="2" string="struggled to make a living" type="VP">
          <tokens>
            <token id="9" string="struggled" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="3" string="make a living" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="4" string="our family" type="NP">
          <tokens>
            <token id="4" string="our" />
            <token id="5" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="other people" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="our family and other people" type="NP">
          <tokens>
            <token id="4" string="our" />
            <token id="5" string="family" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="to make a living" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="8" string="a living" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="9" string="how our family and other people struggled to make a living" type="SBAR">
          <tokens>
            <token id="3" string="how" />
            <token id="4" string="our" />
            <token id="5" string="family" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="people" />
            <token id="9" string="struggled" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="a" />
            <token id="13" string="living" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="11" string="how" type="WHADVP">
          <tokens>
            <token id="3" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">saw</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">saw</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">struggled</governor>
          <dependent id="3">how</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">family</governor>
          <dependent id="4">our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">struggled</governor>
          <dependent id="5">family</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">family</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">people</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">family</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">saw</governor>
          <dependent id="9">struggled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">make</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">struggled</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">living</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">make</governor>
          <dependent id="13">living</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;I guess Clarence wanted to prove to himself he could be what he wanted to be -- and prove to his grandfather he could be the kind of person (his grandfather) wanted him to be&amp;quot;.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="guess" lemma="guess" stem="guess" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP guess) (S (S (NP (NNP Clarence)) (VP (VBD wanted) (S (VP (TO to) (VP (VB prove) (PP (TO to) (NP (PRP himself)))))))) (S (NP (PRP he)) (VP (MD could) (VP (VB be) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBD wanted) (S (VP (TO to) (VP (VP (VB be)) (: --) (CC and) (VP (VB prove) (PP (TO to) (NP (PRP$ his) (NN grandfather))))))))))))) (S (NP (PRP he)) (VP (MD could) (VP (VB be) (NP (NP (DT the) (NN kind)) (PP (IN of) (NP (NN person))))))) (S (-LRB- -LRB-) (NP (PRP$ his) (NN grandfather)) (-RRB- -RRB-) (VP (VBD wanted) (S (NP (PRP him)) (VP (TO to) (VP (VB be)))))))) ('' '') (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could be what he wanted to be -- and prove to his grandfather" type="VP">
          <tokens>
            <token id="11" string="could" />
            <token id="12" string="be" />
            <token id="13" string="what" />
            <token id="14" string="he" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted to prove to himself" type="VP">
          <tokens>
            <token id="5" string="wanted" />
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="to" />
            <token id="9" string="himself" />
          </tokens>
        </chunking>
        <chunking id="3" string="the kind of person" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="kind" />
            <token id="29" string="of" />
            <token id="30" string="person" />
          </tokens>
        </chunking>
        <chunking id="4" string="prove to himself" type="VP">
          <tokens>
            <token id="7" string="prove" />
            <token id="8" string="to" />
            <token id="9" string="himself" />
          </tokens>
        </chunking>
        <chunking id="5" string="person" type="NP">
          <tokens>
            <token id="30" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="prove to his grandfather" type="VP">
          <tokens>
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="himself" type="NP">
          <tokens>
            <token id="9" string="himself" />
          </tokens>
        </chunking>
        <chunking id="9" string="the kind" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="kind" />
          </tokens>
        </chunking>
        <chunking id="10" string="be" type="VP">
          <tokens>
            <token id="17" string="be" />
          </tokens>
        </chunking>
        <chunking id="11" string="wanted to be -- and prove to his grandfather" type="VP">
          <tokens>
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="12" string="guess Clarence wanted to prove to himself he could be what he wanted to be -- and prove to his grandfather he could be the kind of person -LRB- his grandfather -RRB- wanted him to be" type="VP">
          <tokens>
            <token id="3" string="guess" />
            <token id="4" string="Clarence" />
            <token id="5" string="wanted" />
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="to" />
            <token id="9" string="himself" />
            <token id="10" string="he" />
            <token id="11" string="could" />
            <token id="12" string="be" />
            <token id="13" string="what" />
            <token id="14" string="he" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
            <token id="24" string="he" />
            <token id="25" string="could" />
            <token id="26" string="be" />
            <token id="27" string="the" />
            <token id="28" string="kind" />
            <token id="29" string="of" />
            <token id="30" string="person" />
            <token id="31" string="(" />
            <token id="32" string="his" />
            <token id="33" string="grandfather" />
            <token id="34" string=")" />
            <token id="35" string="wanted" />
            <token id="36" string="him" />
            <token id="37" string="to" />
            <token id="38" string="be" />
          </tokens>
        </chunking>
        <chunking id="13" string="his grandfather" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="14" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="15" string="him" type="NP">
          <tokens>
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="to prove to himself" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="prove" />
            <token id="8" string="to" />
            <token id="9" string="himself" />
          </tokens>
        </chunking>
        <chunking id="17" string="be -- and prove to his grandfather" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="18" string="Clarence" type="NP">
          <tokens>
            <token id="4" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="19" string="to be" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="be" />
          </tokens>
        </chunking>
        <chunking id="20" string="could be the kind of person" type="VP">
          <tokens>
            <token id="25" string="could" />
            <token id="26" string="be" />
            <token id="27" string="the" />
            <token id="28" string="kind" />
            <token id="29" string="of" />
            <token id="30" string="person" />
          </tokens>
        </chunking>
        <chunking id="21" string="wanted him to be" type="VP">
          <tokens>
            <token id="35" string="wanted" />
            <token id="36" string="him" />
            <token id="37" string="to" />
            <token id="38" string="be" />
          </tokens>
        </chunking>
        <chunking id="22" string="what he wanted to be -- and prove to his grandfather" type="SBAR">
          <tokens>
            <token id="13" string="what" />
            <token id="14" string="he" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="23" string="be what he wanted to be -- and prove to his grandfather" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="what" />
            <token id="14" string="he" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="24" string="to be -- and prove to his grandfather" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="--" />
            <token id="19" string="and" />
            <token id="20" string="prove" />
            <token id="21" string="to" />
            <token id="22" string="his" />
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="25" string="be the kind of person" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="the" />
            <token id="28" string="kind" />
            <token id="29" string="of" />
            <token id="30" string="person" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">guess</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">guess</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">wanted</governor>
          <dependent id="4">Clarence</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">guess</governor>
          <dependent id="5">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">prove</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">wanted</governor>
          <dependent id="7">prove</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">himself</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">prove</governor>
          <dependent id="9">himself</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">be</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">be</governor>
          <dependent id="11">could</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">wanted</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">wanted</governor>
          <dependent id="13">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">wanted</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">be</governor>
          <dependent id="15">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">be</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">wanted</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">be</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">be</governor>
          <dependent id="20">prove</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">grandfather</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">grandfather</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">prove</governor>
          <dependent id="23">grandfather</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">kind</governor>
          <dependent id="24">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">kind</governor>
          <dependent id="25">could</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">kind</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">kind</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">wanted</governor>
          <dependent id="28">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">person</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">kind</governor>
          <dependent id="30">person</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">grandfather</governor>
          <dependent id="32">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">wanted</governor>
          <dependent id="33">grandfather</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">wanted</governor>
          <dependent id="35">wanted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">wanted</governor>
          <dependent id="36">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">be</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="35">wanted</governor>
          <dependent id="38">be</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>The grandfather, the late Myers Anderson, began training Thomas in earnest when the boy was 9 and Leola Williams&amp;apost; life suddenly began coming apart.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Myers" lemma="Myers" stem="myer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="training" lemma="train" stem="train" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="earnest" lemma="earnest" stem="earnest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="boy" lemma="boy" stem="boi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Leola" lemma="Leola" stem="leola" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="apart" lemma="apart" stem="apart" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN grandfather)) (, ,) (NP (DT the) (JJ late) (NNP Myers) (NNP Anderson)) (, ,)) (VP (VBD began) (S (VP (VBG training) (NP (NP (NNP Thomas)) (PP (IN in) (NP (NN earnest)))))) (SBAR (WHADVP (WRB when)) (S (S (NP (DT the) (NN boy)) (VP (VBD was) (NP (CD 9)))) (CC and) (S (NP (NP (NNP Leola) (NNP Williams) (POS ')) (NN life)) (ADVP (RB suddenly)) (VP (VBD began) (S (VP (VBG coming) (ADVP (RB apart))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the late Myers Anderson" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="late" />
            <token id="6" string="Myers" />
            <token id="7" string="Anderson" />
          </tokens>
        </chunking>
        <chunking id="2" string="training Thomas in earnest" type="VP">
          <tokens>
            <token id="10" string="training" />
            <token id="11" string="Thomas" />
            <token id="12" string="in" />
            <token id="13" string="earnest" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="coming apart" type="VP">
          <tokens>
            <token id="26" string="coming" />
            <token id="27" string="apart" />
          </tokens>
        </chunking>
        <chunking id="5" string="The grandfather" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="6" string="when the boy was 9 and Leola Williams ' life suddenly began coming apart" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="the" />
            <token id="16" string="boy" />
            <token id="17" string="was" />
            <token id="18" string="9" />
            <token id="19" string="and" />
            <token id="20" string="Leola" />
            <token id="21" string="Williams" />
            <token id="22" string="'" />
            <token id="23" string="life" />
            <token id="24" string="suddenly" />
            <token id="25" string="began" />
            <token id="26" string="coming" />
            <token id="27" string="apart" />
          </tokens>
        </chunking>
        <chunking id="7" string="The grandfather , the late Myers Anderson ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="grandfather" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="late" />
            <token id="6" string="Myers" />
            <token id="7" string="Anderson" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="Leola Williams ' life" type="NP">
          <tokens>
            <token id="20" string="Leola" />
            <token id="21" string="Williams" />
            <token id="22" string="'" />
            <token id="23" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="Thomas in earnest" type="NP">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="in" />
            <token id="13" string="earnest" />
          </tokens>
        </chunking>
        <chunking id="11" string="the boy" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="boy" />
          </tokens>
        </chunking>
        <chunking id="12" string="began training Thomas in earnest when the boy was 9 and Leola Williams ' life suddenly began coming apart" type="VP">
          <tokens>
            <token id="9" string="began" />
            <token id="10" string="training" />
            <token id="11" string="Thomas" />
            <token id="12" string="in" />
            <token id="13" string="earnest" />
            <token id="14" string="when" />
            <token id="15" string="the" />
            <token id="16" string="boy" />
            <token id="17" string="was" />
            <token id="18" string="9" />
            <token id="19" string="and" />
            <token id="20" string="Leola" />
            <token id="21" string="Williams" />
            <token id="22" string="'" />
            <token id="23" string="life" />
            <token id="24" string="suddenly" />
            <token id="25" string="began" />
            <token id="26" string="coming" />
            <token id="27" string="apart" />
          </tokens>
        </chunking>
        <chunking id="13" string="earnest" type="NP">
          <tokens>
            <token id="13" string="earnest" />
          </tokens>
        </chunking>
        <chunking id="14" string="9" type="NP">
          <tokens>
            <token id="18" string="9" />
          </tokens>
        </chunking>
        <chunking id="15" string="Leola Williams '" type="NP">
          <tokens>
            <token id="20" string="Leola" />
            <token id="21" string="Williams" />
            <token id="22" string="'" />
          </tokens>
        </chunking>
        <chunking id="16" string="began coming apart" type="VP">
          <tokens>
            <token id="25" string="began" />
            <token id="26" string="coming" />
            <token id="27" string="apart" />
          </tokens>
        </chunking>
        <chunking id="17" string="was 9" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="9" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">grandfather</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">began</governor>
          <dependent id="2">grandfather</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Anderson</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Anderson</governor>
          <dependent id="5">late</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Anderson</governor>
          <dependent id="6">Myers</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">grandfather</governor>
          <dependent id="7">Anderson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">began</governor>
          <dependent id="10">training</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">training</governor>
          <dependent id="11">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">earnest</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Thomas</governor>
          <dependent id="13">earnest</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">9</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">boy</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">9</governor>
          <dependent id="16">boy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">9</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">began</governor>
          <dependent id="18">9</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">9</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Williams</governor>
          <dependent id="20">Leola</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">life</governor>
          <dependent id="21">Williams</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Williams</governor>
          <dependent id="22">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">began</governor>
          <dependent id="23">life</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">began</governor>
          <dependent id="24">suddenly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">9</governor>
          <dependent id="25">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">began</governor>
          <dependent id="26">coming</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">coming</governor>
          <dependent id="27">apart</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Myers Anderson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Myers" />
            <token id="7" string="Anderson" />
          </tokens>
        </entity>
        <entity id="2" string="Leola Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Leola" />
            <token id="21" string="Williams" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="9" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="9" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Her house off Pin Point Avenue had gone up in smoke, and some months later, her husband went north to Philadelphia, leaving her with two young children and a third on the way.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Pin" lemma="pin" stem="pin" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Avenue" lemma="Avenue" stem="avenu" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="smoke" lemma="smoke" stem="smoke" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="north" lemma="north" stem="north" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Philadelphia" lemma="Philadelphia" stem="philadelphia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="leaving" lemma="leave" stem="leav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (PRP$ Her) (NN house)) (PP (IN off) (NP (NN Pin) (NN Point) (NNP Avenue)))) (VP (VBD had) (VP (VBN gone) (ADVP (RB up)) (PP (IN in) (NP (NN smoke)))))) (, ,) (CC and) (S (NP (DT some) (NNS months)) (ADVP (RB later)) (, ,) (NP (PRP$ her) (NN husband)) (VP (VBD went) (ADVP (RB north) (PP (TO to) (NP (NNP Philadelphia)))) (, ,) (S (VP (VBG leaving) (NP (PRP$ her)) (PP (IN with) (NP (NP (CD two) (JJ young) (NNS children)) (CC and) (NP (DT a) (JJ third)))) (PP (IN on) (NP (DT the) (NN way))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had gone up in smoke" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="gone" />
            <token id="9" string="up" />
            <token id="10" string="in" />
            <token id="11" string="smoke" />
          </tokens>
        </chunking>
        <chunking id="2" string="two young children" type="NP">
          <tokens>
            <token id="28" string="two" />
            <token id="29" string="young" />
            <token id="30" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="leaving her with two young children and a third on the way" type="VP">
          <tokens>
            <token id="25" string="leaving" />
            <token id="26" string="her" />
            <token id="27" string="with" />
            <token id="28" string="two" />
            <token id="29" string="young" />
            <token id="30" string="children" />
            <token id="31" string="and" />
            <token id="32" string="a" />
            <token id="33" string="third" />
            <token id="34" string="on" />
            <token id="35" string="the" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="went north to Philadelphia , leaving her with two young children and a third on the way" type="VP">
          <tokens>
            <token id="20" string="went" />
            <token id="21" string="north" />
            <token id="22" string="to" />
            <token id="23" string="Philadelphia" />
            <token id="24" string="," />
            <token id="25" string="leaving" />
            <token id="26" string="her" />
            <token id="27" string="with" />
            <token id="28" string="two" />
            <token id="29" string="young" />
            <token id="30" string="children" />
            <token id="31" string="and" />
            <token id="32" string="a" />
            <token id="33" string="third" />
            <token id="34" string="on" />
            <token id="35" string="the" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="5" string="smoke" type="NP">
          <tokens>
            <token id="11" string="smoke" />
          </tokens>
        </chunking>
        <chunking id="6" string="a third" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="third" />
          </tokens>
        </chunking>
        <chunking id="7" string="gone up in smoke" type="VP">
          <tokens>
            <token id="8" string="gone" />
            <token id="9" string="up" />
            <token id="10" string="in" />
            <token id="11" string="smoke" />
          </tokens>
        </chunking>
        <chunking id="8" string="Her house" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="house" />
          </tokens>
        </chunking>
        <chunking id="9" string="Her house off Pin Point Avenue" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="house" />
            <token id="3" string="off" />
            <token id="4" string="Pin" />
            <token id="5" string="Point" />
            <token id="6" string="Avenue" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="26" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="the way" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="12" string="Pin Point Avenue" type="NP">
          <tokens>
            <token id="4" string="Pin" />
            <token id="5" string="Point" />
            <token id="6" string="Avenue" />
          </tokens>
        </chunking>
        <chunking id="13" string="two young children and a third" type="NP">
          <tokens>
            <token id="28" string="two" />
            <token id="29" string="young" />
            <token id="30" string="children" />
            <token id="31" string="and" />
            <token id="32" string="a" />
            <token id="33" string="third" />
          </tokens>
        </chunking>
        <chunking id="14" string="some months" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="months" />
          </tokens>
        </chunking>
        <chunking id="15" string="her husband" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="husband" />
          </tokens>
        </chunking>
        <chunking id="16" string="Philadelphia" type="NP">
          <tokens>
            <token id="23" string="Philadelphia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">house</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">gone</governor>
          <dependent id="2">house</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Avenue</governor>
          <dependent id="3">off</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Avenue</governor>
          <dependent id="4">Pin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Avenue</governor>
          <dependent id="5">Point</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">house</governor>
          <dependent id="6">Avenue</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">gone</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">gone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">gone</governor>
          <dependent id="9">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">smoke</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">gone</governor>
          <dependent id="11">smoke</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">gone</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">months</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">went</governor>
          <dependent id="15">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">went</governor>
          <dependent id="16">later</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">husband</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">went</governor>
          <dependent id="19">husband</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">gone</governor>
          <dependent id="20">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">went</governor>
          <dependent id="21">north</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Philadelphia</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">north</governor>
          <dependent id="23">Philadelphia</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">went</governor>
          <dependent id="25">leaving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">leaving</governor>
          <dependent id="26">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">children</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">children</governor>
          <dependent id="28">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">children</governor>
          <dependent id="29">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">leaving</governor>
          <dependent id="30">children</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">children</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">third</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">children</governor>
          <dependent id="33">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">way</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">way</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">leaving</governor>
          <dependent id="36">way</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="months later" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="months" />
            <token id="16" string="later" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="33" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="Pin Point Avenue" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Pin" />
            <token id="5" string="Point" />
            <token id="6" string="Avenue" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="two" />
          </tokens>
        </entity>
        <entity id="5" string="Philadelphia" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Philadelphia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Williams took her daughter, Emma Mae, and moved in with an aunt while she awaited the birth of her second son, Myers.</content>
      <tokens>
        <token id="1" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Emma" lemma="Emma" stem="emma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Mae" lemma="Mae" stem="mae" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="aunt" lemma="aunt" stem="aunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="awaited" lemma="await" stem="await" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="birth" lemma="birth" stem="birth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="23" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Myers" lemma="Myers" stem="myer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Williams)) (VP (VP (VBD took) (NP (NP (PRP$ her) (NN daughter)) (, ,) (NP (NNP Emma) (NNP Mae)) (, ,))) (CC and) (VP (VBD moved) (PP (IN in) (PP (IN with) (NP (DT an) (NN aunt)))) (SBAR (IN while) (S (NP (PRP she)) (VP (VBD awaited) (NP (NP (DT the) (NN birth)) (PP (IN of) (NP (NP (PRP$ her) (JJ second) (NN son)) (, ,) (NP (NNP Myers)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her second son , Myers" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="2" string="took her daughter , Emma Mae , and moved in with an aunt while she awaited the birth of her second son , Myers" type="VP">
          <tokens>
            <token id="2" string="took" />
            <token id="3" string="her" />
            <token id="4" string="daughter" />
            <token id="5" string="," />
            <token id="6" string="Emma" />
            <token id="7" string="Mae" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="moved" />
            <token id="11" string="in" />
            <token id="12" string="with" />
            <token id="13" string="an" />
            <token id="14" string="aunt" />
            <token id="15" string="while" />
            <token id="16" string="she" />
            <token id="17" string="awaited" />
            <token id="18" string="the" />
            <token id="19" string="birth" />
            <token id="20" string="of" />
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="3" string="while she awaited the birth of her second son , Myers" type="SBAR">
          <tokens>
            <token id="15" string="while" />
            <token id="16" string="she" />
            <token id="17" string="awaited" />
            <token id="18" string="the" />
            <token id="19" string="birth" />
            <token id="20" string="of" />
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="4" string="Williams" type="NP">
          <tokens>
            <token id="1" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="5" string="the birth" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="birth" />
          </tokens>
        </chunking>
        <chunking id="6" string="Myers" type="NP">
          <tokens>
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="7" string="took her daughter , Emma Mae ," type="VP">
          <tokens>
            <token id="2" string="took" />
            <token id="3" string="her" />
            <token id="4" string="daughter" />
            <token id="5" string="," />
            <token id="6" string="Emma" />
            <token id="7" string="Mae" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="moved in with an aunt while she awaited the birth of her second son , Myers" type="VP">
          <tokens>
            <token id="10" string="moved" />
            <token id="11" string="in" />
            <token id="12" string="with" />
            <token id="13" string="an" />
            <token id="14" string="aunt" />
            <token id="15" string="while" />
            <token id="16" string="she" />
            <token id="17" string="awaited" />
            <token id="18" string="the" />
            <token id="19" string="birth" />
            <token id="20" string="of" />
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="9" string="an aunt" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="aunt" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="16" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="her daughter" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="12" string="Emma Mae" type="NP">
          <tokens>
            <token id="6" string="Emma" />
            <token id="7" string="Mae" />
          </tokens>
        </chunking>
        <chunking id="13" string="her daughter , Emma Mae ," type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="daughter" />
            <token id="5" string="," />
            <token id="6" string="Emma" />
            <token id="7" string="Mae" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="her second son" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
          </tokens>
        </chunking>
        <chunking id="15" string="awaited the birth of her second son , Myers" type="VP">
          <tokens>
            <token id="17" string="awaited" />
            <token id="18" string="the" />
            <token id="19" string="birth" />
            <token id="20" string="of" />
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
        <chunking id="16" string="the birth of her second son , Myers" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="birth" />
            <token id="20" string="of" />
            <token id="21" string="her" />
            <token id="22" string="second" />
            <token id="23" string="son" />
            <token id="24" string="," />
            <token id="25" string="Myers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">took</governor>
          <dependent id="1">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">took</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">daughter</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">took</governor>
          <dependent id="4">daughter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Mae</governor>
          <dependent id="6">Emma</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">daughter</governor>
          <dependent id="7">Mae</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">took</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">took</governor>
          <dependent id="10">moved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">aunt</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">aunt</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">aunt</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">moved</governor>
          <dependent id="14">aunt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">awaited</governor>
          <dependent id="15">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">awaited</governor>
          <dependent id="16">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">moved</governor>
          <dependent id="17">awaited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">birth</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">awaited</governor>
          <dependent id="19">birth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">son</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">son</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">son</governor>
          <dependent id="22">second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">birth</governor>
          <dependent id="23">son</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">son</governor>
          <dependent id="25">Myers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Emma Mae" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Emma" />
            <token id="7" string="Mae" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="22" string="second" />
          </tokens>
        </entity>
        <entity id="3" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Williams" />
          </tokens>
        </entity>
        <entity id="4" string="Myers" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Myers" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Clarence went to live with his grandparents in Savannah, to help with Anderson&amp;apost;s year-round oil and ice delivery business.</content>
      <tokens>
        <token id="1" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="year-round" lemma="year-round" stem="year-round" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="ice" lemma="ice" stem="ic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="delivery" lemma="delivery" stem="deliveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Clarence)) (VP (VBD went) (S (VP (TO to) (VP (VB live) (PP (IN with) (NP (PRP$ his) (NNS grandparents))) (PP (IN in) (NP (NNP Savannah)))))) (, ,) (S (VP (TO to) (VP (VB help) (PP (IN with) (NP (NP (NNP Anderson) (POS 's)) (JJ year-round) (NN oil) (CC and) (NN ice) (NN delivery) (NN business))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="help with Anderson 's year-round oil and ice delivery business" type="VP">
          <tokens>
            <token id="12" string="help" />
            <token id="13" string="with" />
            <token id="14" string="Anderson" />
            <token id="15" string="'s" />
            <token id="16" string="year-round" />
            <token id="17" string="oil" />
            <token id="18" string="and" />
            <token id="19" string="ice" />
            <token id="20" string="delivery" />
            <token id="21" string="business" />
          </tokens>
        </chunking>
        <chunking id="2" string="his grandparents" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="3" string="to help with Anderson 's year-round oil and ice delivery business" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="with" />
            <token id="14" string="Anderson" />
            <token id="15" string="'s" />
            <token id="16" string="year-round" />
            <token id="17" string="oil" />
            <token id="18" string="and" />
            <token id="19" string="ice" />
            <token id="20" string="delivery" />
            <token id="21" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="Anderson 's year-round oil and ice delivery business" type="NP">
          <tokens>
            <token id="14" string="Anderson" />
            <token id="15" string="'s" />
            <token id="16" string="year-round" />
            <token id="17" string="oil" />
            <token id="18" string="and" />
            <token id="19" string="ice" />
            <token id="20" string="delivery" />
            <token id="21" string="business" />
          </tokens>
        </chunking>
        <chunking id="5" string="Anderson 's" type="NP">
          <tokens>
            <token id="14" string="Anderson" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="live with his grandparents in Savannah" type="VP">
          <tokens>
            <token id="4" string="live" />
            <token id="5" string="with" />
            <token id="6" string="his" />
            <token id="7" string="grandparents" />
            <token id="8" string="in" />
            <token id="9" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="7" string="Savannah" type="NP">
          <tokens>
            <token id="9" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="8" string="went to live with his grandparents in Savannah , to help with Anderson 's year-round oil and ice delivery business" type="VP">
          <tokens>
            <token id="2" string="went" />
            <token id="3" string="to" />
            <token id="4" string="live" />
            <token id="5" string="with" />
            <token id="6" string="his" />
            <token id="7" string="grandparents" />
            <token id="8" string="in" />
            <token id="9" string="Savannah" />
            <token id="10" string="," />
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="with" />
            <token id="14" string="Anderson" />
            <token id="15" string="'s" />
            <token id="16" string="year-round" />
            <token id="17" string="oil" />
            <token id="18" string="and" />
            <token id="19" string="ice" />
            <token id="20" string="delivery" />
            <token id="21" string="business" />
          </tokens>
        </chunking>
        <chunking id="9" string="to live with his grandparents in Savannah" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="live" />
            <token id="5" string="with" />
            <token id="6" string="his" />
            <token id="7" string="grandparents" />
            <token id="8" string="in" />
            <token id="9" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="10" string="Clarence" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">went</governor>
          <dependent id="1">Clarence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">went</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">live</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">went</governor>
          <dependent id="4">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">grandparents</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">grandparents</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">live</governor>
          <dependent id="7">grandparents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Savannah</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">live</governor>
          <dependent id="9">Savannah</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">help</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">went</governor>
          <dependent id="12">help</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">oil</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">oil</governor>
          <dependent id="14">Anderson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Anderson</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">oil</governor>
          <dependent id="16">year-round</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">help</governor>
          <dependent id="17">oil</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">oil</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">business</governor>
          <dependent id="19">ice</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">business</governor>
          <dependent id="20">delivery</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">oil</governor>
          <dependent id="21">business</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Savannah" />
          </tokens>
        </entity>
        <entity id="2" string="Anderson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Anderson" />
          </tokens>
        </entity>
        <entity id="3" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>His grandfather proved to be a profound force in Thomas&amp;apost; life -- a mentor, a role model, an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="proved" lemma="prove" stem="prove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="profound" lemma="profound" stem="profound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="mentor" lemma="mentor" stem="mentor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="unrelenting" lemma="unrelenting" stem="unrel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="taskmaster" lemma="taskmaster" stem="taskmast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="embodiment" lemma="embodiment" stem="embodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ His) (NN grandfather)) (VP (VBD proved) (S (VP (TO to) (VP (VB be) (NP (NP (NP (DT a) (JJ profound) (NN force)) (PP (IN in) (NP (NP (NNP Thomas) (POS ')) (NN life)))) (: --) (NP (NP (DT a) (NN mentor)) (, ,) (NP (DT a) (NN role) (NN model)) (, ,) (NP (DT an) (JJ unrelenting) (NN taskmaster)) (CC and) (NP (NP (DT the) (NN embodiment)) (PP (IN of) (NP (DT a) (JJ personal) (NN philosophy))) (SBAR (WHNP (WDT that)) (S (NP (NNP Thomas)) (ADVP (RB once)) (VP (VBD recalled) (NP (DT this) (NN way)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="proved to be a profound force in Thomas ' life -- a mentor , a role model , an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way" type="VP">
          <tokens>
            <token id="3" string="proved" />
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
            <token id="9" string="in" />
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
            <token id="13" string="--" />
            <token id="14" string="a" />
            <token id="15" string="mentor" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
            <token id="20" string="," />
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="2" string="a mentor" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="mentor" />
          </tokens>
        </chunking>
        <chunking id="3" string="to be a profound force in Thomas ' life -- a mentor , a role model , an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
            <token id="9" string="in" />
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
            <token id="13" string="--" />
            <token id="14" string="a" />
            <token id="15" string="mentor" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
            <token id="20" string="," />
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas ' life" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="32" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="a profound force in Thomas ' life" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
            <token id="9" string="in" />
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas '" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="His grandfather" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="9" string="a profound force" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="a mentor , a role model , an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="mentor" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
            <token id="20" string="," />
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="11" string="be a profound force in Thomas ' life -- a mentor , a role model , an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
            <token id="9" string="in" />
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
            <token id="13" string="--" />
            <token id="14" string="a" />
            <token id="15" string="mentor" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
            <token id="20" string="," />
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="12" string="an unrelenting taskmaster" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
          </tokens>
        </chunking>
        <chunking id="13" string="a profound force in Thomas ' life -- a mentor , a role model , an unrelenting taskmaster and the embodiment of a personal philosophy that Thomas once recalled this way" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="profound" />
            <token id="8" string="force" />
            <token id="9" string="in" />
            <token id="10" string="Thomas" />
            <token id="11" string="'" />
            <token id="12" string="life" />
            <token id="13" string="--" />
            <token id="14" string="a" />
            <token id="15" string="mentor" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
            <token id="20" string="," />
            <token id="21" string="an" />
            <token id="22" string="unrelenting" />
            <token id="23" string="taskmaster" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="14" string="that Thomas once recalled this way" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="15" string="this way" type="NP">
          <tokens>
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="16" string="the embodiment" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
          </tokens>
        </chunking>
        <chunking id="17" string="a role model" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="role" />
            <token id="19" string="model" />
          </tokens>
        </chunking>
        <chunking id="18" string="the embodiment of a personal philosophy that Thomas once recalled this way" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="embodiment" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
            <token id="31" string="that" />
            <token id="32" string="Thomas" />
            <token id="33" string="once" />
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="19" string="recalled this way" type="VP">
          <tokens>
            <token id="34" string="recalled" />
            <token id="35" string="this" />
            <token id="36" string="way" />
          </tokens>
        </chunking>
        <chunking id="20" string="a personal philosophy" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="personal" />
            <token id="30" string="philosophy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">grandfather</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">proved</governor>
          <dependent id="2">grandfather</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">proved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">force</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">force</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">force</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">force</governor>
          <dependent id="7">profound</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">proved</governor>
          <dependent id="8">force</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">life</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">life</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Thomas</governor>
          <dependent id="11">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">force</governor>
          <dependent id="12">life</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">mentor</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">force</governor>
          <dependent id="15">mentor</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">model</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">model</governor>
          <dependent id="18">role</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">mentor</governor>
          <dependent id="19">model</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">taskmaster</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">taskmaster</governor>
          <dependent id="22">unrelenting</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">mentor</governor>
          <dependent id="23">taskmaster</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">mentor</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">embodiment</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">mentor</governor>
          <dependent id="26">embodiment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">philosophy</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">philosophy</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">philosophy</governor>
          <dependent id="29">personal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">embodiment</governor>
          <dependent id="30">philosophy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">recalled</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">recalled</governor>
          <dependent id="32">Thomas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">recalled</governor>
          <dependent id="33">once</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">embodiment</governor>
          <dependent id="34">recalled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">way</governor>
          <dependent id="35">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">recalled</governor>
          <dependent id="36">way</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>&amp;quot;He used to tell me that there was no problem that elbow grease couldn&amp;apost;t solve.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="elbow" lemma="elbow" stem="elbow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="grease" lemma="grease" stem="greas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="solve" lemma="solve" stem="solv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP He)) (VP (VBD used) (S (VP (TO to) (VP (VB tell) (NP (PRP me)) (SBAR (IN that) (S (NP (EX there)) (VP (VBD was) (NP (NP (DT no) (NN problem)) (SBAR (WHNP (WDT that)) (S (NP (NN elbow) (NN grease)) (VP (MD could) (RB n't) (VP (VB solve))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that elbow grease could n't solve" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell me that there was no problem that elbow grease could n't solve" type="VP">
          <tokens>
            <token id="5" string="tell" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="there" />
            <token id="9" string="was" />
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="3" string="to tell me that there was no problem that elbow grease could n't solve" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="tell" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="there" />
            <token id="9" string="was" />
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="4" string="used to tell me that there was no problem that elbow grease could n't solve" type="VP">
          <tokens>
            <token id="3" string="used" />
            <token id="4" string="to" />
            <token id="5" string="tell" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="there" />
            <token id="9" string="was" />
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="5" string="there" type="NP">
          <tokens>
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="no problem that elbow grease could n't solve" type="NP">
          <tokens>
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="7" string="no problem" type="NP">
          <tokens>
            <token id="10" string="no" />
            <token id="11" string="problem" />
          </tokens>
        </chunking>
        <chunking id="8" string="elbow grease" type="NP">
          <tokens>
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
          </tokens>
        </chunking>
        <chunking id="9" string="could n't solve" type="VP">
          <tokens>
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="10" string="solve" type="VP">
          <tokens>
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="11" string="me" type="NP">
          <tokens>
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="13" string="that there was no problem that elbow grease could n't solve" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="there" />
            <token id="9" string="was" />
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
        <chunking id="14" string="was no problem that elbow grease could n't solve" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="no" />
            <token id="11" string="problem" />
            <token id="12" string="that" />
            <token id="13" string="elbow" />
            <token id="14" string="grease" />
            <token id="15" string="could" />
            <token id="16" string="n't" />
            <token id="17" string="solve" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">used</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">tell</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">used</governor>
          <dependent id="5">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">tell</governor>
          <dependent id="6">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">was</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="9">was</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">tell</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">problem</governor>
          <dependent id="10">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">was</governor>
          <dependent id="11">problem</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">solve</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">grease</governor>
          <dependent id="13">elbow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">solve</governor>
          <dependent id="14">grease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">solve</governor>
          <dependent id="15">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">solve</governor>
          <dependent id="16">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">problem</governor>
          <dependent id="17">solve</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Then he&amp;apost;d say, &amp;quot;Old Man Can&amp;apost;t is dead.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (PRP he)) (VP (MD 'd) (VP (VB say) (, ,) (`` ``) (S (NP (JJ Old) (NN Man)) (VP (MD Ca) (RB n't) (VP (VBZ is) (ADJP (JJ dead))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ca n't is dead" type="VP">
          <tokens>
            <token id="9" string="Ca" />
            <token id="10" string="n't" />
            <token id="11" string="is" />
            <token id="12" string="dead" />
          </tokens>
        </chunking>
        <chunking id="2" string="say , `` Old Man Ca n't is dead" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="Old" />
            <token id="8" string="Man" />
            <token id="9" string="Ca" />
            <token id="10" string="n't" />
            <token id="11" string="is" />
            <token id="12" string="dead" />
          </tokens>
        </chunking>
        <chunking id="3" string="is dead" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="dead" />
          </tokens>
        </chunking>
        <chunking id="4" string="Old Man" type="NP">
          <tokens>
            <token id="7" string="Old" />
            <token id="8" string="Man" />
          </tokens>
        </chunking>
        <chunking id="5" string="'d say , `` Old Man Ca n't is dead" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="say" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="Old" />
            <token id="8" string="Man" />
            <token id="9" string="Ca" />
            <token id="10" string="n't" />
            <token id="11" string="is" />
            <token id="12" string="dead" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="dead" type="ADJP">
          <tokens>
            <token id="12" string="dead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">say</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">say</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Man</governor>
          <dependent id="7">Old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">dead</governor>
          <dependent id="8">Man</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">dead</governor>
          <dependent id="9">Ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">dead</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">dead</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="12">dead</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>I helped bury him&amp;quot;.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="bury" lemma="bury" stem="buri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD helped) (VP (VB bury) (NP (PRP him) ('' '')))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="him ''" type="NP">
          <tokens>
            <token id="4" string="him" />
            <token id="5" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="bury him ''" type="VP">
          <tokens>
            <token id="3" string="bury" />
            <token id="4" string="him" />
            <token id="5" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="helped bury him ''" type="VP">
          <tokens>
            <token id="2" string="helped" />
            <token id="3" string="bury" />
            <token id="4" string="him" />
            <token id="5" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">helped</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">helped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">helped</governor>
          <dependent id="3">bury</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">bury</governor>
          <dependent id="4">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>When Anderson wasn&amp;apost;t coaching Thomas, in his farm fields or on his delivery truck, he made sure the lessons continued, in the hands of the Franciscan nuns of all-black St. Benedict the Moor School.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="coaching" lemma="coaching" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="farm" lemma="farm" stem="farm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="fields" lemma="field" stem="field" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="delivery" lemma="delivery" stem="deliveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="truck" lemma="truck" stem="truck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="lessons" lemma="lesson" stem="lesson" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="Franciscan" lemma="franciscan" stem="franciscan" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="31" string="nuns" lemma="nun" stem="nun" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="all-black" lemma="all-black" stem="all-black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="Benedict" lemma="Benedict" stem="benedict" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="Moor" lemma="Moor" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="38" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NNP Anderson)) (VP (VBD was) (RB n't) (NP (NN coaching) (NNP Thomas))))) (, ,) (PP (PP (IN in) (NP (PRP$ his) (NN farm) (NNS fields))) (CC or) (PP (IN on) (NP (PRP$ his) (NN delivery) (NN truck)))) (, ,) (NP (PRP he)) (VP (VBD made) (ADJP (JJ sure) (SBAR (S (NP (DT the) (NNS lessons)) (VP (VBD continued))))) (, ,) (PP (IN in) (NP (NP (DT the) (NNS hands)) (PP (IN of) (NP (NP (DT the) (JJ Franciscan) (NNS nuns)) (PP (IN of) (NP (NP (JJ all-black) (NNP St.) (NNP Benedict)) (NP (DT the) (NNP Moor) (NNP School))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sure the lessons continued" type="ADJP">
          <tokens>
            <token id="20" string="sure" />
            <token id="21" string="the" />
            <token id="22" string="lessons" />
            <token id="23" string="continued" />
          </tokens>
        </chunking>
        <chunking id="2" string="the hands" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="hands" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Franciscan nuns" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Franciscan" />
            <token id="31" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="4" string="the lessons continued" type="SBAR">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="lessons" />
            <token id="23" string="continued" />
          </tokens>
        </chunking>
        <chunking id="5" string="continued" type="VP">
          <tokens>
            <token id="23" string="continued" />
          </tokens>
        </chunking>
        <chunking id="6" string="the hands of the Franciscan nuns of all-black St. Benedict the Moor School" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="hands" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Franciscan" />
            <token id="31" string="nuns" />
            <token id="32" string="of" />
            <token id="33" string="all-black" />
            <token id="34" string="St." />
            <token id="35" string="Benedict" />
            <token id="36" string="the" />
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </chunking>
        <chunking id="7" string="all-black St. Benedict the Moor School" type="NP">
          <tokens>
            <token id="33" string="all-black" />
            <token id="34" string="St." />
            <token id="35" string="Benedict" />
            <token id="36" string="the" />
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </chunking>
        <chunking id="8" string="coaching Thomas" type="NP">
          <tokens>
            <token id="5" string="coaching" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="9" string="the lessons" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="lessons" />
          </tokens>
        </chunking>
        <chunking id="10" string="Anderson" type="NP">
          <tokens>
            <token id="2" string="Anderson" />
          </tokens>
        </chunking>
        <chunking id="11" string="made sure the lessons continued , in the hands of the Franciscan nuns of all-black St. Benedict the Moor School" type="VP">
          <tokens>
            <token id="19" string="made" />
            <token id="20" string="sure" />
            <token id="21" string="the" />
            <token id="22" string="lessons" />
            <token id="23" string="continued" />
            <token id="24" string="," />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="hands" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Franciscan" />
            <token id="31" string="nuns" />
            <token id="32" string="of" />
            <token id="33" string="all-black" />
            <token id="34" string="St." />
            <token id="35" string="Benedict" />
            <token id="36" string="the" />
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </chunking>
        <chunking id="12" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="13" string="his farm fields" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="farm" />
            <token id="11" string="fields" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Moor School" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </chunking>
        <chunking id="15" string="When Anderson was n't coaching Thomas" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Anderson" />
            <token id="3" string="was" />
            <token id="4" string="n't" />
            <token id="5" string="coaching" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Franciscan nuns of all-black St. Benedict the Moor School" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Franciscan" />
            <token id="31" string="nuns" />
            <token id="32" string="of" />
            <token id="33" string="all-black" />
            <token id="34" string="St." />
            <token id="35" string="Benedict" />
            <token id="36" string="the" />
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </chunking>
        <chunking id="17" string="his delivery truck" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="delivery" />
            <token id="16" string="truck" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="all-black St. Benedict" type="NP">
          <tokens>
            <token id="33" string="all-black" />
            <token id="34" string="St." />
            <token id="35" string="Benedict" />
          </tokens>
        </chunking>
        <chunking id="20" string="was n't coaching Thomas" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="n't" />
            <token id="5" string="coaching" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">Thomas</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">Thomas</governor>
          <dependent id="2">Anderson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">Thomas</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">Thomas</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Thomas</governor>
          <dependent id="5">coaching</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">made</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fields</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">fields</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">fields</governor>
          <dependent id="10">farm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">made</governor>
          <dependent id="11">fields</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">made</governor>
          <dependent id="12">or</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">truck</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">truck</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">truck</governor>
          <dependent id="15">delivery</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">made</governor>
          <dependent id="16">truck</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">made</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">made</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">made</governor>
          <dependent id="19">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">made</governor>
          <dependent id="20">sure</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">lessons</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">continued</governor>
          <dependent id="22">lessons</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">sure</governor>
          <dependent id="23">continued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">hands</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">hands</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">made</governor>
          <dependent id="27">hands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">nuns</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">nuns</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">nuns</governor>
          <dependent id="30">Franciscan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">hands</governor>
          <dependent id="31">nuns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Benedict</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Benedict</governor>
          <dependent id="33">all-black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Benedict</governor>
          <dependent id="34">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">nuns</governor>
          <dependent id="35">Benedict</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">School</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">School</governor>
          <dependent id="37">Moor</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">Benedict</governor>
          <dependent id="38">School</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Franciscan" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="30" string="Franciscan" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Benedict" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Benedict" />
          </tokens>
        </entity>
        <entity id="4" string="Anderson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Anderson" />
          </tokens>
        </entity>
        <entity id="5" string="Moor School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="37" string="Moor" />
            <token id="38" string="School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Thomas, who had experienced racial mistreatment by white seminarians in Georgia, ultimately rejected seminary life.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="experienced" lemma="experience" stem="experienc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="mistreatment" lemma="mistreatment" stem="mistreat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="seminarians" lemma="seminarian" stem="seminarian" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ultimately" lemma="ultimately" stem="ultim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="rejected" lemma="reject" stem="reject" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="seminary" lemma="seminary" stem="seminari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN experienced) (NP (JJ racial) (NN mistreatment)) (PP (IN by) (NP (NP (JJ white) (NNS seminarians)) (PP (IN in) (NP (NNP Georgia))))))))) (, ,)) (ADVP (RB ultimately)) (VP (VBD rejected) (NP (JJ seminary) (NN life))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="rejected seminary life" type="VP">
          <tokens>
            <token id="15" string="rejected" />
            <token id="16" string="seminary" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="had experienced racial mistreatment by white seminarians in Georgia" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="experienced" />
            <token id="6" string="racial" />
            <token id="7" string="mistreatment" />
            <token id="8" string="by" />
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
            <token id="11" string="in" />
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="3" string="seminary life" type="NP">
          <tokens>
            <token id="16" string="seminary" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas , who had experienced racial mistreatment by white seminarians in Georgia ," type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="experienced" />
            <token id="6" string="racial" />
            <token id="7" string="mistreatment" />
            <token id="8" string="by" />
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
            <token id="11" string="in" />
            <token id="12" string="Georgia" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="who had experienced racial mistreatment by white seminarians in Georgia" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="experienced" />
            <token id="6" string="racial" />
            <token id="7" string="mistreatment" />
            <token id="8" string="by" />
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
            <token id="11" string="in" />
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="racial mistreatment" type="NP">
          <tokens>
            <token id="6" string="racial" />
            <token id="7" string="mistreatment" />
          </tokens>
        </chunking>
        <chunking id="8" string="Georgia" type="NP">
          <tokens>
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="9" string="white seminarians in Georgia" type="NP">
          <tokens>
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
            <token id="11" string="in" />
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="10" string="white seminarians" type="NP">
          <tokens>
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
          </tokens>
        </chunking>
        <chunking id="11" string="experienced racial mistreatment by white seminarians in Georgia" type="VP">
          <tokens>
            <token id="5" string="experienced" />
            <token id="6" string="racial" />
            <token id="7" string="mistreatment" />
            <token id="8" string="by" />
            <token id="9" string="white" />
            <token id="10" string="seminarians" />
            <token id="11" string="in" />
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">rejected</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">experienced</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">experienced</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Thomas</governor>
          <dependent id="5">experienced</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">mistreatment</governor>
          <dependent id="6">racial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">experienced</governor>
          <dependent id="7">mistreatment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">seminarians</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">seminarians</governor>
          <dependent id="9">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">experienced</governor>
          <dependent id="10">seminarians</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Georgia</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">seminarians</governor>
          <dependent id="12">Georgia</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">rejected</governor>
          <dependent id="14">ultimately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">rejected</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">life</governor>
          <dependent id="16">seminary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">rejected</governor>
          <dependent id="17">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Georgia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>He has identified an episode at Immaculate Conception Seminary in Conception, Mo., in 1968 as the final humiliation.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="identified" lemma="identify" stem="identifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="episode" lemma="episode" stem="episod" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Immaculate" lemma="immaculate" stem="immacul" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Conception" lemma="conception" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Seminary" lemma="Seminary" stem="seminari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Conception" lemma="conception" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Mo." lemma="Mo." stem="mo." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1968" lemma="1968" stem="1968" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="humiliation" lemma="humiliation" stem="humili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ has) (VP (VBN identified) (NP (NP (DT an) (NN episode)) (PP (IN at) (NP (NP (JJ Immaculate) (NN Conception) (NNP Seminary)) (PP (IN in) (NP (NP (NN Conception)) (, ,) (NP (NNP Mo.)) (, ,)))))) (PP (IN in) (NP (CD 1968))) (PP (IN as) (NP (DT the) (JJ final) (NN humiliation))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the final humiliation" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="final" />
            <token id="20" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="2" string="an episode at Immaculate Conception Seminary in Conception , Mo. ," type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="episode" />
            <token id="6" string="at" />
            <token id="7" string="Immaculate" />
            <token id="8" string="Conception" />
            <token id="9" string="Seminary" />
            <token id="10" string="in" />
            <token id="11" string="Conception" />
            <token id="12" string="," />
            <token id="13" string="Mo." />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="identified an episode at Immaculate Conception Seminary in Conception , Mo. , in 1968 as the final humiliation" type="VP">
          <tokens>
            <token id="3" string="identified" />
            <token id="4" string="an" />
            <token id="5" string="episode" />
            <token id="6" string="at" />
            <token id="7" string="Immaculate" />
            <token id="8" string="Conception" />
            <token id="9" string="Seminary" />
            <token id="10" string="in" />
            <token id="11" string="Conception" />
            <token id="12" string="," />
            <token id="13" string="Mo." />
            <token id="14" string="," />
            <token id="15" string="in" />
            <token id="16" string="1968" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="final" />
            <token id="20" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="4" string="an episode" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="episode" />
          </tokens>
        </chunking>
        <chunking id="5" string="Immaculate Conception Seminary" type="NP">
          <tokens>
            <token id="7" string="Immaculate" />
            <token id="8" string="Conception" />
            <token id="9" string="Seminary" />
          </tokens>
        </chunking>
        <chunking id="6" string="Conception" type="NP">
          <tokens>
            <token id="11" string="Conception" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mo." type="NP">
          <tokens>
            <token id="13" string="Mo." />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="Conception , Mo. ," type="NP">
          <tokens>
            <token id="11" string="Conception" />
            <token id="12" string="," />
            <token id="13" string="Mo." />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="Immaculate Conception Seminary in Conception , Mo. ," type="NP">
          <tokens>
            <token id="7" string="Immaculate" />
            <token id="8" string="Conception" />
            <token id="9" string="Seminary" />
            <token id="10" string="in" />
            <token id="11" string="Conception" />
            <token id="12" string="," />
            <token id="13" string="Mo." />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="has identified an episode at Immaculate Conception Seminary in Conception , Mo. , in 1968 as the final humiliation" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="identified" />
            <token id="4" string="an" />
            <token id="5" string="episode" />
            <token id="6" string="at" />
            <token id="7" string="Immaculate" />
            <token id="8" string="Conception" />
            <token id="9" string="Seminary" />
            <token id="10" string="in" />
            <token id="11" string="Conception" />
            <token id="12" string="," />
            <token id="13" string="Mo." />
            <token id="14" string="," />
            <token id="15" string="in" />
            <token id="16" string="1968" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="final" />
            <token id="20" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="12" string="1968" type="NP">
          <tokens>
            <token id="16" string="1968" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">identified</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">identified</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">identified</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">episode</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">identified</governor>
          <dependent id="5">episode</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Seminary</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Seminary</governor>
          <dependent id="7">Immaculate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Seminary</governor>
          <dependent id="8">Conception</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">episode</governor>
          <dependent id="9">Seminary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Conception</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Seminary</governor>
          <dependent id="11">Conception</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Conception</governor>
          <dependent id="13">Mo.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1968</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">identified</governor>
          <dependent id="16">1968</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">humiliation</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">humiliation</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">humiliation</governor>
          <dependent id="19">final</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">identified</governor>
          <dependent id="20">humiliation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mo." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Mo." />
          </tokens>
        </entity>
        <entity id="2" string="1968" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1968" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>He said he heard a seminarian there react to the shooting of Dr. Martin Luther King Jr. by saying, &amp;quot;Good, I hope the son of a bitch dies&amp;quot;.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="seminarian" lemma="seminarian" stem="seminarian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="react" lemma="react" stem="react" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="shooting" lemma="shooting" stem="shoot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Luther" lemma="Luther" stem="luther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="bitch" lemma="bitch" stem="bitch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="dies" lemma="die" stem="di" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD heard) (SBAR (S (NP (DT a) (NN seminarian)) (ADVP (RB there)) (VP (VBP react) (PP (TO to) (NP (NP (DT the) (NN shooting)) (PP (IN of) (NP (NNP Dr.) (NNP Martin) (NNP Luther) (NNP King) (NNP Jr.))))) (PP (IN by) (S (VP (VBG saying) (, ,) (`` ``) (S (INTJ (JJ Good)) (, ,) (NP (PRP I)) (VP (VBP hope) (SBAR (S (NP (NP (DT the) (NN son)) (PP (IN of) (NP (DT a) (NN bitch)))) (VP (VBZ dies))))) ('' '')))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="saying , `` Good , I hope the son of a bitch dies ''" type="VP">
          <tokens>
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="the shooting of Dr. Martin Luther King Jr." type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="3" string="the son of a bitch" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
          </tokens>
        </chunking>
        <chunking id="4" string="heard a seminarian there react to the shooting of Dr. Martin Luther King Jr. by saying , `` Good , I hope the son of a bitch dies ''" type="VP">
          <tokens>
            <token id="4" string="heard" />
            <token id="5" string="a" />
            <token id="6" string="seminarian" />
            <token id="7" string="there" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
            <token id="18" string="by" />
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="he heard a seminarian there react to the shooting of Dr. Martin Luther King Jr. by saying , `` Good , I hope the son of a bitch dies ''" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="heard" />
            <token id="5" string="a" />
            <token id="6" string="seminarian" />
            <token id="7" string="there" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
            <token id="18" string="by" />
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="24" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="the son" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="son" />
          </tokens>
        </chunking>
        <chunking id="8" string="the shooting" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="shooting" />
          </tokens>
        </chunking>
        <chunking id="9" string="a seminarian" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="seminarian" />
          </tokens>
        </chunking>
        <chunking id="10" string="react to the shooting of Dr. Martin Luther King Jr. by saying , `` Good , I hope the son of a bitch dies ''" type="VP">
          <tokens>
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
            <token id="18" string="by" />
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="11" string="Dr. Martin Luther King Jr." type="NP">
          <tokens>
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="12" string="a seminarian there react to the shooting of Dr. Martin Luther King Jr. by saying , `` Good , I hope the son of a bitch dies ''" type="SBAR">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="seminarian" />
            <token id="7" string="there" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
            <token id="18" string="by" />
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="hope the son of a bitch dies" type="VP">
          <tokens>
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="the son of a bitch dies" type="SBAR">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
          </tokens>
        </chunking>
        <chunking id="17" string="a bitch" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="bitch" />
          </tokens>
        </chunking>
        <chunking id="18" string="dies" type="VP">
          <tokens>
            <token id="31" string="dies" />
          </tokens>
        </chunking>
        <chunking id="19" string="said he heard a seminarian there react to the shooting of Dr. Martin Luther King Jr. by saying , `` Good , I hope the son of a bitch dies ''" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="heard" />
            <token id="5" string="a" />
            <token id="6" string="seminarian" />
            <token id="7" string="there" />
            <token id="8" string="react" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="shooting" />
            <token id="12" string="of" />
            <token id="13" string="Dr." />
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
            <token id="18" string="by" />
            <token id="19" string="saying" />
            <token id="20" string="," />
            <token id="21" string="&quot;" />
            <token id="22" string="Good" />
            <token id="23" string="," />
            <token id="24" string="I" />
            <token id="25" string="hope" />
            <token id="26" string="the" />
            <token id="27" string="son" />
            <token id="28" string="of" />
            <token id="29" string="a" />
            <token id="30" string="bitch" />
            <token id="31" string="dies" />
            <token id="32" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">heard</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">heard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">seminarian</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">react</governor>
          <dependent id="6">seminarian</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">react</governor>
          <dependent id="7">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">heard</governor>
          <dependent id="8">react</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">shooting</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">shooting</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">react</governor>
          <dependent id="11">shooting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Jr.</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Jr.</governor>
          <dependent id="13">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Jr.</governor>
          <dependent id="14">Martin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Jr.</governor>
          <dependent id="15">Luther</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Jr.</governor>
          <dependent id="16">King</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">shooting</governor>
          <dependent id="17">Jr.</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">saying</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">react</governor>
          <dependent id="19">saying</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="25">hope</governor>
          <dependent id="22">Good</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">hope</governor>
          <dependent id="24">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">saying</governor>
          <dependent id="25">hope</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">son</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">dies</governor>
          <dependent id="27">son</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">bitch</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">bitch</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">son</governor>
          <dependent id="30">bitch</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">hope</governor>
          <dependent id="31">dies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Martin Luther King Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Martin" />
            <token id="15" string="Luther" />
            <token id="16" string="King" />
            <token id="17" string="Jr." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Thomas left the seminary and went north to enroll at Holy Cross College in the gritty New England factory city of Worcester, Mass.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="seminary" lemma="seminary" stem="seminari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="north" lemma="north" stem="north" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="enroll" lemma="enroll" stem="enrol" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Holy" lemma="Holy" stem="holi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Cross" lemma="Cross" stem="cross" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="gritty" lemma="gritty" stem="gritti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="factory" lemma="factory" stem="factori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Worcester" lemma="Worcester" stem="worcest" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Mass" lemma="Mass." stem="mass" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thomas)) (VP (VP (VBD left) (NP (DT the) (JJ seminary))) (CC and) (VP (VBD went) (ADVP (RB north) (S (VP (TO to) (VP (VB enroll) (PP (IN at) (NP (NP (NNP Holy) (NNP Cross) (NNP College)) (PP (IN in) (NP (NP (DT the) (JJ gritty) (NNP New) (NNP England) (NN factory) (NN city)) (PP (IN of) (NP (NNP Worcester) (, ,) (NNP Mass.))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the seminary" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="seminary" />
          </tokens>
        </chunking>
        <chunking id="2" string="went north to enroll at Holy Cross College in the gritty New England factory city of Worcester , Mass." type="VP">
          <tokens>
            <token id="6" string="went" />
            <token id="7" string="north" />
            <token id="8" string="to" />
            <token id="9" string="enroll" />
            <token id="10" string="at" />
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="3" string="left the seminary and went north to enroll at Holy Cross College in the gritty New England factory city of Worcester , Mass." type="VP">
          <tokens>
            <token id="2" string="left" />
            <token id="3" string="the" />
            <token id="4" string="seminary" />
            <token id="5" string="and" />
            <token id="6" string="went" />
            <token id="7" string="north" />
            <token id="8" string="to" />
            <token id="9" string="enroll" />
            <token id="10" string="at" />
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="4" string="to enroll at Holy Cross College in the gritty New England factory city of Worcester , Mass." type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="enroll" />
            <token id="10" string="at" />
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="5" string="left the seminary" type="VP">
          <tokens>
            <token id="2" string="left" />
            <token id="3" string="the" />
            <token id="4" string="seminary" />
          </tokens>
        </chunking>
        <chunking id="6" string="the gritty New England factory city" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="enroll at Holy Cross College in the gritty New England factory city of Worcester , Mass." type="VP">
          <tokens>
            <token id="9" string="enroll" />
            <token id="10" string="at" />
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="9" string="Worcester , Mass." type="NP">
          <tokens>
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="10" string="Holy Cross College" type="NP">
          <tokens>
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
          </tokens>
        </chunking>
        <chunking id="11" string="Holy Cross College in the gritty New England factory city of Worcester , Mass." type="NP">
          <tokens>
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="12" string="the gritty New England factory city of Worcester , Mass." type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="gritty" />
            <token id="17" string="New" />
            <token id="18" string="England" />
            <token id="19" string="factory" />
            <token id="20" string="city" />
            <token id="21" string="of" />
            <token id="22" string="Worcester" />
            <token id="23" string="," />
            <token id="24" string="Mass" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">left</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">left</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">seminary</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">left</governor>
          <dependent id="4">seminary</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">left</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">left</governor>
          <dependent id="6">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">went</governor>
          <dependent id="7">north</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">enroll</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">north</governor>
          <dependent id="9">enroll</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">College</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">College</governor>
          <dependent id="11">Holy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">College</governor>
          <dependent id="12">Cross</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">enroll</governor>
          <dependent id="13">College</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">city</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">city</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">city</governor>
          <dependent id="16">gritty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">city</governor>
          <dependent id="17">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">city</governor>
          <dependent id="18">England</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">city</governor>
          <dependent id="19">factory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">College</governor>
          <dependent id="20">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Mass.</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Mass.</governor>
          <dependent id="22">Worcester</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">city</governor>
          <dependent id="24">Mass.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="New England" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="New" />
            <token id="18" string="England" />
          </tokens>
        </entity>
        <entity id="3" string="Worcester" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Worcester" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Mass" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Mass" />
          </tokens>
        </entity>
        <entity id="6" string="Holy Cross College" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Holy" />
            <token id="12" string="Cross" />
            <token id="13" string="College" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>A Southerner in New England; The Southern farm boy was forced to endure not only the harsh winters of New England, but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Southerner" lemma="southerner" stem="southern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="farm" lemma="farm" stem="farm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="boy" lemma="boy" stem="boi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="forced" lemma="force" stem="forc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="endure" lemma="endure" stem="endur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="harsh" lemma="harsh" stem="harsh" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="winters" lemma="winter" stem="winter" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="chilly" lemma="chilly" stem="chilli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="atmosphere" lemma="atmosphere" stem="atmospher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="college" lemma="college" stem="colleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="beginning" lemma="begin" stem="begin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="widen" lemma="widen" stem="widen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="opportunities" lemma="opportunity" stem="opportun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN Southerner)) (PP (IN in) (NP (NP (NNP New) (NNP England)) (: ;) (NP (DT The) (NNP Southern) (NN farm) (NN boy))))) (VP (VBD was) (VP (VBN forced) (S (VP (TO to) (VP (VB endure) (NP (CONJP (RB not) (RB only)) (NP (NP (DT the) (JJ harsh) (NNS winters)) (PP (IN of) (NP (NNP New) (NNP England)))) (, ,) (CONJP (CC but) (RB also)) (NP (NP (DT the) (JJ chilly) (NN atmosphere)) (PP (IN of) (NP (DT a) (JJ white) (NN college))) (VP (ADVP (RB just)) (VBG beginning) (S (VP (TO to) (VP (VB widen) (NP (NP (NNS opportunities)) (PP (IN for) (NP (NNS blacks))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="2" string="the chilly atmosphere" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
          </tokens>
        </chunking>
        <chunking id="3" string="a white college" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
          </tokens>
        </chunking>
        <chunking id="4" string="A Southerner in New England ; The Southern farm boy" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Southerner" />
            <token id="3" string="in" />
            <token id="4" string="New" />
            <token id="5" string="England" />
            <token id="6" string=";" />
            <token id="7" string="The" />
            <token id="8" string="Southern" />
            <token id="9" string="farm" />
            <token id="10" string="boy" />
          </tokens>
        </chunking>
        <chunking id="5" string="the harsh winters" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
          </tokens>
        </chunking>
        <chunking id="6" string="widen opportunities for blacks" type="VP">
          <tokens>
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="was forced to endure not only the harsh winters of New England , but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="forced" />
            <token id="13" string="to" />
            <token id="14" string="endure" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="also" />
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="8" string="New England ; The Southern farm boy" type="NP">
          <tokens>
            <token id="4" string="New" />
            <token id="5" string="England" />
            <token id="6" string=";" />
            <token id="7" string="The" />
            <token id="8" string="Southern" />
            <token id="9" string="farm" />
            <token id="10" string="boy" />
          </tokens>
        </chunking>
        <chunking id="9" string="forced to endure not only the harsh winters of New England , but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="12" string="forced" />
            <token id="13" string="to" />
            <token id="14" string="endure" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="also" />
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="10" string="blacks" type="NP">
          <tokens>
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="11" string="the harsh winters of New England" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
          </tokens>
        </chunking>
        <chunking id="12" string="not only the harsh winters of New England , but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="NP">
          <tokens>
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="also" />
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="13" string="opportunities" type="NP">
          <tokens>
            <token id="37" string="opportunities" />
          </tokens>
        </chunking>
        <chunking id="14" string="just beginning to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="15" string="endure not only the harsh winters of New England , but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="14" string="endure" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="also" />
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="16" string="the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="17" string="The Southern farm boy" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Southern" />
            <token id="9" string="farm" />
            <token id="10" string="boy" />
          </tokens>
        </chunking>
        <chunking id="18" string="New England" type="NP">
          <tokens>
            <token id="4" string="New" />
            <token id="5" string="England" />
          </tokens>
        </chunking>
        <chunking id="19" string="A Southerner" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Southerner" />
          </tokens>
        </chunking>
        <chunking id="20" string="to endure not only the harsh winters of New England , but also the chilly atmosphere of a white college just beginning to widen opportunities for blacks" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="endure" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="the" />
            <token id="18" string="harsh" />
            <token id="19" string="winters" />
            <token id="20" string="of" />
            <token id="21" string="New" />
            <token id="22" string="England" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="also" />
            <token id="26" string="the" />
            <token id="27" string="chilly" />
            <token id="28" string="atmosphere" />
            <token id="29" string="of" />
            <token id="30" string="a" />
            <token id="31" string="white" />
            <token id="32" string="college" />
            <token id="33" string="just" />
            <token id="34" string="beginning" />
            <token id="35" string="to" />
            <token id="36" string="widen" />
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="21" string="opportunities for blacks" type="NP">
          <tokens>
            <token id="37" string="opportunities" />
            <token id="38" string="for" />
            <token id="39" string="blacks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Southerner</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">forced</governor>
          <dependent id="2">Southerner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">England</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">England</governor>
          <dependent id="4">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Southerner</governor>
          <dependent id="5">England</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">boy</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">boy</governor>
          <dependent id="8">Southern</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">boy</governor>
          <dependent id="9">farm</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">England</governor>
          <dependent id="10">boy</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">forced</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">forced</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">endure</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">forced</governor>
          <dependent id="14">endure</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">only</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="19">winters</governor>
          <dependent id="16">only</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">winters</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">winters</governor>
          <dependent id="18">harsh</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">endure</governor>
          <dependent id="19">winters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">England</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">England</governor>
          <dependent id="21">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">winters</governor>
          <dependent id="22">England</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">winters</governor>
          <dependent id="24">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">atmosphere</governor>
          <dependent id="25">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">atmosphere</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">atmosphere</governor>
          <dependent id="27">chilly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">winters</governor>
          <dependent id="28">atmosphere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">college</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">college</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">college</governor>
          <dependent id="31">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">atmosphere</governor>
          <dependent id="32">college</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">beginning</governor>
          <dependent id="33">just</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">atmosphere</governor>
          <dependent id="34">beginning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">widen</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">beginning</governor>
          <dependent id="36">widen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">widen</governor>
          <dependent id="37">opportunities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">blacks</governor>
          <dependent id="38">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">opportunities</governor>
          <dependent id="39">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New England" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="New" />
            <token id="5" string="England" />
          </tokens>
        </entity>
        <entity id="2" string="winters" type="SET" score="0.0">
          <tokens>
            <token id="19" string="winters" />
          </tokens>
        </entity>
        <entity id="3" string="Southern" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Southern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Within days of King&amp;apost;s assassination, the school created a scholarship fund named after the civil-rights leader and stepped up the recruiting of blacks.</content>
      <tokens>
        <token id="1" string="Within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="assassination" lemma="assassination" stem="assassin" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="created" lemma="create" stem="creat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="scholarship" lemma="scholarship" stem="scholarship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="fund" lemma="fund" stem="fund" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="civil-rights" lemma="civil-rights" stem="civil-right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="stepped" lemma="step" stem="step" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="recruiting" lemma="recruiting" stem="recruit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Within) (NP (NP (NNS days)) (PP (IN of) (NP (NP (NNP King) (POS 's)) (NN assassination))))) (, ,) (NP (DT the) (NN school)) (VP (VP (VBD created) (NP (NP (DT a) (NN scholarship) (NN fund)) (VP (VBN named) (PP (IN after) (NP (DT the) (NNS civil-rights) (NN leader)))))) (CC and) (VP (VBD stepped) (PRT (RP up)) (NP (NP (DT the) (NN recruiting)) (PP (IN of) (NP (NNS blacks)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the recruiting of blacks" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="recruiting" />
            <token id="24" string="of" />
            <token id="25" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="2" string="the recruiting" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="recruiting" />
          </tokens>
        </chunking>
        <chunking id="3" string="King 's" type="NP">
          <tokens>
            <token id="4" string="King" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="blacks" type="NP">
          <tokens>
            <token id="25" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="5" string="King 's assassination" type="NP">
          <tokens>
            <token id="4" string="King" />
            <token id="5" string="'s" />
            <token id="6" string="assassination" />
          </tokens>
        </chunking>
        <chunking id="6" string="stepped up the recruiting of blacks" type="VP">
          <tokens>
            <token id="20" string="stepped" />
            <token id="21" string="up" />
            <token id="22" string="the" />
            <token id="23" string="recruiting" />
            <token id="24" string="of" />
            <token id="25" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="the school" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="8" string="a scholarship fund" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="scholarship" />
            <token id="13" string="fund" />
          </tokens>
        </chunking>
        <chunking id="9" string="a scholarship fund named after the civil-rights leader" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="scholarship" />
            <token id="13" string="fund" />
            <token id="14" string="named" />
            <token id="15" string="after" />
            <token id="16" string="the" />
            <token id="17" string="civil-rights" />
            <token id="18" string="leader" />
          </tokens>
        </chunking>
        <chunking id="10" string="days" type="NP">
          <tokens>
            <token id="2" string="days" />
          </tokens>
        </chunking>
        <chunking id="11" string="the civil-rights leader" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="civil-rights" />
            <token id="18" string="leader" />
          </tokens>
        </chunking>
        <chunking id="12" string="created a scholarship fund named after the civil-rights leader and stepped up the recruiting of blacks" type="VP">
          <tokens>
            <token id="10" string="created" />
            <token id="11" string="a" />
            <token id="12" string="scholarship" />
            <token id="13" string="fund" />
            <token id="14" string="named" />
            <token id="15" string="after" />
            <token id="16" string="the" />
            <token id="17" string="civil-rights" />
            <token id="18" string="leader" />
            <token id="19" string="and" />
            <token id="20" string="stepped" />
            <token id="21" string="up" />
            <token id="22" string="the" />
            <token id="23" string="recruiting" />
            <token id="24" string="of" />
            <token id="25" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="13" string="created a scholarship fund named after the civil-rights leader" type="VP">
          <tokens>
            <token id="10" string="created" />
            <token id="11" string="a" />
            <token id="12" string="scholarship" />
            <token id="13" string="fund" />
            <token id="14" string="named" />
            <token id="15" string="after" />
            <token id="16" string="the" />
            <token id="17" string="civil-rights" />
            <token id="18" string="leader" />
          </tokens>
        </chunking>
        <chunking id="14" string="named after the civil-rights leader" type="VP">
          <tokens>
            <token id="14" string="named" />
            <token id="15" string="after" />
            <token id="16" string="the" />
            <token id="17" string="civil-rights" />
            <token id="18" string="leader" />
          </tokens>
        </chunking>
        <chunking id="15" string="days of King 's assassination" type="NP">
          <tokens>
            <token id="2" string="days" />
            <token id="3" string="of" />
            <token id="4" string="King" />
            <token id="5" string="'s" />
            <token id="6" string="assassination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">days</governor>
          <dependent id="1">Within</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">created</governor>
          <dependent id="2">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">assassination</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">assassination</governor>
          <dependent id="4">King</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">King</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">days</governor>
          <dependent id="6">assassination</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">school</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">created</governor>
          <dependent id="9">school</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">created</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">fund</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">fund</governor>
          <dependent id="12">scholarship</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">created</governor>
          <dependent id="13">fund</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">fund</governor>
          <dependent id="14">named</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">leader</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">leader</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">leader</governor>
          <dependent id="17">civil-rights</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">named</governor>
          <dependent id="18">leader</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">created</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">created</governor>
          <dependent id="20">stepped</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="20">stepped</governor>
          <dependent id="21">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">recruiting</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">stepped</governor>
          <dependent id="23">recruiting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">blacks</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">recruiting</governor>
          <dependent id="25">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="assassination" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="6" string="assassination" />
          </tokens>
        </entity>
        <entity id="3" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>And so Thomas, who was driven from the Missouri seminary by racism, became one of the beneficiaries of an effort to combat it.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="driven" lemma="drive" stem="driven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="Missouri" lemma="Missouri" stem="missouri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="11" string="seminary" lemma="seminary" stem="seminari" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="beneficiaries" lemma="beneficiary" stem="beneficiari" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="combat" lemma="combat" stem="combat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (RB so) (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN driven) (PP (IN from) (NP (DT the) (NNP Missouri) (NN seminary))) (PP (IN by) (NP (NN racism))))))) (, ,)) (VP (VBD became) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NNS beneficiaries)) (PP (IN of) (NP (DT an) (NN effort) (S (VP (TO to) (VP (VB combat) (NP (PRP it))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Missouri seminary" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Missouri" />
            <token id="11" string="seminary" />
          </tokens>
        </chunking>
        <chunking id="2" string="racism" type="NP">
          <tokens>
            <token id="13" string="racism" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="was driven from the Missouri seminary by racism" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="driven" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Missouri" />
            <token id="11" string="seminary" />
            <token id="12" string="by" />
            <token id="13" string="racism" />
          </tokens>
        </chunking>
        <chunking id="5" string="an effort to combat it" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="effort" />
            <token id="23" string="to" />
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="so Thomas" type="NP">
          <tokens>
            <token id="2" string="so" />
            <token id="3" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="became one of the beneficiaries of an effort to combat it" type="VP">
          <tokens>
            <token id="15" string="became" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="beneficiaries" />
            <token id="20" string="of" />
            <token id="21" string="an" />
            <token id="22" string="effort" />
            <token id="23" string="to" />
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="so Thomas , who was driven from the Missouri seminary by racism ," type="NP">
          <tokens>
            <token id="2" string="so" />
            <token id="3" string="Thomas" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="was" />
            <token id="7" string="driven" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Missouri" />
            <token id="11" string="seminary" />
            <token id="12" string="by" />
            <token id="13" string="racism" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="to combat it" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="who was driven from the Missouri seminary by racism" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="was" />
            <token id="7" string="driven" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Missouri" />
            <token id="11" string="seminary" />
            <token id="12" string="by" />
            <token id="13" string="racism" />
          </tokens>
        </chunking>
        <chunking id="12" string="the beneficiaries" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="beneficiaries" />
          </tokens>
        </chunking>
        <chunking id="13" string="one of the beneficiaries of an effort to combat it" type="NP">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="beneficiaries" />
            <token id="20" string="of" />
            <token id="21" string="an" />
            <token id="22" string="effort" />
            <token id="23" string="to" />
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="combat it" type="VP">
          <tokens>
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="the beneficiaries of an effort to combat it" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="beneficiaries" />
            <token id="20" string="of" />
            <token id="21" string="an" />
            <token id="22" string="effort" />
            <token id="23" string="to" />
            <token id="24" string="combat" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="driven from the Missouri seminary by racism" type="VP">
          <tokens>
            <token id="7" string="driven" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="Missouri" />
            <token id="11" string="seminary" />
            <token id="12" string="by" />
            <token id="13" string="racism" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">became</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">Thomas</governor>
          <dependent id="2">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">became</governor>
          <dependent id="3">Thomas</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">driven</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">driven</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Thomas</governor>
          <dependent id="7">driven</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">seminary</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">seminary</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">seminary</governor>
          <dependent id="10">Missouri</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">driven</governor>
          <dependent id="11">seminary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">racism</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">driven</governor>
          <dependent id="13">racism</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">became</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">became</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">beneficiaries</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">beneficiaries</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">one</governor>
          <dependent id="19">beneficiaries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">effort</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">effort</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">beneficiaries</governor>
          <dependent id="22">effort</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">combat</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">effort</governor>
          <dependent id="24">combat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">combat</governor>
          <dependent id="25">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Missouri" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Missouri" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Thomas, who paid for his college education with loans, jobs and the newly raised scholarship funds, soon was drawn into the turbulence of Vietnam War and &amp;quot;black power&amp;quot; politics.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="paid" lemma="pay" stem="paid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="college" lemma="college" stem="colleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="loans" lemma="loan" stem="loan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="newly" lemma="newly" stem="newli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="raised" lemma="raise" stem="rais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="scholarship" lemma="scholarship" stem="scholarship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="funds" lemma="fund" stem="fund" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="drawn" lemma="draw" stem="drawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="turbulence" lemma="turbulence" stem="turbul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Vietnam" lemma="Vietnam" stem="vietnam" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="28" string="War" lemma="War" stem="war" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD paid) (PP (IN for) (NP (PRP$ his) (NN college) (NN education))) (PP (IN with) (NP (NP (NNS loans)) (, ,) (NP (NNS jobs)) (CC and) (NP (DT the) (ADJP (RB newly) (VBN raised)) (NN scholarship) (NNS funds))))))) (, ,)) (ADVP (RB soon)) (VP (VBD was) (VP (VBN drawn) (PP (IN into) (NP (NP (DT the) (NN turbulence)) (PP (IN of) (NP (NP (NNP Vietnam) (NNP War)) (CC and) (NP (`` ``) (JJ black) (NN power) ('' '') (NNS politics)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Vietnam War" type="NP">
          <tokens>
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` black power '' politics" type="NP">
          <tokens>
            <token id="30" string="&quot;" />
            <token id="31" string="black" />
            <token id="32" string="power" />
            <token id="33" string="&quot;" />
            <token id="34" string="politics" />
          </tokens>
        </chunking>
        <chunking id="3" string="jobs" type="NP">
          <tokens>
            <token id="12" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="4" string="the turbulence" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="turbulence" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas , who paid for his college education with loans , jobs and the newly raised scholarship funds ," type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="paid" />
            <token id="5" string="for" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="education" />
            <token id="9" string="with" />
            <token id="10" string="loans" />
            <token id="11" string="," />
            <token id="12" string="jobs" />
            <token id="13" string="and" />
            <token id="14" string="the" />
            <token id="15" string="newly" />
            <token id="16" string="raised" />
            <token id="17" string="scholarship" />
            <token id="18" string="funds" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="loans" type="NP">
          <tokens>
            <token id="10" string="loans" />
          </tokens>
        </chunking>
        <chunking id="8" string="who paid for his college education with loans , jobs and the newly raised scholarship funds" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="paid" />
            <token id="5" string="for" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="education" />
            <token id="9" string="with" />
            <token id="10" string="loans" />
            <token id="11" string="," />
            <token id="12" string="jobs" />
            <token id="13" string="and" />
            <token id="14" string="the" />
            <token id="15" string="newly" />
            <token id="16" string="raised" />
            <token id="17" string="scholarship" />
            <token id="18" string="funds" />
          </tokens>
        </chunking>
        <chunking id="9" string="paid for his college education with loans , jobs and the newly raised scholarship funds" type="VP">
          <tokens>
            <token id="4" string="paid" />
            <token id="5" string="for" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="education" />
            <token id="9" string="with" />
            <token id="10" string="loans" />
            <token id="11" string="," />
            <token id="12" string="jobs" />
            <token id="13" string="and" />
            <token id="14" string="the" />
            <token id="15" string="newly" />
            <token id="16" string="raised" />
            <token id="17" string="scholarship" />
            <token id="18" string="funds" />
          </tokens>
        </chunking>
        <chunking id="10" string="drawn into the turbulence of Vietnam War and `` black power '' politics" type="VP">
          <tokens>
            <token id="22" string="drawn" />
            <token id="23" string="into" />
            <token id="24" string="the" />
            <token id="25" string="turbulence" />
            <token id="26" string="of" />
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
            <token id="29" string="and" />
            <token id="30" string="&quot;" />
            <token id="31" string="black" />
            <token id="32" string="power" />
            <token id="33" string="&quot;" />
            <token id="34" string="politics" />
          </tokens>
        </chunking>
        <chunking id="11" string="his college education" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="education" />
          </tokens>
        </chunking>
        <chunking id="12" string="the turbulence of Vietnam War and `` black power '' politics" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="turbulence" />
            <token id="26" string="of" />
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
            <token id="29" string="and" />
            <token id="30" string="&quot;" />
            <token id="31" string="black" />
            <token id="32" string="power" />
            <token id="33" string="&quot;" />
            <token id="34" string="politics" />
          </tokens>
        </chunking>
        <chunking id="13" string="loans , jobs and the newly raised scholarship funds" type="NP">
          <tokens>
            <token id="10" string="loans" />
            <token id="11" string="," />
            <token id="12" string="jobs" />
            <token id="13" string="and" />
            <token id="14" string="the" />
            <token id="15" string="newly" />
            <token id="16" string="raised" />
            <token id="17" string="scholarship" />
            <token id="18" string="funds" />
          </tokens>
        </chunking>
        <chunking id="14" string="newly raised" type="ADJP">
          <tokens>
            <token id="15" string="newly" />
            <token id="16" string="raised" />
          </tokens>
        </chunking>
        <chunking id="15" string="was drawn into the turbulence of Vietnam War and `` black power '' politics" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="drawn" />
            <token id="23" string="into" />
            <token id="24" string="the" />
            <token id="25" string="turbulence" />
            <token id="26" string="of" />
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
            <token id="29" string="and" />
            <token id="30" string="&quot;" />
            <token id="31" string="black" />
            <token id="32" string="power" />
            <token id="33" string="&quot;" />
            <token id="34" string="politics" />
          </tokens>
        </chunking>
        <chunking id="16" string="Vietnam War and `` black power '' politics" type="NP">
          <tokens>
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
            <token id="29" string="and" />
            <token id="30" string="&quot;" />
            <token id="31" string="black" />
            <token id="32" string="power" />
            <token id="33" string="&quot;" />
            <token id="34" string="politics" />
          </tokens>
        </chunking>
        <chunking id="17" string="the newly raised scholarship funds" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="newly" />
            <token id="16" string="raised" />
            <token id="17" string="scholarship" />
            <token id="18" string="funds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="22">drawn</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">paid</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Thomas</governor>
          <dependent id="4">paid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">education</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">education</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">education</governor>
          <dependent id="7">college</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">paid</governor>
          <dependent id="8">education</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">loans</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">paid</governor>
          <dependent id="10">loans</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">loans</governor>
          <dependent id="12">jobs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">loans</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">funds</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">raised</governor>
          <dependent id="15">newly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">funds</governor>
          <dependent id="16">raised</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">funds</governor>
          <dependent id="17">scholarship</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">loans</governor>
          <dependent id="18">funds</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">drawn</governor>
          <dependent id="20">soon</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">drawn</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">drawn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">turbulence</governor>
          <dependent id="23">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">turbulence</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">drawn</governor>
          <dependent id="25">turbulence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">War</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">War</governor>
          <dependent id="27">Vietnam</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">turbulence</governor>
          <dependent id="28">War</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">War</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">politics</governor>
          <dependent id="31">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">politics</governor>
          <dependent id="32">power</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">War</governor>
          <dependent id="34">politics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Vietnam War" type="MISC" score="0.0">
          <tokens>
            <token id="27" string="Vietnam" />
            <token id="28" string="War" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>He helped found a Black Student Union, writing and typing its constitution.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="Student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="7" string="Union" lemma="Union" stem="union" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="writing" lemma="write" stem="write" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="typing" lemma="typing" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="constitution" lemma="constitution" stem="constitut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD helped) (S (VP (VP (VBN found) (NP (DT a) (JJ Black) (NN Student) (NNP Union)) (, ,) (S (VP (VBG writing)))) (CC and) (VP (NN typing) (NP (PRP$ its) (NN constitution)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="helped found a Black Student Union , writing and typing its constitution" type="VP">
          <tokens>
            <token id="2" string="helped" />
            <token id="3" string="found" />
            <token id="4" string="a" />
            <token id="5" string="Black" />
            <token id="6" string="Student" />
            <token id="7" string="Union" />
            <token id="8" string="," />
            <token id="9" string="writing" />
            <token id="10" string="and" />
            <token id="11" string="typing" />
            <token id="12" string="its" />
            <token id="13" string="constitution" />
          </tokens>
        </chunking>
        <chunking id="2" string="writing" type="VP">
          <tokens>
            <token id="9" string="writing" />
          </tokens>
        </chunking>
        <chunking id="3" string="typing its constitution" type="VP">
          <tokens>
            <token id="11" string="typing" />
            <token id="12" string="its" />
            <token id="13" string="constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Black Student Union" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Black" />
            <token id="6" string="Student" />
            <token id="7" string="Union" />
          </tokens>
        </chunking>
        <chunking id="5" string="its constitution" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="constitution" />
          </tokens>
        </chunking>
        <chunking id="6" string="found a Black Student Union , writing and typing its constitution" type="VP">
          <tokens>
            <token id="3" string="found" />
            <token id="4" string="a" />
            <token id="5" string="Black" />
            <token id="6" string="Student" />
            <token id="7" string="Union" />
            <token id="8" string="," />
            <token id="9" string="writing" />
            <token id="10" string="and" />
            <token id="11" string="typing" />
            <token id="12" string="its" />
            <token id="13" string="constitution" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="found a Black Student Union , writing" type="VP">
          <tokens>
            <token id="3" string="found" />
            <token id="4" string="a" />
            <token id="5" string="Black" />
            <token id="6" string="Student" />
            <token id="7" string="Union" />
            <token id="8" string="," />
            <token id="9" string="writing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">helped</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">helped</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">helped</governor>
          <dependent id="3">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Union</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Union</governor>
          <dependent id="5">Black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Union</governor>
          <dependent id="6">Student</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">found</governor>
          <dependent id="7">Union</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">found</governor>
          <dependent id="9">writing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">found</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">found</governor>
          <dependent id="11">typing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">constitution</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">typing</governor>
          <dependent id="13">constitution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Student" type="TITLE" score="0.0">
          <tokens>
            <token id="6" string="Student" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>In December 1969, he and other black students resigned to protest the suspensions of black students who had blocked a General Electric recruiter on campus.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="December" lemma="December" stem="decemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="1969" lemma="1969" stem="1969" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="resigned" lemma="resign" stem="resign" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="protest" lemma="protest" stem="protest" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="suspensions" lemma="suspension" stem="suspens" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="blocked" lemma="block" stem="block" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="General" lemma="General" stem="gener" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Electric" lemma="Electric" stem="electric" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="recruiter" lemma="recruiter" stem="recruit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="campus" lemma="campus" stem="campu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP December) (CD 1969))) (, ,) (NP (NP (PRP he)) (CC and) (NP (JJ other) (JJ black) (NNS students))) (VP (VBD resigned) (S (VP (TO to) (VP (VB protest) (NP (NP (DT the) (NNS suspensions)) (PP (IN of) (NP (JJ black) (NNS students))) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN blocked) (NP (NP (DT a) (NNP General) (NNP Electric) (NN recruiter)) (PP (IN on) (NP (NN campus))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="other black students" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="black" />
            <token id="9" string="students" />
          </tokens>
        </chunking>
        <chunking id="2" string="had blocked a General Electric recruiter on campus" type="VP">
          <tokens>
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="3" string="campus" type="NP">
          <tokens>
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="4" string="a General Electric recruiter" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
          </tokens>
        </chunking>
        <chunking id="5" string="a General Electric recruiter on campus" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="6" string="the suspensions" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="suspensions" />
          </tokens>
        </chunking>
        <chunking id="7" string="protest the suspensions of black students who had blocked a General Electric recruiter on campus" type="VP">
          <tokens>
            <token id="12" string="protest" />
            <token id="13" string="the" />
            <token id="14" string="suspensions" />
            <token id="15" string="of" />
            <token id="16" string="black" />
            <token id="17" string="students" />
            <token id="18" string="who" />
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="8" string="he and other black students" type="NP">
          <tokens>
            <token id="5" string="he" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="black" />
            <token id="9" string="students" />
          </tokens>
        </chunking>
        <chunking id="9" string="the suspensions of black students who had blocked a General Electric recruiter on campus" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="suspensions" />
            <token id="15" string="of" />
            <token id="16" string="black" />
            <token id="17" string="students" />
            <token id="18" string="who" />
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="10" string="December 1969" type="NP">
          <tokens>
            <token id="2" string="December" />
            <token id="3" string="1969" />
          </tokens>
        </chunking>
        <chunking id="11" string="black students" type="NP">
          <tokens>
            <token id="16" string="black" />
            <token id="17" string="students" />
          </tokens>
        </chunking>
        <chunking id="12" string="who had blocked a General Electric recruiter on campus" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="13" string="blocked a General Electric recruiter on campus" type="VP">
          <tokens>
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="resigned to protest the suspensions of black students who had blocked a General Electric recruiter on campus" type="VP">
          <tokens>
            <token id="10" string="resigned" />
            <token id="11" string="to" />
            <token id="12" string="protest" />
            <token id="13" string="the" />
            <token id="14" string="suspensions" />
            <token id="15" string="of" />
            <token id="16" string="black" />
            <token id="17" string="students" />
            <token id="18" string="who" />
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
        <chunking id="16" string="to protest the suspensions of black students who had blocked a General Electric recruiter on campus" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="protest" />
            <token id="13" string="the" />
            <token id="14" string="suspensions" />
            <token id="15" string="of" />
            <token id="16" string="black" />
            <token id="17" string="students" />
            <token id="18" string="who" />
            <token id="19" string="had" />
            <token id="20" string="blocked" />
            <token id="21" string="a" />
            <token id="22" string="General" />
            <token id="23" string="Electric" />
            <token id="24" string="recruiter" />
            <token id="25" string="on" />
            <token id="26" string="campus" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">December</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">resigned</governor>
          <dependent id="2">December</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">December</governor>
          <dependent id="3">1969</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">resigned</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">he</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">students</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">students</governor>
          <dependent id="8">black</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">he</governor>
          <dependent id="9">students</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">resigned</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">protest</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">resigned</governor>
          <dependent id="12">protest</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">suspensions</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">protest</governor>
          <dependent id="14">suspensions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">students</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">students</governor>
          <dependent id="16">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">suspensions</governor>
          <dependent id="17">students</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">blocked</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">blocked</governor>
          <dependent id="19">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">suspensions</governor>
          <dependent id="20">blocked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">recruiter</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">recruiter</governor>
          <dependent id="22">General</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">recruiter</governor>
          <dependent id="23">Electric</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">blocked</governor>
          <dependent id="24">recruiter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">campus</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">recruiter</governor>
          <dependent id="26">campus</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="General Electric" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="General" />
            <token id="23" string="Electric" />
          </tokens>
        </entity>
        <entity id="2" string="December 1969" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="December" />
            <token id="3" string="1969" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Stung, school officials granted a blanket amnesty and the students returned.</content>
      <tokens>
        <token id="1" string="Stung" lemma="sting" stem="stung" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="granted" lemma="grant" stem="grant" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blanket" lemma="blanket" stem="blanket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="amnesty" lemma="amnesty" stem="amnesti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="returned" lemma="return" stem="return" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Stung))) (, ,) (NP (NN school) (NNS officials)) (VP (VBD granted) (SBAR (S (NP (NP (DT a) (NN blanket) (NN amnesty)) (CC and) (NP (DT the) (NNS students))) (VP (VBD returned))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="school officials" type="NP">
          <tokens>
            <token id="3" string="school" />
            <token id="4" string="officials" />
          </tokens>
        </chunking>
        <chunking id="2" string="a blanket amnesty and the students returned" type="SBAR">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="blanket" />
            <token id="8" string="amnesty" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="students" />
            <token id="12" string="returned" />
          </tokens>
        </chunking>
        <chunking id="3" string="Stung" type="VP">
          <tokens>
            <token id="1" string="Stung" />
          </tokens>
        </chunking>
        <chunking id="4" string="the students" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="students" />
          </tokens>
        </chunking>
        <chunking id="5" string="granted a blanket amnesty and the students returned" type="VP">
          <tokens>
            <token id="5" string="granted" />
            <token id="6" string="a" />
            <token id="7" string="blanket" />
            <token id="8" string="amnesty" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="students" />
            <token id="12" string="returned" />
          </tokens>
        </chunking>
        <chunking id="6" string="a blanket amnesty" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="blanket" />
            <token id="8" string="amnesty" />
          </tokens>
        </chunking>
        <chunking id="7" string="returned" type="VP">
          <tokens>
            <token id="12" string="returned" />
          </tokens>
        </chunking>
        <chunking id="8" string="a blanket amnesty and the students" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="blanket" />
            <token id="8" string="amnesty" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="students" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="5">granted</governor>
          <dependent id="1">Stung</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">officials</governor>
          <dependent id="3">school</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">granted</governor>
          <dependent id="4">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">granted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">amnesty</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">amnesty</governor>
          <dependent id="7">blanket</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">returned</governor>
          <dependent id="8">amnesty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">amnesty</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">students</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">amnesty</governor>
          <dependent id="11">students</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">granted</governor>
          <dependent id="12">returned</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Thomas went on to run track and write for the campus newspaper.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="campus" lemma="campus" stem="campu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thomas)) (VP (VBD went) (PP (IN on)) (S (VP (TO to) (VP (VP (VB run) (NP (NN track))) (CC and) (VP (VB write) (PP (IN for) (NP (DT the) (NN campus) (NN newspaper)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run track and write for the campus newspaper" type="VP">
          <tokens>
            <token id="5" string="run" />
            <token id="6" string="track" />
            <token id="7" string="and" />
            <token id="8" string="write" />
            <token id="9" string="for" />
            <token id="10" string="the" />
            <token id="11" string="campus" />
            <token id="12" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="2" string="write for the campus newspaper" type="VP">
          <tokens>
            <token id="8" string="write" />
            <token id="9" string="for" />
            <token id="10" string="the" />
            <token id="11" string="campus" />
            <token id="12" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="3" string="run track" type="VP">
          <tokens>
            <token id="5" string="run" />
            <token id="6" string="track" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="to run track and write for the campus newspaper" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="run" />
            <token id="6" string="track" />
            <token id="7" string="and" />
            <token id="8" string="write" />
            <token id="9" string="for" />
            <token id="10" string="the" />
            <token id="11" string="campus" />
            <token id="12" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="6" string="went on to run track and write for the campus newspaper" type="VP">
          <tokens>
            <token id="2" string="went" />
            <token id="3" string="on" />
            <token id="4" string="to" />
            <token id="5" string="run" />
            <token id="6" string="track" />
            <token id="7" string="and" />
            <token id="8" string="write" />
            <token id="9" string="for" />
            <token id="10" string="the" />
            <token id="11" string="campus" />
            <token id="12" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="7" string="track" type="NP">
          <tokens>
            <token id="6" string="track" />
          </tokens>
        </chunking>
        <chunking id="8" string="the campus newspaper" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="campus" />
            <token id="12" string="newspaper" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">went</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">went</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">went</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">run</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">went</governor>
          <dependent id="5">run</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">run</governor>
          <dependent id="6">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">run</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">run</governor>
          <dependent id="8">write</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">newspaper</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">newspaper</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">newspaper</governor>
          <dependent id="11">campus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">write</governor>
          <dependent id="12">newspaper</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>He graduated from Holy Cross with honors and left for Yale University Law School in New Haven, Conn.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="graduated" lemma="graduate" stem="graduat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Holy" lemma="Holy" stem="holi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Cross" lemma="Cross" stem="cross" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="honors" lemma="honor" stem="honor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Law" lemma="Law" stem="law" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Haven" lemma="Haven" stem="haven" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Conn" lemma="Conn." stem="conn" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBD graduated) (PP (IN from) (NP (NNP Holy) (NNP Cross))) (PP (IN with) (NP (NNS honors)))) (CC and) (VP (VBD left) (PP (IN for) (NP (NNP Yale) (NNP University) (NNP Law) (NNP School))) (PP (IN in) (NP (NP (NNP New) (NNP Haven)) (, ,) (NP (NNP Conn.)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New Haven" type="NP">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="Haven" />
          </tokens>
        </chunking>
        <chunking id="2" string="New Haven , Conn." type="NP">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="Haven" />
            <token id="18" string="," />
            <token id="19" string="Conn" />
          </tokens>
        </chunking>
        <chunking id="3" string="Conn." type="NP">
          <tokens>
            <token id="19" string="Conn" />
          </tokens>
        </chunking>
        <chunking id="4" string="graduated from Holy Cross with honors and left for Yale University Law School in New Haven , Conn." type="VP">
          <tokens>
            <token id="2" string="graduated" />
            <token id="3" string="from" />
            <token id="4" string="Holy" />
            <token id="5" string="Cross" />
            <token id="6" string="with" />
            <token id="7" string="honors" />
            <token id="8" string="and" />
            <token id="9" string="left" />
            <token id="10" string="for" />
            <token id="11" string="Yale" />
            <token id="12" string="University" />
            <token id="13" string="Law" />
            <token id="14" string="School" />
            <token id="15" string="in" />
            <token id="16" string="New" />
            <token id="17" string="Haven" />
            <token id="18" string="," />
            <token id="19" string="Conn" />
          </tokens>
        </chunking>
        <chunking id="5" string="Holy Cross" type="NP">
          <tokens>
            <token id="4" string="Holy" />
            <token id="5" string="Cross" />
          </tokens>
        </chunking>
        <chunking id="6" string="Yale University Law School" type="NP">
          <tokens>
            <token id="11" string="Yale" />
            <token id="12" string="University" />
            <token id="13" string="Law" />
            <token id="14" string="School" />
          </tokens>
        </chunking>
        <chunking id="7" string="graduated from Holy Cross with honors" type="VP">
          <tokens>
            <token id="2" string="graduated" />
            <token id="3" string="from" />
            <token id="4" string="Holy" />
            <token id="5" string="Cross" />
            <token id="6" string="with" />
            <token id="7" string="honors" />
          </tokens>
        </chunking>
        <chunking id="8" string="left for Yale University Law School in New Haven , Conn." type="VP">
          <tokens>
            <token id="9" string="left" />
            <token id="10" string="for" />
            <token id="11" string="Yale" />
            <token id="12" string="University" />
            <token id="13" string="Law" />
            <token id="14" string="School" />
            <token id="15" string="in" />
            <token id="16" string="New" />
            <token id="17" string="Haven" />
            <token id="18" string="," />
            <token id="19" string="Conn" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="10" string="honors" type="NP">
          <tokens>
            <token id="7" string="honors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">graduated</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">graduated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Cross</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Cross</governor>
          <dependent id="4">Holy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">graduated</governor>
          <dependent id="5">Cross</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">honors</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">graduated</governor>
          <dependent id="7">honors</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">graduated</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">graduated</governor>
          <dependent id="9">left</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">School</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">School</governor>
          <dependent id="11">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">School</governor>
          <dependent id="12">University</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">School</governor>
          <dependent id="13">Law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">left</governor>
          <dependent id="14">School</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Haven</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Haven</governor>
          <dependent id="16">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">left</governor>
          <dependent id="17">Haven</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Haven</governor>
          <dependent id="19">Conn.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New Haven" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="Haven" />
          </tokens>
        </entity>
        <entity id="2" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="left" />
          </tokens>
        </entity>
        <entity id="3" string="Holy Cross" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Holy" />
            <token id="5" string="Cross" />
          </tokens>
        </entity>
        <entity id="4" string="Yale University Law School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Yale" />
            <token id="12" string="University" />
            <token id="13" string="Law" />
            <token id="14" string="School" />
          </tokens>
        </entity>
        <entity id="5" string="Conn" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Conn" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Freewheeling liberalism; &amp;quot;He came into law school espousing liberal views from his freewheeling, unattached undergraduate days,&amp;quot; said Harry Singleton, a black classmate, close friend and a former civil rights official in the Reagan Education Department.</content>
      <tokens>
        <token id="1" string="Freewheeling" lemma="freewheel" stem="freewheel" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="liberalism" lemma="liberalism" stem="liber" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="3" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="espousing" lemma="espouse" stem="espous" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="12" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="freewheeling" lemma="freewheeling" stem="freewheel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="unattached" lemma="unattached" stem="unattach" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="undergraduate" lemma="undergraduate" stem="undergradu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Harry" lemma="Harry" stem="harri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Singleton" lemma="Singleton" stem="singleton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="classmate" lemma="classmate" stem="classmat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="41" string="Education" lemma="Education" stem="educat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="42" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (VP (VBG Freewheeling) (NP (NN liberalism)))) (: ;) (S (`` ``) (NP (PRP He)) (VP (VBD came) (PP (IN into) (NP (NN law) (NN school))) (S (VP (VBG espousing) (NP (JJ liberal) (NNS views)) (PP (IN from) (NP (PRP$ his) (NN freewheeling) (, ,) (JJ unattached) (JJ undergraduate) (NNS days)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Harry) (NNP Singleton)) (, ,) (NP (NP (DT a) (JJ black) (NN classmate)) (, ,) (NP (JJ close) (NN friend)) (CC and) (NP (NP (DT a) (JJ former) (JJ civil) (NNS rights) (NN official)) (PP (IN in) (NP (DT the) (NNP Reagan) (NNP Education) (NNP Department)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a black classmate" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="black" />
            <token id="28" string="classmate" />
          </tokens>
        </chunking>
        <chunking id="2" string="liberalism" type="NP">
          <tokens>
            <token id="2" string="liberalism" />
          </tokens>
        </chunking>
        <chunking id="3" string="espousing liberal views from his freewheeling , unattached undergraduate days" type="VP">
          <tokens>
            <token id="10" string="espousing" />
            <token id="11" string="liberal" />
            <token id="12" string="views" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="freewheeling" />
            <token id="16" string="," />
            <token id="17" string="unattached" />
            <token id="18" string="undergraduate" />
            <token id="19" string="days" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Reagan Education Department" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="Reagan" />
            <token id="41" string="Education" />
            <token id="42" string="Department" />
          </tokens>
        </chunking>
        <chunking id="5" string="a black classmate , close friend and a former civil rights official in the Reagan Education Department" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="black" />
            <token id="28" string="classmate" />
            <token id="29" string="," />
            <token id="30" string="close" />
            <token id="31" string="friend" />
            <token id="32" string="and" />
            <token id="33" string="a" />
            <token id="34" string="former" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="official" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="Reagan" />
            <token id="41" string="Education" />
            <token id="42" string="Department" />
          </tokens>
        </chunking>
        <chunking id="6" string="his freewheeling , unattached undergraduate days" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="freewheeling" />
            <token id="16" string="," />
            <token id="17" string="unattached" />
            <token id="18" string="undergraduate" />
            <token id="19" string="days" />
          </tokens>
        </chunking>
        <chunking id="7" string="liberal views" type="NP">
          <tokens>
            <token id="11" string="liberal" />
            <token id="12" string="views" />
          </tokens>
        </chunking>
        <chunking id="8" string="a former civil rights official in the Reagan Education Department" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="former" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="official" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="Reagan" />
            <token id="41" string="Education" />
            <token id="42" string="Department" />
          </tokens>
        </chunking>
        <chunking id="9" string="close friend" type="NP">
          <tokens>
            <token id="30" string="close" />
            <token id="31" string="friend" />
          </tokens>
        </chunking>
        <chunking id="10" string="law school" type="NP">
          <tokens>
            <token id="8" string="law" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="Harry Singleton , a black classmate , close friend and a former civil rights official in the Reagan Education Department" type="NP">
          <tokens>
            <token id="23" string="Harry" />
            <token id="24" string="Singleton" />
            <token id="25" string="," />
            <token id="26" string="a" />
            <token id="27" string="black" />
            <token id="28" string="classmate" />
            <token id="29" string="," />
            <token id="30" string="close" />
            <token id="31" string="friend" />
            <token id="32" string="and" />
            <token id="33" string="a" />
            <token id="34" string="former" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="official" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="Reagan" />
            <token id="41" string="Education" />
            <token id="42" string="Department" />
          </tokens>
        </chunking>
        <chunking id="12" string="came into law school espousing liberal views from his freewheeling , unattached undergraduate days" type="VP">
          <tokens>
            <token id="6" string="came" />
            <token id="7" string="into" />
            <token id="8" string="law" />
            <token id="9" string="school" />
            <token id="10" string="espousing" />
            <token id="11" string="liberal" />
            <token id="12" string="views" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="freewheeling" />
            <token id="16" string="," />
            <token id="17" string="unattached" />
            <token id="18" string="undergraduate" />
            <token id="19" string="days" />
          </tokens>
        </chunking>
        <chunking id="13" string="a former civil rights official" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="former" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="official" />
          </tokens>
        </chunking>
        <chunking id="14" string="Harry Singleton" type="NP">
          <tokens>
            <token id="23" string="Harry" />
            <token id="24" string="Singleton" />
          </tokens>
        </chunking>
        <chunking id="15" string="Freewheeling liberalism" type="VP">
          <tokens>
            <token id="1" string="Freewheeling" />
            <token id="2" string="liberalism" />
          </tokens>
        </chunking>
        <chunking id="16" string="He" type="NP">
          <tokens>
            <token id="5" string="He" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="1">Freewheeling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Freewheeling</governor>
          <dependent id="2">liberalism</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">came</governor>
          <dependent id="5">He</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Freewheeling</governor>
          <dependent id="6">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">school</governor>
          <dependent id="7">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">school</governor>
          <dependent id="8">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">came</governor>
          <dependent id="9">school</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">came</governor>
          <dependent id="10">espousing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">views</governor>
          <dependent id="11">liberal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">espousing</governor>
          <dependent id="12">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">days</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">days</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">days</governor>
          <dependent id="15">freewheeling</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">days</governor>
          <dependent id="17">unattached</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">days</governor>
          <dependent id="18">undergraduate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">espousing</governor>
          <dependent id="19">days</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Singleton</governor>
          <dependent id="23">Harry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="24">Singleton</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">classmate</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">classmate</governor>
          <dependent id="27">black</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">Singleton</governor>
          <dependent id="28">classmate</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">friend</governor>
          <dependent id="30">close</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">classmate</governor>
          <dependent id="31">friend</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">classmate</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">official</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">official</governor>
          <dependent id="34">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">official</governor>
          <dependent id="35">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">official</governor>
          <dependent id="36">rights</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">classmate</governor>
          <dependent id="37">official</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">Department</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">Department</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Department</governor>
          <dependent id="40">Reagan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Department</governor>
          <dependent id="41">Education</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">official</governor>
          <dependent id="42">Department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="liberalism" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="liberalism" />
          </tokens>
        </entity>
        <entity id="2" string="Harry Singleton" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Harry" />
            <token id="24" string="Singleton" />
          </tokens>
        </entity>
        <entity id="3" string="Reagan Education Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="40" string="Reagan" />
            <token id="41" string="Education" />
            <token id="42" string="Department" />
          </tokens>
        </entity>
        <entity id="4" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="days" />
          </tokens>
        </entity>
        <entity id="5" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>&amp;quot;But he became more conservative as he went through the process of legal education&amp;quot;.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP he)) (VP (VBD became) (ADJP (RBR more) (JJ conservative)) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD went) (PP (IN through) (NP (NP (DT the) (NN process)) (PP (IN of) (NP (JJ legal) (NN education))) ('' ''))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the process of legal education ''" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="process" />
            <token id="13" string="of" />
            <token id="14" string="legal" />
            <token id="15" string="education" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="the process" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="process" />
          </tokens>
        </chunking>
        <chunking id="3" string="as he went through the process of legal education ''" type="SBAR">
          <tokens>
            <token id="7" string="as" />
            <token id="8" string="he" />
            <token id="9" string="went" />
            <token id="10" string="through" />
            <token id="11" string="the" />
            <token id="12" string="process" />
            <token id="13" string="of" />
            <token id="14" string="legal" />
            <token id="15" string="education" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="became more conservative as he went through the process of legal education ''" type="VP">
          <tokens>
            <token id="4" string="became" />
            <token id="5" string="more" />
            <token id="6" string="conservative" />
            <token id="7" string="as" />
            <token id="8" string="he" />
            <token id="9" string="went" />
            <token id="10" string="through" />
            <token id="11" string="the" />
            <token id="12" string="process" />
            <token id="13" string="of" />
            <token id="14" string="legal" />
            <token id="15" string="education" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="legal education" type="NP">
          <tokens>
            <token id="14" string="legal" />
            <token id="15" string="education" />
          </tokens>
        </chunking>
        <chunking id="7" string="more conservative" type="ADJP">
          <tokens>
            <token id="5" string="more" />
            <token id="6" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="8" string="went through the process of legal education ''" type="VP">
          <tokens>
            <token id="9" string="went" />
            <token id="10" string="through" />
            <token id="11" string="the" />
            <token id="12" string="process" />
            <token id="13" string="of" />
            <token id="14" string="legal" />
            <token id="15" string="education" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">became</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">became</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">became</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">conservative</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">became</governor>
          <dependent id="6">conservative</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">went</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">went</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">became</governor>
          <dependent id="9">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">process</governor>
          <dependent id="10">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">process</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">went</governor>
          <dependent id="12">process</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">education</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">education</governor>
          <dependent id="14">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">process</governor>
          <dependent id="15">education</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="conservative" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Yale law students, Singleton explained, were exposed to conservative law professors with powerful minds.</content>
      <tokens>
        <token id="1" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="2" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Singleton" lemma="Singleton" stem="singleton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="exposed" lemma="expose" stem="expos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="12" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="professors" lemma="professor" stem="professor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="powerful" lemma="powerful" stem="power" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="minds" lemma="mind" stem="mind" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Yale) (NN law) (NNS students)) (PRN (, ,) (NP (NNP Singleton)) (VP (VBD explained)) (, ,)) (VP (VBD were) (VP (VBN exposed) (PP (TO to) (NP (JJ conservative) (NN law) (NNS professors))) (PP (IN with) (NP (JJ powerful) (NNS minds))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="exposed to conservative law professors with powerful minds" type="VP">
          <tokens>
            <token id="9" string="exposed" />
            <token id="10" string="to" />
            <token id="11" string="conservative" />
            <token id="12" string="law" />
            <token id="13" string="professors" />
            <token id="14" string="with" />
            <token id="15" string="powerful" />
            <token id="16" string="minds" />
          </tokens>
        </chunking>
        <chunking id="2" string="Yale law students" type="NP">
          <tokens>
            <token id="1" string="Yale" />
            <token id="2" string="law" />
            <token id="3" string="students" />
          </tokens>
        </chunking>
        <chunking id="3" string="Singleton" type="NP">
          <tokens>
            <token id="5" string="Singleton" />
          </tokens>
        </chunking>
        <chunking id="4" string="were exposed to conservative law professors with powerful minds" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="exposed" />
            <token id="10" string="to" />
            <token id="11" string="conservative" />
            <token id="12" string="law" />
            <token id="13" string="professors" />
            <token id="14" string="with" />
            <token id="15" string="powerful" />
            <token id="16" string="minds" />
          </tokens>
        </chunking>
        <chunking id="5" string="conservative law professors" type="NP">
          <tokens>
            <token id="11" string="conservative" />
            <token id="12" string="law" />
            <token id="13" string="professors" />
          </tokens>
        </chunking>
        <chunking id="6" string="powerful minds" type="NP">
          <tokens>
            <token id="15" string="powerful" />
            <token id="16" string="minds" />
          </tokens>
        </chunking>
        <chunking id="7" string="explained" type="VP">
          <tokens>
            <token id="6" string="explained" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">students</governor>
          <dependent id="1">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">students</governor>
          <dependent id="2">law</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">exposed</governor>
          <dependent id="3">students</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">explained</governor>
          <dependent id="5">Singleton</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">exposed</governor>
          <dependent id="6">explained</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">exposed</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">exposed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">professors</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">professors</governor>
          <dependent id="11">conservative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">professors</governor>
          <dependent id="12">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">exposed</governor>
          <dependent id="13">professors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">minds</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">minds</governor>
          <dependent id="15">powerful</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">exposed</governor>
          <dependent id="16">minds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Singleton" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Singleton" />
          </tokens>
        </entity>
        <entity id="3" string="Yale" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Yale" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>&amp;quot;I used to discuss conservative ideas with Clarence and he was interested in them,&amp;quot; Singleton said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="discuss" lemma="discuss" stem="discuss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="7" string="ideas" lemma="idea" stem="idea" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="interested" lemma="interested" stem="interest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Singleton" lemma="Singleton" stem="singleton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBD used) (S (VP (TO to) (VP (VB discuss) (NP (JJ conservative) (NNS ideas)) (PP (IN with) (NP (NNP Clarence)))))))) (CC and) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ interested) (PP (IN in) (NP (PRP them))))))) (, ,) ('' '') (NP (NNP Singleton)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="used to discuss conservative ideas with Clarence" type="VP">
          <tokens>
            <token id="3" string="used" />
            <token id="4" string="to" />
            <token id="5" string="discuss" />
            <token id="6" string="conservative" />
            <token id="7" string="ideas" />
            <token id="8" string="with" />
            <token id="9" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="2" string="was interested in them" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="interested" />
            <token id="14" string="in" />
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="conservative ideas" type="NP">
          <tokens>
            <token id="6" string="conservative" />
            <token id="7" string="ideas" />
          </tokens>
        </chunking>
        <chunking id="4" string="to discuss conservative ideas with Clarence" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="discuss" />
            <token id="6" string="conservative" />
            <token id="7" string="ideas" />
            <token id="8" string="with" />
            <token id="9" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="5" string="Singleton" type="NP">
          <tokens>
            <token id="18" string="Singleton" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="interested in them" type="ADJP">
          <tokens>
            <token id="13" string="interested" />
            <token id="14" string="in" />
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="discuss conservative ideas with Clarence" type="VP">
          <tokens>
            <token id="5" string="discuss" />
            <token id="6" string="conservative" />
            <token id="7" string="ideas" />
            <token id="8" string="with" />
            <token id="9" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="Clarence" type="NP">
          <tokens>
            <token id="9" string="Clarence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">used</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">discuss</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">used</governor>
          <dependent id="5">discuss</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">ideas</governor>
          <dependent id="6">conservative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">discuss</governor>
          <dependent id="7">ideas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Clarence</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">discuss</governor>
          <dependent id="9">Clarence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">used</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">interested</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">interested</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">used</governor>
          <dependent id="13">interested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">them</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">interested</governor>
          <dependent id="15">them</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Singleton</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Singleton" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Singleton" />
          </tokens>
        </entity>
        <entity id="3" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;They were about the dangers of big government trying to solve all the ills of society and how every time you do that you take away from the liberties of the people&amp;quot;.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="dangers" lemma="danger" stem="danger" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="solve" lemma="solve" stem="solv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="ills" lemma="ill" stem="ill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="liberties" lemma="liberty" stem="liberti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBD were) (UCP (PP (IN about) (NP (NP (DT the) (NNS dangers)) (PP (IN of) (NP (NP (JJ big) (NN government)) (VP (VBG trying) (S (VP (TO to) (VP (VB solve) (NP (NP (PDT all) (DT the) (NNS ills)) (PP (IN of) (NP (NN society)))))))))))) (CC and) (SBAR (WHADVP (WRB how)) (S (NP-TMP (DT every) (NN time)) (NP (PRP you)) (VP (VBP do) (SBAR (IN that) (S (NP (PRP you)) (VP (VBP take) (ADVP (RB away)) (PP (IN from) (NP (NP (DT the) (NNS liberties)) (PP (IN of) (NP (DT the) (NNS people))))))))))))) ('' '') (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the liberties" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="liberties" />
          </tokens>
        </chunking>
        <chunking id="3" string="all the ills of society" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="4" string="do that you take away from the liberties of the people" type="VP">
          <tokens>
            <token id="23" string="do" />
            <token id="24" string="that" />
            <token id="25" string="you" />
            <token id="26" string="take" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="big government trying to solve all the ills of society" type="NP">
          <tokens>
            <token id="8" string="big" />
            <token id="9" string="government" />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="6" string="the dangers of big government trying to solve all the ills of society" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="dangers" />
            <token id="7" string="of" />
            <token id="8" string="big" />
            <token id="9" string="government" />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="7" string="all the ills" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
          </tokens>
        </chunking>
        <chunking id="8" string="big government" type="NP">
          <tokens>
            <token id="8" string="big" />
            <token id="9" string="government" />
          </tokens>
        </chunking>
        <chunking id="9" string="solve all the ills of society" type="VP">
          <tokens>
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="10" string="the people" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="how every time you do that you take away from the liberties of the people" type="SBAR">
          <tokens>
            <token id="19" string="how" />
            <token id="20" string="every" />
            <token id="21" string="time" />
            <token id="22" string="you" />
            <token id="23" string="do" />
            <token id="24" string="that" />
            <token id="25" string="you" />
            <token id="26" string="take" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="12" string="to solve all the ills of society" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="13" string="how" type="WHADVP">
          <tokens>
            <token id="19" string="how" />
          </tokens>
        </chunking>
        <chunking id="14" string="the dangers" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="dangers" />
          </tokens>
        </chunking>
        <chunking id="15" string="trying to solve all the ills of society" type="VP">
          <tokens>
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="16" string="were about the dangers of big government trying to solve all the ills of society and how every time you do that you take away from the liberties of the people" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="about" />
            <token id="5" string="the" />
            <token id="6" string="dangers" />
            <token id="7" string="of" />
            <token id="8" string="big" />
            <token id="9" string="government" />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="solve" />
            <token id="13" string="all" />
            <token id="14" string="the" />
            <token id="15" string="ills" />
            <token id="16" string="of" />
            <token id="17" string="society" />
            <token id="18" string="and" />
            <token id="19" string="how" />
            <token id="20" string="every" />
            <token id="21" string="time" />
            <token id="22" string="you" />
            <token id="23" string="do" />
            <token id="24" string="that" />
            <token id="25" string="you" />
            <token id="26" string="take" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="17" string="that you take away from the liberties of the people" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="you" />
            <token id="26" string="take" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="18" string="take away from the liberties of the people" type="VP">
          <tokens>
            <token id="26" string="take" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="19" string="society" type="NP">
          <tokens>
            <token id="17" string="society" />
          </tokens>
        </chunking>
        <chunking id="20" string="the liberties of the people" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="liberties" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="people" />
          </tokens>
        </chunking>
        <chunking id="21" string="you" type="NP">
          <tokens>
            <token id="22" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">dangers</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">dangers</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">dangers</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">dangers</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">dangers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">government</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">government</governor>
          <dependent id="8">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">dangers</governor>
          <dependent id="9">government</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">government</governor>
          <dependent id="10">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">solve</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">trying</governor>
          <dependent id="12">solve</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="15">ills</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">ills</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">solve</governor>
          <dependent id="15">ills</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">society</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">ills</governor>
          <dependent id="17">society</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">dangers</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">do</governor>
          <dependent id="19">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">time</governor>
          <dependent id="20">every</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="23">do</governor>
          <dependent id="21">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">do</governor>
          <dependent id="22">you</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">dangers</governor>
          <dependent id="23">do</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">take</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">take</governor>
          <dependent id="25">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">do</governor>
          <dependent id="26">take</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">take</governor>
          <dependent id="27">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">liberties</governor>
          <dependent id="28">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">liberties</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">take</governor>
          <dependent id="30">liberties</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">people</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">people</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">liberties</governor>
          <dependent id="33">people</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>But it was Thomas Sowell, the conservative black economist now at Stanford University&amp;apost;s Hoover Institution, whose work came to grip Thomas&amp;apost; mind.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="9" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="economist" lemma="economist" stem="economist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Stanford" lemma="Stanford" stem="stanford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Hoover" lemma="Hoover" stem="hoover" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Institution" lemma="Institution" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="grip" lemma="grip" stem="grip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBD was) (NP (NP (NNP Thomas) (NNP Sowell)) (, ,) (NP (NP (DT the) (JJ conservative) (JJ black) (NN economist)) (PP (ADVP (RB now)) (IN at) (NP (NP (NNP Stanford) (NNP University) (POS 's)) (NNP Hoover) (NNP Institution)))) (, ,) (SBAR (WP$ whose) (S (NP (NN work)) (VP (VBD came) (PP (TO to) (NP (NP (NN grip) (NNP Thomas) (POS ')) (NN mind)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="grip Thomas ' mind" type="NP">
          <tokens>
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="2" string="was Thomas Sowell , the conservative black economist now at Stanford University 's Hoover Institution , whose work came to grip Thomas ' mind" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="Thomas" />
            <token id="5" string="Sowell" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="conservative" />
            <token id="9" string="black" />
            <token id="10" string="economist" />
            <token id="11" string="now" />
            <token id="12" string="at" />
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
            <token id="16" string="Hoover" />
            <token id="17" string="Institution" />
            <token id="18" string="," />
            <token id="19" string="whose" />
            <token id="20" string="work" />
            <token id="21" string="came" />
            <token id="22" string="to" />
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="work" type="NP">
          <tokens>
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="grip Thomas '" type="NP">
          <tokens>
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas Sowell" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="Sowell" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas Sowell , the conservative black economist now at Stanford University 's Hoover Institution , whose work came to grip Thomas ' mind" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="Sowell" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="conservative" />
            <token id="9" string="black" />
            <token id="10" string="economist" />
            <token id="11" string="now" />
            <token id="12" string="at" />
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
            <token id="16" string="Hoover" />
            <token id="17" string="Institution" />
            <token id="18" string="," />
            <token id="19" string="whose" />
            <token id="20" string="work" />
            <token id="21" string="came" />
            <token id="22" string="to" />
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="8" string="the conservative black economist now at Stanford University 's Hoover Institution" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="conservative" />
            <token id="9" string="black" />
            <token id="10" string="economist" />
            <token id="11" string="now" />
            <token id="12" string="at" />
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
            <token id="16" string="Hoover" />
            <token id="17" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="9" string="Stanford University 's" type="NP">
          <tokens>
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Stanford University 's Hoover Institution" type="NP">
          <tokens>
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
            <token id="16" string="Hoover" />
            <token id="17" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="11" string="whose work came to grip Thomas ' mind" type="SBAR">
          <tokens>
            <token id="19" string="whose" />
            <token id="20" string="work" />
            <token id="21" string="came" />
            <token id="22" string="to" />
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="12" string="the conservative black economist" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="conservative" />
            <token id="9" string="black" />
            <token id="10" string="economist" />
          </tokens>
        </chunking>
        <chunking id="13" string="came to grip Thomas ' mind" type="VP">
          <tokens>
            <token id="21" string="came" />
            <token id="22" string="to" />
            <token id="23" string="grip" />
            <token id="24" string="Thomas" />
            <token id="25" string="'" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">Sowell</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">Sowell</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Sowell</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Sowell</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Sowell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">economist</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">economist</governor>
          <dependent id="8">conservative</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">economist</governor>
          <dependent id="9">black</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Sowell</governor>
          <dependent id="10">economist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">Institution</governor>
          <dependent id="11">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Institution</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">University</governor>
          <dependent id="13">Stanford</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">Institution</governor>
          <dependent id="14">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">University</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Institution</governor>
          <dependent id="16">Hoover</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">economist</governor>
          <dependent id="17">Institution</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">came</governor>
          <dependent id="19">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">came</governor>
          <dependent id="20">work</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Sowell</governor>
          <dependent id="21">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">mind</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Thomas</governor>
          <dependent id="23">grip</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">mind</governor>
          <dependent id="24">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Thomas</governor>
          <dependent id="25">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">came</governor>
          <dependent id="26">mind</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Stanford University 's Hoover Institution" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Stanford" />
            <token id="14" string="University" />
            <token id="15" string="'s" />
            <token id="16" string="Hoover" />
            <token id="17" string="Institution" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Thomas Sowell" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="Sowell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>Shortly after his arrival at Yale, Thomas remembered when someone gave him one of Sowell&amp;apost;s books and &amp;quot;I threw it in the trash&amp;quot; because &amp;quot;it really went against all the things we&amp;apost;d been indoctrinated to believe about the radical movement and the peace movement&amp;quot;.</content>
      <tokens>
        <token id="1" string="Shortly" lemma="shortly" stem="shortli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="arrival" lemma="arrival" stem="arriv" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="remembered" lemma="remember" stem="rememb" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="threw" lemma="throw" stem="threw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="trash" lemma="trash" stem="trash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="indoctrinated" lemma="indoctrinate" stem="indoctrin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="radical" lemma="radical" stem="radic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="movement" lemma="movement" stem="movement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="movement" lemma="movement" stem="movement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (RB Shortly) (IN after) (NP (NP (PRP$ his) (NN arrival)) (PP (IN at) (NP (NNP Yale))))) (, ,) (S (NP (NNP Thomas)) (VP (VBD remembered) (SBAR (WHADVP (WRB when)) (S (NP (NN someone)) (VP (VBD gave) (NP (PRP him)) (NP (NP (CD one)) (PP (IN of) (NP (NP (NNP Sowell) (POS 's)) (NNS books))))))))) (CC and) (S (`` ``) (NP (PRP I)) (VP (VBD threw) (S (NP (PRP it))) (PP (IN in) (NP (DT the) (NN trash))) ('' '') (SBAR (IN because) (`` ``) (S (NP (PRP it)) (ADVP (RB really)) (VP (VBD went) (PP (IN against) (NP (DT all))) (NP (NP (DT the) (NNS things)) (SBAR (S (NP (PRP we)) (VP (MD 'd) (VP (VBN been) (VP (VBN indoctrinated) (S (VP (TO to) (VP (VB believe) (PP (IN about) (NP (NP (DT the) (JJ radical) (NN movement)) (CC and) (NP (DT the) (NN peace) (NN movement))))))))))))))))) ('' '')) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="34" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="the radical movement and the peace movement" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="threw it in the trash '' because `` it really went against all the things we 'd been indoctrinated to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="22" string="threw" />
            <token id="23" string="it" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="trash" />
            <token id="27" string="&quot;" />
            <token id="28" string="because" />
            <token id="29" string="&quot;" />
            <token id="30" string="it" />
            <token id="31" string="really" />
            <token id="32" string="went" />
            <token id="33" string="against" />
            <token id="34" string="all" />
            <token id="35" string="the" />
            <token id="36" string="things" />
            <token id="37" string="we" />
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="his arrival at Yale" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="arrival" />
            <token id="5" string="at" />
            <token id="6" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="been indoctrinated to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="9" string="Sowell 's books" type="NP">
          <tokens>
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="10" string="to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="11" string="someone" type="NP">
          <tokens>
            <token id="11" string="someone" />
          </tokens>
        </chunking>
        <chunking id="12" string="gave him one of Sowell 's books" type="VP">
          <tokens>
            <token id="12" string="gave" />
            <token id="13" string="him" />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="indoctrinated to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="14" string="one of Sowell 's books" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="15" string="because `` it really went against all the things we 'd been indoctrinated to believe about the radical movement and the peace movement" type="SBAR">
          <tokens>
            <token id="28" string="because" />
            <token id="29" string="&quot;" />
            <token id="30" string="it" />
            <token id="31" string="really" />
            <token id="32" string="went" />
            <token id="33" string="against" />
            <token id="34" string="all" />
            <token id="35" string="the" />
            <token id="36" string="things" />
            <token id="37" string="we" />
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="16" string="the things we 'd been indoctrinated to believe about the radical movement and the peace movement" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="things" />
            <token id="37" string="we" />
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="17" string="his arrival" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="arrival" />
          </tokens>
        </chunking>
        <chunking id="18" string="believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="19" string="the peace movement" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="20" string="the radical movement" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
          </tokens>
        </chunking>
        <chunking id="21" string="we 'd been indoctrinated to believe about the radical movement and the peace movement" type="SBAR">
          <tokens>
            <token id="37" string="we" />
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="22" string="remembered when someone gave him one of Sowell 's books" type="VP">
          <tokens>
            <token id="9" string="remembered" />
            <token id="10" string="when" />
            <token id="11" string="someone" />
            <token id="12" string="gave" />
            <token id="13" string="him" />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="23" string="I" type="NP">
          <tokens>
            <token id="21" string="I" />
          </tokens>
        </chunking>
        <chunking id="24" string="Yale" type="NP">
          <tokens>
            <token id="6" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="25" string="him" type="NP">
          <tokens>
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="26" string="the trash" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="trash" />
          </tokens>
        </chunking>
        <chunking id="27" string="we" type="NP">
          <tokens>
            <token id="37" string="we" />
          </tokens>
        </chunking>
        <chunking id="28" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="29" string="'d been indoctrinated to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
        <chunking id="30" string="Sowell 's" type="NP">
          <tokens>
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="31" string="when someone gave him one of Sowell 's books" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="someone" />
            <token id="12" string="gave" />
            <token id="13" string="him" />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="Sowell" />
            <token id="17" string="'s" />
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="32" string="the things" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="things" />
          </tokens>
        </chunking>
        <chunking id="33" string="went against all the things we 'd been indoctrinated to believe about the radical movement and the peace movement" type="VP">
          <tokens>
            <token id="32" string="went" />
            <token id="33" string="against" />
            <token id="34" string="all" />
            <token id="35" string="the" />
            <token id="36" string="things" />
            <token id="37" string="we" />
            <token id="38" string="'d" />
            <token id="39" string="been" />
            <token id="40" string="indoctrinated" />
            <token id="41" string="to" />
            <token id="42" string="believe" />
            <token id="43" string="about" />
            <token id="44" string="the" />
            <token id="45" string="radical" />
            <token id="46" string="movement" />
            <token id="47" string="and" />
            <token id="48" string="the" />
            <token id="49" string="peace" />
            <token id="50" string="movement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">arrival</governor>
          <dependent id="1">Shortly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">arrival</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">arrival</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">remembered</governor>
          <dependent id="4">arrival</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Yale</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">arrival</governor>
          <dependent id="6">Yale</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">remembered</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">remembered</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">gave</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">gave</governor>
          <dependent id="11">someone</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">remembered</governor>
          <dependent id="12">gave</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="12">gave</governor>
          <dependent id="13">him</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">gave</governor>
          <dependent id="14">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">books</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">books</governor>
          <dependent id="16">Sowell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Sowell</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">one</governor>
          <dependent id="18">books</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">remembered</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">threw</governor>
          <dependent id="21">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">remembered</governor>
          <dependent id="22">threw</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">threw</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">trash</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">trash</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">threw</governor>
          <dependent id="26">trash</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">went</governor>
          <dependent id="28">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">went</governor>
          <dependent id="30">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">went</governor>
          <dependent id="31">really</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">threw</governor>
          <dependent id="32">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">all</governor>
          <dependent id="33">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">went</governor>
          <dependent id="34">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">things</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">went</governor>
          <dependent id="36">things</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="40">indoctrinated</governor>
          <dependent id="37">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">indoctrinated</governor>
          <dependent id="38">'d</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">indoctrinated</governor>
          <dependent id="39">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="36">things</governor>
          <dependent id="40">indoctrinated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">believe</governor>
          <dependent id="41">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">indoctrinated</governor>
          <dependent id="42">believe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">movement</governor>
          <dependent id="43">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">movement</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">movement</governor>
          <dependent id="45">radical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">believe</governor>
          <dependent id="46">movement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="46">movement</governor>
          <dependent id="47">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">movement</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">movement</governor>
          <dependent id="49">peace</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="46">movement</governor>
          <dependent id="50">movement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Yale" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Yale" />
          </tokens>
        </entity>
        <entity id="4" string="Sowell" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Sowell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>But after law school, Thomas rediscovered one of Sowell&amp;apost;s books.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="rediscovered" lemma="rediscover" stem="rediscov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN after) (NP (NN law) (NN school))) (, ,) (NP (NNP Thomas)) (VP (VBD rediscovered) (NP (NP (CD one)) (PP (IN of) (NP (NP (NNP Sowell) (POS 's)) (NNS books))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sowell 's books" type="NP">
          <tokens>
            <token id="10" string="Sowell" />
            <token id="11" string="'s" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sowell 's" type="NP">
          <tokens>
            <token id="10" string="Sowell" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="rediscovered one of Sowell 's books" type="VP">
          <tokens>
            <token id="7" string="rediscovered" />
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="Sowell" />
            <token id="11" string="'s" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="6" string="one of Sowell 's books" type="NP">
          <tokens>
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="Sowell" />
            <token id="11" string="'s" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="7" string="law school" type="NP">
          <tokens>
            <token id="3" string="law" />
            <token id="4" string="school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">rediscovered</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">school</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">school</governor>
          <dependent id="3">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">rediscovered</governor>
          <dependent id="4">school</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">rediscovered</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">rediscovered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">rediscovered</governor>
          <dependent id="8">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">books</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">books</governor>
          <dependent id="10">Sowell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Sowell</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">one</governor>
          <dependent id="12">books</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Sowell" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Sowell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Sowell&amp;apost;s provocative 1983 work, &amp;quot;The Economics and Politics of Race,&amp;quot; was &amp;quot;manna from heaven,&amp;quot; Thomas said.</content>
      <tokens>
        <token id="1" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="provocative" lemma="provocative" stem="provoc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Economics" lemma="Economics" stem="econom" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Politics" lemma="Politics" stem="polit" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Race" lemma="Race" stem="race" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="manna" lemma="manna" stem="manna" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="heaven" lemma="heaven" stem="heaven" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NP (NNP Sowell) (POS 's)) (ADJP (JJ provocative) (NP-TMP (CD 1983))) (NN work)) (, ,) (`` ``) (NP (DT The) (NNP Economics) (CC and) (NNP Politics) (IN of) (NNP Race)) (, ,) ('' '')) (VP (VBD was) (`` ``) (NP (FW manna)) (PP (IN from) (NP (NN heaven))))) (, ,) ('' '') (NP (NNP Thomas)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sowell 's provocative 1983 work , `` The Economics and Politics of Race , ''" type="NP">
          <tokens>
            <token id="1" string="Sowell" />
            <token id="2" string="'s" />
            <token id="3" string="provocative" />
            <token id="4" string="1983" />
            <token id="5" string="work" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="The" />
            <token id="9" string="Economics" />
            <token id="10" string="and" />
            <token id="11" string="Politics" />
            <token id="12" string="of" />
            <token id="13" string="Race" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="manna" type="NP">
          <tokens>
            <token id="18" string="manna" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sowell 's" type="NP">
          <tokens>
            <token id="1" string="Sowell" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="The Economics and Politics of Race" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="Economics" />
            <token id="10" string="and" />
            <token id="11" string="Politics" />
            <token id="12" string="of" />
            <token id="13" string="Race" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="provocative 1983" type="ADJP">
          <tokens>
            <token id="3" string="provocative" />
            <token id="4" string="1983" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sowell 's provocative 1983 work" type="NP">
          <tokens>
            <token id="1" string="Sowell" />
            <token id="2" string="'s" />
            <token id="3" string="provocative" />
            <token id="4" string="1983" />
            <token id="5" string="work" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="was `` manna from heaven" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="&quot;" />
            <token id="18" string="manna" />
            <token id="19" string="from" />
            <token id="20" string="heaven" />
          </tokens>
        </chunking>
        <chunking id="10" string="heaven" type="NP">
          <tokens>
            <token id="20" string="heaven" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="5">work</governor>
          <dependent id="1">Sowell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Sowell</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">work</governor>
          <dependent id="3">provocative</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">provocative</governor>
          <dependent id="4">1983</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">manna</governor>
          <dependent id="5">work</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Economics</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">work</governor>
          <dependent id="9">Economics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Economics</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Race</governor>
          <dependent id="11">Politics</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Race</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Economics</governor>
          <dependent id="13">Race</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">manna</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="18">manna</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">heaven</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">manna</governor>
          <dependent id="20">heaven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Sowell" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Sowell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>In that book, Sowell, arguing from a laissez-faire perspective, endorsed the notion that blacks would benefit more from pursuing economic achievement than political agitation.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="laissez-faire" lemma="laissez-faire" stem="laissez-fair" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="perspective" lemma="perspective" stem="perspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="endorsed" lemma="endorse" stem="endors" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="notion" lemma="notion" stem="notion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="benefit" lemma="benefit" stem="benefit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="pursuing" lemma="pursue" stem="pursu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="economic" lemma="economic" stem="econom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="achievement" lemma="achievement" stem="achiev" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="agitation" lemma="agitation" stem="agit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT that) (NN book))) (, ,) (NP (NP (NNP Sowell)) (, ,) (VP (VBG arguing) (PP (IN from) (NP (DT a) (FW laissez-faire) (NN perspective)))) (, ,)) (VP (VBD endorsed) (NP (DT the) (NN notion)) (SBAR (IN that) (S (NP (NNS blacks)) (VP (MD would) (VP (VB benefit) (ADVP (RBR more)) (PP (IN from) (S (VP (VBG pursuing) (NP (JJ economic) (NN achievement)) (PP (IN than) (NP (JJ political) (NN agitation))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="political agitation" type="NP">
          <tokens>
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="2" string="benefit more from pursuing economic achievement than political agitation" type="VP">
          <tokens>
            <token id="19" string="benefit" />
            <token id="20" string="more" />
            <token id="21" string="from" />
            <token id="22" string="pursuing" />
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
            <token id="25" string="than" />
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="3" string="blacks" type="NP">
          <tokens>
            <token id="17" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="economic achievement" type="NP">
          <tokens>
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
          </tokens>
        </chunking>
        <chunking id="5" string="would benefit more from pursuing economic achievement than political agitation" type="VP">
          <tokens>
            <token id="18" string="would" />
            <token id="19" string="benefit" />
            <token id="20" string="more" />
            <token id="21" string="from" />
            <token id="22" string="pursuing" />
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
            <token id="25" string="than" />
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="6" string="pursuing economic achievement than political agitation" type="VP">
          <tokens>
            <token id="22" string="pursuing" />
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
            <token id="25" string="than" />
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sowell , arguing from a laissez-faire perspective ," type="NP">
          <tokens>
            <token id="5" string="Sowell" />
            <token id="6" string="," />
            <token id="7" string="arguing" />
            <token id="8" string="from" />
            <token id="9" string="a" />
            <token id="10" string="laissez-faire" />
            <token id="11" string="perspective" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="endorsed the notion that blacks would benefit more from pursuing economic achievement than political agitation" type="VP">
          <tokens>
            <token id="13" string="endorsed" />
            <token id="14" string="the" />
            <token id="15" string="notion" />
            <token id="16" string="that" />
            <token id="17" string="blacks" />
            <token id="18" string="would" />
            <token id="19" string="benefit" />
            <token id="20" string="more" />
            <token id="21" string="from" />
            <token id="22" string="pursuing" />
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
            <token id="25" string="than" />
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="9" string="a laissez-faire perspective" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="laissez-faire" />
            <token id="11" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="10" string="arguing from a laissez-faire perspective" type="VP">
          <tokens>
            <token id="7" string="arguing" />
            <token id="8" string="from" />
            <token id="9" string="a" />
            <token id="10" string="laissez-faire" />
            <token id="11" string="perspective" />
          </tokens>
        </chunking>
        <chunking id="11" string="the notion" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="notion" />
          </tokens>
        </chunking>
        <chunking id="12" string="that blacks would benefit more from pursuing economic achievement than political agitation" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="blacks" />
            <token id="18" string="would" />
            <token id="19" string="benefit" />
            <token id="20" string="more" />
            <token id="21" string="from" />
            <token id="22" string="pursuing" />
            <token id="23" string="economic" />
            <token id="24" string="achievement" />
            <token id="25" string="than" />
            <token id="26" string="political" />
            <token id="27" string="agitation" />
          </tokens>
        </chunking>
        <chunking id="13" string="that book" type="NP">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="book" />
          </tokens>
        </chunking>
        <chunking id="14" string="Sowell" type="NP">
          <tokens>
            <token id="5" string="Sowell" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">book</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">book</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">endorsed</governor>
          <dependent id="3">book</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">endorsed</governor>
          <dependent id="5">Sowell</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">Sowell</governor>
          <dependent id="7">arguing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">perspective</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">perspective</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">perspective</governor>
          <dependent id="10">laissez-faire</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">arguing</governor>
          <dependent id="11">perspective</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">endorsed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">notion</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">endorsed</governor>
          <dependent id="15">notion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">benefit</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">benefit</governor>
          <dependent id="17">blacks</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">benefit</governor>
          <dependent id="18">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">endorsed</governor>
          <dependent id="19">benefit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">benefit</governor>
          <dependent id="20">more</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">pursuing</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">benefit</governor>
          <dependent id="22">pursuing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">achievement</governor>
          <dependent id="23">economic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">pursuing</governor>
          <dependent id="24">achievement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">agitation</governor>
          <dependent id="25">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">agitation</governor>
          <dependent id="26">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">pursuing</governor>
          <dependent id="27">agitation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>From Yale to Washington; Thomas, always a top student, was recruited out of Yale in 1974 by John Danforth, R-Mo., then Missouri attorney general, a Yale trustee and a frequent campus visitor.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="recruited" lemma="recruit" stem="recruit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="R-Mo." lemma="R-Mo." stem="r-mo." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Missouri" lemma="Missouri" stem="missouri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="28" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="general" lemma="general" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="33" string="trustee" lemma="trustee" stem="truste" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="frequent" lemma="frequent" stem="frequent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="campus" lemma="campus" stem="campu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="visitor" lemma="visitor" stem="visitor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (NP (NP (NNP Yale)) (PP (TO to) (NP (NNP Washington)))) (: ;) (NP (NNP Thomas)))) (, ,) (S (ADVP (RB always)) (NP (DT a) (JJ top) (NN student))) (, ,) (VP (VBD was) (VP (VBN recruited) (PRT (IN out)) (PP (IN of) (NP (NP (NNP Yale)) (PP (IN in) (NP (CD 1974))))) (PP (IN by) (NP (NP (NNP John) (NNP Danforth)) (, ,) (NP (NNP R-Mo.)) (, ,) (ADVP (RB then)) (NP (NP (NNP Missouri) (NN attorney) (NN general)) (, ,) (NP (DT a) (NNP Yale) (NN trustee)) (CC and) (NP (DT a) (JJ frequent) (NN campus) (NN visitor))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Yale trustee" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="Yale" />
            <token id="33" string="trustee" />
          </tokens>
        </chunking>
        <chunking id="2" string="Yale to Washington ; Thomas" type="NP">
          <tokens>
            <token id="2" string="Yale" />
            <token id="3" string="to" />
            <token id="4" string="Washington" />
            <token id="5" string=";" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="Yale in 1974" type="NP">
          <tokens>
            <token id="17" string="Yale" />
            <token id="18" string="in" />
            <token id="19" string="1974" />
          </tokens>
        </chunking>
        <chunking id="5" string="Yale" type="NP">
          <tokens>
            <token id="2" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="6" string="R-Mo." type="NP">
          <tokens>
            <token id="24" string="R-Mo." />
          </tokens>
        </chunking>
        <chunking id="7" string="John Danforth , R-Mo. , then Missouri attorney general , a Yale trustee and a frequent campus visitor" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Danforth" />
            <token id="23" string="," />
            <token id="24" string="R-Mo." />
            <token id="25" string="," />
            <token id="26" string="then" />
            <token id="27" string="Missouri" />
            <token id="28" string="attorney" />
            <token id="29" string="general" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="Yale" />
            <token id="33" string="trustee" />
            <token id="34" string="and" />
            <token id="35" string="a" />
            <token id="36" string="frequent" />
            <token id="37" string="campus" />
            <token id="38" string="visitor" />
          </tokens>
        </chunking>
        <chunking id="8" string="was recruited out of Yale in 1974 by John Danforth , R-Mo. , then Missouri attorney general , a Yale trustee and a frequent campus visitor" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="recruited" />
            <token id="15" string="out" />
            <token id="16" string="of" />
            <token id="17" string="Yale" />
            <token id="18" string="in" />
            <token id="19" string="1974" />
            <token id="20" string="by" />
            <token id="21" string="John" />
            <token id="22" string="Danforth" />
            <token id="23" string="," />
            <token id="24" string="R-Mo." />
            <token id="25" string="," />
            <token id="26" string="then" />
            <token id="27" string="Missouri" />
            <token id="28" string="attorney" />
            <token id="29" string="general" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="Yale" />
            <token id="33" string="trustee" />
            <token id="34" string="and" />
            <token id="35" string="a" />
            <token id="36" string="frequent" />
            <token id="37" string="campus" />
            <token id="38" string="visitor" />
          </tokens>
        </chunking>
        <chunking id="9" string="Missouri attorney general , a Yale trustee and a frequent campus visitor" type="NP">
          <tokens>
            <token id="27" string="Missouri" />
            <token id="28" string="attorney" />
            <token id="29" string="general" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="Yale" />
            <token id="33" string="trustee" />
            <token id="34" string="and" />
            <token id="35" string="a" />
            <token id="36" string="frequent" />
            <token id="37" string="campus" />
            <token id="38" string="visitor" />
          </tokens>
        </chunking>
        <chunking id="10" string="Washington" type="NP">
          <tokens>
            <token id="4" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="11" string="1974" type="NP">
          <tokens>
            <token id="19" string="1974" />
          </tokens>
        </chunking>
        <chunking id="12" string="a frequent campus visitor" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="frequent" />
            <token id="37" string="campus" />
            <token id="38" string="visitor" />
          </tokens>
        </chunking>
        <chunking id="13" string="Yale to Washington" type="NP">
          <tokens>
            <token id="2" string="Yale" />
            <token id="3" string="to" />
            <token id="4" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="14" string="a top student" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="top" />
            <token id="11" string="student" />
          </tokens>
        </chunking>
        <chunking id="15" string="recruited out of Yale in 1974 by John Danforth , R-Mo. , then Missouri attorney general , a Yale trustee and a frequent campus visitor" type="VP">
          <tokens>
            <token id="14" string="recruited" />
            <token id="15" string="out" />
            <token id="16" string="of" />
            <token id="17" string="Yale" />
            <token id="18" string="in" />
            <token id="19" string="1974" />
            <token id="20" string="by" />
            <token id="21" string="John" />
            <token id="22" string="Danforth" />
            <token id="23" string="," />
            <token id="24" string="R-Mo." />
            <token id="25" string="," />
            <token id="26" string="then" />
            <token id="27" string="Missouri" />
            <token id="28" string="attorney" />
            <token id="29" string="general" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="Yale" />
            <token id="33" string="trustee" />
            <token id="34" string="and" />
            <token id="35" string="a" />
            <token id="36" string="frequent" />
            <token id="37" string="campus" />
            <token id="38" string="visitor" />
          </tokens>
        </chunking>
        <chunking id="16" string="Missouri attorney general" type="NP">
          <tokens>
            <token id="27" string="Missouri" />
            <token id="28" string="attorney" />
            <token id="29" string="general" />
          </tokens>
        </chunking>
        <chunking id="17" string="John Danforth" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Danforth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Yale</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">recruited</governor>
          <dependent id="2">Yale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Washington</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Yale</governor>
          <dependent id="4">Washington</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Yale</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">student</governor>
          <dependent id="8">always</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">student</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">student</governor>
          <dependent id="10">top</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">recruited</governor>
          <dependent id="11">student</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">recruited</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">recruited</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">recruited</governor>
          <dependent id="15">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Yale</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">recruited</governor>
          <dependent id="17">Yale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1974</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">Yale</governor>
          <dependent id="19">1974</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Danforth</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Danforth</governor>
          <dependent id="21">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">recruited</governor>
          <dependent id="22">Danforth</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Danforth</governor>
          <dependent id="24">R-Mo.</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">general</governor>
          <dependent id="26">then</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">general</governor>
          <dependent id="27">Missouri</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">general</governor>
          <dependent id="28">attorney</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Danforth</governor>
          <dependent id="29">general</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">trustee</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">trustee</governor>
          <dependent id="32">Yale</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">general</governor>
          <dependent id="33">trustee</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">general</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">visitor</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">visitor</governor>
          <dependent id="36">frequent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">visitor</governor>
          <dependent id="37">campus</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">general</governor>
          <dependent id="38">visitor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1974" />
          </tokens>
        </entity>
        <entity id="3" string="Missouri" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="Missouri" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Yale" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Yale" />
          </tokens>
        </entity>
        <entity id="6" string="R-Mo." type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="R-Mo." />
          </tokens>
        </entity>
        <entity id="7" string="John Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Danforth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>Danforth brought Thomas to Jefferson City, Mo., to work in the attorney general&amp;apost;s office.</content>
      <tokens>
        <token id="1" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="brought" lemma="bring" stem="brought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Jefferson" lemma="Jefferson" stem="jefferson" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Mo." lemma="Mo." stem="mo." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="general" lemma="general" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Danforth)) (VP (VBD brought) (NP (NNP Thomas)) (PP (TO to) (NP (NP (NNP Jefferson) (NNP City)) (, ,) (NP (NNP Mo.)) (, ,))) (S (VP (TO to) (VP (VB work) (PP (IN in) (NP (NP (DT the) (NN attorney) (NN general) (POS 's)) (NN office))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the attorney general 's office" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="attorney" />
            <token id="15" string="general" />
            <token id="16" string="'s" />
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="the attorney general 's" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="attorney" />
            <token id="15" string="general" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jefferson City , Mo. ," type="NP">
          <tokens>
            <token id="5" string="Jefferson" />
            <token id="6" string="City" />
            <token id="7" string="," />
            <token id="8" string="Mo." />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="to work in the attorney general 's office" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="work" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="attorney" />
            <token id="15" string="general" />
            <token id="16" string="'s" />
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="Danforth" type="NP">
          <tokens>
            <token id="1" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="7" string="brought Thomas to Jefferson City , Mo. , to work in the attorney general 's office" type="VP">
          <tokens>
            <token id="2" string="brought" />
            <token id="3" string="Thomas" />
            <token id="4" string="to" />
            <token id="5" string="Jefferson" />
            <token id="6" string="City" />
            <token id="7" string="," />
            <token id="8" string="Mo." />
            <token id="9" string="," />
            <token id="10" string="to" />
            <token id="11" string="work" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="attorney" />
            <token id="15" string="general" />
            <token id="16" string="'s" />
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="8" string="work in the attorney general 's office" type="VP">
          <tokens>
            <token id="11" string="work" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="attorney" />
            <token id="15" string="general" />
            <token id="16" string="'s" />
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="9" string="Jefferson City" type="NP">
          <tokens>
            <token id="5" string="Jefferson" />
            <token id="6" string="City" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mo." type="NP">
          <tokens>
            <token id="8" string="Mo." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">brought</governor>
          <dependent id="1">Danforth</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">brought</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">brought</governor>
          <dependent id="3">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">City</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">City</governor>
          <dependent id="5">Jefferson</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">brought</governor>
          <dependent id="6">City</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">City</governor>
          <dependent id="8">Mo.</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">work</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">brought</governor>
          <dependent id="11">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">office</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">general</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">general</governor>
          <dependent id="14">attorney</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">office</governor>
          <dependent id="15">general</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">general</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">work</governor>
          <dependent id="17">office</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Danforth" />
          </tokens>
        </entity>
        <entity id="3" string="Jefferson City" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Jefferson" />
            <token id="6" string="City" />
          </tokens>
        </entity>
        <entity id="4" string="Mo." type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Mo." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>When Danforth became a U.S. senator in 1977, Thomas stayed in St. Louis to work as an assistant counsel for the Monsanto Corp., then in 1979 joined Danforth in Washington as a legislative aide.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="senator" lemma="senator" stem="senat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1977" lemma="1977" stem="1977" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="stayed" lemma="stay" stem="stai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Louis" lemma="Louis" stem="loui" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="counsel" lemma="counsel" stem="counsel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Monsanto" lemma="Monsanto" stem="monsanto" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Corp." lemma="Corp." stem="corp." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="29" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="aide" lemma="aide" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (WHADVP (WRB When)) (S (NP (NNP Danforth)) (VP (VBD became) (NP (DT a) (NNP U.S.) (NN senator)) (PP (IN in) (NP (CD 1977)))))) (, ,) (NP (NNP Thomas)) (VP (VBD stayed) (PP (IN in) (NP (NNP St.) (NNP Louis))) (S (VP (TO to) (VP (VB work) (PP (IN as) (NP (NP (DT an) (JJ assistant) (NN counsel)) (PP (IN for) (NP (DT the) (NNP Monsanto) (NNP Corp.)))))))))) (, ,) (NP (NP (RB then)) (PP (IN in) (NP (CD 1979)))) (VP (VBD joined) (NP (NNP Danforth)) (PP (IN in) (NP (NNP Washington))) (PP (IN as) (NP (DT a) (JJ legislative) (NN aide)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stayed in St. Louis to work as an assistant counsel for the Monsanto Corp." type="VP">
          <tokens>
            <token id="11" string="stayed" />
            <token id="12" string="in" />
            <token id="13" string="St." />
            <token id="14" string="Louis" />
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="as" />
            <token id="18" string="an" />
            <token id="19" string="assistant" />
            <token id="20" string="counsel" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="2" string="a U.S. senator" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="U.S." />
            <token id="6" string="senator" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Monsanto Corp." type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="When Danforth became a U.S. senator in 1977" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Danforth" />
            <token id="3" string="became" />
            <token id="4" string="a" />
            <token id="5" string="U.S." />
            <token id="6" string="senator" />
            <token id="7" string="in" />
            <token id="8" string="1977" />
          </tokens>
        </chunking>
        <chunking id="6" string="then in 1979" type="NP">
          <tokens>
            <token id="26" string="then" />
            <token id="27" string="in" />
            <token id="28" string="1979" />
          </tokens>
        </chunking>
        <chunking id="7" string="then" type="NP">
          <tokens>
            <token id="26" string="then" />
          </tokens>
        </chunking>
        <chunking id="8" string="a legislative aide" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="legislative" />
            <token id="36" string="aide" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="1977" type="NP">
          <tokens>
            <token id="8" string="1977" />
          </tokens>
        </chunking>
        <chunking id="11" string="Washington" type="NP">
          <tokens>
            <token id="32" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="12" string="work as an assistant counsel for the Monsanto Corp." type="VP">
          <tokens>
            <token id="16" string="work" />
            <token id="17" string="as" />
            <token id="18" string="an" />
            <token id="19" string="assistant" />
            <token id="20" string="counsel" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="13" string="joined Danforth in Washington as a legislative aide" type="VP">
          <tokens>
            <token id="29" string="joined" />
            <token id="30" string="Danforth" />
            <token id="31" string="in" />
            <token id="32" string="Washington" />
            <token id="33" string="as" />
            <token id="34" string="a" />
            <token id="35" string="legislative" />
            <token id="36" string="aide" />
          </tokens>
        </chunking>
        <chunking id="14" string="Danforth" type="NP">
          <tokens>
            <token id="2" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="15" string="became a U.S. senator in 1977" type="VP">
          <tokens>
            <token id="3" string="became" />
            <token id="4" string="a" />
            <token id="5" string="U.S." />
            <token id="6" string="senator" />
            <token id="7" string="in" />
            <token id="8" string="1977" />
          </tokens>
        </chunking>
        <chunking id="16" string="to work as an assistant counsel for the Monsanto Corp." type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="work" />
            <token id="17" string="as" />
            <token id="18" string="an" />
            <token id="19" string="assistant" />
            <token id="20" string="counsel" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="17" string="an assistant counsel for the Monsanto Corp." type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="assistant" />
            <token id="20" string="counsel" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="18" string="St. Louis" type="NP">
          <tokens>
            <token id="13" string="St." />
            <token id="14" string="Louis" />
          </tokens>
        </chunking>
        <chunking id="19" string="an assistant counsel" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="assistant" />
            <token id="20" string="counsel" />
          </tokens>
        </chunking>
        <chunking id="20" string="1979" type="NP">
          <tokens>
            <token id="28" string="1979" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">became</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">became</governor>
          <dependent id="2">Danforth</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">stayed</governor>
          <dependent id="3">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">senator</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">senator</governor>
          <dependent id="5">U.S.</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">became</governor>
          <dependent id="6">senator</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1977</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">became</governor>
          <dependent id="8">1977</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">stayed</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">joined</governor>
          <dependent id="11">stayed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Louis</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Louis</governor>
          <dependent id="13">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">stayed</governor>
          <dependent id="14">Louis</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">work</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">stayed</governor>
          <dependent id="16">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">counsel</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">counsel</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">counsel</governor>
          <dependent id="19">assistant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">work</governor>
          <dependent id="20">counsel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Corp.</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Corp.</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Corp.</governor>
          <dependent id="23">Monsanto</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">counsel</governor>
          <dependent id="24">Corp.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">joined</governor>
          <dependent id="26">then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">1979</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">then</governor>
          <dependent id="28">1979</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">joined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">joined</governor>
          <dependent id="30">Danforth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Washington</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">joined</governor>
          <dependent id="32">Washington</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">aide</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">aide</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">aide</governor>
          <dependent id="35">legislative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">joined</governor>
          <dependent id="36">aide</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1977" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1977" />
          </tokens>
        </entity>
        <entity id="2" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="32" string="Washington" />
          </tokens>
        </entity>
        <entity id="3" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="U.S." />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Danforth" />
          </tokens>
        </entity>
        <entity id="6" string="St. Louis" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="St." />
            <token id="14" string="Louis" />
          </tokens>
        </entity>
        <entity id="7" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="1979" />
          </tokens>
        </entity>
        <entity id="8" string="Monsanto Corp." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="Monsanto" />
            <token id="24" string="Corp." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>Reagan administration officials were so impressed by Thomas and his new conservative leanings that they appointed him assistant secretary for civil rights in the Department of Education.</content>
      <tokens>
        <token id="1" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="impressed" lemma="impressed" stem="impress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="13" string="leanings" lemma="leaning" stem="lean" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="appointed" lemma="appoint" stem="appoint" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="27" string="Education" lemma="Education" stem="educat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Reagan) (NN administration) (NNS officials)) (VP (VBD were) (ADJP (RB so) (JJ impressed) (PP (IN by) (NP (NP (NNP Thomas)) (CC and) (NP (PRP$ his) (JJ new) (JJ conservative) (NNS leanings))))) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD appointed) (S (NP (PRP him)) (NP (NP (NN assistant) (NN secretary)) (PP (IN for) (NP (NP (JJ civil) (NNS rights)) (PP (IN in) (NP (NP (DT the) (NNP Department)) (PP (IN of) (NP (NNP Education))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Department" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Department" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="assistant secretary" type="NP">
          <tokens>
            <token id="18" string="assistant" />
            <token id="19" string="secretary" />
          </tokens>
        </chunking>
        <chunking id="5" string="appointed him assistant secretary for civil rights in the Department of Education" type="VP">
          <tokens>
            <token id="16" string="appointed" />
            <token id="17" string="him" />
            <token id="18" string="assistant" />
            <token id="19" string="secretary" />
            <token id="20" string="for" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="6" string="assistant secretary for civil rights in the Department of Education" type="NP">
          <tokens>
            <token id="18" string="assistant" />
            <token id="19" string="secretary" />
            <token id="20" string="for" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="7" string="so impressed by Thomas and his new conservative leanings" type="ADJP">
          <tokens>
            <token id="5" string="so" />
            <token id="6" string="impressed" />
            <token id="7" string="by" />
            <token id="8" string="Thomas" />
            <token id="9" string="and" />
            <token id="10" string="his" />
            <token id="11" string="new" />
            <token id="12" string="conservative" />
            <token id="13" string="leanings" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="15" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="civil rights" type="NP">
          <tokens>
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="10" string="his new conservative leanings" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="new" />
            <token id="12" string="conservative" />
            <token id="13" string="leanings" />
          </tokens>
        </chunking>
        <chunking id="11" string="were so impressed by Thomas and his new conservative leanings that they appointed him assistant secretary for civil rights in the Department of Education" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="so" />
            <token id="6" string="impressed" />
            <token id="7" string="by" />
            <token id="8" string="Thomas" />
            <token id="9" string="and" />
            <token id="10" string="his" />
            <token id="11" string="new" />
            <token id="12" string="conservative" />
            <token id="13" string="leanings" />
            <token id="14" string="that" />
            <token id="15" string="they" />
            <token id="16" string="appointed" />
            <token id="17" string="him" />
            <token id="18" string="assistant" />
            <token id="19" string="secretary" />
            <token id="20" string="for" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="12" string="Thomas and his new conservative leanings" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
            <token id="9" string="and" />
            <token id="10" string="his" />
            <token id="11" string="new" />
            <token id="12" string="conservative" />
            <token id="13" string="leanings" />
          </tokens>
        </chunking>
        <chunking id="13" string="Education" type="NP">
          <tokens>
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="14" string="that they appointed him assistant secretary for civil rights in the Department of Education" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="they" />
            <token id="16" string="appointed" />
            <token id="17" string="him" />
            <token id="18" string="assistant" />
            <token id="19" string="secretary" />
            <token id="20" string="for" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Department of Education" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
        <chunking id="16" string="Reagan administration officials" type="NP">
          <tokens>
            <token id="1" string="Reagan" />
            <token id="2" string="administration" />
            <token id="3" string="officials" />
          </tokens>
        </chunking>
        <chunking id="17" string="civil rights in the Department of Education" type="NP">
          <tokens>
            <token id="21" string="civil" />
            <token id="22" string="rights" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">officials</governor>
          <dependent id="1">Reagan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">officials</governor>
          <dependent id="2">administration</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">impressed</governor>
          <dependent id="3">officials</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">impressed</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">impressed</governor>
          <dependent id="5">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">impressed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thomas</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">impressed</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Thomas</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">leanings</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">leanings</governor>
          <dependent id="11">new</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">leanings</governor>
          <dependent id="12">conservative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Thomas</governor>
          <dependent id="13">leanings</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">appointed</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">appointed</governor>
          <dependent id="15">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">impressed</governor>
          <dependent id="16">appointed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">secretary</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">secretary</governor>
          <dependent id="18">assistant</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">appointed</governor>
          <dependent id="19">secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">rights</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">rights</governor>
          <dependent id="21">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">secretary</governor>
          <dependent id="22">rights</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Department</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Department</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">rights</governor>
          <dependent id="25">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Education</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Department</governor>
          <dependent id="27">Education</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Department of Education" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Department" />
            <token id="26" string="of" />
            <token id="27" string="Education" />
          </tokens>
        </entity>
        <entity id="4" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>In 1982, they promoted him to the more visible post of chairman of the Equal Employment Opportunity Commission.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1982" lemma="1982" stem="1982" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="promoted" lemma="promote" stem="promot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="visible" lemma="visible" stem="visibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="post" lemma="post" stem="post" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Equal" lemma="Equal" stem="equal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Employment" lemma="Employment" stem="employment" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="Opportunity" lemma="Opportunity" stem="opportun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1982))) (, ,) (NP (PRP they)) (VP (VBD promoted) (NP (PRP him)) (PP (TO to) (NP (NP (DT the) (ADJP (RBR more) (JJ visible)) (NN post)) (PP (IN of) (NP (NP (NN chairman)) (PP (IN of) (NP (DT the) (NNP Equal) (NNP Employment) (NNP Opportunity) (NNP Commission)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Equal" />
            <token id="17" string="Employment" />
            <token id="18" string="Opportunity" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="the more visible post of chairman of the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="more" />
            <token id="10" string="visible" />
            <token id="11" string="post" />
            <token id="12" string="of" />
            <token id="13" string="chairman" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="Equal" />
            <token id="17" string="Employment" />
            <token id="18" string="Opportunity" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="4" string="1982" type="NP">
          <tokens>
            <token id="2" string="1982" />
          </tokens>
        </chunking>
        <chunking id="5" string="the more visible post" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="more" />
            <token id="10" string="visible" />
            <token id="11" string="post" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="chairman of the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="13" string="chairman" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="Equal" />
            <token id="17" string="Employment" />
            <token id="18" string="Opportunity" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="8" string="chairman" type="NP">
          <tokens>
            <token id="13" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="9" string="promoted him to the more visible post of chairman of the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="5" string="promoted" />
            <token id="6" string="him" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="more" />
            <token id="10" string="visible" />
            <token id="11" string="post" />
            <token id="12" string="of" />
            <token id="13" string="chairman" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="Equal" />
            <token id="17" string="Employment" />
            <token id="18" string="Opportunity" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="10" string="more visible" type="ADJP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="visible" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1982</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">promoted</governor>
          <dependent id="2">1982</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">promoted</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">promoted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">promoted</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">post</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">post</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">visible</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">post</governor>
          <dependent id="10">visible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">promoted</governor>
          <dependent id="11">post</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">chairman</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">post</governor>
          <dependent id="13">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Commission</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Commission</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Commission</governor>
          <dependent id="16">Equal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Commission</governor>
          <dependent id="17">Employment</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Commission</governor>
          <dependent id="18">Opportunity</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">chairman</governor>
          <dependent id="19">Commission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Equal Employment Opportunity Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Equal" />
            <token id="17" string="Employment" />
            <token id="18" string="Opportunity" />
            <token id="19" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="1982" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1982" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>There controversy dogged him for the next eight years.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="dogged" lemma="dog" stem="dog" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (NP (NN controversy)) (VP (VBD dogged) (NP (PRP him)) (PP (IN for) (NP (DT the) (JJ next) (CD eight) (NNS years)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="the next eight years" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="next" />
            <token id="8" string="eight" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="controversy" type="NP">
          <tokens>
            <token id="2" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="5" string="dogged him for the next eight years" type="VP">
          <tokens>
            <token id="3" string="dogged" />
            <token id="4" string="him" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="next" />
            <token id="8" string="eight" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">dogged</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">dogged</governor>
          <dependent id="2">controversy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">dogged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">dogged</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">years</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">years</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">years</governor>
          <dependent id="7">next</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">years</governor>
          <dependent id="8">eight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">dogged</governor>
          <dependent id="9">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the next eight years" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="next" />
            <token id="8" string="eight" />
            <token id="9" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>Congress learned in 1989 that the EEOC under Thomas&amp;apost; direction had permitted more than 13,000 age discrimination claims to lapse.</content>
      <tokens>
        <token id="1" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="learned" lemma="learn" stem="learn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="EEOC" lemma="EEOC" stem="eeoc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="direction" lemma="direction" stem="direct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="permitted" lemma="permit" stem="permit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="13,000" lemma="13,000" stem="13,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="claims" lemma="claim" stem="claim" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lapse" lemma="lapse" stem="laps" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Congress)) (VP (VBD learned) (PP (IN in) (NP (CD 1989))) (SBAR (IN that) (S (NP (NP (DT the) (NNP EEOC)) (PP (IN under) (NP (NP (NNP Thomas) (POS ')) (NN direction)))) (VP (VBD had) (VP (VBN permitted) (SBAR (S (NP (QP (RBR more) (IN than) (CD 13,000)) (NN age) (NN discrimination)) (VP (VBZ claims) (PP (TO to) (NP (NN lapse))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="claims to lapse" type="VP">
          <tokens>
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' direction" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="direction" />
          </tokens>
        </chunking>
        <chunking id="3" string="had permitted more than 13,000 age discrimination claims to lapse" type="VP">
          <tokens>
            <token id="12" string="had" />
            <token id="13" string="permitted" />
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="4" string="more than 13,000 age discrimination" type="NP">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="5" string="more than 13,000 age discrimination claims to lapse" type="SBAR">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas '" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the EEOC under Thomas ' direction had permitted more than 13,000 age discrimination claims to lapse" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="EEOC" />
            <token id="8" string="under" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="direction" />
            <token id="12" string="had" />
            <token id="13" string="permitted" />
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="8" string="learned in 1989 that the EEOC under Thomas ' direction had permitted more than 13,000 age discrimination claims to lapse" type="VP">
          <tokens>
            <token id="2" string="learned" />
            <token id="3" string="in" />
            <token id="4" string="1989" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="EEOC" />
            <token id="8" string="under" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="direction" />
            <token id="12" string="had" />
            <token id="13" string="permitted" />
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="9" string="Congress" type="NP">
          <tokens>
            <token id="1" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="10" string="the EEOC" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="EEOC" />
          </tokens>
        </chunking>
        <chunking id="11" string="lapse" type="NP">
          <tokens>
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="12" string="the EEOC under Thomas ' direction" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="EEOC" />
            <token id="8" string="under" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="direction" />
          </tokens>
        </chunking>
        <chunking id="13" string="permitted more than 13,000 age discrimination claims to lapse" type="VP">
          <tokens>
            <token id="13" string="permitted" />
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="13,000" />
            <token id="17" string="age" />
            <token id="18" string="discrimination" />
            <token id="19" string="claims" />
            <token id="20" string="to" />
            <token id="21" string="lapse" />
          </tokens>
        </chunking>
        <chunking id="14" string="1989" type="NP">
          <tokens>
            <token id="4" string="1989" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">learned</governor>
          <dependent id="1">Congress</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">learned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1989</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">learned</governor>
          <dependent id="4">1989</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">permitted</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">EEOC</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">permitted</governor>
          <dependent id="7">EEOC</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">direction</governor>
          <dependent id="8">under</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">direction</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Thomas</governor>
          <dependent id="10">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">EEOC</governor>
          <dependent id="11">direction</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">permitted</governor>
          <dependent id="12">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">learned</governor>
          <dependent id="13">permitted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">13,000</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">more</governor>
          <dependent id="15">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">discrimination</governor>
          <dependent id="16">13,000</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">discrimination</governor>
          <dependent id="17">age</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">claims</governor>
          <dependent id="18">discrimination</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">permitted</governor>
          <dependent id="19">claims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">lapse</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">claims</governor>
          <dependent id="21">lapse</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="EEOC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="EEOC" />
          </tokens>
        </entity>
        <entity id="2" string="13,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="13,000" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Congress" />
          </tokens>
        </entity>
        <entity id="5" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>Civil-rights groups accused Thomas of failing to enforce other anti-discrimination laws as well, and of retaliating against employees who disagreed with his policies.</content>
      <tokens>
        <token id="1" string="Civil-rights" lemma="civil-rights" stem="civil-right" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="failing" lemma="fail" stem="fail" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="enforce" lemma="enforce" stem="enforc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="anti-discrimination" lemma="anti-discrimination" stem="anti-discrimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="retaliating" lemma="retaliate" stem="retali" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="disagreed" lemma="disagree" stem="disagre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="policies" lemma="policy" stem="polici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Civil-rights) (NNS groups)) (VP (VBD accused) (NP (NNP Thomas)) (PP (PP (IN of) (S (VP (VBG failing) (S (VP (TO to) (VP (VB enforce) (NP (JJ other) (JJ anti-discrimination) (NNS laws)) (ADVP (RB as) (RB well)))))))) (, ,) (CC and) (PP (IN of) (S (VP (VBG retaliating) (PP (IN against) (NP (NP (NNS employees)) (SBAR (WHNP (WP who)) (S (VP (VBD disagreed) (PP (IN with) (NP (PRP$ his) (NNS policies))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his policies" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="retaliating against employees who disagreed with his policies" type="VP">
          <tokens>
            <token id="17" string="retaliating" />
            <token id="18" string="against" />
            <token id="19" string="employees" />
            <token id="20" string="who" />
            <token id="21" string="disagreed" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
        <chunking id="4" string="accused Thomas of failing to enforce other anti-discrimination laws as well , and of retaliating against employees who disagreed with his policies" type="VP">
          <tokens>
            <token id="3" string="accused" />
            <token id="4" string="Thomas" />
            <token id="5" string="of" />
            <token id="6" string="failing" />
            <token id="7" string="to" />
            <token id="8" string="enforce" />
            <token id="9" string="other" />
            <token id="10" string="anti-discrimination" />
            <token id="11" string="laws" />
            <token id="12" string="as" />
            <token id="13" string="well" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="of" />
            <token id="17" string="retaliating" />
            <token id="18" string="against" />
            <token id="19" string="employees" />
            <token id="20" string="who" />
            <token id="21" string="disagreed" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
        <chunking id="5" string="failing to enforce other anti-discrimination laws as well" type="VP">
          <tokens>
            <token id="6" string="failing" />
            <token id="7" string="to" />
            <token id="8" string="enforce" />
            <token id="9" string="other" />
            <token id="10" string="anti-discrimination" />
            <token id="11" string="laws" />
            <token id="12" string="as" />
            <token id="13" string="well" />
          </tokens>
        </chunking>
        <chunking id="6" string="to enforce other anti-discrimination laws as well" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="enforce" />
            <token id="9" string="other" />
            <token id="10" string="anti-discrimination" />
            <token id="11" string="laws" />
            <token id="12" string="as" />
            <token id="13" string="well" />
          </tokens>
        </chunking>
        <chunking id="7" string="enforce other anti-discrimination laws as well" type="VP">
          <tokens>
            <token id="8" string="enforce" />
            <token id="9" string="other" />
            <token id="10" string="anti-discrimination" />
            <token id="11" string="laws" />
            <token id="12" string="as" />
            <token id="13" string="well" />
          </tokens>
        </chunking>
        <chunking id="8" string="disagreed with his policies" type="VP">
          <tokens>
            <token id="21" string="disagreed" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
        <chunking id="9" string="Civil-rights groups" type="NP">
          <tokens>
            <token id="1" string="Civil-rights" />
            <token id="2" string="groups" />
          </tokens>
        </chunking>
        <chunking id="10" string="other anti-discrimination laws" type="NP">
          <tokens>
            <token id="9" string="other" />
            <token id="10" string="anti-discrimination" />
            <token id="11" string="laws" />
          </tokens>
        </chunking>
        <chunking id="11" string="employees" type="NP">
          <tokens>
            <token id="19" string="employees" />
          </tokens>
        </chunking>
        <chunking id="12" string="employees who disagreed with his policies" type="NP">
          <tokens>
            <token id="19" string="employees" />
            <token id="20" string="who" />
            <token id="21" string="disagreed" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
        <chunking id="13" string="who disagreed with his policies" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="disagreed" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="policies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">groups</governor>
          <dependent id="1">Civil-rights</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">accused</governor>
          <dependent id="2">groups</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">accused</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">accused</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">failing</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">accused</governor>
          <dependent id="6">failing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">enforce</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">failing</governor>
          <dependent id="8">enforce</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">laws</governor>
          <dependent id="9">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">laws</governor>
          <dependent id="10">anti-discrimination</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">enforce</governor>
          <dependent id="11">laws</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">enforce</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">as</governor>
          <dependent id="13">well</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">failing</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">retaliating</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">failing</governor>
          <dependent id="17">retaliating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">employees</governor>
          <dependent id="18">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">retaliating</governor>
          <dependent id="19">employees</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">disagreed</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">employees</governor>
          <dependent id="21">disagreed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">policies</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">policies</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">disagreed</governor>
          <dependent id="24">policies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Civil-rights" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Civil-rights" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>Thomas concentrated on winning relief for victims of actual discrimination.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="concentrated" lemma="concentrate" stem="concentr" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="relief" lemma="relief" stem="relief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="actual" lemma="actual" stem="actual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thomas)) (VP (VBD concentrated) (PP (IN on) (S (VP (VBG winning) (NP (NN relief)) (PP (IN for) (NP (NP (NNS victims)) (PP (IN of) (NP (JJ actual) (NN discrimination))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="concentrated on winning relief for victims of actual discrimination" type="VP">
          <tokens>
            <token id="2" string="concentrated" />
            <token id="3" string="on" />
            <token id="4" string="winning" />
            <token id="5" string="relief" />
            <token id="6" string="for" />
            <token id="7" string="victims" />
            <token id="8" string="of" />
            <token id="9" string="actual" />
            <token id="10" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="2" string="winning relief for victims of actual discrimination" type="VP">
          <tokens>
            <token id="4" string="winning" />
            <token id="5" string="relief" />
            <token id="6" string="for" />
            <token id="7" string="victims" />
            <token id="8" string="of" />
            <token id="9" string="actual" />
            <token id="10" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="3" string="actual discrimination" type="NP">
          <tokens>
            <token id="9" string="actual" />
            <token id="10" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="relief" type="NP">
          <tokens>
            <token id="5" string="relief" />
          </tokens>
        </chunking>
        <chunking id="6" string="victims of actual discrimination" type="NP">
          <tokens>
            <token id="7" string="victims" />
            <token id="8" string="of" />
            <token id="9" string="actual" />
            <token id="10" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="7" string="victims" type="NP">
          <tokens>
            <token id="7" string="victims" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">concentrated</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">concentrated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">winning</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">concentrated</governor>
          <dependent id="4">winning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">winning</governor>
          <dependent id="5">relief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">victims</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">winning</governor>
          <dependent id="7">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">discrimination</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">discrimination</governor>
          <dependent id="9">actual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">victims</governor>
          <dependent id="10">discrimination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>He steered away from lawsuits based on statistical evidence and remedies that included timetables for future hiring.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="steered" lemma="steer" stem="steer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="statistical" lemma="statistical" stem="statist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="remedies" lemma="remedy" stem="remedi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="timetables" lemma="timetable" stem="timet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="future" lemma="future" stem="futur" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="hiring" lemma="hiring" stem="hire" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD steered) (ADVP (RB away)) (PP (IN from) (NP (NP (NNS lawsuits)) (VP (VBN based) (PP (IN on) (NP (NP (JJ statistical) (NN evidence) (CC and) (NNS remedies)) (SBAR (WHNP (WDT that)) (S (VP (VBD included) (NP (NNS timetables)) (PP (IN for) (NP (JJ future) (NN hiring)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="based on statistical evidence and remedies that included timetables for future hiring" type="VP">
          <tokens>
            <token id="6" string="based" />
            <token id="7" string="on" />
            <token id="8" string="statistical" />
            <token id="9" string="evidence" />
            <token id="10" string="and" />
            <token id="11" string="remedies" />
            <token id="12" string="that" />
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="2" string="statistical evidence and remedies that included timetables for future hiring" type="NP">
          <tokens>
            <token id="8" string="statistical" />
            <token id="9" string="evidence" />
            <token id="10" string="and" />
            <token id="11" string="remedies" />
            <token id="12" string="that" />
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="3" string="that included timetables for future hiring" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="4" string="lawsuits" type="NP">
          <tokens>
            <token id="5" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="5" string="timetables" type="NP">
          <tokens>
            <token id="14" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="6" string="lawsuits based on statistical evidence and remedies that included timetables for future hiring" type="NP">
          <tokens>
            <token id="5" string="lawsuits" />
            <token id="6" string="based" />
            <token id="7" string="on" />
            <token id="8" string="statistical" />
            <token id="9" string="evidence" />
            <token id="10" string="and" />
            <token id="11" string="remedies" />
            <token id="12" string="that" />
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="7" string="included timetables for future hiring" type="VP">
          <tokens>
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="steered away from lawsuits based on statistical evidence and remedies that included timetables for future hiring" type="VP">
          <tokens>
            <token id="2" string="steered" />
            <token id="3" string="away" />
            <token id="4" string="from" />
            <token id="5" string="lawsuits" />
            <token id="6" string="based" />
            <token id="7" string="on" />
            <token id="8" string="statistical" />
            <token id="9" string="evidence" />
            <token id="10" string="and" />
            <token id="11" string="remedies" />
            <token id="12" string="that" />
            <token id="13" string="included" />
            <token id="14" string="timetables" />
            <token id="15" string="for" />
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
        <chunking id="10" string="statistical evidence and remedies" type="NP">
          <tokens>
            <token id="8" string="statistical" />
            <token id="9" string="evidence" />
            <token id="10" string="and" />
            <token id="11" string="remedies" />
          </tokens>
        </chunking>
        <chunking id="11" string="future hiring" type="NP">
          <tokens>
            <token id="16" string="future" />
            <token id="17" string="hiring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">steered</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">steered</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">steered</governor>
          <dependent id="3">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">lawsuits</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">steered</governor>
          <dependent id="5">lawsuits</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">lawsuits</governor>
          <dependent id="6">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">evidence</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">evidence</governor>
          <dependent id="8">statistical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">based</governor>
          <dependent id="9">evidence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">evidence</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">evidence</governor>
          <dependent id="11">remedies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">included</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">evidence</governor>
          <dependent id="13">included</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">included</governor>
          <dependent id="14">timetables</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">hiring</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">hiring</governor>
          <dependent id="16">future</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">included</governor>
          <dependent id="17">hiring</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="future" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>But he was unwilling to go along with more strident voices in the Reagan administration who opposed most legal remedies for discrimination, so he often felt isolated from both the administration and the civil rights establishment.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="unwilling" lemma="unwilling" stem="unwil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="along" lemma="along" stem="along" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="strident" lemma="strident" stem="strident" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="voices" lemma="voice" stem="voic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="remedies" lemma="remedy" stem="remedi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="isolated" lemma="isolate" stem="isol" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="establishment" lemma="establishment" stem="establish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ unwilling) (S (VP (TO to) (VP (VB go) (PRT (RP along)) (PP (IN with) (NP (NP (JJR more) (JJ strident) (NNS voices)) (PP (IN in) (NP (DT the) (NNP Reagan) (NN administration))) (SBAR (WHNP (WP who)) (S (VP (VBD opposed) (NP (ADJP (RBS most) (JJ legal)) (NNS remedies)) (PP (IN for) (NP (NN discrimination)))))))))))))) (, ,) (RB so) (S (NP (PRP he)) (ADVP (RB often)) (VP (VBD felt) (VP (VBN isolated) (PP (IN from) (NP (CC both) (NP (DT the) (NN administration)) (CC and) (NP (DT the) (JJ civil) (NNS rights) (NN establishment))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the civil rights establishment" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="2" string="the administration" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="administration" />
          </tokens>
        </chunking>
        <chunking id="3" string="more strident voices" type="NP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
          </tokens>
        </chunking>
        <chunking id="4" string="more strident voices in the Reagan administration who opposed most legal remedies for discrimination" type="NP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="5" string="most legal remedies" type="NP">
          <tokens>
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
          </tokens>
        </chunking>
        <chunking id="6" string="isolated from both the administration and the civil rights establishment" type="VP">
          <tokens>
            <token id="28" string="isolated" />
            <token id="29" string="from" />
            <token id="30" string="both" />
            <token id="31" string="the" />
            <token id="32" string="administration" />
            <token id="33" string="and" />
            <token id="34" string="the" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="7" string="both the administration and the civil rights establishment" type="NP">
          <tokens>
            <token id="30" string="both" />
            <token id="31" string="the" />
            <token id="32" string="administration" />
            <token id="33" string="and" />
            <token id="34" string="the" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="8" string="unwilling to go along with more strident voices in the Reagan administration who opposed most legal remedies for discrimination" type="ADJP">
          <tokens>
            <token id="4" string="unwilling" />
            <token id="5" string="to" />
            <token id="6" string="go" />
            <token id="7" string="along" />
            <token id="8" string="with" />
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="9" string="was unwilling to go along with more strident voices in the Reagan administration who opposed most legal remedies for discrimination" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="unwilling" />
            <token id="5" string="to" />
            <token id="6" string="go" />
            <token id="7" string="along" />
            <token id="8" string="with" />
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="10" string="opposed most legal remedies for discrimination" type="VP">
          <tokens>
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="11" string="who opposed most legal remedies for discrimination" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="12" string="discrimination" type="NP">
          <tokens>
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="go along with more strident voices in the Reagan administration who opposed most legal remedies for discrimination" type="VP">
          <tokens>
            <token id="6" string="go" />
            <token id="7" string="along" />
            <token id="8" string="with" />
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="15" string="most legal" type="ADJP">
          <tokens>
            <token id="18" string="most" />
            <token id="19" string="legal" />
          </tokens>
        </chunking>
        <chunking id="16" string="to go along with more strident voices in the Reagan administration who opposed most legal remedies for discrimination" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="go" />
            <token id="7" string="along" />
            <token id="8" string="with" />
            <token id="9" string="more" />
            <token id="10" string="strident" />
            <token id="11" string="voices" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="who" />
            <token id="17" string="opposed" />
            <token id="18" string="most" />
            <token id="19" string="legal" />
            <token id="20" string="remedies" />
            <token id="21" string="for" />
            <token id="22" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Reagan administration" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
          </tokens>
        </chunking>
        <chunking id="18" string="felt isolated from both the administration and the civil rights establishment" type="VP">
          <tokens>
            <token id="27" string="felt" />
            <token id="28" string="isolated" />
            <token id="29" string="from" />
            <token id="30" string="both" />
            <token id="31" string="the" />
            <token id="32" string="administration" />
            <token id="33" string="and" />
            <token id="34" string="the" />
            <token id="35" string="civil" />
            <token id="36" string="rights" />
            <token id="37" string="establishment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">unwilling</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">unwilling</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">unwilling</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">unwilling</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">go</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">unwilling</governor>
          <dependent id="6">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">go</governor>
          <dependent id="7">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">voices</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">voices</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">voices</governor>
          <dependent id="10">strident</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">go</governor>
          <dependent id="11">voices</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">administration</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">administration</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">administration</governor>
          <dependent id="14">Reagan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">voices</governor>
          <dependent id="15">administration</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">opposed</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">voices</governor>
          <dependent id="17">opposed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">legal</governor>
          <dependent id="18">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">remedies</governor>
          <dependent id="19">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">opposed</governor>
          <dependent id="20">remedies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">discrimination</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">opposed</governor>
          <dependent id="22">discrimination</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">unwilling</governor>
          <dependent id="24">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">felt</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">felt</governor>
          <dependent id="26">often</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">unwilling</governor>
          <dependent id="27">felt</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">felt</governor>
          <dependent id="28">isolated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">administration</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="32">administration</governor>
          <dependent id="30">both</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">administration</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">isolated</governor>
          <dependent id="32">administration</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">administration</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">establishment</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">establishment</governor>
          <dependent id="35">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">establishment</governor>
          <dependent id="36">rights</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">administration</governor>
          <dependent id="37">establishment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>Several years ago, a top Reagan domestic adviser who wanted his coffee cup refilled at a black-tie dinner looked up and spotted a black man in a tuxedo hovering near the table.</content>
      <tokens>
        <token id="1" string="Several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="domestic" lemma="domestic" stem="domest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="adviser" lemma="adviser" stem="advis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="coffee" lemma="coffee" stem="coffe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="cup" lemma="cup" stem="cup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="refilled" lemma="refill" stem="refil" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="black-tie" lemma="black-tie" stem="black-ti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="dinner" lemma="dinner" stem="dinner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="looked" lemma="look" stem="look" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="spotted" lemma="spot" stem="spot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tuxedo" lemma="tuxedo" stem="tuxedo" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="hovering" lemma="hover" stem="hover" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="table" lemma="table" stem="tabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (JJ Several) (NNS years)) (RB ago)) (, ,) (NP (NP (DT a) (JJ top) (NNP Reagan) (JJ domestic) (NN adviser)) (SBAR (WHNP (WP who)) (S (VP (VBD wanted) (NP (NP (PRP$ his) (NN coffee) (NN cup)) (VP (VBN refilled) (PP (IN at) (NP (DT a) (JJ black-tie) (NN dinner))))))))) (VP (VP (VBD looked) (ADVP (RB up))) (CC and) (VP (VBD spotted) (NP (DT a) (JJ black) (NN man)) (PP (IN in) (NP (NP (DT a) (NN tuxedo)) (VP (VBG hovering) (PP (IN near) (NP (DT the) (NN table)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a top Reagan domestic adviser who wanted his coffee cup refilled at a black-tie dinner" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="top" />
            <token id="7" string="Reagan" />
            <token id="8" string="domestic" />
            <token id="9" string="adviser" />
            <token id="10" string="who" />
            <token id="11" string="wanted" />
            <token id="12" string="his" />
            <token id="13" string="coffee" />
            <token id="14" string="cup" />
            <token id="15" string="refilled" />
            <token id="16" string="at" />
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="2" string="a tuxedo" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="tuxedo" />
          </tokens>
        </chunking>
        <chunking id="3" string="the table" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="table" />
          </tokens>
        </chunking>
        <chunking id="4" string="Several years" type="NP">
          <tokens>
            <token id="1" string="Several" />
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="refilled at a black-tie dinner" type="VP">
          <tokens>
            <token id="15" string="refilled" />
            <token id="16" string="at" />
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="6" string="a black-tie dinner" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="7" string="a tuxedo hovering near the table" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="tuxedo" />
            <token id="30" string="hovering" />
            <token id="31" string="near" />
            <token id="32" string="the" />
            <token id="33" string="table" />
          </tokens>
        </chunking>
        <chunking id="8" string="a top Reagan domestic adviser" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="top" />
            <token id="7" string="Reagan" />
            <token id="8" string="domestic" />
            <token id="9" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="9" string="his coffee cup" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="coffee" />
            <token id="14" string="cup" />
          </tokens>
        </chunking>
        <chunking id="10" string="his coffee cup refilled at a black-tie dinner" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="coffee" />
            <token id="14" string="cup" />
            <token id="15" string="refilled" />
            <token id="16" string="at" />
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="11" string="wanted his coffee cup refilled at a black-tie dinner" type="VP">
          <tokens>
            <token id="11" string="wanted" />
            <token id="12" string="his" />
            <token id="13" string="coffee" />
            <token id="14" string="cup" />
            <token id="15" string="refilled" />
            <token id="16" string="at" />
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="12" string="spotted a black man in a tuxedo hovering near the table" type="VP">
          <tokens>
            <token id="23" string="spotted" />
            <token id="24" string="a" />
            <token id="25" string="black" />
            <token id="26" string="man" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="tuxedo" />
            <token id="30" string="hovering" />
            <token id="31" string="near" />
            <token id="32" string="the" />
            <token id="33" string="table" />
          </tokens>
        </chunking>
        <chunking id="13" string="looked up and spotted a black man in a tuxedo hovering near the table" type="VP">
          <tokens>
            <token id="20" string="looked" />
            <token id="21" string="up" />
            <token id="22" string="and" />
            <token id="23" string="spotted" />
            <token id="24" string="a" />
            <token id="25" string="black" />
            <token id="26" string="man" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="tuxedo" />
            <token id="30" string="hovering" />
            <token id="31" string="near" />
            <token id="32" string="the" />
            <token id="33" string="table" />
          </tokens>
        </chunking>
        <chunking id="14" string="looked up" type="VP">
          <tokens>
            <token id="20" string="looked" />
            <token id="21" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="who wanted his coffee cup refilled at a black-tie dinner" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="wanted" />
            <token id="12" string="his" />
            <token id="13" string="coffee" />
            <token id="14" string="cup" />
            <token id="15" string="refilled" />
            <token id="16" string="at" />
            <token id="17" string="a" />
            <token id="18" string="black-tie" />
            <token id="19" string="dinner" />
          </tokens>
        </chunking>
        <chunking id="16" string="hovering near the table" type="VP">
          <tokens>
            <token id="30" string="hovering" />
            <token id="31" string="near" />
            <token id="32" string="the" />
            <token id="33" string="table" />
          </tokens>
        </chunking>
        <chunking id="17" string="a black man" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="black" />
            <token id="26" string="man" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">years</governor>
          <dependent id="1">Several</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">ago</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">looked</governor>
          <dependent id="3">ago</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">adviser</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">adviser</governor>
          <dependent id="6">top</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">adviser</governor>
          <dependent id="7">Reagan</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">adviser</governor>
          <dependent id="8">domestic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">looked</governor>
          <dependent id="9">adviser</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">wanted</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">adviser</governor>
          <dependent id="11">wanted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">cup</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">cup</governor>
          <dependent id="13">coffee</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">wanted</governor>
          <dependent id="14">cup</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">cup</governor>
          <dependent id="15">refilled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">dinner</governor>
          <dependent id="16">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">dinner</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">dinner</governor>
          <dependent id="18">black-tie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">refilled</governor>
          <dependent id="19">dinner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">looked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">looked</governor>
          <dependent id="21">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">looked</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">looked</governor>
          <dependent id="23">spotted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">man</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">man</governor>
          <dependent id="25">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">spotted</governor>
          <dependent id="26">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">tuxedo</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">tuxedo</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">spotted</governor>
          <dependent id="29">tuxedo</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">tuxedo</governor>
          <dependent id="30">hovering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">table</governor>
          <dependent id="31">near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">table</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">hovering</governor>
          <dependent id="33">table</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Several years ago" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Several" />
            <token id="2" string="years" />
            <token id="3" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>Holding the cup aloft, the official asked for more coffee.</content>
      <tokens>
        <token id="1" string="Holding" lemma="hold" stem="hold" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="cup" lemma="cup" stem="cup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="aloft" lemma="aloft" stem="aloft" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="official" lemma="official" stem="offici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="coffee" lemma="coffee" stem="coffe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Holding) (NP (DT the) (NN cup)) (ADVP (RB aloft)))) (, ,) (NP (DT the) (JJ official)) (VP (VBD asked) (PP (IN for) (NP (JJR more) (NN coffee)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the cup" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="cup" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked for more coffee" type="VP">
          <tokens>
            <token id="8" string="asked" />
            <token id="9" string="for" />
            <token id="10" string="more" />
            <token id="11" string="coffee" />
          </tokens>
        </chunking>
        <chunking id="3" string="the official" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="official" />
          </tokens>
        </chunking>
        <chunking id="4" string="Holding the cup aloft" type="VP">
          <tokens>
            <token id="1" string="Holding" />
            <token id="2" string="the" />
            <token id="3" string="cup" />
            <token id="4" string="aloft" />
          </tokens>
        </chunking>
        <chunking id="5" string="more coffee" type="NP">
          <tokens>
            <token id="10" string="more" />
            <token id="11" string="coffee" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="8">asked</governor>
          <dependent id="1">Holding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">cup</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Holding</governor>
          <dependent id="3">cup</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="1">Holding</governor>
          <dependent id="4">aloft</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">official</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">asked</governor>
          <dependent id="7">official</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">asked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">coffee</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">coffee</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">asked</governor>
          <dependent id="11">coffee</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>The black man reached past the cup to shake hands and said evenly: &amp;quot;Perhaps we haven&amp;apost;t met.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="past" lemma="past" stem="past" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="cup" lemma="cup" stem="cup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="shake" lemma="shake" stem="shake" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="evenly" lemma="evenly" stem="evenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="met" lemma="meet" stem="met" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (JJ black) (NN man)) (VP (VP (VBN reached) (PP (IN past) (NP (DT the) (NN cup))) (S (VP (TO to) (VP (VB shake) (NP (NNS hands)))))) (CC and) (VP (VBD said) (ADVP (RB evenly))))) (: :) (S (`` ``) (ADVP (RB Perhaps)) (NP (PRP we)) (VP (VBP have) (RB n't) (VP (VBN met)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have n't met" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="n't" />
            <token id="20" string="met" />
          </tokens>
        </chunking>
        <chunking id="2" string="the cup" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="cup" />
          </tokens>
        </chunking>
        <chunking id="3" string="hands" type="NP">
          <tokens>
            <token id="10" string="hands" />
          </tokens>
        </chunking>
        <chunking id="4" string="reached past the cup to shake hands and said evenly" type="VP">
          <tokens>
            <token id="4" string="reached" />
            <token id="5" string="past" />
            <token id="6" string="the" />
            <token id="7" string="cup" />
            <token id="8" string="to" />
            <token id="9" string="shake" />
            <token id="10" string="hands" />
            <token id="11" string="and" />
            <token id="12" string="said" />
            <token id="13" string="evenly" />
          </tokens>
        </chunking>
        <chunking id="5" string="reached past the cup to shake hands" type="VP">
          <tokens>
            <token id="4" string="reached" />
            <token id="5" string="past" />
            <token id="6" string="the" />
            <token id="7" string="cup" />
            <token id="8" string="to" />
            <token id="9" string="shake" />
            <token id="10" string="hands" />
          </tokens>
        </chunking>
        <chunking id="6" string="The black man" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="black" />
            <token id="3" string="man" />
          </tokens>
        </chunking>
        <chunking id="7" string="met" type="VP">
          <tokens>
            <token id="20" string="met" />
          </tokens>
        </chunking>
        <chunking id="8" string="said evenly" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="evenly" />
          </tokens>
        </chunking>
        <chunking id="9" string="shake hands" type="VP">
          <tokens>
            <token id="9" string="shake" />
            <token id="10" string="hands" />
          </tokens>
        </chunking>
        <chunking id="10" string="to shake hands" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="shake" />
            <token id="10" string="hands" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="17" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">man</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">man</governor>
          <dependent id="2">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">reached</governor>
          <dependent id="3">man</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">reached</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">cup</governor>
          <dependent id="5">past</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">cup</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reached</governor>
          <dependent id="7">cup</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">shake</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">reached</governor>
          <dependent id="9">shake</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">shake</governor>
          <dependent id="10">hands</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">reached</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">reached</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">said</governor>
          <dependent id="13">evenly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">met</governor>
          <dependent id="16">Perhaps</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">met</governor>
          <dependent id="17">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">met</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">met</governor>
          <dependent id="19">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">reached</governor>
          <dependent id="20">met</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="past" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>I&amp;apost;m Clarence Thomas&amp;quot;.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 'm) (NP (NNP Clarence) (NNP Thomas))) ('' '') (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="'m Clarence Thomas" type="VP">
          <tokens>
            <token id="2" string="'m" />
            <token id="3" string="Clarence" />
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="3" string="Clarence" />
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">Thomas</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">Thomas</governor>
          <dependent id="2">'m</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Thomas</governor>
          <dependent id="3">Clarence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Clarence" />
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>SUNDAY IN PERSPECTIVE: A reporter who saw Clarence Thomas at his most candid writes about the nominee&amp;apost;s opinions, fears and frustrations.</content>
      <tokens>
        <token id="1" string="SUNDAY" lemma="SUNDAY" stem="sunday" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="IN" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="PERSPECTIVE" lemma="PERSPECTIVE" stem="perspective" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="A" lemma="a" stem="a" pos="NN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="candid" lemma="candid" stem="candid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="opinions" lemma="opinion" stem="opinion" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="fears" lemma="fear" stem="fear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="frustrations" lemma="frustration" stem="frustrat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NNP SUNDAY)) (PP (IN IN) (NP (NNP PERSPECTIVE)))) (: :) (NP (NP (NN A) (NN reporter)) (SBAR (WHNP (WP who)) (S (VP (VBD saw) (SBAR (S (NP (NP (NNP Clarence) (NNP Thomas)) (PP (IN at) (NP (NP (PRP$ his)) (ADJP (RBS most) (JJ candid))))) (VP (VBZ writes) (PP (IN about) (NP (NP (DT the) (NN nominee) (POS 's)) (NNS opinions) (, ,) (NNS fears) (CC and) (NNS frustrations)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A reporter" type="NP">
          <tokens>
            <token id="5" string="A" />
            <token id="6" string="reporter" />
          </tokens>
        </chunking>
        <chunking id="2" string="writes about the nominee 's opinions , fears and frustrations" type="VP">
          <tokens>
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="3" string="PERSPECTIVE" type="NP">
          <tokens>
            <token id="3" string="PERSPECTIVE" />
          </tokens>
        </chunking>
        <chunking id="4" string="SUNDAY IN PERSPECTIVE" type="NP">
          <tokens>
            <token id="1" string="SUNDAY" />
            <token id="2" string="IN" />
            <token id="3" string="PERSPECTIVE" />
          </tokens>
        </chunking>
        <chunking id="5" string="the nominee 's" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="saw Clarence Thomas at his most candid writes about the nominee 's opinions , fears and frustrations" type="VP">
          <tokens>
            <token id="8" string="saw" />
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="7" string="Clarence Thomas at his most candid" type="NP">
          <tokens>
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
          </tokens>
        </chunking>
        <chunking id="8" string="his" type="NP">
          <tokens>
            <token id="12" string="his" />
          </tokens>
        </chunking>
        <chunking id="9" string="the nominee 's opinions , fears and frustrations" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="10" string="A reporter who saw Clarence Thomas at his most candid writes about the nominee 's opinions , fears and frustrations" type="NP">
          <tokens>
            <token id="5" string="A" />
            <token id="6" string="reporter" />
            <token id="7" string="who" />
            <token id="8" string="saw" />
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="11" string="SUNDAY IN PERSPECTIVE : A reporter who saw Clarence Thomas at his most candid writes about the nominee 's opinions , fears and frustrations ." type="NP">
          <tokens>
            <token id="1" string="SUNDAY" />
            <token id="2" string="IN" />
            <token id="3" string="PERSPECTIVE" />
            <token id="4" string=":" />
            <token id="5" string="A" />
            <token id="6" string="reporter" />
            <token id="7" string="who" />
            <token id="8" string="saw" />
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
            <token id="25" string="." />
          </tokens>
        </chunking>
        <chunking id="12" string="most candid" type="ADJP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="candid" />
          </tokens>
        </chunking>
        <chunking id="13" string="Clarence Thomas at his most candid writes about the nominee 's opinions , fears and frustrations" type="SBAR">
          <tokens>
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="14" string="his most candid" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
          </tokens>
        </chunking>
        <chunking id="15" string="SUNDAY" type="NP">
          <tokens>
            <token id="1" string="SUNDAY" />
          </tokens>
        </chunking>
        <chunking id="16" string="who saw Clarence Thomas at his most candid writes about the nominee 's opinions , fears and frustrations" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="saw" />
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
            <token id="11" string="at" />
            <token id="12" string="his" />
            <token id="13" string="most" />
            <token id="14" string="candid" />
            <token id="15" string="writes" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="nominee" />
            <token id="19" string="'s" />
            <token id="20" string="opinions" />
            <token id="21" string="," />
            <token id="22" string="fears" />
            <token id="23" string="and" />
            <token id="24" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="17" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">SUNDAY</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">PERSPECTIVE</governor>
          <dependent id="2">IN</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">SUNDAY</governor>
          <dependent id="3">PERSPECTIVE</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">reporter</governor>
          <dependent id="5">A</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">SUNDAY</governor>
          <dependent id="6">reporter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">saw</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">reporter</governor>
          <dependent id="8">saw</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Thomas</governor>
          <dependent id="9">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">writes</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">his</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Thomas</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">candid</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">his</governor>
          <dependent id="14">candid</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">saw</governor>
          <dependent id="15">writes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">opinions</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">nominee</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">opinions</governor>
          <dependent id="18">nominee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">nominee</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">writes</governor>
          <dependent id="20">opinions</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">opinions</governor>
          <dependent id="22">fears</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">opinions</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">opinions</governor>
          <dependent id="24">frustrations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="SUNDAY" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="SUNDAY" />
          </tokens>
        </entity>
        <entity id="2" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Clarence" />
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Nomination Of Clarence Thomas; President Bush has chosen Judge Clarence Thomas of the U.S. Court of Appeals to replace Justice Thurgood Marshall, who is retiring from the Supreme Court.</content>
      <tokens>
        <token id="1" string="Nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="7" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="11" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Appeals" lemma="Appeals" stem="appeal" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="replace" lemma="replace" stem="replac" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Justice" lemma="Justice" stem="justic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="Thurgood" lemma="Thurgood" stem="thurgood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="Marshall" lemma="Marshall" stem="marshal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="retiring" lemma="retire" stem="retir" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="31" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (NP (NN Nomination)) (IN Of) (NP (NNP Clarence) (NNP Thomas))) (: ;) (NP (NNP President) (NNP Bush)) (VP (VBZ has) (VP (VBN chosen) (NP (NP (NNP Judge) (NNP Clarence) (NNP Thomas)) (PP (IN of) (NP (NP (DT the) (NNP U.S.) (NNP Court)) (PP (IN of) (NP (NNPS Appeals)))))) (S (VP (TO to) (VP (VB replace) (NP (NP (NNP Justice) (NNP Thurgood) (NNP Marshall)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (VP (VBG retiring) (PP (IN from) (NP (DT the) (NNP Supreme) (NNP Court))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="chosen Judge Clarence Thomas of the U.S. Court of Appeals to replace Justice Thurgood Marshall , who is retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="9" string="chosen" />
            <token id="10" string="Judge" />
            <token id="11" string="Clarence" />
            <token id="12" string="Thomas" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
            <token id="17" string="of" />
            <token id="18" string="Appeals" />
            <token id="19" string="to" />
            <token id="20" string="replace" />
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="2" string="Judge Clarence Thomas" type="NP">
          <tokens>
            <token id="10" string="Judge" />
            <token id="11" string="Clarence" />
            <token id="12" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="Judge Clarence Thomas of the U.S. Court of Appeals" type="NP">
          <tokens>
            <token id="10" string="Judge" />
            <token id="11" string="Clarence" />
            <token id="12" string="Thomas" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
            <token id="17" string="of" />
            <token id="18" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="4" string="replace Justice Thurgood Marshall , who is retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="20" string="replace" />
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="who is retiring from the Supreme Court" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="6" string="President Bush" type="NP">
          <tokens>
            <token id="6" string="President" />
            <token id="7" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="7" string="the U.S. Court of Appeals" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
            <token id="17" string="of" />
            <token id="18" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="8" string="retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="9" string="Appeals" type="NP">
          <tokens>
            <token id="18" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="10" string="to replace Justice Thurgood Marshall , who is retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="replace" />
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="11" string="is retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Supreme Court" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="13" string="Justice Thurgood Marshall , who is retiring from the Supreme Court" type="NP">
          <tokens>
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="14" string="Justice Thurgood Marshall" type="NP">
          <tokens>
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="15" string="the U.S. Court" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="16" string="has chosen Judge Clarence Thomas of the U.S. Court of Appeals to replace Justice Thurgood Marshall , who is retiring from the Supreme Court" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="chosen" />
            <token id="10" string="Judge" />
            <token id="11" string="Clarence" />
            <token id="12" string="Thomas" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
            <token id="17" string="of" />
            <token id="18" string="Appeals" />
            <token id="19" string="to" />
            <token id="20" string="replace" />
            <token id="21" string="Justice" />
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="is" />
            <token id="27" string="retiring" />
            <token id="28" string="from" />
            <token id="29" string="the" />
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </chunking>
        <chunking id="17" string="Nomination" type="NP">
          <tokens>
            <token id="1" string="Nomination" />
          </tokens>
        </chunking>
        <chunking id="18" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="3" string="Clarence" />
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod">
          <governor id="9">chosen</governor>
          <dependent id="1">Nomination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Nomination</governor>
          <dependent id="2">Of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Thomas</governor>
          <dependent id="3">Clarence</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Nomination</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Bush</governor>
          <dependent id="6">President</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">chosen</governor>
          <dependent id="7">Bush</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">chosen</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">chosen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Thomas</governor>
          <dependent id="10">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Thomas</governor>
          <dependent id="11">Clarence</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">chosen</governor>
          <dependent id="12">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Court</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Court</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Court</governor>
          <dependent id="15">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Thomas</governor>
          <dependent id="16">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Appeals</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Court</governor>
          <dependent id="18">Appeals</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">replace</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">chosen</governor>
          <dependent id="20">replace</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Marshall</governor>
          <dependent id="21">Justice</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Marshall</governor>
          <dependent id="22">Thurgood</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">replace</governor>
          <dependent id="23">Marshall</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">retiring</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">retiring</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">Marshall</governor>
          <dependent id="27">retiring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Court</governor>
          <dependent id="28">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Court</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Court</governor>
          <dependent id="30">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">retiring</governor>
          <dependent id="31">Court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="Supreme" />
            <token id="31" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Court of Appeals" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="U.S." />
            <token id="16" string="Court" />
            <token id="17" string="of" />
            <token id="18" string="Appeals" />
          </tokens>
        </entity>
        <entity id="3" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Bush" />
          </tokens>
        </entity>
        <entity id="4" string="Thurgood Marshall" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Thurgood" />
            <token id="23" string="Marshall" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="6" string="President" />
          </tokens>
        </entity>
        <entity id="6" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Clarence" />
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
        <entity id="7" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="10" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>Nominee&amp;apost;s background; Age: 43; Birthplace: Savannah, Ga.</content>
      <tokens>
        <token id="1" string="Nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Age" lemma="age" stem="age" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="43" lemma="43" stem="43" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Birthplace" lemma="Birthplace" stem="birthplac" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ga" lemma="Ga." stem="ga" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN Nominee) (POS 's)) (NN background)) (: ;) (NP (NP (NP (NN Age)) (: :) (NP (CD 43))) (: ;) (NP (NP (NNP Birthplace)) (: :) (NP (NNP Savannah) (, ,) (NNP Ga.)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Age : 43" type="NP">
          <tokens>
            <token id="5" string="Age" />
            <token id="6" string=":" />
            <token id="7" string="43" />
          </tokens>
        </chunking>
        <chunking id="2" string="Savannah , Ga." type="NP">
          <tokens>
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="Ga" />
          </tokens>
        </chunking>
        <chunking id="3" string="Birthplace : Savannah , Ga." type="NP">
          <tokens>
            <token id="9" string="Birthplace" />
            <token id="10" string=":" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="Ga" />
          </tokens>
        </chunking>
        <chunking id="4" string="Age : 43 ; Birthplace : Savannah , Ga." type="NP">
          <tokens>
            <token id="5" string="Age" />
            <token id="6" string=":" />
            <token id="7" string="43" />
            <token id="8" string=";" />
            <token id="9" string="Birthplace" />
            <token id="10" string=":" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="Ga" />
          </tokens>
        </chunking>
        <chunking id="5" string="Nominee 's" type="NP">
          <tokens>
            <token id="1" string="Nominee" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Birthplace" type="NP">
          <tokens>
            <token id="9" string="Birthplace" />
          </tokens>
        </chunking>
        <chunking id="7" string="Nominee 's background ; Age : 43 ; Birthplace : Savannah , Ga. ." type="NP">
          <tokens>
            <token id="1" string="Nominee" />
            <token id="2" string="'s" />
            <token id="3" string="background" />
            <token id="4" string=";" />
            <token id="5" string="Age" />
            <token id="6" string=":" />
            <token id="7" string="43" />
            <token id="8" string=";" />
            <token id="9" string="Birthplace" />
            <token id="10" string=":" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="Ga" />
            <token id="14" string="." />
          </tokens>
        </chunking>
        <chunking id="8" string="Nominee 's background" type="NP">
          <tokens>
            <token id="1" string="Nominee" />
            <token id="2" string="'s" />
            <token id="3" string="background" />
          </tokens>
        </chunking>
        <chunking id="9" string="43" type="NP">
          <tokens>
            <token id="7" string="43" />
          </tokens>
        </chunking>
        <chunking id="10" string="Age" type="NP">
          <tokens>
            <token id="5" string="Age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">background</governor>
          <dependent id="1">Nominee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Nominee</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">background</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">background</governor>
          <dependent id="5">Age</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Age</governor>
          <dependent id="7">43</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Age</governor>
          <dependent id="9">Birthplace</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ga.</governor>
          <dependent id="11">Savannah</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">Birthplace</governor>
          <dependent id="13">Ga.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ga" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Ga" />
          </tokens>
        </entity>
        <entity id="2" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Savannah" />
          </tokens>
        </entity>
        <entity id="3" string="43" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="43" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Family: Married to Virginia Lamp Thomas; he has one son, Jamal; Education: Bachelor&amp;apost;s degree, 1971, Holy Cross College; law degree, Yale Law School, 1974; Professional experience: Missouri assistant attorney general, 1974-&amp;apost;77; chairman of Equal Employment Opportunity Commission, 1982-&amp;apost;89; judge on U.S. Court of Appeals for District of Columbia since 1990.</content>
      <tokens>
        <token id="1" string="Family" lemma="Family" stem="famili" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Married" lemma="Married" stem="marri" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Lamp" lemma="Lamp" stem="lamp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Jamal" lemma="Jamal" stem="jamal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Education" lemma="education" stem="educat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Bachelor" lemma="bachelor" stem="bachelor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="degree" lemma="degree" stem="degre" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1971" lemma="1971" stem="1971" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Holy" lemma="Holy" stem="holi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="25" string="Cross" lemma="Cross" stem="cross" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="27" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="degree" lemma="degree" stem="degre" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="32" string="Law" lemma="Law" stem="law" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="33" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="36" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Professional" lemma="Professional" stem="profession" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="experience" lemma="experience" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Missouri" lemma="Missouri" stem="missouri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="41" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="general" lemma="general" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="46" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="48" string="77" lemma="77" stem="77" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="49" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="Equal" lemma="Equal" stem="equal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="53" string="Employment" lemma="Employment" stem="employment" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="54" string="Opportunity" lemma="Opportunity" stem="opportun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="55" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="56" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="1982" lemma="1982" stem="1982" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="58" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="60" string="89" lemma="89" stem="89" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="61" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="65" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="66" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="67" string="Appeals" lemma="Appeals" stem="appeal" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="68" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="69" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="70" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="71" string="Columbia" lemma="Columbia" stem="columbia" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="72" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="73" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="74" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Family)) (: :) (NP (NP (NP (NNP Married)) (PP (TO to) (NP (NNP Virginia) (NNP Lamp) (NNP Thomas)))) (: ;) (S (NP (PRP he)) (VP (VBZ has) (NP (NP (CD one) (NN son)) (, ,) (NP (NP (NNP Jamal)) (: ;) (NP (NP (NN Education)) (: :) (NP (NP (NN Bachelor) (POS 's)) (NN degree)))) (, ,) (NP (NP (CD 1971)) (, ,) (NP (NNP Holy) (NNP Cross) (NNP College))) (: ;) (NP (NP (NN law) (NN degree)) (, ,) (NP (NNP Yale) (NNP Law) (NNP School)) (, ,) (NP (CD 1974))) (: ;) (NP (NP (NNP Professional)) (NP (NP (NN experience)) (: :) (NP (NP (NNP Missouri) (NN assistant) (NN attorney) (NN general)) (, ,) (NP (CD 1974))) (: -))) ('' ') (NP (NP (CD 77)) (PRN (: ;) (NP (NP (NN chairman)) (PP (IN of) (NP (NP (NNP Equal) (NNP Employment) (NNP Opportunity) (NNP Commission)) (, ,) (NP (CD 1982))))) (: -))) ('' ') (NP (CD 89)) (: ;) (NP (NP (NN judge)) (PP (IN on) (NP (NP (NNP U.S.) (NNP Court)) (PP (IN of) (NP (NP (NNPS Appeals)) (PP (IN for) (NP (NP (NNP District)) (PP (IN of) (NP (NP (NNP Columbia)) (PP (IN since) (NP (CD 1990)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has one son , Jamal ; Education : Bachelor 's degree , 1971 , Holy Cross College ; law degree , Yale Law School , 1974 ; Professional experience : Missouri assistant attorney general , 1974 - ' 77 ; chairman of Equal Employment Opportunity Commission , 1982 - ' 89 ; judge on U.S. Court of Appeals for District of Columbia since 1990" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="one" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Jamal" />
            <token id="15" string=";" />
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
            <token id="21" string="," />
            <token id="22" string="1971" />
            <token id="23" string="," />
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
            <token id="27" string=";" />
            <token id="28" string="law" />
            <token id="29" string="degree" />
            <token id="30" string="," />
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
            <token id="34" string="," />
            <token id="35" string="1974" />
            <token id="36" string=";" />
            <token id="37" string="Professional" />
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
            <token id="47" string="'" />
            <token id="48" string="77" />
            <token id="49" string=";" />
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
            <token id="58" string="-" />
            <token id="59" string="'" />
            <token id="60" string="89" />
            <token id="61" string=";" />
            <token id="62" string="judge" />
            <token id="63" string="on" />
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jamal" type="NP">
          <tokens>
            <token id="14" string="Jamal" />
          </tokens>
        </chunking>
        <chunking id="3" string="1971 , Holy Cross College" type="NP">
          <tokens>
            <token id="22" string="1971" />
            <token id="23" string="," />
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
          </tokens>
        </chunking>
        <chunking id="4" string="Yale Law School" type="NP">
          <tokens>
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
          </tokens>
        </chunking>
        <chunking id="5" string="1990" type="NP">
          <tokens>
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="6" string="experience : Missouri assistant attorney general , 1974 -" type="NP">
          <tokens>
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
          </tokens>
        </chunking>
        <chunking id="7" string="chairman" type="NP">
          <tokens>
            <token id="50" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="8" string="Missouri assistant attorney general" type="NP">
          <tokens>
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
          </tokens>
        </chunking>
        <chunking id="9" string="Appeals for District of Columbia since 1990" type="NP">
          <tokens>
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="10" string="Holy Cross College" type="NP">
          <tokens>
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
          </tokens>
        </chunking>
        <chunking id="11" string="77 ; chairman of Equal Employment Opportunity Commission , 1982 -" type="NP">
          <tokens>
            <token id="48" string="77" />
            <token id="49" string=";" />
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
            <token id="58" string="-" />
          </tokens>
        </chunking>
        <chunking id="12" string="Married to Virginia Lamp Thomas ; he has one son , Jamal ; Education : Bachelor 's degree , 1971 , Holy Cross College ; law degree , Yale Law School , 1974 ; Professional experience : Missouri assistant attorney general , 1974 - ' 77 ; chairman of Equal Employment Opportunity Commission , 1982 - ' 89 ; judge on U.S. Court of Appeals for District of Columbia since 1990" type="NP">
          <tokens>
            <token id="3" string="Married" />
            <token id="4" string="to" />
            <token id="5" string="Virginia" />
            <token id="6" string="Lamp" />
            <token id="7" string="Thomas" />
            <token id="8" string=";" />
            <token id="9" string="he" />
            <token id="10" string="has" />
            <token id="11" string="one" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Jamal" />
            <token id="15" string=";" />
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
            <token id="21" string="," />
            <token id="22" string="1971" />
            <token id="23" string="," />
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
            <token id="27" string=";" />
            <token id="28" string="law" />
            <token id="29" string="degree" />
            <token id="30" string="," />
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
            <token id="34" string="," />
            <token id="35" string="1974" />
            <token id="36" string=";" />
            <token id="37" string="Professional" />
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
            <token id="47" string="'" />
            <token id="48" string="77" />
            <token id="49" string=";" />
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
            <token id="58" string="-" />
            <token id="59" string="'" />
            <token id="60" string="89" />
            <token id="61" string=";" />
            <token id="62" string="judge" />
            <token id="63" string="on" />
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="13" string="U.S. Court" type="NP">
          <tokens>
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
          </tokens>
        </chunking>
        <chunking id="14" string="Columbia" type="NP">
          <tokens>
            <token id="71" string="Columbia" />
          </tokens>
        </chunking>
        <chunking id="15" string="Professional experience : Missouri assistant attorney general , 1974 -" type="NP">
          <tokens>
            <token id="37" string="Professional" />
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
          </tokens>
        </chunking>
        <chunking id="16" string="Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="17" string="Columbia since 1990" type="NP">
          <tokens>
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="18" string="Bachelor 's degree" type="NP">
          <tokens>
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
          </tokens>
        </chunking>
        <chunking id="19" string="Professional" type="NP">
          <tokens>
            <token id="37" string="Professional" />
          </tokens>
        </chunking>
        <chunking id="20" string="1982" type="NP">
          <tokens>
            <token id="57" string="1982" />
          </tokens>
        </chunking>
        <chunking id="21" string="Family : Married to Virginia Lamp Thomas ; he has one son , Jamal ; Education : Bachelor 's degree , 1971 , Holy Cross College ; law degree , Yale Law School , 1974 ; Professional experience : Missouri assistant attorney general , 1974 - ' 77 ; chairman of Equal Employment Opportunity Commission , 1982 - ' 89 ; judge on U.S. Court of Appeals for District of Columbia since 1990 ." type="NP">
          <tokens>
            <token id="1" string="Family" />
            <token id="2" string=":" />
            <token id="3" string="Married" />
            <token id="4" string="to" />
            <token id="5" string="Virginia" />
            <token id="6" string="Lamp" />
            <token id="7" string="Thomas" />
            <token id="8" string=";" />
            <token id="9" string="he" />
            <token id="10" string="has" />
            <token id="11" string="one" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Jamal" />
            <token id="15" string=";" />
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
            <token id="21" string="," />
            <token id="22" string="1971" />
            <token id="23" string="," />
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
            <token id="27" string=";" />
            <token id="28" string="law" />
            <token id="29" string="degree" />
            <token id="30" string="," />
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
            <token id="34" string="," />
            <token id="35" string="1974" />
            <token id="36" string=";" />
            <token id="37" string="Professional" />
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
            <token id="47" string="'" />
            <token id="48" string="77" />
            <token id="49" string=";" />
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
            <token id="58" string="-" />
            <token id="59" string="'" />
            <token id="60" string="89" />
            <token id="61" string=";" />
            <token id="62" string="judge" />
            <token id="63" string="on" />
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
            <token id="74" string="." />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="Family" type="NP">
          <tokens>
            <token id="1" string="Family" />
          </tokens>
        </chunking>
        <chunking id="24" string="District" type="NP">
          <tokens>
            <token id="69" string="District" />
          </tokens>
        </chunking>
        <chunking id="25" string="one son" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="son" />
          </tokens>
        </chunking>
        <chunking id="26" string="89" type="NP">
          <tokens>
            <token id="60" string="89" />
          </tokens>
        </chunking>
        <chunking id="27" string="U.S. Court of Appeals for District of Columbia since 1990" type="NP">
          <tokens>
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="28" string="District of Columbia since 1990" type="NP">
          <tokens>
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="29" string="Missouri assistant attorney general , 1974" type="NP">
          <tokens>
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
          </tokens>
        </chunking>
        <chunking id="30" string="law degree , Yale Law School , 1974" type="NP">
          <tokens>
            <token id="28" string="law" />
            <token id="29" string="degree" />
            <token id="30" string="," />
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
            <token id="34" string="," />
            <token id="35" string="1974" />
          </tokens>
        </chunking>
        <chunking id="31" string="law degree" type="NP">
          <tokens>
            <token id="28" string="law" />
            <token id="29" string="degree" />
          </tokens>
        </chunking>
        <chunking id="32" string="Married to Virginia Lamp Thomas" type="NP">
          <tokens>
            <token id="3" string="Married" />
            <token id="4" string="to" />
            <token id="5" string="Virginia" />
            <token id="6" string="Lamp" />
            <token id="7" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="33" string="Education : Bachelor 's degree" type="NP">
          <tokens>
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
          </tokens>
        </chunking>
        <chunking id="34" string="Appeals" type="NP">
          <tokens>
            <token id="67" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="35" string="Jamal ; Education : Bachelor 's degree" type="NP">
          <tokens>
            <token id="14" string="Jamal" />
            <token id="15" string=";" />
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
          </tokens>
        </chunking>
        <chunking id="36" string="experience" type="NP">
          <tokens>
            <token id="38" string="experience" />
          </tokens>
        </chunking>
        <chunking id="37" string="Bachelor 's" type="NP">
          <tokens>
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="38" string="Married" type="NP">
          <tokens>
            <token id="3" string="Married" />
          </tokens>
        </chunking>
        <chunking id="39" string="chairman of Equal Employment Opportunity Commission , 1982" type="NP">
          <tokens>
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
          </tokens>
        </chunking>
        <chunking id="40" string="1974" type="NP">
          <tokens>
            <token id="35" string="1974" />
          </tokens>
        </chunking>
        <chunking id="41" string="1971" type="NP">
          <tokens>
            <token id="22" string="1971" />
          </tokens>
        </chunking>
        <chunking id="42" string="Virginia Lamp Thomas" type="NP">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Lamp" />
            <token id="7" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="43" string="Equal Employment Opportunity Commission , 1982" type="NP">
          <tokens>
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
          </tokens>
        </chunking>
        <chunking id="44" string="Education" type="NP">
          <tokens>
            <token id="16" string="Education" />
          </tokens>
        </chunking>
        <chunking id="45" string="judge" type="NP">
          <tokens>
            <token id="62" string="judge" />
          </tokens>
        </chunking>
        <chunking id="46" string="judge on U.S. Court of Appeals for District of Columbia since 1990" type="NP">
          <tokens>
            <token id="62" string="judge" />
            <token id="63" string="on" />
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="47" string="one son , Jamal ; Education : Bachelor 's degree , 1971 , Holy Cross College ; law degree , Yale Law School , 1974 ; Professional experience : Missouri assistant attorney general , 1974 - ' 77 ; chairman of Equal Employment Opportunity Commission , 1982 - ' 89 ; judge on U.S. Court of Appeals for District of Columbia since 1990" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Jamal" />
            <token id="15" string=";" />
            <token id="16" string="Education" />
            <token id="17" string=":" />
            <token id="18" string="Bachelor" />
            <token id="19" string="'s" />
            <token id="20" string="degree" />
            <token id="21" string="," />
            <token id="22" string="1971" />
            <token id="23" string="," />
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
            <token id="27" string=";" />
            <token id="28" string="law" />
            <token id="29" string="degree" />
            <token id="30" string="," />
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
            <token id="34" string="," />
            <token id="35" string="1974" />
            <token id="36" string=";" />
            <token id="37" string="Professional" />
            <token id="38" string="experience" />
            <token id="39" string=":" />
            <token id="40" string="Missouri" />
            <token id="41" string="assistant" />
            <token id="42" string="attorney" />
            <token id="43" string="general" />
            <token id="44" string="," />
            <token id="45" string="1974" />
            <token id="46" string="-" />
            <token id="47" string="'" />
            <token id="48" string="77" />
            <token id="49" string=";" />
            <token id="50" string="chairman" />
            <token id="51" string="of" />
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
            <token id="56" string="," />
            <token id="57" string="1982" />
            <token id="58" string="-" />
            <token id="59" string="'" />
            <token id="60" string="89" />
            <token id="61" string=";" />
            <token id="62" string="judge" />
            <token id="63" string="on" />
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
            <token id="72" string="since" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="48" string="77" type="NP">
          <tokens>
            <token id="48" string="77" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Family</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Family</governor>
          <dependent id="3">Married</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Thomas</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Thomas</governor>
          <dependent id="5">Virginia</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Thomas</governor>
          <dependent id="6">Lamp</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Married</governor>
          <dependent id="7">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">has</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">Married</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">son</governor>
          <dependent id="11">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">has</governor>
          <dependent id="12">son</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">son</governor>
          <dependent id="14">Jamal</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Jamal</governor>
          <dependent id="16">Education</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">degree</governor>
          <dependent id="18">Bachelor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Bachelor</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">Education</governor>
          <dependent id="20">degree</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">son</governor>
          <dependent id="22">1971</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">College</governor>
          <dependent id="24">Holy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">College</governor>
          <dependent id="25">Cross</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">1971</governor>
          <dependent id="26">College</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">degree</governor>
          <dependent id="28">law</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">son</governor>
          <dependent id="29">degree</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">School</governor>
          <dependent id="31">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">School</governor>
          <dependent id="32">Law</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">degree</governor>
          <dependent id="33">School</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">degree</governor>
          <dependent id="35">1974</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">son</governor>
          <dependent id="37">Professional</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">Professional</governor>
          <dependent id="38">experience</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">general</governor>
          <dependent id="40">Missouri</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">general</governor>
          <dependent id="41">assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">general</governor>
          <dependent id="42">attorney</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">experience</governor>
          <dependent id="43">general</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">general</governor>
          <dependent id="45">1974</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">son</governor>
          <dependent id="48">77</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="48">77</governor>
          <dependent id="50">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">Commission</governor>
          <dependent id="51">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Commission</governor>
          <dependent id="52">Equal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Commission</governor>
          <dependent id="53">Employment</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Commission</governor>
          <dependent id="54">Opportunity</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="50">chairman</governor>
          <dependent id="55">Commission</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="55">Commission</governor>
          <dependent id="57">1982</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">son</governor>
          <dependent id="60">89</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">son</governor>
          <dependent id="62">judge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="65">Court</governor>
          <dependent id="63">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="65">Court</governor>
          <dependent id="64">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="62">judge</governor>
          <dependent id="65">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="67">Appeals</governor>
          <dependent id="66">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="65">Court</governor>
          <dependent id="67">Appeals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">District</governor>
          <dependent id="68">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="67">Appeals</governor>
          <dependent id="69">District</dependent>
        </dependency>
        <dependency type="case">
          <governor id="71">Columbia</governor>
          <dependent id="70">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="69">District</governor>
          <dependent id="71">Columbia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="73">1990</governor>
          <dependent id="72">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="71">Columbia</governor>
          <dependent id="73">1990</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jamal" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Jamal" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Court of Appeals for District of Columbia" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="64" string="U.S." />
            <token id="65" string="Court" />
            <token id="66" string="of" />
            <token id="67" string="Appeals" />
            <token id="68" string="for" />
            <token id="69" string="District" />
            <token id="70" string="of" />
            <token id="71" string="Columbia" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Yale Law School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Yale" />
            <token id="32" string="Law" />
            <token id="33" string="School" />
          </tokens>
        </entity>
        <entity id="5" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="73" string="1990" />
          </tokens>
        </entity>
        <entity id="6" string="' 77" type="DATE" score="0.0">
          <tokens>
            <token id="47" string="'" />
            <token id="48" string="77" />
          </tokens>
        </entity>
        <entity id="7" string="' 89" type="DATE" score="0.0">
          <tokens>
            <token id="59" string="'" />
            <token id="60" string="89" />
          </tokens>
        </entity>
        <entity id="8" string="Holy Cross College" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Holy" />
            <token id="25" string="Cross" />
            <token id="26" string="College" />
          </tokens>
        </entity>
        <entity id="9" string="Equal Employment Opportunity Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="52" string="Equal" />
            <token id="53" string="Employment" />
            <token id="54" string="Opportunity" />
            <token id="55" string="Commission" />
          </tokens>
        </entity>
        <entity id="10" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="35" string="1974" />
          </tokens>
        </entity>
        <entity id="11" string="1971" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1971" />
          </tokens>
        </entity>
        <entity id="12" string="Missouri" type="LOCATION" score="0.0">
          <tokens>
            <token id="40" string="Missouri" />
          </tokens>
        </entity>
        <entity id="13" string="1982" type="DATE" score="0.0">
          <tokens>
            <token id="57" string="1982" />
          </tokens>
        </entity>
        <entity id="14" string="Virginia Lamp Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Lamp" />
            <token id="7" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="false">
      <content>On quotas.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="quotas" lemma="quota" stem="quota" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN On) (NP (NNS quotas))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="quotas" type="NP">
          <tokens>
            <token id="2" string="quotas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">quotas</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">quotas</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>&amp;quot;Federal enforcement agencies turned the statutes on their heads by requiring discrimination in the form of hiring and promotion quotas, so-called goals and timetables&amp;quot;.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Federal" lemma="Federal" stem="feder" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="agencies" lemma="agency" stem="agenc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="statutes" lemma="statute" stem="statut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="heads" lemma="head" stem="head" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="requiring" lemma="require" stem="requir" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="hiring" lemma="hire" stem="hire" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="promotion" lemma="promotion" stem="promot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="quotas" lemma="quota" stem="quota" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="so-called" lemma="so-called" stem="so-cal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="goals" lemma="goal" stem="goal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="timetables" lemma="timetable" stem="timet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Federal) (NN enforcement) (NNS agencies)) (VP (VBD turned) (NP (DT the) (NNS statutes)) (PP (IN on) (NP (PRP$ their) (NNS heads))) (PP (IN by) (S (VP (VBG requiring) (NP (NN discrimination)) (PP (IN in) (NP (NP (NP (DT the) (NN form)) (PP (IN of) (NP (VBG hiring) (CC and) (NN promotion) (NNS quotas)))) (, ,) (NP (JJ so-called) (NNS goals)) (CC and) (NP (NNS timetables)))))))) ('' '') (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their heads" type="NP">
          <tokens>
            <token id="9" string="their" />
            <token id="10" string="heads" />
          </tokens>
        </chunking>
        <chunking id="2" string="requiring discrimination in the form of hiring and promotion quotas , so-called goals and timetables" type="VP">
          <tokens>
            <token id="12" string="requiring" />
            <token id="13" string="discrimination" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="form" />
            <token id="17" string="of" />
            <token id="18" string="hiring" />
            <token id="19" string="and" />
            <token id="20" string="promotion" />
            <token id="21" string="quotas" />
            <token id="22" string="," />
            <token id="23" string="so-called" />
            <token id="24" string="goals" />
            <token id="25" string="and" />
            <token id="26" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="3" string="Federal enforcement agencies" type="NP">
          <tokens>
            <token id="2" string="Federal" />
            <token id="3" string="enforcement" />
            <token id="4" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="4" string="timetables" type="NP">
          <tokens>
            <token id="26" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="5" string="so-called goals" type="NP">
          <tokens>
            <token id="23" string="so-called" />
            <token id="24" string="goals" />
          </tokens>
        </chunking>
        <chunking id="6" string="the statutes" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="statutes" />
          </tokens>
        </chunking>
        <chunking id="7" string="the form of hiring and promotion quotas , so-called goals and timetables" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="form" />
            <token id="17" string="of" />
            <token id="18" string="hiring" />
            <token id="19" string="and" />
            <token id="20" string="promotion" />
            <token id="21" string="quotas" />
            <token id="22" string="," />
            <token id="23" string="so-called" />
            <token id="24" string="goals" />
            <token id="25" string="and" />
            <token id="26" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="8" string="discrimination" type="NP">
          <tokens>
            <token id="13" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="9" string="hiring and promotion quotas" type="NP">
          <tokens>
            <token id="18" string="hiring" />
            <token id="19" string="and" />
            <token id="20" string="promotion" />
            <token id="21" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="10" string="turned the statutes on their heads by requiring discrimination in the form of hiring and promotion quotas , so-called goals and timetables" type="VP">
          <tokens>
            <token id="5" string="turned" />
            <token id="6" string="the" />
            <token id="7" string="statutes" />
            <token id="8" string="on" />
            <token id="9" string="their" />
            <token id="10" string="heads" />
            <token id="11" string="by" />
            <token id="12" string="requiring" />
            <token id="13" string="discrimination" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="form" />
            <token id="17" string="of" />
            <token id="18" string="hiring" />
            <token id="19" string="and" />
            <token id="20" string="promotion" />
            <token id="21" string="quotas" />
            <token id="22" string="," />
            <token id="23" string="so-called" />
            <token id="24" string="goals" />
            <token id="25" string="and" />
            <token id="26" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="11" string="the form of hiring and promotion quotas" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="form" />
            <token id="17" string="of" />
            <token id="18" string="hiring" />
            <token id="19" string="and" />
            <token id="20" string="promotion" />
            <token id="21" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="12" string="the form" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">agencies</governor>
          <dependent id="2">Federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">agencies</governor>
          <dependent id="3">enforcement</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">turned</governor>
          <dependent id="4">agencies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">turned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">statutes</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">turned</governor>
          <dependent id="7">statutes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">heads</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">heads</governor>
          <dependent id="9">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">turned</governor>
          <dependent id="10">heads</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">requiring</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">turned</governor>
          <dependent id="12">requiring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">requiring</governor>
          <dependent id="13">discrimination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">form</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">form</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">requiring</governor>
          <dependent id="16">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">quotas</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">quotas</governor>
          <dependent id="18">hiring</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">hiring</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">hiring</governor>
          <dependent id="20">promotion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">form</governor>
          <dependent id="21">quotas</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">goals</governor>
          <dependent id="23">so-called</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">form</governor>
          <dependent id="24">goals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">form</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">form</governor>
          <dependent id="26">timetables</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="74" has_coreference="false">
      <content>On affirmative action.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN On) (NP (JJ affirmative) (NN action))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="affirmative action" type="NP">
          <tokens>
            <token id="2" string="affirmative" />
            <token id="3" string="action" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">action</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">action</governor>
          <dependent id="2">affirmative</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">action</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>He referred to it as &amp;quot;social engineering.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="referred" lemma="refer" stem="refer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD referred) (PP (TO to) (NP (PRP it))) (PP (IN as) (`` ``) (NP (JJ social) (NN engineering)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="referred to it as `` social engineering" type="VP">
          <tokens>
            <token id="2" string="referred" />
            <token id="3" string="to" />
            <token id="4" string="it" />
            <token id="5" string="as" />
            <token id="6" string="&quot;" />
            <token id="7" string="social" />
            <token id="8" string="engineering" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="social engineering" type="NP">
          <tokens>
            <token id="7" string="social" />
            <token id="8" string="engineering" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">referred</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">referred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">it</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">referred</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">engineering</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">engineering</governor>
          <dependent id="7">social</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">referred</governor>
          <dependent id="8">engineering</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="76" has_coreference="true">
      <content>We&amp;apost;re standing the principle of non-discrimination on its head&amp;quot;.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="principle" lemma="principle" stem="principl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="non-discrimination" lemma="non-discrimination" stem="non-discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP 're) (VP (VBG standing) (NP (NP (DT the) (NN principle)) (PP (IN of) (NP (NN non-discrimination)))) (PP (IN on) (NP (PRP$ its) (NN head) ('' ''))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="standing the principle of non-discrimination on its head ''" type="VP">
          <tokens>
            <token id="3" string="standing" />
            <token id="4" string="the" />
            <token id="5" string="principle" />
            <token id="6" string="of" />
            <token id="7" string="non-discrimination" />
            <token id="8" string="on" />
            <token id="9" string="its" />
            <token id="10" string="head" />
            <token id="11" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="non-discrimination" type="NP">
          <tokens>
            <token id="7" string="non-discrimination" />
          </tokens>
        </chunking>
        <chunking id="3" string="its head ''" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="head" />
            <token id="11" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="5" string="'re standing the principle of non-discrimination on its head ''" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="standing" />
            <token id="4" string="the" />
            <token id="5" string="principle" />
            <token id="6" string="of" />
            <token id="7" string="non-discrimination" />
            <token id="8" string="on" />
            <token id="9" string="its" />
            <token id="10" string="head" />
            <token id="11" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="the principle of non-discrimination" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="principle" />
            <token id="6" string="of" />
            <token id="7" string="non-discrimination" />
          </tokens>
        </chunking>
        <chunking id="7" string="the principle" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="principle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">standing</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">standing</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">standing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">principle</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">standing</governor>
          <dependent id="5">principle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">non-discrimination</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">principle</governor>
          <dependent id="7">non-discrimination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">head</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">head</governor>
          <dependent id="9">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">standing</governor>
          <dependent id="10">head</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="77" has_coreference="true">
      <content>How justice is chosen; President: The president nominates Supreme Court justices.</content>
      <tokens>
        <token id="1" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="nominates" lemma="nominate" stem="nomin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="12" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="13" string="justices" lemma="justice" stem="justic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (SBAR (WHADVP (WRB How)) (S (NP (NN justice)) (VP (VBZ is) (VP (VBN chosen))))) (: ;) (PRN (FRAG (NP (NNP President))))) (: :) (NP (DT The) (NN president)) (VP (VBZ nominates) (NP (NNP Supreme) (NNP Court) (NNS justices))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The president" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="Supreme Court justices" type="NP">
          <tokens>
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="justices" />
          </tokens>
        </chunking>
        <chunking id="3" string="How justice is chosen ; President" type="SBAR">
          <tokens>
            <token id="1" string="How" />
            <token id="2" string="justice" />
            <token id="3" string="is" />
            <token id="4" string="chosen" />
            <token id="5" string=";" />
            <token id="6" string="President" />
          </tokens>
        </chunking>
        <chunking id="4" string="justice" type="NP">
          <tokens>
            <token id="2" string="justice" />
          </tokens>
        </chunking>
        <chunking id="5" string="is chosen" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="chosen" />
          </tokens>
        </chunking>
        <chunking id="6" string="nominates Supreme Court justices" type="VP">
          <tokens>
            <token id="10" string="nominates" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="justices" />
          </tokens>
        </chunking>
        <chunking id="7" string="chosen" type="VP">
          <tokens>
            <token id="4" string="chosen" />
          </tokens>
        </chunking>
        <chunking id="8" string="How justice is chosen" type="SBAR">
          <tokens>
            <token id="1" string="How" />
            <token id="2" string="justice" />
            <token id="3" string="is" />
            <token id="4" string="chosen" />
          </tokens>
        </chunking>
        <chunking id="9" string="How" type="WHADVP">
          <tokens>
            <token id="1" string="How" />
          </tokens>
        </chunking>
        <chunking id="10" string="President" type="NP">
          <tokens>
            <token id="6" string="President" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">chosen</governor>
          <dependent id="1">How</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">chosen</governor>
          <dependent id="2">justice</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">chosen</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">nominates</governor>
          <dependent id="4">chosen</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">chosen</governor>
          <dependent id="6">President</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">president</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">nominates</governor>
          <dependent id="9">president</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">nominates</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">justices</governor>
          <dependent id="11">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">justices</governor>
          <dependent id="12">Court</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">nominates</governor>
          <dependent id="13">justices</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="6" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="78" has_coreference="true">
      <content>Senate: Senate holds hearings into qualifications of a nominee prior to confirming, rejecting or failing to act upon the nomination.</content>
      <tokens>
        <token id="1" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="qualifications" lemma="qualification" stem="qualif" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="prior" lemma="prior" stem="prior" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="confirming" lemma="confirm" stem="confirm" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="rejecting" lemma="reject" stem="reject" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="failing" lemma="fail" stem="fail" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="act" lemma="act" stem="act" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="upon" lemma="upon" stem="upon" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NNP Senate)) (: :) (S (NP (NNP Senate)) (VP (VBZ holds) (NP (NNS hearings)) (PP (IN into) (NP (NP (NNS qualifications)) (PP (IN of) (NP (DT a) (NN nominee))) (ADVP (RB prior) (PP (TO to) (S (VP (VP (VBG confirming)) (, ,) (VP (VBG rejecting)) (CC or) (VP (VBG failing) (S (VP (TO to) (VP (VB act) (PP (IN upon) (NP (DT the) (NN nomination))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="holds hearings into qualifications of a nominee prior to confirming , rejecting or failing to act upon the nomination" type="VP">
          <tokens>
            <token id="4" string="holds" />
            <token id="5" string="hearings" />
            <token id="6" string="into" />
            <token id="7" string="qualifications" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="nominee" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="confirming" />
            <token id="14" string="," />
            <token id="15" string="rejecting" />
            <token id="16" string="or" />
            <token id="17" string="failing" />
            <token id="18" string="to" />
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="2" string="confirming , rejecting or failing to act upon the nomination" type="VP">
          <tokens>
            <token id="13" string="confirming" />
            <token id="14" string="," />
            <token id="15" string="rejecting" />
            <token id="16" string="or" />
            <token id="17" string="failing" />
            <token id="18" string="to" />
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="3" string="the nomination" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="4" string="rejecting" type="VP">
          <tokens>
            <token id="15" string="rejecting" />
          </tokens>
        </chunking>
        <chunking id="5" string="to act upon the nomination" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="6" string="a nominee" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="7" string="Senate" type="NP">
          <tokens>
            <token id="1" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="8" string="hearings" type="NP">
          <tokens>
            <token id="5" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="9" string="qualifications of a nominee prior to confirming , rejecting or failing to act upon the nomination" type="NP">
          <tokens>
            <token id="7" string="qualifications" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="nominee" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="confirming" />
            <token id="14" string="," />
            <token id="15" string="rejecting" />
            <token id="16" string="or" />
            <token id="17" string="failing" />
            <token id="18" string="to" />
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="10" string="qualifications" type="NP">
          <tokens>
            <token id="7" string="qualifications" />
          </tokens>
        </chunking>
        <chunking id="11" string="confirming" type="VP">
          <tokens>
            <token id="13" string="confirming" />
          </tokens>
        </chunking>
        <chunking id="12" string="failing to act upon the nomination" type="VP">
          <tokens>
            <token id="17" string="failing" />
            <token id="18" string="to" />
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="13" string="act upon the nomination" type="VP">
          <tokens>
            <token id="19" string="act" />
            <token id="20" string="upon" />
            <token id="21" string="the" />
            <token id="22" string="nomination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Senate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">holds</governor>
          <dependent id="3">Senate</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Senate</governor>
          <dependent id="4">holds</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">holds</governor>
          <dependent id="5">hearings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">qualifications</governor>
          <dependent id="6">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">holds</governor>
          <dependent id="7">qualifications</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">nominee</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">nominee</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">qualifications</governor>
          <dependent id="10">nominee</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">qualifications</governor>
          <dependent id="11">prior</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">confirming</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">prior</governor>
          <dependent id="13">confirming</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">confirming</governor>
          <dependent id="15">rejecting</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">confirming</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">confirming</governor>
          <dependent id="17">failing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">act</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">failing</governor>
          <dependent id="19">act</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">nomination</governor>
          <dependent id="20">upon</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">nomination</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">act</governor>
          <dependent id="22">nomination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Senate" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="79" has_coreference="true">
      <content>Qualifications: The Constitution sets no qualifications for justices.</content>
      <tokens>
        <token id="1" string="Qualifications" lemma="qualification" stem="qualif" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="sets" lemma="set" stem="set" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="qualifications" lemma="qualification" stem="qualif" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="justices" lemma="justice" stem="justic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNS Qualifications)) (: :) (S (NP (DT The) (NNP Constitution)) (VP (VBZ sets) (NP (NP (DT no) (NNS qualifications)) (PP (IN for) (NP (NNS justices)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Qualifications : The Constitution sets no qualifications for justices ." type="NP">
          <tokens>
            <token id="1" string="Qualifications" />
            <token id="2" string=":" />
            <token id="3" string="The" />
            <token id="4" string="Constitution" />
            <token id="5" string="sets" />
            <token id="6" string="no" />
            <token id="7" string="qualifications" />
            <token id="8" string="for" />
            <token id="9" string="justices" />
            <token id="10" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="no qualifications for justices" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="qualifications" />
            <token id="8" string="for" />
            <token id="9" string="justices" />
          </tokens>
        </chunking>
        <chunking id="3" string="justices" type="NP">
          <tokens>
            <token id="9" string="justices" />
          </tokens>
        </chunking>
        <chunking id="4" string="sets no qualifications for justices" type="VP">
          <tokens>
            <token id="5" string="sets" />
            <token id="6" string="no" />
            <token id="7" string="qualifications" />
            <token id="8" string="for" />
            <token id="9" string="justices" />
          </tokens>
        </chunking>
        <chunking id="5" string="Qualifications" type="NP">
          <tokens>
            <token id="1" string="Qualifications" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Constitution" type="NP">
          <tokens>
            <token id="3" string="The" />
            <token id="4" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="7" string="no qualifications" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="qualifications" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Qualifications</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Constitution</governor>
          <dependent id="3">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">sets</governor>
          <dependent id="4">Constitution</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Qualifications</governor>
          <dependent id="5">sets</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">qualifications</governor>
          <dependent id="6">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">sets</governor>
          <dependent id="7">qualifications</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">justices</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">qualifications</governor>
          <dependent id="9">justices</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="80" has_coreference="true">
      <content>Traditionally, justices have had some legal training and most have been judges, lawyers or law teachers.</content>
      <tokens>
        <token id="1" string="Traditionally" lemma="traditionally" stem="tradition" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="justices" lemma="justice" stem="justic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="lawyers" lemma="lawyer" stem="lawyer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="teachers" lemma="teacher" stem="teacher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Traditionally)) (, ,) (S (NP (NNS justices)) (VP (VBP have) (VP (VBN had) (NP (DT some) (JJ legal) (NN training))))) (CC and) (S (NP (JJS most)) (VP (VBP have) (VP (VBN been) (NP (NNS judges) (, ,) (NNS lawyers) (CC or) (NN law) (NNS teachers))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most" type="NP">
          <tokens>
            <token id="10" string="most" />
          </tokens>
        </chunking>
        <chunking id="2" string="judges , lawyers or law teachers" type="NP">
          <tokens>
            <token id="13" string="judges" />
            <token id="14" string="," />
            <token id="15" string="lawyers" />
            <token id="16" string="or" />
            <token id="17" string="law" />
            <token id="18" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="3" string="justices" type="NP">
          <tokens>
            <token id="3" string="justices" />
          </tokens>
        </chunking>
        <chunking id="4" string="had some legal training" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="some" />
            <token id="7" string="legal" />
            <token id="8" string="training" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been judges , lawyers or law teachers" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="judges" />
            <token id="14" string="," />
            <token id="15" string="lawyers" />
            <token id="16" string="or" />
            <token id="17" string="law" />
            <token id="18" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="6" string="some legal training" type="NP">
          <tokens>
            <token id="6" string="some" />
            <token id="7" string="legal" />
            <token id="8" string="training" />
          </tokens>
        </chunking>
        <chunking id="7" string="have had some legal training" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="had" />
            <token id="6" string="some" />
            <token id="7" string="legal" />
            <token id="8" string="training" />
          </tokens>
        </chunking>
        <chunking id="8" string="been judges , lawyers or law teachers" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="judges" />
            <token id="14" string="," />
            <token id="15" string="lawyers" />
            <token id="16" string="or" />
            <token id="17" string="law" />
            <token id="18" string="teachers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">had</governor>
          <dependent id="1">Traditionally</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="3">justices</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">had</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">training</governor>
          <dependent id="6">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">training</governor>
          <dependent id="7">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="8">training</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">had</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">lawyers</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">lawyers</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">lawyers</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">lawyers</governor>
          <dependent id="13">judges</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">had</governor>
          <dependent id="15">lawyers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">lawyers</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">teachers</governor>
          <dependent id="17">law</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">lawyers</governor>
          <dependent id="18">teachers</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="81" has_coreference="true">
      <content>Past Nominees; David Souter: Confirmed by Senate, 1990, despite concerns of some Democrats about his views on the right to privacy; Anthony M. Kennedy: Confirmed unanimously, 1988; Robert H. Bork: Rejected, 1987, because of his strict interpretation of the Constitution, which critics said would have set back progress on individual rights; Douglas H. Ginsburg: Ginsburg asked that his nomination be withdrawn, 1987, after he admitted having smoked marijuana as recently as 1979.</content>
      <tokens>
        <token id="1" string="Past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="Nominees" lemma="nominee" stem="nomine" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Souter" lemma="Souter" stem="souter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="concerns" lemma="concern" stem="concern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Democrats" lemma="democrat" stem="democrat" pos="NNS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="18" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Anthony" lemma="Anthony" stem="anthoni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="unanimously" lemma="unanimously" stem="unanim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="37" string="H." lemma="H." stem="h." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="38" string="Bork" lemma="Bork" stem="bork" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="39" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Rejected" lemma="reject" stem="reject" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="strict" lemma="strict" stem="strict" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="interpretation" lemma="interpretation" stem="interpret" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="individual" lemma="individual" stem="individu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="Douglas" lemma="Douglas" stem="dougla" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="66" string="H." lemma="H." stem="h." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="67" string="Ginsburg" lemma="Ginsburg" stem="ginsburg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="68" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="Ginsburg" lemma="Ginsburg" stem="ginsburg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="70" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="72" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="73" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="74" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="75" string="withdrawn" lemma="withdraw" stem="withdrawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="76" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="77" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="78" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="79" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="80" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="81" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="82" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="83" string="smoked" lemma="smoke" stem="smoke" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="84" string="marijuana" lemma="marijuana" stem="marijuana" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="85" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="86" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="87" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="88" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="89" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (JJ Past) (NNS Nominees)) (: ;) (NP (NP (NNP David) (NNP Souter)) (: :) (S (S (VP (VBN Confirmed) (PP (IN by) (NP (NP (NNP Senate)) (, ,) (NP (CD 1990)) (, ,))) (PP (IN despite) (NP (NP (NNS concerns)) (PP (IN of) (NP (NP (DT some) (NNS Democrats)) (PP (IN about) (NP (PRP$ his) (NNS views))))))) (PP (IN on) (NP (NP (NP (DT the) (NN right)) (PP (TO to) (NP (NN privacy)))) (: ;) (NP (NNP Anthony) (NNP M.) (NNP Kennedy)))))) (: :) (S (VP (VP (VBN Confirmed) (ADVP (RB unanimously))) (, ,) (NP (NP (CD 1988)) (: ;) (NP (NNP Robert) (NNP H.) (NNP Bork))))) (: :) (S (VP (VBN Rejected))) (, ,) (S (NP (NP (NP (CD 1987)) (, ,) (SBAR (IN because) (S (PP (IN of) (NP (NP (PRP$ his) (JJ strict) (NN interpretation)) (PP (IN of) (NP (DT the) (NNP Constitution))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (NNS critics)) (VP (VBD said) (SBAR (S (VP (MD would) (VP (VB have) (VP (VBN set) (PRT (RP back)) (NP (NP (NP (NN progress)) (PP (IN on) (NP (JJ individual) (NNS rights)))) (: ;) (NP (NNP Douglas) (NNP H.) (NNP Ginsburg))))))))))) (: :))) (NP (NNP Ginsburg)) (VP (VBD asked) (SBAR (IN that) (S (NP (PRP$ his) (NN nomination)) (VP (VB be) (VP (VBN withdrawn))))))))) (, ,) (NP (CD 1987)) (, ,) (SBAR (IN after) (S (NP (PRP he)) (VP (VBD admitted) (S (VP (VBG having) (VP (VBN smoked) (NP (NN marijuana)) (PP (IN as) (ADVP (RB recently))) (PP (IN as) (NP (CD 1979))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said would have set back progress on individual rights ; Douglas H. Ginsburg" type="VP">
          <tokens>
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="2" string="some Democrats about his views" type="NP">
          <tokens>
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
            <token id="18" string="about" />
            <token id="19" string="his" />
            <token id="20" string="views" />
          </tokens>
        </chunking>
        <chunking id="3" string="David Souter" type="NP">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Souter" />
          </tokens>
        </chunking>
        <chunking id="4" string="Senate" type="NP">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="5" string="critics" type="NP">
          <tokens>
            <token id="54" string="critics" />
          </tokens>
        </chunking>
        <chunking id="6" string="Past Nominees" type="NP">
          <tokens>
            <token id="1" string="Past" />
            <token id="2" string="Nominees" />
          </tokens>
        </chunking>
        <chunking id="7" string="Confirmed by Senate , 1990 , despite concerns of some Democrats about his views on the right to privacy ; Anthony M. Kennedy" type="VP">
          <tokens>
            <token id="7" string="Confirmed" />
            <token id="8" string="by" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="1990" />
            <token id="12" string="," />
            <token id="13" string="despite" />
            <token id="14" string="concerns" />
            <token id="15" string="of" />
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
            <token id="18" string="about" />
            <token id="19" string="his" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="right" />
            <token id="24" string="to" />
            <token id="25" string="privacy" />
            <token id="26" string=";" />
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="8" string="would have set back progress on individual rights ; Douglas H. Ginsburg" type="SBAR">
          <tokens>
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="9" string="Robert H. Bork" type="NP">
          <tokens>
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
          </tokens>
        </chunking>
        <chunking id="10" string="Senate , 1990 ," type="NP">
          <tokens>
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="1990" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="his nomination" type="NP">
          <tokens>
            <token id="72" string="his" />
            <token id="73" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="12" string="progress" type="NP">
          <tokens>
            <token id="60" string="progress" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="80" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="his views" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="views" />
          </tokens>
        </chunking>
        <chunking id="15" string="1988 ; Robert H. Bork" type="NP">
          <tokens>
            <token id="34" string="1988" />
            <token id="35" string=";" />
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
          </tokens>
        </chunking>
        <chunking id="16" string="Douglas H. Ginsburg" type="NP">
          <tokens>
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="17" string="David Souter : Confirmed by Senate , 1990 , despite concerns of some Democrats about his views on the right to privacy ; Anthony M. Kennedy : Confirmed unanimously , 1988 ; Robert H. Bork : Rejected , 1987 , because of his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg : Ginsburg asked that his nomination be withdrawn , 1987 , after he admitted having smoked marijuana as recently as 1979" type="NP">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Souter" />
            <token id="6" string=":" />
            <token id="7" string="Confirmed" />
            <token id="8" string="by" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="1990" />
            <token id="12" string="," />
            <token id="13" string="despite" />
            <token id="14" string="concerns" />
            <token id="15" string="of" />
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
            <token id="18" string="about" />
            <token id="19" string="his" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="right" />
            <token id="24" string="to" />
            <token id="25" string="privacy" />
            <token id="26" string=";" />
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
            <token id="30" string=":" />
            <token id="31" string="Confirmed" />
            <token id="32" string="unanimously" />
            <token id="33" string="," />
            <token id="34" string="1988" />
            <token id="35" string=";" />
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
            <token id="39" string=":" />
            <token id="40" string="Rejected" />
            <token id="41" string="," />
            <token id="42" string="1987" />
            <token id="43" string="," />
            <token id="44" string="because" />
            <token id="45" string="of" />
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
            <token id="69" string="Ginsburg" />
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
            <token id="76" string="," />
            <token id="77" string="1987" />
            <token id="78" string="," />
            <token id="79" string="after" />
            <token id="80" string="he" />
            <token id="81" string="admitted" />
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="18" string="his strict interpretation" type="NP">
          <tokens>
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
          </tokens>
        </chunking>
        <chunking id="19" string="the right" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="right" />
          </tokens>
        </chunking>
        <chunking id="20" string="Rejected" type="VP">
          <tokens>
            <token id="40" string="Rejected" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Constitution" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="22" string="because of his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg : Ginsburg asked that his nomination be withdrawn" type="SBAR">
          <tokens>
            <token id="44" string="because" />
            <token id="45" string="of" />
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
            <token id="69" string="Ginsburg" />
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="23" string="Confirmed unanimously , 1988 ; Robert H. Bork" type="VP">
          <tokens>
            <token id="31" string="Confirmed" />
            <token id="32" string="unanimously" />
            <token id="33" string="," />
            <token id="34" string="1988" />
            <token id="35" string=";" />
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
          </tokens>
        </chunking>
        <chunking id="24" string="be withdrawn" type="VP">
          <tokens>
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="25" string="having smoked marijuana as recently as 1979" type="VP">
          <tokens>
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="26" string="his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg :" type="NP">
          <tokens>
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
          </tokens>
        </chunking>
        <chunking id="27" string="which critics said would have set back progress on individual rights ; Douglas H. Ginsburg" type="SBAR">
          <tokens>
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="28" string="Ginsburg" type="NP">
          <tokens>
            <token id="69" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="29" string="Anthony M. Kennedy" type="NP">
          <tokens>
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="30" string="that his nomination be withdrawn" type="SBAR">
          <tokens>
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="31" string="some Democrats" type="NP">
          <tokens>
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="32" string="individual rights" type="NP">
          <tokens>
            <token id="62" string="individual" />
            <token id="63" string="rights" />
          </tokens>
        </chunking>
        <chunking id="33" string="1979" type="NP">
          <tokens>
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="34" string="asked that his nomination be withdrawn" type="VP">
          <tokens>
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="35" string="Past Nominees ; David Souter : Confirmed by Senate , 1990 , despite concerns of some Democrats about his views on the right to privacy ; Anthony M. Kennedy : Confirmed unanimously , 1988 ; Robert H. Bork : Rejected , 1987 , because of his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg : Ginsburg asked that his nomination be withdrawn , 1987 , after he admitted having smoked marijuana as recently as 1979 ." type="NP">
          <tokens>
            <token id="1" string="Past" />
            <token id="2" string="Nominees" />
            <token id="3" string=";" />
            <token id="4" string="David" />
            <token id="5" string="Souter" />
            <token id="6" string=":" />
            <token id="7" string="Confirmed" />
            <token id="8" string="by" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="1990" />
            <token id="12" string="," />
            <token id="13" string="despite" />
            <token id="14" string="concerns" />
            <token id="15" string="of" />
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
            <token id="18" string="about" />
            <token id="19" string="his" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="right" />
            <token id="24" string="to" />
            <token id="25" string="privacy" />
            <token id="26" string=";" />
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
            <token id="30" string=":" />
            <token id="31" string="Confirmed" />
            <token id="32" string="unanimously" />
            <token id="33" string="," />
            <token id="34" string="1988" />
            <token id="35" string=";" />
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
            <token id="39" string=":" />
            <token id="40" string="Rejected" />
            <token id="41" string="," />
            <token id="42" string="1987" />
            <token id="43" string="," />
            <token id="44" string="because" />
            <token id="45" string="of" />
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
            <token id="69" string="Ginsburg" />
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
            <token id="76" string="," />
            <token id="77" string="1987" />
            <token id="78" string="," />
            <token id="79" string="after" />
            <token id="80" string="he" />
            <token id="81" string="admitted" />
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
            <token id="89" string="." />
          </tokens>
        </chunking>
        <chunking id="36" string="1990" type="NP">
          <tokens>
            <token id="11" string="1990" />
          </tokens>
        </chunking>
        <chunking id="37" string="the right to privacy ; Anthony M. Kennedy" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="right" />
            <token id="24" string="to" />
            <token id="25" string="privacy" />
            <token id="26" string=";" />
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="38" string="concerns" type="NP">
          <tokens>
            <token id="14" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="39" string="after he admitted having smoked marijuana as recently as 1979" type="SBAR">
          <tokens>
            <token id="79" string="after" />
            <token id="80" string="he" />
            <token id="81" string="admitted" />
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="40" string="1988" type="NP">
          <tokens>
            <token id="34" string="1988" />
          </tokens>
        </chunking>
        <chunking id="41" string="1987" type="NP">
          <tokens>
            <token id="42" string="1987" />
          </tokens>
        </chunking>
        <chunking id="42" string="progress on individual rights" type="NP">
          <tokens>
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
          </tokens>
        </chunking>
        <chunking id="43" string="have set back progress on individual rights ; Douglas H. Ginsburg" type="VP">
          <tokens>
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="44" string="set back progress on individual rights ; Douglas H. Ginsburg" type="VP">
          <tokens>
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="45" string="the right to privacy" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="right" />
            <token id="24" string="to" />
            <token id="25" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="46" string="privacy" type="NP">
          <tokens>
            <token id="25" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="47" string="marijuana" type="NP">
          <tokens>
            <token id="84" string="marijuana" />
          </tokens>
        </chunking>
        <chunking id="48" string="Confirmed unanimously" type="VP">
          <tokens>
            <token id="31" string="Confirmed" />
            <token id="32" string="unanimously" />
          </tokens>
        </chunking>
        <chunking id="49" string="withdrawn" type="VP">
          <tokens>
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="50" string="1987 , because of his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg : Ginsburg asked that his nomination be withdrawn , 1987 , after he admitted having smoked marijuana as recently as 1979" type="NP">
          <tokens>
            <token id="42" string="1987" />
            <token id="43" string="," />
            <token id="44" string="because" />
            <token id="45" string="of" />
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
            <token id="69" string="Ginsburg" />
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
            <token id="76" string="," />
            <token id="77" string="1987" />
            <token id="78" string="," />
            <token id="79" string="after" />
            <token id="80" string="he" />
            <token id="81" string="admitted" />
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="51" string="admitted having smoked marijuana as recently as 1979" type="VP">
          <tokens>
            <token id="81" string="admitted" />
            <token id="82" string="having" />
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
        <chunking id="52" string="progress on individual rights ; Douglas H. Ginsburg" type="NP">
          <tokens>
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </chunking>
        <chunking id="53" string="concerns of some Democrats about his views" type="NP">
          <tokens>
            <token id="14" string="concerns" />
            <token id="15" string="of" />
            <token id="16" string="some" />
            <token id="17" string="Democrats" />
            <token id="18" string="about" />
            <token id="19" string="his" />
            <token id="20" string="views" />
          </tokens>
        </chunking>
        <chunking id="54" string="1987 , because of his strict interpretation of the Constitution , which critics said would have set back progress on individual rights ; Douglas H. Ginsburg : Ginsburg asked that his nomination be withdrawn" type="NP">
          <tokens>
            <token id="42" string="1987" />
            <token id="43" string="," />
            <token id="44" string="because" />
            <token id="45" string="of" />
            <token id="46" string="his" />
            <token id="47" string="strict" />
            <token id="48" string="interpretation" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="Constitution" />
            <token id="52" string="," />
            <token id="53" string="which" />
            <token id="54" string="critics" />
            <token id="55" string="said" />
            <token id="56" string="would" />
            <token id="57" string="have" />
            <token id="58" string="set" />
            <token id="59" string="back" />
            <token id="60" string="progress" />
            <token id="61" string="on" />
            <token id="62" string="individual" />
            <token id="63" string="rights" />
            <token id="64" string=";" />
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
            <token id="68" string=":" />
            <token id="69" string="Ginsburg" />
            <token id="70" string="asked" />
            <token id="71" string="that" />
            <token id="72" string="his" />
            <token id="73" string="nomination" />
            <token id="74" string="be" />
            <token id="75" string="withdrawn" />
          </tokens>
        </chunking>
        <chunking id="55" string="smoked marijuana as recently as 1979" type="VP">
          <tokens>
            <token id="83" string="smoked" />
            <token id="84" string="marijuana" />
            <token id="85" string="as" />
            <token id="86" string="recently" />
            <token id="87" string="as" />
            <token id="88" string="1979" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">Nominees</governor>
          <dependent id="1">Past</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Nominees</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Souter</governor>
          <dependent id="4">David</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Nominees</governor>
          <dependent id="5">Souter</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">Souter</governor>
          <dependent id="7">Confirmed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Senate</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Confirmed</governor>
          <dependent id="9">Senate</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Senate</governor>
          <dependent id="11">1990</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">concerns</governor>
          <dependent id="13">despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Confirmed</governor>
          <dependent id="14">concerns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Democrats</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Democrats</governor>
          <dependent id="16">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">concerns</governor>
          <dependent id="17">Democrats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">views</governor>
          <dependent id="18">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">views</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">Democrats</governor>
          <dependent id="20">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">right</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">right</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Confirmed</governor>
          <dependent id="23">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">privacy</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">right</governor>
          <dependent id="25">privacy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Kennedy</governor>
          <dependent id="27">Anthony</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Kennedy</governor>
          <dependent id="28">M.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">right</governor>
          <dependent id="29">Kennedy</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">Confirmed</governor>
          <dependent id="31">Confirmed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">Confirmed</governor>
          <dependent id="32">unanimously</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">Confirmed</governor>
          <dependent id="34">1988</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Bork</governor>
          <dependent id="36">Robert</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Bork</governor>
          <dependent id="37">H.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">1988</governor>
          <dependent id="38">Bork</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">Confirmed</governor>
          <dependent id="40">Rejected</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">Confirmed</governor>
          <dependent id="42">1987</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="70">asked</governor>
          <dependent id="44">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">interpretation</governor>
          <dependent id="45">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="48">interpretation</governor>
          <dependent id="46">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">interpretation</governor>
          <dependent id="47">strict</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="70">asked</governor>
          <dependent id="48">interpretation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">Constitution</governor>
          <dependent id="49">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">Constitution</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">interpretation</governor>
          <dependent id="51">Constitution</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="55">said</governor>
          <dependent id="53">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="55">said</governor>
          <dependent id="54">critics</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="48">interpretation</governor>
          <dependent id="55">said</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="58">set</governor>
          <dependent id="56">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="58">set</governor>
          <dependent id="57">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="55">said</governor>
          <dependent id="58">set</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="58">set</governor>
          <dependent id="59">back</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="58">set</governor>
          <dependent id="60">progress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">rights</governor>
          <dependent id="61">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="63">rights</governor>
          <dependent id="62">individual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">progress</governor>
          <dependent id="63">rights</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">Ginsburg</governor>
          <dependent id="65">Douglas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">Ginsburg</governor>
          <dependent id="66">H.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="60">progress</governor>
          <dependent id="67">Ginsburg</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="70">asked</governor>
          <dependent id="69">Ginsburg</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">1987</governor>
          <dependent id="70">asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="75">withdrawn</governor>
          <dependent id="71">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="73">nomination</governor>
          <dependent id="72">his</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="75">withdrawn</governor>
          <dependent id="73">nomination</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="75">withdrawn</governor>
          <dependent id="74">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="70">asked</governor>
          <dependent id="75">withdrawn</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">1987</governor>
          <dependent id="77">1987</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="81">admitted</governor>
          <dependent id="79">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="81">admitted</governor>
          <dependent id="80">he</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">1987</governor>
          <dependent id="81">admitted</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="83">smoked</governor>
          <dependent id="82">having</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="81">admitted</governor>
          <dependent id="83">smoked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="83">smoked</governor>
          <dependent id="84">marijuana</dependent>
        </dependency>
        <dependency type="case">
          <governor id="86">recently</governor>
          <dependent id="85">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="83">smoked</governor>
          <dependent id="86">recently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="88">1979</governor>
          <dependent id="87">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="83">smoked</governor>
          <dependent id="88">1979</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Douglas H. Ginsburg" type="PERSON" score="0.0">
          <tokens>
            <token id="65" string="Douglas" />
            <token id="66" string="H." />
            <token id="67" string="Ginsburg" />
          </tokens>
        </entity>
        <entity id="2" string="David Souter" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Souter" />
          </tokens>
        </entity>
        <entity id="3" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1990" />
          </tokens>
        </entity>
        <entity id="4" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="86" string="recently" />
          </tokens>
        </entity>
        <entity id="5" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="23" string="right" />
          </tokens>
        </entity>
        <entity id="6" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="17" string="Democrats" />
          </tokens>
        </entity>
        <entity id="7" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="1988" />
          </tokens>
        </entity>
        <entity id="8" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </entity>
        <entity id="9" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="42" string="1987" />
          </tokens>
        </entity>
        <entity id="10" string="Past" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Past" />
          </tokens>
        </entity>
        <entity id="11" string="Robert H. Bork" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Robert" />
            <token id="37" string="H." />
            <token id="38" string="Bork" />
          </tokens>
        </entity>
        <entity id="12" string="Ginsburg" type="PERSON" score="0.0">
          <tokens>
            <token id="69" string="Ginsburg" />
          </tokens>
        </entity>
        <entity id="13" string="Anthony M. Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Anthony" />
            <token id="28" string="M." />
            <token id="29" string="Kennedy" />
          </tokens>
        </entity>
        <entity id="14" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="88" string="1979" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="82" has_coreference="false">
      <content>Sources: Chicago Tribune, World Book Encyclopedia, Compton&amp;apost;s Encyclopedia, Who&amp;apost;s Who Among Black Americans, news reports; Knight-Ridder News Service</content>
      <tokens>
        <token id="1" string="Sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Chicago" lemma="Chicago" stem="chicago" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Tribune" lemma="Tribune" stem="tribun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="7" string="Book" lemma="Book" stem="book" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="8" string="Encyclopedia" lemma="Encyclopedia" stem="encyclopedia" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Compton" lemma="Compton" stem="compton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Encyclopedia" lemma="Encyclopedia" stem="encyclopedia" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="17" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="Black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="reports" lemma="report" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Knight-Ridder" lemma="Knight-Ridder" stem="knight-ridd" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="News" lemma="News" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (NNS Sources)) (: :) (NP (NNP Chicago) (NNP Tribune)) (, ,) (NP (NP (NNP World) (NNP Book) (NNP Encyclopedia)) (, ,) (NP (NP (NNP Compton) (POS 's)) (NNP Encyclopedia)) (, ,) (SBAR (WHNP (WP Who)) (S (VP (VBZ 's) (WHNP (WHNP (WP Who)) (PP (IN Among) (NP (NP (JJ Black) (NNPS Americans)) (, ,) (NP (NP (NN news) (NNS reports)) (: ;) (NP (NNP Knight-Ridder) (NNP News) (NNP Service)))))))))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sources" type="NP">
          <tokens>
            <token id="1" string="Sources" />
          </tokens>
        </chunking>
        <chunking id="2" string="Black Americans" type="NP">
          <tokens>
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="3" string="news reports" type="NP">
          <tokens>
            <token id="21" string="news" />
            <token id="22" string="reports" />
          </tokens>
        </chunking>
        <chunking id="4" string="World Book Encyclopedia , Compton 's Encyclopedia , Who 's Who Among Black Americans , news reports ; Knight-Ridder News Service" type="NP">
          <tokens>
            <token id="6" string="World" />
            <token id="7" string="Book" />
            <token id="8" string="Encyclopedia" />
            <token id="9" string="," />
            <token id="10" string="Compton" />
            <token id="11" string="'s" />
            <token id="12" string="Encyclopedia" />
            <token id="13" string="," />
            <token id="14" string="Who" />
            <token id="15" string="'s" />
            <token id="16" string="Who" />
            <token id="17" string="Among" />
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="5" string="Who 's Who Among Black Americans , news reports ; Knight-Ridder News Service" type="SBAR">
          <tokens>
            <token id="14" string="Who" />
            <token id="15" string="'s" />
            <token id="16" string="Who" />
            <token id="17" string="Among" />
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="6" string="World Book Encyclopedia" type="NP">
          <tokens>
            <token id="6" string="World" />
            <token id="7" string="Book" />
            <token id="8" string="Encyclopedia" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s Who Among Black Americans , news reports ; Knight-Ridder News Service" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="Who" />
            <token id="17" string="Among" />
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="8" string="Knight-Ridder News Service" type="NP">
          <tokens>
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="9" string="news reports ; Knight-Ridder News Service" type="NP">
          <tokens>
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="10" string="Compton 's Encyclopedia" type="NP">
          <tokens>
            <token id="10" string="Compton" />
            <token id="11" string="'s" />
            <token id="12" string="Encyclopedia" />
          </tokens>
        </chunking>
        <chunking id="11" string="Black Americans , news reports ; Knight-Ridder News Service" type="NP">
          <tokens>
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="12" string="Compton 's" type="NP">
          <tokens>
            <token id="10" string="Compton" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sources : Chicago Tribune , World Book Encyclopedia , Compton 's Encyclopedia , Who 's Who Among Black Americans , news reports ; Knight-Ridder News Service" type="NP">
          <tokens>
            <token id="1" string="Sources" />
            <token id="2" string=":" />
            <token id="3" string="Chicago" />
            <token id="4" string="Tribune" />
            <token id="5" string="," />
            <token id="6" string="World" />
            <token id="7" string="Book" />
            <token id="8" string="Encyclopedia" />
            <token id="9" string="," />
            <token id="10" string="Compton" />
            <token id="11" string="'s" />
            <token id="12" string="Encyclopedia" />
            <token id="13" string="," />
            <token id="14" string="Who" />
            <token id="15" string="'s" />
            <token id="16" string="Who" />
            <token id="17" string="Among" />
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="news" />
            <token id="22" string="reports" />
            <token id="23" string=";" />
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </chunking>
        <chunking id="14" string="Chicago Tribune" type="NP">
          <tokens>
            <token id="3" string="Chicago" />
            <token id="4" string="Tribune" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Sources</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Tribune</governor>
          <dependent id="3">Chicago</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Sources</governor>
          <dependent id="4">Tribune</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Encyclopedia</governor>
          <dependent id="6">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Encyclopedia</governor>
          <dependent id="7">Book</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Sources</governor>
          <dependent id="8">Encyclopedia</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">Encyclopedia</governor>
          <dependent id="10">Compton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Compton</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Encyclopedia</governor>
          <dependent id="12">Encyclopedia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">Who</governor>
          <dependent id="14">Who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">Who</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">Encyclopedia</governor>
          <dependent id="16">Who</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Americans</governor>
          <dependent id="17">Among</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">Americans</governor>
          <dependent id="18">Black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Who</governor>
          <dependent id="19">Americans</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">reports</governor>
          <dependent id="21">news</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">Americans</governor>
          <dependent id="22">reports</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Service</governor>
          <dependent id="24">Knight-Ridder</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Service</governor>
          <dependent id="25">News</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">reports</governor>
          <dependent id="26">Service</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Who Among Black Americans" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Who" />
            <token id="17" string="Among" />
            <token id="18" string="Black" />
            <token id="19" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="Encyclopedia" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Encyclopedia" />
          </tokens>
        </entity>
        <entity id="3" string="Compton" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Compton" />
          </tokens>
        </entity>
        <entity id="4" string="Chicago Tribune" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Chicago" />
            <token id="4" string="Tribune" />
          </tokens>
        </entity>
        <entity id="5" string="World Book Encyclopedia" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="World" />
            <token id="7" string="Book" />
            <token id="8" string="Encyclopedia" />
          </tokens>
        </entity>
        <entity id="6" string="Knight-Ridder News Service" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Knight-Ridder" />
            <token id="25" string="News" />
            <token id="26" string="Service" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="8-9" string="Clarence Thomas" id_sentence="1" />
      <mentions>
        <mention ids_tokens="30" string="his" id_sentence="2" />
        <mention ids_tokens="9" string="his" id_sentence="3" />
        <mention ids_tokens="17-20" string="Clarence Thomas , nominee" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="45-46" string="black Savannah" id_sentence="5" />
      <mentions>
        <mention ids_tokens="13" string="Savannah" id_sentence="2" />
        <mention ids_tokens="9" string="Savannah" id_sentence="24" />
        <mention ids_tokens="11" string="Savannah" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="15" string="Ga." id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="Georgia" id_sentence="16" />
        <mention ids_tokens="21" string="Georgia" id_sentence="16" />
        <mention ids_tokens="12" string="Georgia" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12-13-14-15" string="a woodsy , one-lane , white-sand road outside Savannah , Ga." id_sentence="2" />
      <mentions>
        <mention ids_tokens="34-35" string="the road" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="9-10" string="his family" id_sentence="3" />
      <mentions>
        <mention ids_tokens="4-5" string="our family" id_sentence="19" />
        <mention ids_tokens="2" string="I" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="40-41" string="the heads" id_sentence="3" />
      <mentions>
        <mention ids_tokens="9-10" string="their heads" id_sentence="73" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20" string="the toughening of Clarence Thomas , nominee" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3" string="his" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="22-23-24-25-26" string="the United States Supreme Court" id_sentence="4" />
      <mentions>
        <mention ids_tokens="50-51" string="Supreme Court" id_sentence="6" />
        <mention ids_tokens="6-7" string="Supreme Court" id_sentence="10" />
        <mention ids_tokens="29-31" string="the Supreme Court" id_sentence="69" />
        <mention ids_tokens="11-12" string="Supreme Court" id_sentence="77" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="3-4" string="his father" id_sentence="5" />
      <mentions>
        <mention ids_tokens="5" string="he" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="his hard-eyed grandfather" id_sentence="5" />
      <mentions>
        <mention ids_tokens="22-23" string="his grandfather" id_sentence="20" />
        <mention ids_tokens="32-33" string="his grandfather" id_sentence="20" />
        <mention ids_tokens="36" string="him" id_sentence="20" />
        <mention ids_tokens="1-2" string="The grandfather" id_sentence="21" />
        <mention ids_tokens="1-2" string="His grandfather" id_sentence="25" />
        <mention ids_tokens="2" string="He" id_sentence="26" />
        <mention ids_tokens="2" string="he" id_sentence="27" />
        <mention ids_tokens="1" string="I" id_sentence="28" />
        <mention ids_tokens="4-5" string="him &quot;" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="23-24" string="young Clarence" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2" string="Clarence" id_sentence="18" />
        <mention ids_tokens="1" string="He" id_sentence="19" />
        <mention ids_tokens="4" string="Clarence" id_sentence="20" />
        <mention ids_tokens="9" string="himself" id_sentence="20" />
        <mention ids_tokens="10" string="he" id_sentence="20" />
        <mention ids_tokens="14" string="he" id_sentence="20" />
        <mention ids_tokens="22" string="his" id_sentence="20" />
        <mention ids_tokens="24" string="he" id_sentence="20" />
        <mention ids_tokens="32" string="his" id_sentence="20" />
        <mention ids_tokens="1" string="Clarence" id_sentence="24" />
        <mention ids_tokens="6" string="his" id_sentence="24" />
        <mention ids_tokens="1" string="His" id_sentence="25" />
        <mention ids_tokens="6" string="me" id_sentence="26" />
        <mention ids_tokens="9" string="Clarence" id_sentence="46" />
        <mention ids_tokens="11" string="he" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="30" string="liberal" id_sentence="6" />
      <mentions>
        <mention ids_tokens="14" string="his" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="14-15-16-17" string="the revered Thurgood Marshall" id_sentence="16" />
      <mentions>
        <mention ids_tokens="43-55" string="Thurgood Marshall , the retiring justice whose Supreme Court seat Thomas might take" id_sentence="6" />
        <mention ids_tokens="43-44" string="Thurgood Marshall" id_sentence="6" />
        <mention ids_tokens="21-31" string="Justice Thurgood Marshall , who is retiring from the Supreme Court" id_sentence="69" />
        <mention ids_tokens="21-23" string="Justice Thurgood Marshall" id_sentence="69" />
        <mention ids_tokens="22-23" string="Thurgood Marshall" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="50-51-52-53" string="Supreme Court seat Thomas" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3-6" string="Thomas , now 43" id_sentence="7" />
        <mention ids_tokens="3" string="Thomas" id_sentence="7" />
        <mention ids_tokens="4" string="he" id_sentence="8" />
        <mention ids_tokens="13" string="he" id_sentence="8" />
        <mention ids_tokens="30" string="he" id_sentence="8" />
        <mention ids_tokens="2" string="he" id_sentence="9" />
        <mention ids_tokens="15-18" string="him of Senate confirmation" id_sentence="9" />
        <mention ids_tokens="14-15" string="Anderson's" id_sentence="24" />
        <mention ids_tokens="32" string="Thomas" id_sentence="25" />
        <mention ids_tokens="2" string="Anderson" id_sentence="29" />
        <mention ids_tokens="5-6" string="coaching Thomas" id_sentence="29" />
        <mention ids_tokens="6" string="Thomas" id_sentence="29" />
        <mention ids_tokens="9" string="his" id_sentence="29" />
        <mention ids_tokens="14" string="his" id_sentence="29" />
        <mention ids_tokens="18" string="he" id_sentence="29" />
        <mention ids_tokens="1-12" string="Thomas , who had experienced racial mistreatment by white seminarians in Georgia" id_sentence="30" />
        <mention ids_tokens="1" string="Thomas" id_sentence="30" />
        <mention ids_tokens="1" string="He" id_sentence="31" />
        <mention ids_tokens="1" string="He" id_sentence="32" />
        <mention ids_tokens="3" string="he" id_sentence="32" />
        <mention ids_tokens="24" string="I" id_sentence="32" />
        <mention ids_tokens="1" string="Thomas" id_sentence="33" />
        <mention ids_tokens="2-13" string="so Thomas , who was driven from the Missouri seminary by racism" id_sentence="36" />
        <mention ids_tokens="2-3" string="so Thomas" id_sentence="36" />
        <mention ids_tokens="3" string="Thomas" id_sentence="36" />
        <mention ids_tokens="1-18" string="Thomas , who paid for his college education with loans , jobs and the newly raised scholarship funds" id_sentence="37" />
        <mention ids_tokens="1" string="Thomas" id_sentence="37" />
        <mention ids_tokens="6" string="his" id_sentence="37" />
        <mention ids_tokens="1" string="He" id_sentence="38" />
        <mention ids_tokens="5" string="he" id_sentence="39" />
        <mention ids_tokens="1" string="Thomas" id_sentence="41" />
        <mention ids_tokens="1" string="He" id_sentence="42" />
        <mention ids_tokens="5" string="He" id_sentence="43" />
        <mention ids_tokens="3" string="he" id_sentence="44" />
        <mention ids_tokens="8" string="he" id_sentence="44" />
        <mention ids_tokens="8" string="Thomas" id_sentence="49" />
        <mention ids_tokens="13" string="him" id_sentence="49" />
        <mention ids_tokens="6" string="Thomas" id_sentence="50" />
        <mention ids_tokens="23" string="Thomas" id_sentence="51" />
        <mention ids_tokens="6" string="Thomas" id_sentence="53" />
        <mention ids_tokens="3" string="Thomas" id_sentence="54" />
        <mention ids_tokens="10" string="Thomas" id_sentence="55" />
        <mention ids_tokens="8" string="Thomas" id_sentence="56" />
        <mention ids_tokens="4" string="Thomas" id_sentence="60" />
        <mention ids_tokens="23" string="his" id_sentence="60" />
        <mention ids_tokens="1" string="Thomas" id_sentence="61" />
        <mention ids_tokens="1" string="He" id_sentence="62" />
        <mention ids_tokens="2" string="he" id_sentence="63" />
        <mention ids_tokens="25" string="he" id_sentence="63" />
        <mention ids_tokens="5-7" string="Virginia Lamp Thomas" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="10" string="Reagan" id_sentence="8" />
      <mentions>
        <mention ids_tokens="10" string="his" id_sentence="56" />
        <mention ids_tokens="17" string="him" id_sentence="56" />
        <mention ids_tokens="6" string="him" id_sentence="57" />
        <mention ids_tokens="4" string="him" id_sentence="58" />
        <mention ids_tokens="12" string="his" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="the Reagan administration" id_sentence="8" />
      <mentions>
        <mention ids_tokens="31-32" string="the administration" id_sentence="63" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42" string="a black conservative so impressive to Republican presidents that he was set on the road to the highest court in the land" id_sentence="8" />
      <mentions>
        <mention ids_tokens="6" string="conservative" id_sentence="44" />
        <mention ids_tokens="11" string="conservative" id_sentence="45" />
        <mention ids_tokens="6" string="conservative" id_sentence="46" />
        <mention ids_tokens="8" string="conservative" id_sentence="48" />
        <mention ids_tokens="12" string="conservative" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="17" string="Senate" id_sentence="9" />
      <mentions>
        <mention ids_tokens="9-11" string="Senate , 1990" id_sentence="81" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="3-4" string="many liberals" id_sentence="11" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="8-9-10" string="Thomas ' past" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="12" />
        <mention ids_tokens="1" string="He" id_sentence="13" />
        <mention ids_tokens="4-5" string="Thomas'" id_sentence="14" />
        <mention ids_tokens="3" string="him" id_sentence="15" />
        <mention ids_tokens="11-12" string="Thomas'" id_sentence="17" />
        <mention ids_tokens="10-11" string="Thomas'" id_sentence="25" />
        <mention ids_tokens="9-10" string="Thomas'" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="27" type="LIST">
      <referenced ids_tokens="4-5-6-7-8-9" string="Thomas ' many friends and supporters" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="15" />
        <mention ids_tokens="7" string="our" id_sentence="18" />
        <mention ids_tokens="4" string="our" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="8-9" string="Leola Williams" id_sentence="17" />
      <mentions>
        <mention ids_tokens="20-22" string="Leola Williams'" id_sentence="21" />
        <mention ids_tokens="1" string="Her" id_sentence="22" />
        <mention ids_tokens="18" string="her" id_sentence="22" />
        <mention ids_tokens="26" string="her" id_sentence="22" />
        <mention ids_tokens="1" string="Williams" id_sentence="23" />
        <mention ids_tokens="3" string="her" id_sentence="23" />
        <mention ids_tokens="16" string="she" id_sentence="23" />
        <mention ids_tokens="21" string="her" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="7-8" string="other people" id_sentence="19" />
      <mentions>
        <mention ids_tokens="32-33" string="the people" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="35-36" string="the way" id_sentence="22" />
      <mentions>
        <mention ids_tokens="35-36" string="this way" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="26-27-28-29-30-31-32-33-34-35-36-37-38" string="the hands of the Franciscan nuns of all-black St. Benedict the Moor School" id_sentence="29" />
      <mentions>
        <mention ids_tokens="10" string="hands" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="36-37-38" string="the Moor School" id_sentence="29" />
      <mentions>
        <mention ids_tokens="8-9" string="the school" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="13" string="Mo." id_sentence="31" />
      <mentions>
        <mention ids_tokens="10" string="Missouri" id_sentence="36" />
        <mention ids_tokens="27" string="Missouri" id_sentence="53" />
        <mention ids_tokens="40" string="Missouri" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13" string="Immaculate Conception Seminary in Conception , Mo." id_sentence="31" />
      <mentions>
        <mention ids_tokens="3-4" string="the seminary" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21-22-23-24" string="Holy Cross College in the gritty New England factory city of Worcester , Mass" id_sentence="33" />
      <mentions>
        <mention ids_tokens="4-5" string="Holy Cross" id_sentence="42" />
        <mention ids_tokens="24-26" string="Holy Cross College" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="11" string="Politics" id_sentence="51" />
      <mentions>
        <mention ids_tokens="30-34" string="&quot; black power &quot; politics" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="44" type="PROPER">
      <referenced ids_tokens="3-4" string="The Constitution" id_sentence="79" />
      <mentions>
        <mention ids_tokens="12-13" string="its constitution" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="other black students" id_sentence="39" />
      <mentions>
        <mention ids_tokens="10-11" string="the students" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="46" type="PROPER">
      <referenced ids_tokens="11-12-13-14" string="Yale University Law School" id_sentence="42" />
      <mentions>
        <mention ids_tokens="8-9" string="law school" id_sentence="43" />
        <mention ids_tokens="1" string="Yale" id_sentence="45" />
        <mention ids_tokens="6" string="Yale" id_sentence="49" />
        <mention ids_tokens="3-4" string="law school" id_sentence="50" />
        <mention ids_tokens="32" string="Yale" id_sentence="53" />
        <mention ids_tokens="28-29" string="law degree" id_sentence="71" />
        <mention ids_tokens="31-33" string="Yale Law School" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="23-24" string="Harry Singleton" id_sentence="43" />
      <mentions>
        <mention ids_tokens="5" string="Singleton" id_sentence="45" />
        <mention ids_tokens="2" string="I" id_sentence="46" />
        <mention ids_tokens="18" string="Singleton" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="48" type="NOMINAL">
      <referenced ids_tokens="11-12" string="liberal views" id_sentence="43" />
      <mentions>
        <mention ids_tokens="19-20" string="his views" id_sentence="81" />
      </mentions>
    </coreference>
    <coreference id="49" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38-39-40-41-42" string="a former civil rights official in the Reagan Education Department" id_sentence="43" />
      <mentions>
        <mention ids_tokens="6-7" string="the official" id_sentence="65" />
      </mentions>
    </coreference>
    <coreference id="50" type="PROPER">
      <referenced ids_tokens="39-40-41-42" string="the Reagan Education Department" id_sentence="43" />
      <mentions>
        <mention ids_tokens="24-27" string="the Department of Education" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="51" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Yale law students" id_sentence="45" />
      <mentions>
        <mention ids_tokens="15" string="them" id_sentence="46" />
        <mention ids_tokens="2" string="They" id_sentence="47" />
        <mention ids_tokens="37" string="we" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="53" type="PROPER">
      <referenced ids_tokens="4-5" string="Thomas Sowell" id_sentence="48" />
      <mentions>
        <mention ids_tokens="3" string="his" id_sentence="49" />
        <mention ids_tokens="21" string="I" id_sentence="49" />
        <mention ids_tokens="1-2" string="Sowell's" id_sentence="51" />
        <mention ids_tokens="5-11" string="Sowell , arguing from a laissez-faire perspective" id_sentence="52" />
        <mention ids_tokens="5" string="Sowell" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="56" type="PROPER">
      <referenced ids_tokens="3" string="PERSPECTIVE" id_sentence="68" />
      <mentions>
        <mention ids_tokens="9-11" string="a laissez-faire perspective" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="57" type="PROPER">
      <referenced ids_tokens="21-22" string="John Danforth" id_sentence="53" />
      <mentions>
        <mention ids_tokens="1" string="Danforth" id_sentence="54" />
        <mention ids_tokens="2" string="Danforth" id_sentence="55" />
        <mention ids_tokens="30" string="Danforth" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="27-28-29" string="Missouri attorney general" id_sentence="53" />
      <mentions>
        <mention ids_tokens="13-16" string="the attorney general's" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="61" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Reagan administration officials" id_sentence="56" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="63" type="PROPER">
      <referenced ids_tokens="15-16-17-18-19" string="the Equal Employment Opportunity Commission" id_sentence="57" />
      <mentions>
        <mention ids_tokens="52-55" string="Equal Employment Opportunity Commission" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="65" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19" string="his coffee cup refilled at a black-tie dinner" id_sentence="64" />
      <mentions>
        <mention ids_tokens="2-3" string="the cup" id_sentence="65" />
        <mention ids_tokens="6-7" string="the cup" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="66" type="NOMINAL">
      <referenced ids_tokens="24-25-26" string="a black man" id_sentence="64" />
      <mentions>
        <mention ids_tokens="1-3" string="The black man" id_sentence="66" />
        <mention ids_tokens="1" string="I" id_sentence="67" />
        <mention ids_tokens="12-14" string="his most candid" id_sentence="68" />
      </mentions>
    </coreference>
    <coreference id="67" type="NOMINAL">
      <referenced ids_tokens="17-18-19" string="the nominee 's" id_sentence="68" />
      <mentions>
        <mention ids_tokens="1-2" string="Nominee's" id_sentence="70" />
        <mention ids_tokens="9" string="he" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="68" type="PROPER">
      <referenced ids_tokens="6" string="President" id_sentence="69" />
      <mentions>
        <mention ids_tokens="8-9" string="The president" id_sentence="77" />
      </mentions>
    </coreference>
    <coreference id="71" type="PRONOMINAL">
      <referenced ids_tokens="9" string="their" id_sentence="73" />
      <mentions>
        <mention ids_tokens="1" string="We" id_sentence="76" />
      </mentions>
    </coreference>
    <coreference id="72" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19-20-21" string="the form of hiring and promotion quotas" id_sentence="73" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="75" />
        <mention ids_tokens="9" string="its" id_sentence="76" />
      </mentions>
    </coreference>
    <coreference id="73" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="Supreme Court justices" id_sentence="77" />
      <mentions>
        <mention ids_tokens="9" string="justices" id_sentence="79" />
        <mention ids_tokens="3" string="justices" id_sentence="80" />
      </mentions>
    </coreference>
    <coreference id="74" type="NOMINAL">
      <referenced ids_tokens="9-10" string="a nominee" id_sentence="78" />
      <mentions>
        <mention ids_tokens="19" string="his" id_sentence="81" />
      </mentions>
    </coreference>
    <coreference id="75" type="NOMINAL">
      <referenced ids_tokens="21-22" string="the nomination" id_sentence="78" />
      <mentions>
        <mention ids_tokens="72-73" string="his nomination" id_sentence="81" />
      </mentions>
    </coreference>
  </coreferences>
</document>
