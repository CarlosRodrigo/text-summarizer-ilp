<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA030789-0047">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Carl Lewis said he knew Ben Johnson was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics.</content>
      <tokens>
        <token id="1" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="12" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="100-meter" lemma="100-meter" stem="100-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Carl) (NNP Lewis)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD knew) (SBAR (S (NP (NNP Ben) (NNP Johnson)) (VP (VBD was) (VP (VBG taking) (NP (JJ performance-enhancing) (NNS drugs)) (ADVP (RB just)) (PP (IN after) (NP (NP (PRP$ their) (JJ 100-meter) (JJ final) (JJ last) (NN fall)) (PP (IN at) (NP (DT the) (NNP Seoul) (NNPS Olympics))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their 100-meter final last fall" type="NP">
          <tokens>
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew Ben Johnson was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="VP">
          <tokens>
            <token id="5" string="knew" />
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Seoul Olympics" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ben Johnson was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="SBAR">
          <tokens>
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="VP">
          <tokens>
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="6" string="was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ben Johnson" type="NP">
          <tokens>
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="he knew Ben Johnson was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="knew" />
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="9" string="their 100-meter final last fall at the Seoul Olympics" type="NP">
          <tokens>
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="10" string="Carl Lewis" type="NP">
          <tokens>
            <token id="1" string="Carl" />
            <token id="2" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="11" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="said he knew Ben Johnson was taking performance-enhancing drugs just after their 100-meter final last fall at the Seoul Olympics" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="he" />
            <token id="5" string="knew" />
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="performance-enhancing" />
            <token id="11" string="drugs" />
            <token id="12" string="just" />
            <token id="13" string="after" />
            <token id="14" string="their" />
            <token id="15" string="100-meter" />
            <token id="16" string="final" />
            <token id="17" string="last" />
            <token id="18" string="fall" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Seoul" />
            <token id="22" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lewis</governor>
          <dependent id="1">Carl</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">knew</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">knew</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Johnson</governor>
          <dependent id="6">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">taking</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">taking</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">knew</governor>
          <dependent id="9">taking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">drugs</governor>
          <dependent id="10">performance-enhancing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">taking</governor>
          <dependent id="11">drugs</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">taking</governor>
          <dependent id="12">just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">fall</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">fall</governor>
          <dependent id="14">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">fall</governor>
          <dependent id="15">100-meter</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">fall</governor>
          <dependent id="16">final</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">fall</governor>
          <dependent id="17">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">taking</governor>
          <dependent id="18">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Olympics</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Olympics</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Olympics</governor>
          <dependent id="21">Seoul</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">fall</governor>
          <dependent id="22">Olympics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Seoul" />
          </tokens>
        </entity>
        <entity id="3" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="drugs" />
          </tokens>
        </entity>
        <entity id="4" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="Olympics" />
          </tokens>
        </entity>
        <entity id="5" string="last fall" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="last" />
            <token id="18" string="fall" />
          </tokens>
        </entity>
        <entity id="6" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Carl" />
            <token id="2" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>&amp;quot;He got out of those blocks like a caged lion,&amp;quot; Lewis said in an interview Sunday at the Los Angeles Marathon, where he was representing a sponsor.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blocks" lemma="block" stem="block" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="caged" lemma="caged" stem="cage" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="lion" lemma="lion" stem="lion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="sponsor" lemma="sponsor" stem="sponsor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (VBD got) (ADVP (IN out) (PP (IN of) (NP (DT those) (NNS blocks)))) (PP (IN like) (NP (DT a) (JJ caged) (NN lion))))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview))) (NP-TMP (NNP Sunday)) (PP (IN at) (NP (NP (DT the) (NNP Los) (NNP Angeles) (NNP Marathon)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP he)) (VP (VBD was) (VP (VBG representing) (NP (DT a) (NN sponsor))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="got out of those blocks like a caged lion" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="out" />
            <token id="5" string="of" />
            <token id="6" string="those" />
            <token id="7" string="blocks" />
            <token id="8" string="like" />
            <token id="9" string="a" />
            <token id="10" string="caged" />
            <token id="11" string="lion" />
          </tokens>
        </chunking>
        <chunking id="2" string="representing a sponsor" type="VP">
          <tokens>
            <token id="29" string="representing" />
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="3" string="those blocks" type="NP">
          <tokens>
            <token id="6" string="those" />
            <token id="7" string="blocks" />
          </tokens>
        </chunking>
        <chunking id="4" string="said in an interview Sunday at the Los Angeles Marathon , where he was representing a sponsor" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="in" />
            <token id="17" string="an" />
            <token id="18" string="interview" />
            <token id="19" string="Sunday" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="Marathon" />
            <token id="25" string="," />
            <token id="26" string="where" />
            <token id="27" string="he" />
            <token id="28" string="was" />
            <token id="29" string="representing" />
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Los Angeles Marathon" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="a caged lion" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="caged" />
            <token id="11" string="lion" />
          </tokens>
        </chunking>
        <chunking id="7" string="an interview" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="interview" />
          </tokens>
        </chunking>
        <chunking id="8" string="a sponsor" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lewis" type="NP">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="10" string="where he was representing a sponsor" type="SBAR">
          <tokens>
            <token id="26" string="where" />
            <token id="27" string="he" />
            <token id="28" string="was" />
            <token id="29" string="representing" />
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="11" string="where" type="WHADVP">
          <tokens>
            <token id="26" string="where" />
          </tokens>
        </chunking>
        <chunking id="12" string="was representing a sponsor" type="VP">
          <tokens>
            <token id="28" string="was" />
            <token id="29" string="representing" />
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Los Angeles Marathon , where he was representing a sponsor" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="Marathon" />
            <token id="25" string="," />
            <token id="26" string="where" />
            <token id="27" string="he" />
            <token id="28" string="was" />
            <token id="29" string="representing" />
            <token id="30" string="a" />
            <token id="31" string="sponsor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">got</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">blocks</governor>
          <dependent id="4">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">out</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">blocks</governor>
          <dependent id="6">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">got</governor>
          <dependent id="7">blocks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">lion</governor>
          <dependent id="8">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">lion</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">lion</governor>
          <dependent id="10">caged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">got</governor>
          <dependent id="11">lion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">interview</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">interview</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">said</governor>
          <dependent id="18">interview</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="15">said</governor>
          <dependent id="19">Sunday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Marathon</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Marathon</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Marathon</governor>
          <dependent id="22">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Marathon</governor>
          <dependent id="23">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">said</governor>
          <dependent id="24">Marathon</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">representing</governor>
          <dependent id="26">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">representing</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">representing</governor>
          <dependent id="28">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">Marathon</governor>
          <dependent id="29">representing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">sponsor</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">representing</governor>
          <dependent id="31">sponsor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>&amp;quot;How can anybody in the world do that after running all those rounds (preliminary heats)?</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="anybody" lemma="anybody" stem="anybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="rounds" lemma="round" stem="round" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="heats" lemma="heat" stem="heat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (`` ``) (WHADVP (WRB How)) (SQ (VP (MD can)) (NP (NN anybody)) (PP (IN in) (NP (NP (DT the) (NN world)) (SBAR (S (VP (VBP do) (SBAR (IN that) (IN after) (S (VP (VBG running) (NP (PDT all) (DT those) (NNS rounds)))))))) (PRN (-LRB- -LRB-) (S (NP (JJ preliminary)) (VP (VBZ heats))) (-RRB- -RRB-))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="anybody" type="NP">
          <tokens>
            <token id="4" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="2" string="do that after running all those rounds" type="SBAR">
          <tokens>
            <token id="8" string="do" />
            <token id="9" string="that" />
            <token id="10" string="after" />
            <token id="11" string="running" />
            <token id="12" string="all" />
            <token id="13" string="those" />
            <token id="14" string="rounds" />
          </tokens>
        </chunking>
        <chunking id="3" string="the world do that after running all those rounds -LRB- preliminary heats -RRB-" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="world" />
            <token id="8" string="do" />
            <token id="9" string="that" />
            <token id="10" string="after" />
            <token id="11" string="running" />
            <token id="12" string="all" />
            <token id="13" string="those" />
            <token id="14" string="rounds" />
            <token id="15" string="(" />
            <token id="16" string="preliminary" />
            <token id="17" string="heats" />
            <token id="18" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="running all those rounds" type="VP">
          <tokens>
            <token id="11" string="running" />
            <token id="12" string="all" />
            <token id="13" string="those" />
            <token id="14" string="rounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="all those rounds" type="NP">
          <tokens>
            <token id="12" string="all" />
            <token id="13" string="those" />
            <token id="14" string="rounds" />
          </tokens>
        </chunking>
        <chunking id="6" string="heats" type="VP">
          <tokens>
            <token id="17" string="heats" />
          </tokens>
        </chunking>
        <chunking id="7" string="the world" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="world" />
          </tokens>
        </chunking>
        <chunking id="8" string="that after running all those rounds" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="after" />
            <token id="11" string="running" />
            <token id="12" string="all" />
            <token id="13" string="those" />
            <token id="14" string="rounds" />
          </tokens>
        </chunking>
        <chunking id="9" string="How" type="WHADVP">
          <tokens>
            <token id="2" string="How" />
          </tokens>
        </chunking>
        <chunking id="10" string="can" type="VP">
          <tokens>
            <token id="3" string="can" />
          </tokens>
        </chunking>
        <chunking id="11" string="preliminary" type="NP">
          <tokens>
            <token id="16" string="preliminary" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">can</governor>
          <dependent id="2">How</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">can</governor>
          <dependent id="4">anybody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">world</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">world</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">can</governor>
          <dependent id="7">world</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">world</governor>
          <dependent id="8">do</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">running</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">running</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">do</governor>
          <dependent id="11">running</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="14">rounds</governor>
          <dependent id="12">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">rounds</governor>
          <dependent id="13">those</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">running</governor>
          <dependent id="14">rounds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">heats</governor>
          <dependent id="16">preliminary</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">world</governor>
          <dependent id="17">heats</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>&amp;quot;I said, &amp;apost;Look, I don&amp;apost;t know what he is taking or what he is doing, but he is doing something.&amp;apost; &amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD said) (, ,) (`` `) (S (S (S (VP (VB Look))) (, ,) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBZ is) (VP (VBG taking))))) (CC or) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBZ is) (VP (VBG doing))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBZ is) (VP (VBG doing) (NP (NN something))))))) (. .) ('' ') ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="is taking" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="taking" />
          </tokens>
        </chunking>
        <chunking id="2" string="doing" type="VP">
          <tokens>
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="3" string="is doing something" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="doing" />
            <token id="26" string="something" />
          </tokens>
        </chunking>
        <chunking id="4" string="do n't know what he is taking or what he is doing" type="VP">
          <tokens>
            <token id="9" string="do" />
            <token id="10" string="n't" />
            <token id="11" string="know" />
            <token id="12" string="what" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="taking" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="is" />
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="doing something" type="VP">
          <tokens>
            <token id="25" string="doing" />
            <token id="26" string="something" />
          </tokens>
        </chunking>
        <chunking id="7" string="know what he is taking or what he is doing" type="VP">
          <tokens>
            <token id="11" string="know" />
            <token id="12" string="what" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="taking" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="is" />
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="8" string="something" type="NP">
          <tokens>
            <token id="26" string="something" />
          </tokens>
        </chunking>
        <chunking id="9" string="said , ` Look , I do n't know what he is taking or what he is doing , but he is doing something" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="," />
            <token id="5" string="'" />
            <token id="6" string="Look" />
            <token id="7" string="," />
            <token id="8" string="I" />
            <token id="9" string="do" />
            <token id="10" string="n't" />
            <token id="11" string="know" />
            <token id="12" string="what" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="taking" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="is" />
            <token id="20" string="doing" />
            <token id="21" string="," />
            <token id="22" string="but" />
            <token id="23" string="he" />
            <token id="24" string="is" />
            <token id="25" string="doing" />
            <token id="26" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="what he is doing" type="SBAR">
          <tokens>
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="is" />
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="11" string="what he is taking" type="SBAR">
          <tokens>
            <token id="12" string="what" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="taking" />
          </tokens>
        </chunking>
        <chunking id="12" string="taking" type="VP">
          <tokens>
            <token id="15" string="taking" />
          </tokens>
        </chunking>
        <chunking id="13" string="is doing" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="14" string="Look" type="VP">
          <tokens>
            <token id="6" string="Look" />
          </tokens>
        </chunking>
        <chunking id="15" string="what he is taking or what he is doing" type="SBAR">
          <tokens>
            <token id="12" string="what" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="taking" />
            <token id="16" string="or" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="is" />
            <token id="20" string="doing" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">know</governor>
          <dependent id="6">Look</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">know</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">know</governor>
          <dependent id="9">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">know</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">said</governor>
          <dependent id="11">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">taking</governor>
          <dependent id="12">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">taking</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">taking</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">know</governor>
          <dependent id="15">taking</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">taking</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">doing</governor>
          <dependent id="17">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">doing</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">doing</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">taking</governor>
          <dependent id="20">doing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">know</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">doing</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">doing</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">know</governor>
          <dependent id="25">doing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">doing</governor>
          <dependent id="26">something</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Now Lewis has been implicated in an alleged sabotage of Johnson&amp;apost;s drug test, which returned a positive result for the banned anabolic steroid stanozolol.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="implicated" lemma="implicate" stem="implic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="sabotage" lemma="sabotage" stem="sabotag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="returned" lemma="return" stem="return" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="anabolic" lemma="anabolic" stem="anabol" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (NP (NNP Lewis)) (VP (VBZ has) (VP (VBN been) (VP (VBN implicated) (PP (IN in) (NP (NP (DT an) (JJ alleged) (NN sabotage)) (PP (IN of) (NP (NP (NP (NNP Johnson) (POS 's)) (NN drug) (NN test)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD returned) (NP (NP (DT a) (JJ positive) (NN result)) (PP (IN for) (NP (DT the) (ADJP (VBN banned) (JJ anabolic)) (NN steroid) (NN stanozolol)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an alleged sabotage of Johnson 's drug test , which returned a positive result for the banned anabolic steroid stanozolol" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="alleged" />
            <token id="9" string="sabotage" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
            <token id="15" string="," />
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson 's drug test , which returned a positive result for the banned anabolic steroid stanozolol" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
            <token id="15" string="," />
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="3" string="an alleged sabotage" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="alleged" />
            <token id="9" string="sabotage" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson 's drug test" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
          </tokens>
        </chunking>
        <chunking id="5" string="which returned a positive result for the banned anabolic steroid stanozolol" type="SBAR">
          <tokens>
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="6" string="banned anabolic" type="ADJP">
          <tokens>
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
          </tokens>
        </chunking>
        <chunking id="7" string="been implicated in an alleged sabotage of Johnson 's drug test , which returned a positive result for the banned anabolic steroid stanozolol" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="implicated" />
            <token id="6" string="in" />
            <token id="7" string="an" />
            <token id="8" string="alleged" />
            <token id="9" string="sabotage" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
            <token id="15" string="," />
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="8" string="returned a positive result for the banned anabolic steroid stanozolol" type="VP">
          <tokens>
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="9" string="implicated in an alleged sabotage of Johnson 's drug test , which returned a positive result for the banned anabolic steroid stanozolol" type="VP">
          <tokens>
            <token id="5" string="implicated" />
            <token id="6" string="in" />
            <token id="7" string="an" />
            <token id="8" string="alleged" />
            <token id="9" string="sabotage" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
            <token id="15" string="," />
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="10" string="a positive result" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
          </tokens>
        </chunking>
        <chunking id="11" string="a positive result for the banned anabolic steroid stanozolol" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="12" string="the banned anabolic steroid stanozolol" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lewis" type="NP">
          <tokens>
            <token id="2" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="14" string="has been implicated in an alleged sabotage of Johnson 's drug test , which returned a positive result for the banned anabolic steroid stanozolol" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="implicated" />
            <token id="6" string="in" />
            <token id="7" string="an" />
            <token id="8" string="alleged" />
            <token id="9" string="sabotage" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="drug" />
            <token id="14" string="test" />
            <token id="15" string="," />
            <token id="16" string="which" />
            <token id="17" string="returned" />
            <token id="18" string="a" />
            <token id="19" string="positive" />
            <token id="20" string="result" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="banned" />
            <token id="24" string="anabolic" />
            <token id="25" string="steroid" />
            <token id="26" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="15" string="Johnson 's" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">implicated</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">implicated</governor>
          <dependent id="2">Lewis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">implicated</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">implicated</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">implicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">sabotage</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sabotage</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">sabotage</governor>
          <dependent id="8">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">implicated</governor>
          <dependent id="9">sabotage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">test</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">test</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Johnson</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">test</governor>
          <dependent id="13">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">sabotage</governor>
          <dependent id="14">test</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">returned</governor>
          <dependent id="16">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">test</governor>
          <dependent id="17">returned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">result</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">result</governor>
          <dependent id="19">positive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">returned</governor>
          <dependent id="20">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">stanozolol</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">stanozolol</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">anabolic</governor>
          <dependent id="23">banned</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">stanozolol</governor>
          <dependent id="24">anabolic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">stanozolol</governor>
          <dependent id="25">steroid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">result</governor>
          <dependent id="26">stanozolol</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>At a Canadian inquiry into drug use in sport Monday at Toronto, Charlie Francis, a Canadian sprint coach, testified that Johnson might have drunk contaminated beer before a urinalysis.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="4" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="19" string="sprint" lemma="sprint" stem="sprint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="drunk" lemma="drunk" stem="drunk" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="contaminated" lemma="contaminate" stem="contamin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="beer" lemma="beer" stem="beer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="urinalysis" lemma="urinalysis" stem="urinalysi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (NP (DT a) (JJ Canadian) (NN inquiry)) (PP (IN into) (NP (NP (NN drug) (NN use)) (PP (IN in) (NP (NN sport))) (NP-TMP (NNP Monday)))) (PP (IN at) (NP (NNP Toronto))))) (, ,) (NP (NP (NNP Charlie) (NNP Francis)) (, ,) (NP (DT a) (JJ Canadian) (NN sprint) (NN coach)) (, ,)) (VP (VBD testified) (SBAR (IN that) (S (NP (NNP Johnson)) (VP (MD might) (VP (VB have) (NP (ADJP (JJ drunk) (VBN contaminated)) (NN beer)) (PP (IN before) (NP (DT a) (NN urinalysis)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Canadian sprint coach" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="Canadian" />
            <token id="19" string="sprint" />
            <token id="20" string="coach" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Canadian inquiry" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="Canadian" />
            <token id="4" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="drug use in sport Monday" type="NP">
          <tokens>
            <token id="6" string="drug" />
            <token id="7" string="use" />
            <token id="8" string="in" />
            <token id="9" string="sport" />
            <token id="10" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="5" string="drunk contaminated" type="ADJP">
          <tokens>
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
          </tokens>
        </chunking>
        <chunking id="6" string="a urinalysis" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="urinalysis" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Canadian inquiry into drug use in sport Monday at Toronto" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="Canadian" />
            <token id="4" string="inquiry" />
            <token id="5" string="into" />
            <token id="6" string="drug" />
            <token id="7" string="use" />
            <token id="8" string="in" />
            <token id="9" string="sport" />
            <token id="10" string="Monday" />
            <token id="11" string="at" />
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="8" string="Charlie Francis" type="NP">
          <tokens>
            <token id="14" string="Charlie" />
            <token id="15" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="9" string="might have drunk contaminated beer before a urinalysis" type="VP">
          <tokens>
            <token id="25" string="might" />
            <token id="26" string="have" />
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
            <token id="29" string="beer" />
            <token id="30" string="before" />
            <token id="31" string="a" />
            <token id="32" string="urinalysis" />
          </tokens>
        </chunking>
        <chunking id="10" string="drunk contaminated beer" type="NP">
          <tokens>
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
            <token id="29" string="beer" />
          </tokens>
        </chunking>
        <chunking id="11" string="Charlie Francis , a Canadian sprint coach ," type="NP">
          <tokens>
            <token id="14" string="Charlie" />
            <token id="15" string="Francis" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="Canadian" />
            <token id="19" string="sprint" />
            <token id="20" string="coach" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="that Johnson might have drunk contaminated beer before a urinalysis" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="Johnson" />
            <token id="25" string="might" />
            <token id="26" string="have" />
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
            <token id="29" string="beer" />
            <token id="30" string="before" />
            <token id="31" string="a" />
            <token id="32" string="urinalysis" />
          </tokens>
        </chunking>
        <chunking id="13" string="testified that Johnson might have drunk contaminated beer before a urinalysis" type="VP">
          <tokens>
            <token id="22" string="testified" />
            <token id="23" string="that" />
            <token id="24" string="Johnson" />
            <token id="25" string="might" />
            <token id="26" string="have" />
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
            <token id="29" string="beer" />
            <token id="30" string="before" />
            <token id="31" string="a" />
            <token id="32" string="urinalysis" />
          </tokens>
        </chunking>
        <chunking id="14" string="drug use" type="NP">
          <tokens>
            <token id="6" string="drug" />
            <token id="7" string="use" />
          </tokens>
        </chunking>
        <chunking id="15" string="sport" type="NP">
          <tokens>
            <token id="9" string="sport" />
          </tokens>
        </chunking>
        <chunking id="16" string="have drunk contaminated beer before a urinalysis" type="VP">
          <tokens>
            <token id="26" string="have" />
            <token id="27" string="drunk" />
            <token id="28" string="contaminated" />
            <token id="29" string="beer" />
            <token id="30" string="before" />
            <token id="31" string="a" />
            <token id="32" string="urinalysis" />
          </tokens>
        </chunking>
        <chunking id="17" string="Toronto" type="NP">
          <tokens>
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">inquiry</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">inquiry</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">inquiry</governor>
          <dependent id="3">Canadian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">testified</governor>
          <dependent id="4">inquiry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">use</governor>
          <dependent id="5">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">use</governor>
          <dependent id="6">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">inquiry</governor>
          <dependent id="7">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">sport</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">use</governor>
          <dependent id="9">sport</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">use</governor>
          <dependent id="10">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Toronto</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">inquiry</governor>
          <dependent id="12">Toronto</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Francis</governor>
          <dependent id="14">Charlie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">testified</governor>
          <dependent id="15">Francis</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">coach</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">coach</governor>
          <dependent id="18">Canadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">coach</governor>
          <dependent id="19">sprint</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Francis</governor>
          <dependent id="20">coach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">testified</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">have</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">have</governor>
          <dependent id="24">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">have</governor>
          <dependent id="25">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">testified</governor>
          <dependent id="26">have</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">contaminated</governor>
          <dependent id="27">drunk</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">beer</governor>
          <dependent id="28">contaminated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">have</governor>
          <dependent id="29">beer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">urinalysis</governor>
          <dependent id="30">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">urinalysis</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">have</governor>
          <dependent id="32">urinalysis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="3" string="Canadian" />
          </tokens>
        </entity>
        <entity id="3" string="Charlie Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Charlie" />
            <token id="15" string="Francis" />
          </tokens>
        </entity>
        <entity id="4" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Monday" />
          </tokens>
        </entity>
        <entity id="5" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Francis based his theory on the fact that Johnson took the steroid furazabol three weeks before the Games, not the difficult-to-detect stanozolol.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="furazabol" lemma="furazabol" stem="furazabol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="difficult-to-detect" lemma="difficult-to-detect" stem="difficult-to-detect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Francis)) (VP (VBN based) (NP (PRP$ his) (NN theory)) (PP (IN on) (NP (DT the) (NN fact))) (SBAR (IN that) (S (NP (NNP Johnson)) (VP (VBD took) (NP (DT the) (NN steroid) (NN furazabol)) (NP-TMP (CD three) (NNS weeks)) (PP (IN before) (NP (NP (DT the) (NNPS Games)) (, ,) (RB not) (NP (DT the) (JJ difficult-to-detect) (NN stanozolol)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="took the steroid furazabol three weeks before the Games , not the difficult-to-detect stanozolol" type="VP">
          <tokens>
            <token id="10" string="took" />
            <token id="11" string="the" />
            <token id="12" string="steroid" />
            <token id="13" string="furazabol" />
            <token id="14" string="three" />
            <token id="15" string="weeks" />
            <token id="16" string="before" />
            <token id="17" string="the" />
            <token id="18" string="Games" />
            <token id="19" string="," />
            <token id="20" string="not" />
            <token id="21" string="the" />
            <token id="22" string="difficult-to-detect" />
            <token id="23" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Games" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Games" />
          </tokens>
        </chunking>
        <chunking id="4" string="his theory" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="theory" />
          </tokens>
        </chunking>
        <chunking id="5" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="6" string="the fact" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="fact" />
          </tokens>
        </chunking>
        <chunking id="7" string="the difficult-to-detect stanozolol" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="difficult-to-detect" />
            <token id="23" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="8" string="the steroid furazabol" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="steroid" />
            <token id="13" string="furazabol" />
          </tokens>
        </chunking>
        <chunking id="9" string="based his theory on the fact that Johnson took the steroid furazabol three weeks before the Games , not the difficult-to-detect stanozolol" type="VP">
          <tokens>
            <token id="2" string="based" />
            <token id="3" string="his" />
            <token id="4" string="theory" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="fact" />
            <token id="8" string="that" />
            <token id="9" string="Johnson" />
            <token id="10" string="took" />
            <token id="11" string="the" />
            <token id="12" string="steroid" />
            <token id="13" string="furazabol" />
            <token id="14" string="three" />
            <token id="15" string="weeks" />
            <token id="16" string="before" />
            <token id="17" string="the" />
            <token id="18" string="Games" />
            <token id="19" string="," />
            <token id="20" string="not" />
            <token id="21" string="the" />
            <token id="22" string="difficult-to-detect" />
            <token id="23" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="10" string="that Johnson took the steroid furazabol three weeks before the Games , not the difficult-to-detect stanozolol" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="Johnson" />
            <token id="10" string="took" />
            <token id="11" string="the" />
            <token id="12" string="steroid" />
            <token id="13" string="furazabol" />
            <token id="14" string="three" />
            <token id="15" string="weeks" />
            <token id="16" string="before" />
            <token id="17" string="the" />
            <token id="18" string="Games" />
            <token id="19" string="," />
            <token id="20" string="not" />
            <token id="21" string="the" />
            <token id="22" string="difficult-to-detect" />
            <token id="23" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Games , not the difficult-to-detect stanozolol" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Games" />
            <token id="19" string="," />
            <token id="20" string="not" />
            <token id="21" string="the" />
            <token id="22" string="difficult-to-detect" />
            <token id="23" string="stanozolol" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">based</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">based</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">theory</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">based</governor>
          <dependent id="4">theory</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">fact</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">fact</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">based</governor>
          <dependent id="7">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">took</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">took</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">based</governor>
          <dependent id="10">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">furazabol</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">furazabol</governor>
          <dependent id="12">steroid</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">took</governor>
          <dependent id="13">furazabol</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">weeks</governor>
          <dependent id="14">three</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">took</governor>
          <dependent id="15">weeks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Games</governor>
          <dependent id="16">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Games</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">took</governor>
          <dependent id="18">Games</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">stanozolol</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">stanozolol</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">stanozolol</governor>
          <dependent id="22">difficult-to-detect</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Games</governor>
          <dependent id="23">stanozolol</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="Games" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Games" />
          </tokens>
        </entity>
        <entity id="4" string="three weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="three" />
            <token id="15" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>According to Francis&amp;apost; testimony, Johnson said that an unidentified man who had been talking with Lewis sat near the beer that was provided for the athletes to facilitate them in providing urine samples.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="unidentified" lemma="unidentified" stem="unidentifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="sat" lemma="sit" stem="sat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="beer" lemma="beer" stem="beer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="provided" lemma="provide" stem="provid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="facilitate" lemma="facilitate" stem="facilit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="providing" lemma="provide" stem="provid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="urine" lemma="urine" stem="urin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="samples" lemma="sample" stem="sampl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (NP (NNP Francis) (POS ')) (NN testimony)))) (, ,) (NP (NNP Johnson)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (DT an) (JJ unidentified) (NN man)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN been) (VP (VBG talking) (PP (IN with) (NP (NNP Lewis))))))))) (VP (VBD sat) (PP (IN near) (NP (NP (DT the) (NN beer)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (VBN provided) (PP (IN for) (NP (DT the) (NNS athletes))) (S (VP (TO to) (VP (VB facilitate) (NP (PRP them)) (PP (IN in) (S (VP (VBG providing) (NP (NN urine) (NNS samples)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="that was provided for the athletes to facilitate them in providing urine samples" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="3" string="providing urine samples" type="VP">
          <tokens>
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="4" string="the beer" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="beer" />
          </tokens>
        </chunking>
        <chunking id="5" string="the beer that was provided for the athletes to facilitate them in providing urine samples" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="beer" />
            <token id="23" string="that" />
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="6" string="Francis '" type="NP">
          <tokens>
            <token id="3" string="Francis" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="was provided for the athletes to facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="8" string="sat near the beer that was provided for the athletes to facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="19" string="sat" />
            <token id="20" string="near" />
            <token id="21" string="the" />
            <token id="22" string="beer" />
            <token id="23" string="that" />
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="9" string="facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="10" string="Francis ' testimony" type="NP">
          <tokens>
            <token id="3" string="Francis" />
            <token id="4" string="'" />
            <token id="5" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="11" string="provided for the athletes to facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="urine samples" type="NP">
          <tokens>
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="14" string="the athletes" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="15" string="been talking with Lewis" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="16" string="an unidentified man" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="unidentified" />
            <token id="12" string="man" />
          </tokens>
        </chunking>
        <chunking id="17" string="had been talking with Lewis" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="18" string="Lewis" type="NP">
          <tokens>
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="19" string="who had been talking with Lewis" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="20" string="that an unidentified man who had been talking with Lewis sat near the beer that was provided for the athletes to facilitate them in providing urine samples" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="an" />
            <token id="11" string="unidentified" />
            <token id="12" string="man" />
            <token id="13" string="who" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
            <token id="19" string="sat" />
            <token id="20" string="near" />
            <token id="21" string="the" />
            <token id="22" string="beer" />
            <token id="23" string="that" />
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="21" string="talking with Lewis" type="VP">
          <tokens>
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="22" string="said that an unidentified man who had been talking with Lewis sat near the beer that was provided for the athletes to facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="that" />
            <token id="10" string="an" />
            <token id="11" string="unidentified" />
            <token id="12" string="man" />
            <token id="13" string="who" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
            <token id="19" string="sat" />
            <token id="20" string="near" />
            <token id="21" string="the" />
            <token id="22" string="beer" />
            <token id="23" string="that" />
            <token id="24" string="was" />
            <token id="25" string="provided" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="athletes" />
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
        <chunking id="23" string="an unidentified man who had been talking with Lewis" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="unidentified" />
            <token id="12" string="man" />
            <token id="13" string="who" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="talking" />
            <token id="17" string="with" />
            <token id="18" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="24" string="to facilitate them in providing urine samples" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="facilitate" />
            <token id="31" string="them" />
            <token id="32" string="in" />
            <token id="33" string="providing" />
            <token id="34" string="urine" />
            <token id="35" string="samples" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">testimony</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">testimony</governor>
          <dependent id="3">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Francis</governor>
          <dependent id="4">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">said</governor>
          <dependent id="5">testimony</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">sat</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">man</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">man</governor>
          <dependent id="11">unidentified</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">sat</governor>
          <dependent id="12">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">talking</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">talking</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">talking</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">man</governor>
          <dependent id="16">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Lewis</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">talking</governor>
          <dependent id="18">Lewis</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="19">sat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">beer</governor>
          <dependent id="20">near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">beer</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">sat</governor>
          <dependent id="22">beer</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">provided</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">provided</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">beer</governor>
          <dependent id="25">provided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">athletes</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">athletes</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">provided</governor>
          <dependent id="28">athletes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">facilitate</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">provided</governor>
          <dependent id="30">facilitate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">facilitate</governor>
          <dependent id="31">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">providing</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">facilitate</governor>
          <dependent id="33">providing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">samples</governor>
          <dependent id="34">urine</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">providing</governor>
          <dependent id="35">samples</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Francis said that two witnesses told him that the stranger had spoken with Lewis in another area of the waiting room.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="stranger" lemma="stranger" stem="stranger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="spoken" lemma="speak" stem="spoken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="waiting" lemma="wait" stem="wait" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Francis)) (VP (VBD said) (SBAR (IN that) (S (NP (CD two) (NNS witnesses)) (VP (VBD told) (NP (PRP him)) (SBAR (IN that) (S (NP (DT the) (NN stranger)) (VP (VBD had) (VP (VBN spoken) (PP (IN with) (NP (NNP Lewis))) (PP (IN in) (NP (NP (DT another) (NN area)) (PP (IN of) (NP (DT the) (VBG waiting) (NN room))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the stranger had spoken with Lewis in another area of the waiting room" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="stranger" />
            <token id="11" string="had" />
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="2" string="the waiting room" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="3" string="that two witnesses told him that the stranger had spoken with Lewis in another area of the waiting room" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="two" />
            <token id="5" string="witnesses" />
            <token id="6" string="told" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="stranger" />
            <token id="11" string="had" />
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="4" string="had spoken with Lewis in another area of the waiting room" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="two witnesses" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="7" string="said that two witnesses told him that the stranger had spoken with Lewis in another area of the waiting room" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="two" />
            <token id="5" string="witnesses" />
            <token id="6" string="told" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="stranger" />
            <token id="11" string="had" />
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="8" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="9" string="told him that the stranger had spoken with Lewis in another area of the waiting room" type="VP">
          <tokens>
            <token id="6" string="told" />
            <token id="7" string="him" />
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="stranger" />
            <token id="11" string="had" />
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lewis" type="NP">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="11" string="spoken with Lewis in another area of the waiting room" type="VP">
          <tokens>
            <token id="12" string="spoken" />
            <token id="13" string="with" />
            <token id="14" string="Lewis" />
            <token id="15" string="in" />
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="12" string="another area of the waiting room" type="NP">
          <tokens>
            <token id="16" string="another" />
            <token id="17" string="area" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="waiting" />
            <token id="21" string="room" />
          </tokens>
        </chunking>
        <chunking id="13" string="another area" type="NP">
          <tokens>
            <token id="16" string="another" />
            <token id="17" string="area" />
          </tokens>
        </chunking>
        <chunking id="14" string="the stranger" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="stranger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">told</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">witnesses</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">told</governor>
          <dependent id="5">witnesses</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">told</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">spoken</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">stranger</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">spoken</governor>
          <dependent id="10">stranger</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">spoken</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">told</governor>
          <dependent id="12">spoken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Lewis</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">spoken</governor>
          <dependent id="14">Lewis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">area</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">area</governor>
          <dependent id="16">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">spoken</governor>
          <dependent id="17">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">room</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">room</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">room</governor>
          <dependent id="20">waiting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">area</governor>
          <dependent id="21">room</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Lewis had finished second to Johnson, who set a world record of 9.79 seconds in winning the 100-meter gold medal, and subsequently also had to be tested.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="second" lemma="second" stem="second" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="9.79" lemma="9.79" stem="9.79" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="15" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="100-meter" lemma="100-meter" stem="100-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="subsequently" lemma="subsequently" stem="subsequ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Lewis)) (VP (VBD had) (VP (VBN finished) (ADVP (RB second) (PP (TO to) (NP (NP (NNP Johnson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD set) (NP (NP (DT a) (NN world) (NN record)) (PP (IN of) (NP (CD 9.79) (NNS seconds)))) (PP (IN in) (S (VP (VBG winning) (NP (DT the) (JJ 100-meter) (NN gold) (NN medal)))))))))))))) (, ,) (CC and) (S (ADVP (RB subsequently)) (NP (ADVP (RB also))) (VP (VBD had) (S (VP (TO to) (VP (VB be) (VP (VBN tested))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="a world record" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="a world record of 9.79 seconds" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="4" string="be tested" type="VP">
          <tokens>
            <token id="28" string="be" />
            <token id="29" string="tested" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 100-meter gold medal" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="6" string="tested" type="VP">
          <tokens>
            <token id="29" string="tested" />
          </tokens>
        </chunking>
        <chunking id="7" string="9.79 seconds" type="NP">
          <tokens>
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="8" string="had finished second to Johnson , who set a world record of 9.79 seconds in winning the 100-meter gold medal" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="finished" />
            <token id="4" string="second" />
            <token id="5" string="to" />
            <token id="6" string="Johnson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
            <token id="16" string="in" />
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="9" string="also" type="NP">
          <tokens>
            <token id="25" string="also" />
          </tokens>
        </chunking>
        <chunking id="10" string="Johnson , who set a world record of 9.79 seconds in winning the 100-meter gold medal" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
            <token id="16" string="in" />
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="11" string="winning the 100-meter gold medal" type="VP">
          <tokens>
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="12" string="who set a world record of 9.79 seconds in winning the 100-meter gold medal" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
            <token id="16" string="in" />
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="13" string="to be tested" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="be" />
            <token id="29" string="tested" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="15" string="had to be tested" type="VP">
          <tokens>
            <token id="26" string="had" />
            <token id="27" string="to" />
            <token id="28" string="be" />
            <token id="29" string="tested" />
          </tokens>
        </chunking>
        <chunking id="16" string="finished second to Johnson , who set a world record of 9.79 seconds in winning the 100-meter gold medal" type="VP">
          <tokens>
            <token id="3" string="finished" />
            <token id="4" string="second" />
            <token id="5" string="to" />
            <token id="6" string="Johnson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
            <token id="16" string="in" />
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="17" string="set a world record of 9.79 seconds in winning the 100-meter gold medal" type="VP">
          <tokens>
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="world" />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
            <token id="16" string="in" />
            <token id="17" string="winning" />
            <token id="18" string="the" />
            <token id="19" string="100-meter" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">finished</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">finished</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">finished</governor>
          <dependent id="4">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Johnson</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">second</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">set</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Johnson</governor>
          <dependent id="9">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">record</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">record</governor>
          <dependent id="11">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">set</governor>
          <dependent id="12">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">seconds</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">seconds</governor>
          <dependent id="14">9.79</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">record</governor>
          <dependent id="15">seconds</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">winning</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">set</governor>
          <dependent id="17">winning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">medal</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">medal</governor>
          <dependent id="19">100-meter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">medal</governor>
          <dependent id="20">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">winning</governor>
          <dependent id="21">medal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">finished</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">had</governor>
          <dependent id="24">subsequently</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">had</governor>
          <dependent id="25">also</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">finished</governor>
          <dependent id="26">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">tested</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">tested</governor>
          <dependent id="28">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">had</governor>
          <dependent id="29">tested</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="second" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
        <entity id="4" string="9.79 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="9.79" />
            <token id="15" string="seconds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;Any allocation or innuendo that Carl Lewis tampered with Ben Johnson&amp;apost;s drink or sample is ludicrous,&amp;quot; said David Greifinger, Lewis&amp;apost; attorney.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="allocation" lemma="allocation" stem="alloc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="innuendo" lemma="innuendo" stem="innuendo" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="tampered" lemma="tamper" stem="tamper" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="drink" lemma="drink" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sample" lemma="sample" stem="sampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ludicrous" lemma="ludicrous" stem="ludicr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Greifinger" lemma="Greifinger" stem="greifing" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (DT Any) (NN allocation) (CC or) (NN innuendo)) (SBAR (WHNP (WDT that)) (S (NP (NNP Carl) (NNP Lewis)) (VP (VBD tampered) (PP (IN with) (NP (NP (NNP Ben) (NNP Johnson) (POS 's)) (NN drink) (CC or) (NN sample))))))) (VP (VBZ is) (ADJP (JJ ludicrous)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP David) (NNP Greifinger)) (, ,) (NP (NP (NNP Lewis) (POS ')) (NN attorney))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Any allocation or innuendo that Carl Lewis tampered with Ben Johnson 's drink or sample" type="NP">
          <tokens>
            <token id="2" string="Any" />
            <token id="3" string="allocation" />
            <token id="4" string="or" />
            <token id="5" string="innuendo" />
            <token id="6" string="that" />
            <token id="7" string="Carl" />
            <token id="8" string="Lewis" />
            <token id="9" string="tampered" />
            <token id="10" string="with" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="'s" />
            <token id="14" string="drink" />
            <token id="15" string="or" />
            <token id="16" string="sample" />
          </tokens>
        </chunking>
        <chunking id="2" string="David Greifinger , Lewis ' attorney" type="NP">
          <tokens>
            <token id="22" string="David" />
            <token id="23" string="Greifinger" />
            <token id="24" string="," />
            <token id="25" string="Lewis" />
            <token id="26" string="'" />
            <token id="27" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="ludicrous" type="ADJP">
          <tokens>
            <token id="18" string="ludicrous" />
          </tokens>
        </chunking>
        <chunking id="4" string="is ludicrous" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="ludicrous" />
          </tokens>
        </chunking>
        <chunking id="5" string="tampered with Ben Johnson 's drink or sample" type="VP">
          <tokens>
            <token id="9" string="tampered" />
            <token id="10" string="with" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="'s" />
            <token id="14" string="drink" />
            <token id="15" string="or" />
            <token id="16" string="sample" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lewis ' attorney" type="NP">
          <tokens>
            <token id="25" string="Lewis" />
            <token id="26" string="'" />
            <token id="27" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="7" string="Carl Lewis" type="NP">
          <tokens>
            <token id="7" string="Carl" />
            <token id="8" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Carl Lewis tampered with Ben Johnson 's drink or sample" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="Carl" />
            <token id="8" string="Lewis" />
            <token id="9" string="tampered" />
            <token id="10" string="with" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="'s" />
            <token id="14" string="drink" />
            <token id="15" string="or" />
            <token id="16" string="sample" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ben Johnson 's drink or sample" type="NP">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="'s" />
            <token id="14" string="drink" />
            <token id="15" string="or" />
            <token id="16" string="sample" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ben Johnson 's" type="NP">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Any allocation or innuendo" type="NP">
          <tokens>
            <token id="2" string="Any" />
            <token id="3" string="allocation" />
            <token id="4" string="or" />
            <token id="5" string="innuendo" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="David Greifinger" type="NP">
          <tokens>
            <token id="22" string="David" />
            <token id="23" string="Greifinger" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lewis '" type="NP">
          <tokens>
            <token id="25" string="Lewis" />
            <token id="26" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">allocation</governor>
          <dependent id="2">Any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">ludicrous</governor>
          <dependent id="3">allocation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">allocation</governor>
          <dependent id="4">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">allocation</governor>
          <dependent id="5">innuendo</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">tampered</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Lewis</governor>
          <dependent id="7">Carl</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">tampered</governor>
          <dependent id="8">Lewis</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">allocation</governor>
          <dependent id="9">tampered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">drink</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Johnson</governor>
          <dependent id="11">Ben</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">drink</governor>
          <dependent id="12">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Johnson</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">tampered</governor>
          <dependent id="14">drink</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">drink</governor>
          <dependent id="15">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">drink</governor>
          <dependent id="16">sample</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">ludicrous</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="18">ludicrous</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Greifinger</governor>
          <dependent id="22">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="23">Greifinger</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">attorney</governor>
          <dependent id="25">Lewis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Lewis</governor>
          <dependent id="26">'</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Greifinger</governor>
          <dependent id="27">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Carl" />
            <token id="8" string="Lewis" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Lewis" />
          </tokens>
        </entity>
        <entity id="4" string="David Greifinger" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="David" />
            <token id="23" string="Greifinger" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>&amp;quot;These sound like the last acts of desperate men who know they&amp;apost;ve committed wrong and see no other way out other than to continue to lie and to fabricate stories.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sound" lemma="sound" stem="sound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="acts" lemma="act" stem="act" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="desperate" lemma="desperate" stem="desper" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="committed" lemma="commit" stem="commit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="lie" lemma="lie" stem="lie" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="fabricate" lemma="fabricate" stem="fabric" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT These) (NN sound)) (PP (IN like) (NP (NP (DT the) (JJ last) (NNS acts)) (PP (IN of) (NP (JJ desperate) (NNS men))) (SBAR (WHNP (WP who)) (S (VP (VBP know) (NP (PRP they)))))))) (VP (VBP 've) (VP (VP (VBN committed) (S (ADJP (JJ wrong)))) (CC and) (VP (VB see) (NP (DT no) (JJ other) (NN way)) (PP (IN out) (NP (NP (JJ other)) (PP (IN than) (NP (S (VP (TO to) (VP (VB continue) (S (VP (TO to) (VP (VB lie))))))) (CC and) (S (VP (TO to) (VP (VB fabricate) (NP (NNS stories)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stories" type="NP">
          <tokens>
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="2" string="committed wrong" type="VP">
          <tokens>
            <token id="15" string="committed" />
            <token id="16" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="3" string="know they" type="VP">
          <tokens>
            <token id="12" string="know" />
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="no other way" type="NP">
          <tokens>
            <token id="19" string="no" />
            <token id="20" string="other" />
            <token id="21" string="way" />
          </tokens>
        </chunking>
        <chunking id="5" string="lie" type="VP">
          <tokens>
            <token id="28" string="lie" />
          </tokens>
        </chunking>
        <chunking id="6" string="'ve committed wrong and see no other way out other than to continue to lie and to fabricate stories" type="VP">
          <tokens>
            <token id="14" string="'ve" />
            <token id="15" string="committed" />
            <token id="16" string="wrong" />
            <token id="17" string="and" />
            <token id="18" string="see" />
            <token id="19" string="no" />
            <token id="20" string="other" />
            <token id="21" string="way" />
            <token id="22" string="out" />
            <token id="23" string="other" />
            <token id="24" string="than" />
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
            <token id="29" string="and" />
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="7" string="to fabricate stories" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="8" string="the last acts" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="acts" />
          </tokens>
        </chunking>
        <chunking id="9" string="desperate men" type="NP">
          <tokens>
            <token id="9" string="desperate" />
            <token id="10" string="men" />
          </tokens>
        </chunking>
        <chunking id="10" string="wrong" type="ADJP">
          <tokens>
            <token id="16" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="11" string="These sound" type="NP">
          <tokens>
            <token id="2" string="These" />
            <token id="3" string="sound" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="committed wrong and see no other way out other than to continue to lie and to fabricate stories" type="VP">
          <tokens>
            <token id="15" string="committed" />
            <token id="16" string="wrong" />
            <token id="17" string="and" />
            <token id="18" string="see" />
            <token id="19" string="no" />
            <token id="20" string="other" />
            <token id="21" string="way" />
            <token id="22" string="out" />
            <token id="23" string="other" />
            <token id="24" string="than" />
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
            <token id="29" string="and" />
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="14" string="see no other way out other than to continue to lie and to fabricate stories" type="VP">
          <tokens>
            <token id="18" string="see" />
            <token id="19" string="no" />
            <token id="20" string="other" />
            <token id="21" string="way" />
            <token id="22" string="out" />
            <token id="23" string="other" />
            <token id="24" string="than" />
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
            <token id="29" string="and" />
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="15" string="to continue to lie and to fabricate stories" type="NP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
            <token id="29" string="and" />
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="16" string="continue to lie" type="VP">
          <tokens>
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
          </tokens>
        </chunking>
        <chunking id="17" string="fabricate stories" type="VP">
          <tokens>
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="18" string="the last acts of desperate men who know they" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="acts" />
            <token id="8" string="of" />
            <token id="9" string="desperate" />
            <token id="10" string="men" />
            <token id="11" string="who" />
            <token id="12" string="know" />
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="19" string="to continue to lie" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
          </tokens>
        </chunking>
        <chunking id="20" string="other than to continue to lie and to fabricate stories" type="NP">
          <tokens>
            <token id="23" string="other" />
            <token id="24" string="than" />
            <token id="25" string="to" />
            <token id="26" string="continue" />
            <token id="27" string="to" />
            <token id="28" string="lie" />
            <token id="29" string="and" />
            <token id="30" string="to" />
            <token id="31" string="fabricate" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="21" string="to lie" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="lie" />
          </tokens>
        </chunking>
        <chunking id="22" string="other" type="NP">
          <tokens>
            <token id="23" string="other" />
          </tokens>
        </chunking>
        <chunking id="23" string="who know they" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="know" />
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="24" string="These sound like the last acts of desperate men who know they" type="NP">
          <tokens>
            <token id="2" string="These" />
            <token id="3" string="sound" />
            <token id="4" string="like" />
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="acts" />
            <token id="8" string="of" />
            <token id="9" string="desperate" />
            <token id="10" string="men" />
            <token id="11" string="who" />
            <token id="12" string="know" />
            <token id="13" string="they" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">sound</governor>
          <dependent id="2">These</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">committed</governor>
          <dependent id="3">sound</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">acts</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">acts</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">acts</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sound</governor>
          <dependent id="7">acts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">men</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">men</governor>
          <dependent id="9">desperate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">acts</governor>
          <dependent id="10">men</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">know</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">acts</governor>
          <dependent id="12">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">know</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">committed</governor>
          <dependent id="14">'ve</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">committed</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">committed</governor>
          <dependent id="16">wrong</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">committed</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">committed</governor>
          <dependent id="18">see</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">way</governor>
          <dependent id="19">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">way</governor>
          <dependent id="20">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">see</governor>
          <dependent id="21">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">other</governor>
          <dependent id="22">out</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">see</governor>
          <dependent id="23">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">continue</governor>
          <dependent id="24">than</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">continue</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">other</governor>
          <dependent id="26">continue</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">lie</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">continue</governor>
          <dependent id="28">lie</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">continue</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">fabricate</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">continue</governor>
          <dependent id="31">fabricate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">fabricate</governor>
          <dependent id="32">stories</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;Charlie and Ben should own up to the fact that what they did was wrong, and should promise to never to do it again and move on with their lives.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="own" lemma="own" stem="own" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="promise" lemma="promise" stem="promis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Charlie) (CC and) (NNP Ben)) (VP (MD should) (VP (VP (VB own) (PRT (RP up)) (PP (TO to) (NP (DT the) (NN fact))) (SBAR (IN that) (S (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBD did)))) (VP (VP (VBD was) (ADJP (JJ wrong))) (, ,) (CC and) (VP (MD should) (VP (VB promise) (PP (TO to) (ADVP (RB never))) (S (VP (TO to) (VP (VB do) (NP (PRP it)) (ADVP (RB again))))))))))) (CC and) (VP (VB move) (PP (IN on) (PP (IN with) (NP (PRP$ their) (NNS lives))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="should promise to never to do it again" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="2" string="promise to never to do it again" type="VP">
          <tokens>
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="the fact" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="fact" />
          </tokens>
        </chunking>
        <chunking id="4" string="to do it again" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="wrong" type="ADJP">
          <tokens>
            <token id="16" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="7" string="should own up to the fact that what they did was wrong , and should promise to never to do it again and move on with their lives" type="VP">
          <tokens>
            <token id="5" string="should" />
            <token id="6" string="own" />
            <token id="7" string="up" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="fact" />
            <token id="11" string="that" />
            <token id="12" string="what" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="was" />
            <token id="16" string="wrong" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
            <token id="27" string="and" />
            <token id="28" string="move" />
            <token id="29" string="on" />
            <token id="30" string="with" />
            <token id="31" string="their" />
            <token id="32" string="lives" />
          </tokens>
        </chunking>
        <chunking id="8" string="what they did" type="SBAR">
          <tokens>
            <token id="12" string="what" />
            <token id="13" string="they" />
            <token id="14" string="did" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="own up to the fact that what they did was wrong , and should promise to never to do it again and move on with their lives" type="VP">
          <tokens>
            <token id="6" string="own" />
            <token id="7" string="up" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="fact" />
            <token id="11" string="that" />
            <token id="12" string="what" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="was" />
            <token id="16" string="wrong" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
            <token id="27" string="and" />
            <token id="28" string="move" />
            <token id="29" string="on" />
            <token id="30" string="with" />
            <token id="31" string="their" />
            <token id="32" string="lives" />
          </tokens>
        </chunking>
        <chunking id="11" string="do it again" type="VP">
          <tokens>
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="12" string="that what they did was wrong , and should promise to never to do it again" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="what" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="was" />
            <token id="16" string="wrong" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="13" string="their lives" type="NP">
          <tokens>
            <token id="31" string="their" />
            <token id="32" string="lives" />
          </tokens>
        </chunking>
        <chunking id="14" string="move on with their lives" type="VP">
          <tokens>
            <token id="28" string="move" />
            <token id="29" string="on" />
            <token id="30" string="with" />
            <token id="31" string="their" />
            <token id="32" string="lives" />
          </tokens>
        </chunking>
        <chunking id="15" string="Charlie and Ben" type="NP">
          <tokens>
            <token id="2" string="Charlie" />
            <token id="3" string="and" />
            <token id="4" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="16" string="was wrong , and should promise to never to do it again" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="wrong" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="17" string="own up to the fact that what they did was wrong , and should promise to never to do it again" type="VP">
          <tokens>
            <token id="6" string="own" />
            <token id="7" string="up" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="fact" />
            <token id="11" string="that" />
            <token id="12" string="what" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="was" />
            <token id="16" string="wrong" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="should" />
            <token id="20" string="promise" />
            <token id="21" string="to" />
            <token id="22" string="never" />
            <token id="23" string="to" />
            <token id="24" string="do" />
            <token id="25" string="it" />
            <token id="26" string="again" />
          </tokens>
        </chunking>
        <chunking id="18" string="was wrong" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="19" string="did" type="VP">
          <tokens>
            <token id="14" string="did" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">own</governor>
          <dependent id="2">Charlie</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Charlie</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Charlie</governor>
          <dependent id="4">Ben</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">own</governor>
          <dependent id="5">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">own</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">own</governor>
          <dependent id="7">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">fact</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">fact</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">own</governor>
          <dependent id="10">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">wrong</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">did</governor>
          <dependent id="12">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">did</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="16">wrong</governor>
          <dependent id="14">did</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">wrong</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">own</governor>
          <dependent id="16">wrong</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">wrong</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">promise</governor>
          <dependent id="19">should</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">wrong</governor>
          <dependent id="20">promise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">never</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">promise</governor>
          <dependent id="22">never</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">do</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">promise</governor>
          <dependent id="24">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">do</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">do</governor>
          <dependent id="26">again</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">own</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">own</governor>
          <dependent id="28">move</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">lives</governor>
          <dependent id="29">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">lives</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">lives</governor>
          <dependent id="31">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">move</governor>
          <dependent id="32">lives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Charlie" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Charlie" />
          </tokens>
        </entity>
        <entity id="2" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>By continuing their present course of action they are just embarrassing themselves further.&amp;quot;</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="continuing" lemma="continue" stem="continu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="present" lemma="present" stem="present" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="embarrassing" lemma="embarrassing" stem="embarrass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="further" lemma="further" stem="further" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (S (VP (VBG continuing) (NP (PRP$ their) (JJ present) (NN course))))) (PP (IN of) (NP (NN action))) (NP (PRP they)) (VP (VBP are) (ADVP (RB just)) (ADJP (JJ embarrassing) (NP (PRP themselves))) (ADVP (RB further))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="continuing their present course" type="VP">
          <tokens>
            <token id="2" string="continuing" />
            <token id="3" string="their" />
            <token id="4" string="present" />
            <token id="5" string="course" />
          </tokens>
        </chunking>
        <chunking id="3" string="themselves" type="NP">
          <tokens>
            <token id="12" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="4" string="their present course" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="present" />
            <token id="5" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="are just embarrassing themselves further" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="just" />
            <token id="11" string="embarrassing" />
            <token id="12" string="themselves" />
            <token id="13" string="further" />
          </tokens>
        </chunking>
        <chunking id="6" string="action" type="NP">
          <tokens>
            <token id="7" string="action" />
          </tokens>
        </chunking>
        <chunking id="7" string="embarrassing themselves" type="ADJP">
          <tokens>
            <token id="11" string="embarrassing" />
            <token id="12" string="themselves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">continuing</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">embarrassing</governor>
          <dependent id="2">continuing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">course</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">course</governor>
          <dependent id="4">present</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">continuing</governor>
          <dependent id="5">course</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">action</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">embarrassing</governor>
          <dependent id="7">action</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">embarrassing</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">embarrassing</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">embarrassing</governor>
          <dependent id="10">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">embarrassing</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">embarrassing</governor>
          <dependent id="12">themselves</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">embarrassing</governor>
          <dependent id="13">further</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="present" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="present" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Lewis could not be reached for comment Monday.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (MD could) (RB not) (VP (VB be) (VP (VBN reached) (PP (IN for) (NP (NN comment))) (NP-TMP (NNP Monday))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be reached for comment Monday" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
            <token id="8" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="2" string="could not be reached for comment Monday" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="not" />
            <token id="4" string="be" />
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
            <token id="8" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="3" string="reached for comment Monday" type="VP">
          <tokens>
            <token id="5" string="reached" />
            <token id="6" string="for" />
            <token id="7" string="comment" />
            <token id="8" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="5" string="comment" type="NP">
          <tokens>
            <token id="7" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">reached</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">reached</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">reached</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">reached</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reached</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">comment</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">reached</governor>
          <dependent id="7">comment</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">reached</governor>
          <dependent id="8">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Though Johnson&amp;apost;s gold medal and Seoul world-record time were both revoked, his world mark of 9.83 seconds stands.</content>
      <tokens>
        <token id="1" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="world-record" lemma="world-record" stem="world-record" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="revoked" lemma="revoke" stem="revok" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="9.83" lemma="9.83" stem="9.83" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="stands" lemma="stand" stem="stand" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Though) (S (NP (NP (NP (NNP Johnson) (POS 's)) (NN gold) (NN medal)) (CC and) (NP (NNP Seoul))) (NP-TMP (JJ world-record) (NN time)) (VP (VBD were) (DT both) (VP (VBN revoked))))) (, ,) (NP (NP (PRP$ his) (NN world) (NN mark)) (PP (IN of) (NP (CD 9.83) (NNS seconds)))) (VP (VBZ stands)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stands" type="VP">
          <tokens>
            <token id="20" string="stands" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson 's gold medal" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
            <token id="4" string="gold" />
            <token id="5" string="medal" />
          </tokens>
        </chunking>
        <chunking id="3" string="Seoul" type="NP">
          <tokens>
            <token id="7" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="4" string="his world mark" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="world" />
            <token id="16" string="mark" />
          </tokens>
        </chunking>
        <chunking id="5" string="9.83 seconds" type="NP">
          <tokens>
            <token id="18" string="9.83" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="6" string="Johnson 's gold medal and Seoul" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
            <token id="4" string="gold" />
            <token id="5" string="medal" />
            <token id="6" string="and" />
            <token id="7" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="7" string="his world mark of 9.83 seconds" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="world" />
            <token id="16" string="mark" />
            <token id="17" string="of" />
            <token id="18" string="9.83" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="8" string="Though Johnson 's gold medal and Seoul world-record time were both revoked" type="SBAR">
          <tokens>
            <token id="1" string="Though" />
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
            <token id="4" string="gold" />
            <token id="5" string="medal" />
            <token id="6" string="and" />
            <token id="7" string="Seoul" />
            <token id="8" string="world-record" />
            <token id="9" string="time" />
            <token id="10" string="were" />
            <token id="11" string="both" />
            <token id="12" string="revoked" />
          </tokens>
        </chunking>
        <chunking id="9" string="were both revoked" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="both" />
            <token id="12" string="revoked" />
          </tokens>
        </chunking>
        <chunking id="10" string="Johnson 's" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="revoked" type="VP">
          <tokens>
            <token id="12" string="revoked" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="12">revoked</governor>
          <dependent id="1">Though</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">medal</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Johnson</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">medal</governor>
          <dependent id="4">gold</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">revoked</governor>
          <dependent id="5">medal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">medal</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">medal</governor>
          <dependent id="7">Seoul</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">time</governor>
          <dependent id="8">world-record</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">revoked</governor>
          <dependent id="9">time</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">revoked</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">revoked</governor>
          <dependent id="11">both</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">stands</governor>
          <dependent id="12">revoked</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">mark</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">mark</governor>
          <dependent id="15">world</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">stands</governor>
          <dependent id="16">mark</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">seconds</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">seconds</governor>
          <dependent id="18">9.83</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">mark</governor>
          <dependent id="19">seconds</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">stands</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Seoul" />
          </tokens>
        </entity>
        <entity id="3" string="9.83 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="9.83" />
            <token id="19" string="seconds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>He set the record at the 1987 World Championships at Rome, where Lewis finished second in 9.93 seconds.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="World" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="Championships" lemma="championship" stem="championship" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Rome" lemma="Rome" stem="rome" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="second" lemma="second" stem="second" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="9.93" lemma="9.93" stem="9.93" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD set) (NP (DT the) (NN record)) (PP (IN at) (NP (DT the) (CD 1987) (NN World) (NNS Championships))) (PP (IN at) (NP (NNP Rome))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNP Lewis)) (VP (VBD finished) (ADVP (RB second) (PP (IN in) (NP (CD 9.93) (NNS seconds)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rome" type="NP">
          <tokens>
            <token id="11" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="2" string="set the record at the 1987 World Championships at Rome , where Lewis finished second in 9.93 seconds" type="VP">
          <tokens>
            <token id="2" string="set" />
            <token id="3" string="the" />
            <token id="4" string="record" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="1987" />
            <token id="8" string="World" />
            <token id="9" string="Championships" />
            <token id="10" string="at" />
            <token id="11" string="Rome" />
            <token id="12" string="," />
            <token id="13" string="where" />
            <token id="14" string="Lewis" />
            <token id="15" string="finished" />
            <token id="16" string="second" />
            <token id="17" string="in" />
            <token id="18" string="9.93" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="3" string="finished second in 9.93 seconds" type="VP">
          <tokens>
            <token id="15" string="finished" />
            <token id="16" string="second" />
            <token id="17" string="in" />
            <token id="18" string="9.93" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="4" string="the record" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="record" />
          </tokens>
        </chunking>
        <chunking id="5" string="where Lewis finished second in 9.93 seconds" type="SBAR">
          <tokens>
            <token id="13" string="where" />
            <token id="14" string="Lewis" />
            <token id="15" string="finished" />
            <token id="16" string="second" />
            <token id="17" string="in" />
            <token id="18" string="9.93" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="6" string="9.93 seconds" type="NP">
          <tokens>
            <token id="18" string="9.93" />
            <token id="19" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="7" string="Lewis" type="NP">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1987 World Championships" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="1987" />
            <token id="8" string="World" />
            <token id="9" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="9" string="where" type="WHADVP">
          <tokens>
            <token id="13" string="where" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">set</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">record</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">set</governor>
          <dependent id="4">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Championships</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Championships</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">Championships</governor>
          <dependent id="7">1987</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Championships</governor>
          <dependent id="8">World</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">set</governor>
          <dependent id="9">Championships</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Rome</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">set</governor>
          <dependent id="11">Rome</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">finished</governor>
          <dependent id="13">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">finished</governor>
          <dependent id="14">Lewis</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">set</governor>
          <dependent id="15">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">finished</governor>
          <dependent id="16">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">seconds</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">seconds</governor>
          <dependent id="18">9.93</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">second</governor>
          <dependent id="19">seconds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1987" />
          </tokens>
        </entity>
        <entity id="2" string="Rome" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Rome" />
          </tokens>
        </entity>
        <entity id="3" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="16" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="9.93 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="9.93" />
            <token id="19" string="seconds" />
          </tokens>
        </entity>
        <entity id="5" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lewis" />
          </tokens>
        </entity>
        <entity id="6" string="World Championships" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="World" />
            <token id="9" string="Championships" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Lewis said Sunday that officials of the International Amateur Athletics Federation should disallow Johnson&amp;apost;s world record from Rome because Francis has testified his sprinter took drugs before the World Championships.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Amateur" lemma="amateur" stem="amateur" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Athletics" lemma="Athletics" stem="athletic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Federation" lemma="Federation" stem="feder" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="disallow" lemma="disallow" stem="disallow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Rome" lemma="Rome" stem="rome" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="testified" lemma="testify" stem="testifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="28" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="31" string="Championships" lemma="Championships" stem="championship" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD said) (NP-TMP (NNP Sunday)) (SBAR (IN that) (S (NP (NP (NNS officials)) (PP (IN of) (NP (DT the) (NNP International) (JJ Amateur) (NNP Athletics) (NNP Federation)))) (VP (MD should) (VP (VB disallow) (NP (NP (NP (NNP Johnson) (POS 's)) (NN world) (NN record)) (PP (IN from) (NP (NNP Rome)))) (SBAR (IN because) (S (NP (NNP Francis)) (VP (VBZ has) (VP (VBN testified) (SBAR (S (NP (PRP$ his) (NN sprinter)) (VP (VBD took) (NP (NNS drugs)) (PP (IN before) (NP (DT the) (NNP World) (NNP Championships))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the International Amateur Athletics Federation" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="International" />
            <token id="9" string="Amateur" />
            <token id="10" string="Athletics" />
            <token id="11" string="Federation" />
          </tokens>
        </chunking>
        <chunking id="2" string="should disallow Johnson 's world record from Rome because Francis has testified his sprinter took drugs before the World Championships" type="VP">
          <tokens>
            <token id="12" string="should" />
            <token id="13" string="disallow" />
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
            <token id="18" string="from" />
            <token id="19" string="Rome" />
            <token id="20" string="because" />
            <token id="21" string="Francis" />
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="27" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="officials of the International Amateur Athletics Federation" type="NP">
          <tokens>
            <token id="5" string="officials" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="International" />
            <token id="9" string="Amateur" />
            <token id="10" string="Athletics" />
            <token id="11" string="Federation" />
          </tokens>
        </chunking>
        <chunking id="5" string="took drugs before the World Championships" type="VP">
          <tokens>
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="6" string="testified his sprinter took drugs before the World Championships" type="VP">
          <tokens>
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="7" string="his sprinter took drugs before the World Championships" type="SBAR">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="8" string="Rome" type="NP">
          <tokens>
            <token id="19" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="9" string="has testified his sprinter took drugs before the World Championships" type="VP">
          <tokens>
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="10" string="the World Championships" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="11" string="Francis" type="NP">
          <tokens>
            <token id="21" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="12" string="said Sunday that officials of the International Amateur Athletics Federation should disallow Johnson 's world record from Rome because Francis has testified his sprinter took drugs before the World Championships" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Sunday" />
            <token id="4" string="that" />
            <token id="5" string="officials" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="International" />
            <token id="9" string="Amateur" />
            <token id="10" string="Athletics" />
            <token id="11" string="Federation" />
            <token id="12" string="should" />
            <token id="13" string="disallow" />
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
            <token id="18" string="from" />
            <token id="19" string="Rome" />
            <token id="20" string="because" />
            <token id="21" string="Francis" />
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="13" string="that officials of the International Amateur Athletics Federation should disallow Johnson 's world record from Rome because Francis has testified his sprinter took drugs before the World Championships" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="officials" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="International" />
            <token id="9" string="Amateur" />
            <token id="10" string="Athletics" />
            <token id="11" string="Federation" />
            <token id="12" string="should" />
            <token id="13" string="disallow" />
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
            <token id="18" string="from" />
            <token id="19" string="Rome" />
            <token id="20" string="because" />
            <token id="21" string="Francis" />
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="14" string="officials" type="NP">
          <tokens>
            <token id="5" string="officials" />
          </tokens>
        </chunking>
        <chunking id="15" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="16" string="disallow Johnson 's world record from Rome because Francis has testified his sprinter took drugs before the World Championships" type="VP">
          <tokens>
            <token id="13" string="disallow" />
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
            <token id="18" string="from" />
            <token id="19" string="Rome" />
            <token id="20" string="because" />
            <token id="21" string="Francis" />
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="17" string="because Francis has testified his sprinter took drugs before the World Championships" type="SBAR">
          <tokens>
            <token id="20" string="because" />
            <token id="21" string="Francis" />
            <token id="22" string="has" />
            <token id="23" string="testified" />
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
            <token id="26" string="took" />
            <token id="27" string="drugs" />
            <token id="28" string="before" />
            <token id="29" string="the" />
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </chunking>
        <chunking id="18" string="his sprinter" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="19" string="Johnson 's world record" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
          </tokens>
        </chunking>
        <chunking id="20" string="Johnson 's" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="Johnson 's world record from Rome" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
            <token id="15" string="'s" />
            <token id="16" string="world" />
            <token id="17" string="record" />
            <token id="18" string="from" />
            <token id="19" string="Rome" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">said</governor>
          <dependent id="3">Sunday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">disallow</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">disallow</governor>
          <dependent id="5">officials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Federation</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Federation</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Federation</governor>
          <dependent id="8">International</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Federation</governor>
          <dependent id="9">Amateur</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Federation</governor>
          <dependent id="10">Athletics</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">officials</governor>
          <dependent id="11">Federation</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">disallow</governor>
          <dependent id="12">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="13">disallow</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">record</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Johnson</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">record</governor>
          <dependent id="16">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">disallow</governor>
          <dependent id="17">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Rome</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">record</governor>
          <dependent id="19">Rome</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">testified</governor>
          <dependent id="20">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">testified</governor>
          <dependent id="21">Francis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">testified</governor>
          <dependent id="22">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">disallow</governor>
          <dependent id="23">testified</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">sprinter</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">took</governor>
          <dependent id="25">sprinter</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">testified</governor>
          <dependent id="26">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">took</governor>
          <dependent id="27">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Championships</governor>
          <dependent id="28">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Championships</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Championships</governor>
          <dependent id="30">World</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">took</governor>
          <dependent id="31">Championships</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="International Amateur Athletics Federation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="International" />
            <token id="9" string="Amateur" />
            <token id="10" string="Athletics" />
            <token id="11" string="Federation" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Rome" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Rome" />
          </tokens>
        </entity>
        <entity id="4" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Francis" />
          </tokens>
        </entity>
        <entity id="5" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="27" string="drugs" />
          </tokens>
        </entity>
        <entity id="6" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
        <entity id="7" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Sunday" />
          </tokens>
        </entity>
        <entity id="8" string="World Championships" type="MISC" score="0.0">
          <tokens>
            <token id="30" string="World" />
            <token id="31" string="Championships" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>If that were to happen, Lewis would replace Johnson as the world record-holder.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="replace" lemma="replace" stem="replac" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="record-holder" lemma="record-holder" stem="record-hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT that)) (VP (VBD were) (S (VP (TO to) (VP (VB happen))))))) (, ,) (NP (NNP Lewis)) (VP (MD would) (VP (VB replace) (NP (NP (NNP Johnson)) (PP (IN as) (NP (DT the) (NN world) (NN record-holder)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="would replace Johnson as the world record-holder" type="VP">
          <tokens>
            <token id="8" string="would" />
            <token id="9" string="replace" />
            <token id="10" string="Johnson" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="3" string="happen" type="VP">
          <tokens>
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson as the world record-holder" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="5" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world record-holder" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="7" string="If that were to happen" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="that" />
            <token id="3" string="were" />
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="8" string="replace Johnson as the world record-holder" type="VP">
          <tokens>
            <token id="9" string="replace" />
            <token id="10" string="Johnson" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="9" string="were to happen" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="10" string="to happen" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lewis" type="NP">
          <tokens>
            <token id="7" string="Lewis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">were</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">were</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">replace</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">happen</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">were</governor>
          <dependent id="5">happen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">replace</governor>
          <dependent id="7">Lewis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">replace</governor>
          <dependent id="8">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">replace</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">replace</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">record-holder</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">record-holder</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">record-holder</governor>
          <dependent id="13">world</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Johnson</governor>
          <dependent id="14">record-holder</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>IAAF officials, however, said the record will stand because Johnson passed a drug test after the 1987 race.</content>
      <tokens>
        <token id="1" string="IAAF" lemma="iaaf" stem="iaaf" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="passed" lemma="pass" stem="pass" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN IAAF) (NNS officials)) (, ,) (ADVP (RB however)) (, ,) (VP (VBD said) (SBAR (S (NP (DT the) (NN record)) (VP (MD will) (VP (VB stand) (SBAR (IN because) (S (NP (NNP Johnson)) (VP (VBD passed) (NP (DT a) (NN drug) (NN test)) (PP (IN after) (NP (DT the) (CD 1987) (NN race))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="IAAF officials" type="NP">
          <tokens>
            <token id="1" string="IAAF" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="2" string="because Johnson passed a drug test after the 1987 race" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="Johnson" />
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="the record will stand because Johnson passed a drug test after the 1987 race" type="SBAR">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="record" />
            <token id="9" string="will" />
            <token id="10" string="stand" />
            <token id="11" string="because" />
            <token id="12" string="Johnson" />
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 1987 race" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="6" string="the record" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="record" />
          </tokens>
        </chunking>
        <chunking id="7" string="passed a drug test after the 1987 race" type="VP">
          <tokens>
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="8" string="stand because Johnson passed a drug test after the 1987 race" type="VP">
          <tokens>
            <token id="10" string="stand" />
            <token id="11" string="because" />
            <token id="12" string="Johnson" />
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="9" string="a drug test" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
          </tokens>
        </chunking>
        <chunking id="10" string="said the record will stand because Johnson passed a drug test after the 1987 race" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="the" />
            <token id="8" string="record" />
            <token id="9" string="will" />
            <token id="10" string="stand" />
            <token id="11" string="because" />
            <token id="12" string="Johnson" />
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
        <chunking id="11" string="will stand because Johnson passed a drug test after the 1987 race" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="stand" />
            <token id="11" string="because" />
            <token id="12" string="Johnson" />
            <token id="13" string="passed" />
            <token id="14" string="a" />
            <token id="15" string="drug" />
            <token id="16" string="test" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="1987" />
            <token id="20" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">IAAF</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">said</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">record</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">stand</governor>
          <dependent id="8">record</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">stand</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="10">stand</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">passed</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">passed</governor>
          <dependent id="12">Johnson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">stand</governor>
          <dependent id="13">passed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">test</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">test</governor>
          <dependent id="15">drug</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">passed</governor>
          <dependent id="16">test</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">race</governor>
          <dependent id="17">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">race</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">race</governor>
          <dependent id="19">1987</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">passed</governor>
          <dependent id="20">race</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1987" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="IAAF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="IAAF" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>&amp;quot;If it has been proven that he took drugs, I would think that (withdrawing the record) is the responsible thing for the sport,&amp;quot; Lewis said Sunday.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="proven" lemma="prove" stem="proven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="withdrawing" lemma="withdraw" stem="withdraw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN If) (S (NP (PRP it)) (VP (VBZ has) (VP (VBN been) (VP (VBN proven) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD took) (NP (NNS drugs)))))))))) (, ,) (NP (PRP I)) (VP (MD would) (VP (VB think) (SBAR (IN that) (S (PRN (-LRB- -LRB-) (S (VP (VBG withdrawing) (NP (DT the) (NN record)))) (-RRB- -RRB-)) (VP (VBZ is) (NP (NP (DT the) (JJ responsible) (NN thing)) (PP (IN for) (NP (DT the) (NN sport)))))))))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said) (NP-TMP (NNP Sunday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been proven that he took drugs" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="proven" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="withdrawing the record" type="VP">
          <tokens>
            <token id="17" string="withdrawing" />
            <token id="18" string="the" />
            <token id="19" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="that he took drugs" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Sunday" type="VP">
          <tokens>
            <token id="31" string="said" />
            <token id="32" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="drugs" type="NP">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="the responsible thing for the sport" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
        <chunking id="7" string="the record" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="record" />
          </tokens>
        </chunking>
        <chunking id="8" string="If it has been proven that he took drugs" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="it" />
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="proven" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="10" string="has been proven that he took drugs" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="proven" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="11" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="took drugs" type="VP">
          <tokens>
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="think that -LRB- withdrawing the record -RRB- is the responsible thing for the sport" type="VP">
          <tokens>
            <token id="14" string="think" />
            <token id="15" string="that" />
            <token id="16" string="(" />
            <token id="17" string="withdrawing" />
            <token id="18" string="the" />
            <token id="19" string="record" />
            <token id="20" string=")" />
            <token id="21" string="is" />
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
        <chunking id="14" string="the sport" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
        <chunking id="15" string="the responsible thing" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
          </tokens>
        </chunking>
        <chunking id="16" string="proven that he took drugs" type="VP">
          <tokens>
            <token id="6" string="proven" />
            <token id="7" string="that" />
            <token id="8" string="he" />
            <token id="9" string="took" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="17" string="Lewis" type="NP">
          <tokens>
            <token id="30" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="18" string="would think that -LRB- withdrawing the record -RRB- is the responsible thing for the sport" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="think" />
            <token id="15" string="that" />
            <token id="16" string="(" />
            <token id="17" string="withdrawing" />
            <token id="18" string="the" />
            <token id="19" string="record" />
            <token id="20" string=")" />
            <token id="21" string="is" />
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="that -LRB- withdrawing the record -RRB- is the responsible thing for the sport" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="(" />
            <token id="17" string="withdrawing" />
            <token id="18" string="the" />
            <token id="19" string="record" />
            <token id="20" string=")" />
            <token id="21" string="is" />
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
        <chunking id="21" string="is the responsible thing for the sport" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="the" />
            <token id="23" string="responsible" />
            <token id="24" string="thing" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="sport" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">proven</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">proven</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">proven</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">proven</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">think</governor>
          <dependent id="6">proven</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">took</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">took</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">proven</governor>
          <dependent id="9">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">took</governor>
          <dependent id="10">drugs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">think</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">think</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="14">think</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">thing</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="24">thing</governor>
          <dependent id="17">withdrawing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">record</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">withdrawing</governor>
          <dependent id="19">record</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">thing</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">thing</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">thing</governor>
          <dependent id="23">responsible</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">think</governor>
          <dependent id="24">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">sport</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">sport</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">thing</governor>
          <dependent id="27">sport</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="30">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="31">said</governor>
          <dependent id="32">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Lewis" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Lewis also contended that Francis&amp;apost; testimony painted a false picture as to why Johnson would take performance-enhancing drugs.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="contended" lemma="contend" stem="contend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="painted" lemma="paint" stem="paint" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="false" lemma="false" stem="fals" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (ADVP (RB also)) (VP (VBD contended) (SBAR (IN that) (S (NP (NP (NNP Francis) (POS ')) (NN testimony)) (VP (VBD painted) (NP (DT a) (JJ false) (NN picture)) (PP (IN as) (PP (TO to) (SBAR (WHADVP (WRB why)) (S (NP (NNP Johnson)) (VP (MD would) (VP (VB take) (NP (JJ performance-enhancing) (NNS drugs)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="why" type="WHADVP">
          <tokens>
            <token id="14" string="why" />
          </tokens>
        </chunking>
        <chunking id="3" string="contended that Francis ' testimony painted a false picture as to why Johnson would take performance-enhancing drugs" type="VP">
          <tokens>
            <token id="3" string="contended" />
            <token id="4" string="that" />
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="testimony" />
            <token id="8" string="painted" />
            <token id="9" string="a" />
            <token id="10" string="false" />
            <token id="11" string="picture" />
            <token id="12" string="as" />
            <token id="13" string="to" />
            <token id="14" string="why" />
            <token id="15" string="Johnson" />
            <token id="16" string="would" />
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="Francis '" type="NP">
          <tokens>
            <token id="5" string="Francis" />
            <token id="6" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="painted a false picture as to why Johnson would take performance-enhancing drugs" type="VP">
          <tokens>
            <token id="8" string="painted" />
            <token id="9" string="a" />
            <token id="10" string="false" />
            <token id="11" string="picture" />
            <token id="12" string="as" />
            <token id="13" string="to" />
            <token id="14" string="why" />
            <token id="15" string="Johnson" />
            <token id="16" string="would" />
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="Francis ' testimony" type="NP">
          <tokens>
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="7" string="would take performance-enhancing drugs" type="VP">
          <tokens>
            <token id="16" string="would" />
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="a false picture" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="false" />
            <token id="11" string="picture" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="10" string="take performance-enhancing drugs" type="VP">
          <tokens>
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="11" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="that Francis ' testimony painted a false picture as to why Johnson would take performance-enhancing drugs" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="Francis" />
            <token id="6" string="'" />
            <token id="7" string="testimony" />
            <token id="8" string="painted" />
            <token id="9" string="a" />
            <token id="10" string="false" />
            <token id="11" string="picture" />
            <token id="12" string="as" />
            <token id="13" string="to" />
            <token id="14" string="why" />
            <token id="15" string="Johnson" />
            <token id="16" string="would" />
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="why Johnson would take performance-enhancing drugs" type="SBAR">
          <tokens>
            <token id="14" string="why" />
            <token id="15" string="Johnson" />
            <token id="16" string="would" />
            <token id="17" string="take" />
            <token id="18" string="performance-enhancing" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">contended</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">contended</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">contended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">painted</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">testimony</governor>
          <dependent id="5">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Francis</governor>
          <dependent id="6">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">painted</governor>
          <dependent id="7">testimony</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">contended</governor>
          <dependent id="8">painted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">picture</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">picture</governor>
          <dependent id="10">false</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">painted</governor>
          <dependent id="11">picture</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">take</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">take</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">take</governor>
          <dependent id="14">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">take</governor>
          <dependent id="15">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">take</governor>
          <dependent id="16">would</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">painted</governor>
          <dependent id="17">take</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">drugs</governor>
          <dependent id="18">performance-enhancing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">take</governor>
          <dependent id="19">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="drugs" />
          </tokens>
        </entity>
        <entity id="4" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>According to testimony, since 1981 Johnson has taken such drugs as furazabol, stanozolol and the human growth hormone, which is taken from the pituitary glands of human cadavers or can be taken in synthetic form.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="furazabol" lemma="furazabol" stem="furazabol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="growth" lemma="growth" stem="growth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="hormone" lemma="hormone" stem="hormon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="pituitary" lemma="pituitary" stem="pituitari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="glands" lemma="gland" stem="gland" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="cadavers" lemma="cadaver" stem="cadav" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="synthetic" lemma="synthetic" stem="synthet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (NN testimony))) (, ,) (PP (IN since) (NP (CD 1981)))) (NP (NNP Johnson)) (VP (VP (VBZ has) (VP (VBN taken) (NP (JJ such) (NNS drugs)) (PP (IN as) (NP (NP (NP (NN furazabol)) (, ,) (NP (NN stanozolol)) (CC and) (NP (DT the) (JJ human) (NN growth) (NN hormone))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN taken) (PP (IN from) (NP (NP (DT the) (JJ pituitary) (NNS glands)) (PP (IN of) (NP (JJ human) (NNS cadavers))))))))))))) (CC or) (VP (MD can) (VP (VB be) (VP (VBN taken) (PP (IN in) (NP (JJ synthetic) (NN form))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="has taken such drugs as furazabol , stanozolol and the human growth hormone , which is taken from the pituitary glands of human cadavers or can be taken in synthetic form" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="taken" />
            <token id="10" string="such" />
            <token id="11" string="drugs" />
            <token id="12" string="as" />
            <token id="13" string="furazabol" />
            <token id="14" string="," />
            <token id="15" string="stanozolol" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
            <token id="32" string="or" />
            <token id="33" string="can" />
            <token id="34" string="be" />
            <token id="35" string="taken" />
            <token id="36" string="in" />
            <token id="37" string="synthetic" />
            <token id="38" string="form" />
          </tokens>
        </chunking>
        <chunking id="3" string="stanozolol" type="NP">
          <tokens>
            <token id="15" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="4" string="taken such drugs as furazabol , stanozolol and the human growth hormone , which is taken from the pituitary glands of human cadavers" type="VP">
          <tokens>
            <token id="9" string="taken" />
            <token id="10" string="such" />
            <token id="11" string="drugs" />
            <token id="12" string="as" />
            <token id="13" string="furazabol" />
            <token id="14" string="," />
            <token id="15" string="stanozolol" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="5" string="furazabol" type="NP">
          <tokens>
            <token id="13" string="furazabol" />
          </tokens>
        </chunking>
        <chunking id="6" string="taken from the pituitary glands of human cadavers" type="VP">
          <tokens>
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="7" string="the pituitary glands" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
          </tokens>
        </chunking>
        <chunking id="8" string="synthetic form" type="NP">
          <tokens>
            <token id="37" string="synthetic" />
            <token id="38" string="form" />
          </tokens>
        </chunking>
        <chunking id="9" string="such drugs" type="NP">
          <tokens>
            <token id="10" string="such" />
            <token id="11" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="10" string="has taken such drugs as furazabol , stanozolol and the human growth hormone , which is taken from the pituitary glands of human cadavers" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="taken" />
            <token id="10" string="such" />
            <token id="11" string="drugs" />
            <token id="12" string="as" />
            <token id="13" string="furazabol" />
            <token id="14" string="," />
            <token id="15" string="stanozolol" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="11" string="be taken in synthetic form" type="VP">
          <tokens>
            <token id="34" string="be" />
            <token id="35" string="taken" />
            <token id="36" string="in" />
            <token id="37" string="synthetic" />
            <token id="38" string="form" />
          </tokens>
        </chunking>
        <chunking id="12" string="furazabol , stanozolol and the human growth hormone" type="NP">
          <tokens>
            <token id="13" string="furazabol" />
            <token id="14" string="," />
            <token id="15" string="stanozolol" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
          </tokens>
        </chunking>
        <chunking id="13" string="testimony" type="NP">
          <tokens>
            <token id="3" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="14" string="the human growth hormone" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
          </tokens>
        </chunking>
        <chunking id="15" string="the pituitary glands of human cadavers" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="16" string="1981" type="NP">
          <tokens>
            <token id="6" string="1981" />
          </tokens>
        </chunking>
        <chunking id="17" string="human cadavers" type="NP">
          <tokens>
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="18" string="is taken from the pituitary glands of human cadavers" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="19" string="taken in synthetic form" type="VP">
          <tokens>
            <token id="35" string="taken" />
            <token id="36" string="in" />
            <token id="37" string="synthetic" />
            <token id="38" string="form" />
          </tokens>
        </chunking>
        <chunking id="20" string="which is taken from the pituitary glands of human cadavers" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="21" string="furazabol , stanozolol and the human growth hormone , which is taken from the pituitary glands of human cadavers" type="NP">
          <tokens>
            <token id="13" string="furazabol" />
            <token id="14" string="," />
            <token id="15" string="stanozolol" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="human" />
            <token id="19" string="growth" />
            <token id="20" string="hormone" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="is" />
            <token id="24" string="taken" />
            <token id="25" string="from" />
            <token id="26" string="the" />
            <token id="27" string="pituitary" />
            <token id="28" string="glands" />
            <token id="29" string="of" />
            <token id="30" string="human" />
            <token id="31" string="cadavers" />
          </tokens>
        </chunking>
        <chunking id="22" string="can be taken in synthetic form" type="VP">
          <tokens>
            <token id="33" string="can" />
            <token id="34" string="be" />
            <token id="35" string="taken" />
            <token id="36" string="in" />
            <token id="37" string="synthetic" />
            <token id="38" string="form" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">testimony</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">taken</governor>
          <dependent id="3">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">1981</governor>
          <dependent id="5">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">testimony</governor>
          <dependent id="6">1981</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">taken</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">taken</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">taken</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">drugs</governor>
          <dependent id="10">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">taken</governor>
          <dependent id="11">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">furazabol</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">taken</governor>
          <dependent id="13">furazabol</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">furazabol</governor>
          <dependent id="15">stanozolol</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">furazabol</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">hormone</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">hormone</governor>
          <dependent id="18">human</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">hormone</governor>
          <dependent id="19">growth</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">furazabol</governor>
          <dependent id="20">hormone</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">taken</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">taken</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">furazabol</governor>
          <dependent id="24">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">glands</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">glands</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">glands</governor>
          <dependent id="27">pituitary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">taken</governor>
          <dependent id="28">glands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">cadavers</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">cadavers</governor>
          <dependent id="30">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">glands</governor>
          <dependent id="31">cadavers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">taken</governor>
          <dependent id="32">or</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">taken</governor>
          <dependent id="33">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="35">taken</governor>
          <dependent id="34">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">taken</governor>
          <dependent id="35">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">form</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">form</governor>
          <dependent id="37">synthetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">taken</governor>
          <dependent id="38">form</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1981" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The drugs induce the growth of muscle tissue, and some athletes claim, help performances.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="3" string="induce" lemma="induce" stem="induc" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="growth" lemma="growth" stem="growth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="muscle" lemma="muscle" stem="muscl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="tissue" lemma="tissue" stem="tissu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="claim" lemma="claim" stem="claim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="help" lemma="help" stem="help" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="performances" lemma="performance" stem="perform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS drugs)) (VP (VBP induce) (NP (NP (DT the) (NN growth)) (PP (IN of) (NP (NN muscle) (NN tissue)))))) (, ,) (CC and) (S (NP (DT some) (NNS athletes)) (VP (VP (VBP claim)) (, ,) (VP (VBP help) (NP (NNS performances))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the growth of muscle tissue" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="growth" />
            <token id="6" string="of" />
            <token id="7" string="muscle" />
            <token id="8" string="tissue" />
          </tokens>
        </chunking>
        <chunking id="2" string="the growth" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="growth" />
          </tokens>
        </chunking>
        <chunking id="3" string="The drugs" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="induce the growth of muscle tissue" type="VP">
          <tokens>
            <token id="3" string="induce" />
            <token id="4" string="the" />
            <token id="5" string="growth" />
            <token id="6" string="of" />
            <token id="7" string="muscle" />
            <token id="8" string="tissue" />
          </tokens>
        </chunking>
        <chunking id="5" string="help performances" type="VP">
          <tokens>
            <token id="15" string="help" />
            <token id="16" string="performances" />
          </tokens>
        </chunking>
        <chunking id="6" string="some athletes" type="NP">
          <tokens>
            <token id="11" string="some" />
            <token id="12" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="7" string="muscle tissue" type="NP">
          <tokens>
            <token id="7" string="muscle" />
            <token id="8" string="tissue" />
          </tokens>
        </chunking>
        <chunking id="8" string="claim , help performances" type="VP">
          <tokens>
            <token id="13" string="claim" />
            <token id="14" string="," />
            <token id="15" string="help" />
            <token id="16" string="performances" />
          </tokens>
        </chunking>
        <chunking id="9" string="performances" type="NP">
          <tokens>
            <token id="16" string="performances" />
          </tokens>
        </chunking>
        <chunking id="10" string="claim" type="VP">
          <tokens>
            <token id="13" string="claim" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">drugs</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">induce</governor>
          <dependent id="2">drugs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">induce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">growth</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">induce</governor>
          <dependent id="5">growth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">tissue</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">tissue</governor>
          <dependent id="7">muscle</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">growth</governor>
          <dependent id="8">tissue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">induce</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">athletes</governor>
          <dependent id="11">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">claim</governor>
          <dependent id="12">athletes</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">induce</governor>
          <dependent id="13">claim</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">claim</governor>
          <dependent id="15">help</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">help</governor>
          <dependent id="16">performances</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;quot;He is trying to say that everyone was on it, so they got on it,&amp;quot; Lewis said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP He)) (VP (VBZ is) (VP (VBG trying) (S (VP (TO to) (VP (VB say) (SBAR (IN that) (S (NP (NN everyone)) (VP (VBD was) (PP (IN on) (NP (PRP it)))))))))))) (, ,) (IN so) (S (NP (PRP they)) (VP (VBD got) (PP (IN on) (NP (PRP it)))))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="say that everyone was on it" type="VP">
          <tokens>
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="everyone" />
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="that everyone was on it" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="everyone" />
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="everyone" type="NP">
          <tokens>
            <token id="8" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="was on it" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="got on it" type="VP">
          <tokens>
            <token id="15" string="got" />
            <token id="16" string="on" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="is trying to say that everyone was on it" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="trying" />
            <token id="5" string="to" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="everyone" />
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lewis" type="NP">
          <tokens>
            <token id="20" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="10" string="to say that everyone was on it" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="everyone" />
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="trying to say that everyone was on it" type="VP">
          <tokens>
            <token id="4" string="trying" />
            <token id="5" string="to" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="everyone" />
            <token id="9" string="was" />
            <token id="10" string="on" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">trying</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">trying</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="4">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">say</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">trying</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">it</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">it</governor>
          <dependent id="8">everyone</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">it</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">it</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">say</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">trying</governor>
          <dependent id="13">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">got</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">trying</governor>
          <dependent id="15">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">it</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">got</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>&amp;quot;That&amp;apost;s not true.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT That)) (VP (VBZ 's) (RB not) (ADJP (JJ true))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="true" type="ADJP">
          <tokens>
            <token id="5" string="true" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s not true" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="not" />
            <token id="5" string="true" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">true</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">true</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">true</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">true</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>They wanted to beat people.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="beat" lemma="beat" stem="beat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD wanted) (S (VP (TO to) (VP (VB beat) (NP (NNS people)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted to beat people" type="VP">
          <tokens>
            <token id="2" string="wanted" />
            <token id="3" string="to" />
            <token id="4" string="beat" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="to beat people" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="beat" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="beat people" type="VP">
          <tokens>
            <token id="4" string="beat" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">wanted</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">beat</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">wanted</governor>
          <dependent id="4">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">beat</governor>
          <dependent id="5">people</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>That&amp;apost;s why they got on drugs.&amp;quot;</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (SBAR (WHADVP (WRB why)) (S (NP (PRP they)) (VP (VBD got) (PP (IN on) (NP (NNS drugs))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="7" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s why they got on drugs" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="why" />
            <token id="4" string="they" />
            <token id="5" string="got" />
            <token id="6" string="on" />
            <token id="7" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="why" type="WHADVP">
          <tokens>
            <token id="3" string="why" />
          </tokens>
        </chunking>
        <chunking id="6" string="got on drugs" type="VP">
          <tokens>
            <token id="5" string="got" />
            <token id="6" string="on" />
            <token id="7" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="why they got on drugs" type="SBAR">
          <tokens>
            <token id="3" string="why" />
            <token id="4" string="they" />
            <token id="5" string="got" />
            <token id="6" string="on" />
            <token id="7" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">got</governor>
          <dependent id="3">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">got</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">'s</governor>
          <dependent id="5">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">drugs</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">got</governor>
          <dependent id="7">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Lewis said track and field is not infested with steroid users as some are beginning to believe in light of the Canadian inquiry.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="infested" lemma="infested" stem="infest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="users" lemma="user" stem="user" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="beginning" lemma="begin" stem="begin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="23" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD said) (SBAR (S (NP (NN track) (CC and) (NN field)) (VP (VBZ is) (RB not) (ADJP (JJ infested) (PP (IN with) (NP (NN steroid) (NNS users)))) (SBAR (IN as) (S (NP (DT some)) (VP (VBP are) (VP (VBG beginning) (S (VP (TO to) (VP (VB believe) (PP (IN in) (NP (NP (NN light)) (PP (IN of) (NP (DT the) (JJ Canadian) (NN inquiry)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="steroid users" type="NP">
          <tokens>
            <token id="10" string="steroid" />
            <token id="11" string="users" />
          </tokens>
        </chunking>
        <chunking id="2" string="beginning to believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="3" string="light of the Canadian inquiry" type="NP">
          <tokens>
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="4" string="to believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="13" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Canadian inquiry" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="7" string="infested with steroid users" type="ADJP">
          <tokens>
            <token id="8" string="infested" />
            <token id="9" string="with" />
            <token id="10" string="steroid" />
            <token id="11" string="users" />
          </tokens>
        </chunking>
        <chunking id="8" string="is not infested with steroid users as some are beginning to believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="not" />
            <token id="8" string="infested" />
            <token id="9" string="with" />
            <token id="10" string="steroid" />
            <token id="11" string="users" />
            <token id="12" string="as" />
            <token id="13" string="some" />
            <token id="14" string="are" />
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="9" string="track and field" type="NP">
          <tokens>
            <token id="3" string="track" />
            <token id="4" string="and" />
            <token id="5" string="field" />
          </tokens>
        </chunking>
        <chunking id="10" string="said track and field is not infested with steroid users as some are beginning to believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="track" />
            <token id="4" string="and" />
            <token id="5" string="field" />
            <token id="6" string="is" />
            <token id="7" string="not" />
            <token id="8" string="infested" />
            <token id="9" string="with" />
            <token id="10" string="steroid" />
            <token id="11" string="users" />
            <token id="12" string="as" />
            <token id="13" string="some" />
            <token id="14" string="are" />
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="11" string="believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="12" string="light" type="NP">
          <tokens>
            <token id="19" string="light" />
          </tokens>
        </chunking>
        <chunking id="13" string="are beginning to believe in light of the Canadian inquiry" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="15" string="track and field is not infested with steroid users as some are beginning to believe in light of the Canadian inquiry" type="SBAR">
          <tokens>
            <token id="3" string="track" />
            <token id="4" string="and" />
            <token id="5" string="field" />
            <token id="6" string="is" />
            <token id="7" string="not" />
            <token id="8" string="infested" />
            <token id="9" string="with" />
            <token id="10" string="steroid" />
            <token id="11" string="users" />
            <token id="12" string="as" />
            <token id="13" string="some" />
            <token id="14" string="are" />
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="16" string="as some are beginning to believe in light of the Canadian inquiry" type="SBAR">
          <tokens>
            <token id="12" string="as" />
            <token id="13" string="some" />
            <token id="14" string="are" />
            <token id="15" string="beginning" />
            <token id="16" string="to" />
            <token id="17" string="believe" />
            <token id="18" string="in" />
            <token id="19" string="light" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Canadian" />
            <token id="23" string="inquiry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">infested</governor>
          <dependent id="3">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">track</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">track</governor>
          <dependent id="5">field</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">infested</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">infested</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="8">infested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">users</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">users</governor>
          <dependent id="10">steroid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">infested</governor>
          <dependent id="11">users</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">beginning</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">beginning</governor>
          <dependent id="13">some</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">beginning</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">infested</governor>
          <dependent id="15">beginning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">believe</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">beginning</governor>
          <dependent id="17">believe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">light</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">believe</governor>
          <dependent id="19">light</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">inquiry</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">inquiry</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">inquiry</governor>
          <dependent id="22">Canadian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">light</governor>
          <dependent id="23">inquiry</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="Canadian" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>He said about 90% of the athletes are drug-free.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="5" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="drug-free" lemma="drug-free" stem="drug-fre" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (IN about) (S (NP (NP (CD 90) (NN %)) (PP (IN of) (NP (DT the) (NNS athletes)))) (VP (VBP are) (ADJP (JJ drug-free)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="90 %" type="NP">
          <tokens>
            <token id="4" string="90" />
            <token id="5" string="%" />
          </tokens>
        </chunking>
        <chunking id="2" string="about 90 % of the athletes are drug-free" type="SBAR">
          <tokens>
            <token id="3" string="about" />
            <token id="4" string="90" />
            <token id="5" string="%" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="athletes" />
            <token id="9" string="are" />
            <token id="10" string="drug-free" />
          </tokens>
        </chunking>
        <chunking id="3" string="90 % of the athletes" type="NP">
          <tokens>
            <token id="4" string="90" />
            <token id="5" string="%" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="4" string="said about 90 % of the athletes are drug-free" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="about" />
            <token id="4" string="90" />
            <token id="5" string="%" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="athletes" />
            <token id="9" string="are" />
            <token id="10" string="drug-free" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="6" string="are drug-free" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="drug-free" />
          </tokens>
        </chunking>
        <chunking id="7" string="the athletes" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="8" string="drug-free" type="ADJP">
          <tokens>
            <token id="10" string="drug-free" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">drug-free</governor>
          <dependent id="3">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">%</governor>
          <dependent id="4">90</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">drug-free</governor>
          <dependent id="5">%</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">athletes</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">athletes</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">%</governor>
          <dependent id="8">athletes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">drug-free</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">said</governor>
          <dependent id="10">drug-free</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="4" string="90" />
            <token id="5" string="%" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>&amp;quot;Most of your great athletes are clean,&amp;quot; Lewis said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (JJS Most)) (PP (IN of) (NP (PRP$ your) (JJ great) (NNS athletes)))) (VP (VBP are) (ADJP (JJ clean)))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Most of your great athletes" type="NP">
          <tokens>
            <token id="2" string="Most" />
            <token id="3" string="of" />
            <token id="4" string="your" />
            <token id="5" string="great" />
            <token id="6" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="2" string="Most" type="NP">
          <tokens>
            <token id="2" string="Most" />
          </tokens>
        </chunking>
        <chunking id="3" string="are clean" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="clean" />
          </tokens>
        </chunking>
        <chunking id="4" string="your great athletes" type="NP">
          <tokens>
            <token id="4" string="your" />
            <token id="5" string="great" />
            <token id="6" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lewis" type="NP">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="6" string="clean" type="ADJP">
          <tokens>
            <token id="8" string="clean" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">clean</governor>
          <dependent id="2">Most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">athletes</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">athletes</governor>
          <dependent id="4">your</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">athletes</governor>
          <dependent id="5">great</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Most</governor>
          <dependent id="6">athletes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">clean</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="8">clean</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>&amp;quot;There are athletes who do have a problem.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBP are) (NP (NP (NNS athletes)) (SBAR (WHNP (WP who)) (S (VP (VBP do) (VP (VB have) (NP (DT a) (NN problem)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="are athletes who do have a problem" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="athletes" />
            <token id="5" string="who" />
            <token id="6" string="do" />
            <token id="7" string="have" />
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="athletes who do have a problem" type="NP">
          <tokens>
            <token id="4" string="athletes" />
            <token id="5" string="who" />
            <token id="6" string="do" />
            <token id="7" string="have" />
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="athletes" type="NP">
          <tokens>
            <token id="4" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="5" string="who do have a problem" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="do" />
            <token id="7" string="have" />
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="6" string="do have a problem" type="VP">
          <tokens>
            <token id="6" string="do" />
            <token id="7" string="have" />
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="7" string="have a problem" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="8" string="a problem" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="4">athletes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">have</governor>
          <dependent id="6">do</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">athletes</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">problem</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="9">problem</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>I can tell who&amp;apost;s on it.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD can) (VP (VB tell) (SBAR (WHNP (WP who)) (S (VP (VBZ 's) (PP (IN on) (NP (PRP it)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can tell who 's on it" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="tell" />
            <token id="4" string="who" />
            <token id="5" string="'s" />
            <token id="6" string="on" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s on it" type="VP">
          <tokens>
            <token id="5" string="'s" />
            <token id="6" string="on" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="tell who 's on it" type="VP">
          <tokens>
            <token id="3" string="tell" />
            <token id="4" string="who" />
            <token id="5" string="'s" />
            <token id="6" string="on" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="who 's on it" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="'s" />
            <token id="6" string="on" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tell</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">tell</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tell</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">it</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">it</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">it</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">tell</governor>
          <dependent id="7">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>I&amp;apost;ve been around it too long.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 've) (VP (VBN been) (PP (IN around) (NP (PRP it))) (ADVP (RB too) (RB long)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="been around it too long" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="around" />
            <token id="5" string="it" />
            <token id="6" string="too" />
            <token id="7" string="long" />
          </tokens>
        </chunking>
        <chunking id="2" string="'ve been around it too long" type="VP">
          <tokens>
            <token id="2" string="'ve" />
            <token id="3" string="been" />
            <token id="4" string="around" />
            <token id="5" string="it" />
            <token id="6" string="too" />
            <token id="7" string="long" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">it</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">it</governor>
          <dependent id="2">'ve</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">it</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">it</governor>
          <dependent id="4">around</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">long</governor>
          <dependent id="6">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">it</governor>
          <dependent id="7">long</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Lewis, however, refused to implicate any of his colleagues.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="implicate" lemma="implicate" stem="implic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="colleagues" lemma="colleague" stem="colleagu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (, ,) (ADVP (RB however)) (, ,) (VP (VBD refused) (S (VP (TO to) (VP (VB implicate) (NP (NP (DT any)) (PP (IN of) (NP (PRP$ his) (NNS colleagues)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="implicate any of his colleagues" type="VP">
          <tokens>
            <token id="7" string="implicate" />
            <token id="8" string="any" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="2" string="any of his colleagues" type="NP">
          <tokens>
            <token id="8" string="any" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="4" string="refused to implicate any of his colleagues" type="VP">
          <tokens>
            <token id="5" string="refused" />
            <token id="6" string="to" />
            <token id="7" string="implicate" />
            <token id="8" string="any" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="5" string="any" type="NP">
          <tokens>
            <token id="8" string="any" />
          </tokens>
        </chunking>
        <chunking id="6" string="to implicate any of his colleagues" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="implicate" />
            <token id="8" string="any" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="7" string="his colleagues" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="colleagues" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">refused</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">refused</governor>
          <dependent id="3">however</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">implicate</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">refused</governor>
          <dependent id="7">implicate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">implicate</governor>
          <dependent id="8">any</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">colleagues</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">colleagues</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">any</governor>
          <dependent id="11">colleagues</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>But Lewis defended Evelyn Ashford, a world-class sprinter who was implicated as a steroid user in Francis&amp;apost; testimony last week.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="defended" lemma="defend" stem="defend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Evelyn" lemma="Evelyn" stem="evelyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Ashford" lemma="Ashford" stem="ashford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="world-class" lemma="world-class" stem="world-class" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="implicated" lemma="implicate" stem="implic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="user" lemma="user" stem="user" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Lewis)) (VP (VBD defended) (NP (NP (NNP Evelyn) (NNP Ashford)) (, ,) (NP (NP (DT a) (JJ world-class) (NN sprinter)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN implicated) (PP (IN as) (NP (NP (DT a) (NN steroid) (NN user)) (PP (IN in) (NP (NP (NNP Francis) (POS ')) (NN testimony))))) (NP-TMP (JJ last) (NN week))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Evelyn Ashford" type="NP">
          <tokens>
            <token id="4" string="Evelyn" />
            <token id="5" string="Ashford" />
          </tokens>
        </chunking>
        <chunking id="2" string="a world-class sprinter who was implicated as a steroid user in Francis ' testimony last week" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="world-class" />
            <token id="9" string="sprinter" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="a steroid user in Francis ' testimony" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="4" string="Francis '" type="NP">
          <tokens>
            <token id="18" string="Francis" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="who was implicated as a steroid user in Francis ' testimony last week" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
        <chunking id="6" string="implicated as a steroid user in Francis ' testimony last week" type="VP">
          <tokens>
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
        <chunking id="7" string="Francis ' testimony" type="NP">
          <tokens>
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="8" string="Evelyn Ashford , a world-class sprinter who was implicated as a steroid user in Francis ' testimony last week" type="NP">
          <tokens>
            <token id="4" string="Evelyn" />
            <token id="5" string="Ashford" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="world-class" />
            <token id="9" string="sprinter" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
        <chunking id="9" string="a world-class sprinter" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="world-class" />
            <token id="9" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="10" string="defended Evelyn Ashford , a world-class sprinter who was implicated as a steroid user in Francis ' testimony last week" type="VP">
          <tokens>
            <token id="3" string="defended" />
            <token id="4" string="Evelyn" />
            <token id="5" string="Ashford" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="world-class" />
            <token id="9" string="sprinter" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
        <chunking id="11" string="a steroid user" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lewis" type="NP">
          <tokens>
            <token id="2" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="13" string="was implicated as a steroid user in Francis ' testimony last week" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="implicated" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="steroid" />
            <token id="16" string="user" />
            <token id="17" string="in" />
            <token id="18" string="Francis" />
            <token id="19" string="'" />
            <token id="20" string="testimony" />
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">defended</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">defended</governor>
          <dependent id="2">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">defended</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Ashford</governor>
          <dependent id="4">Evelyn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">defended</governor>
          <dependent id="5">Ashford</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sprinter</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">sprinter</governor>
          <dependent id="8">world-class</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Ashford</governor>
          <dependent id="9">sprinter</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">implicated</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">implicated</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">sprinter</governor>
          <dependent id="12">implicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">user</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">user</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">user</governor>
          <dependent id="15">steroid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">implicated</governor>
          <dependent id="16">user</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">testimony</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">testimony</governor>
          <dependent id="18">Francis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Francis</governor>
          <dependent id="19">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">user</governor>
          <dependent id="20">testimony</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">week</governor>
          <dependent id="21">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">implicated</governor>
          <dependent id="22">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Evelyn Ashford" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Evelyn" />
            <token id="5" string="Ashford" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </entity>
        <entity id="4" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Lewis and Ashford are teammates on the Santa Monica Track Club.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Ashford" lemma="Ashford" stem="ashford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="teammates" lemma="teammate" stem="teammat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Monica" lemma="Monica" stem="monica" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="Track" lemma="Track" stem="track" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Club" lemma="Club" stem="club" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis) (CC and) (NNP Ashford)) (VP (VBP are) (NP (NP (NNS teammates)) (PP (IN on) (NP (DT the) (NNP Santa) (NNP Monica) (NNP Track) (NNP Club))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="teammates on the Santa Monica Track Club" type="NP">
          <tokens>
            <token id="5" string="teammates" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="Santa" />
            <token id="9" string="Monica" />
            <token id="10" string="Track" />
            <token id="11" string="Club" />
          </tokens>
        </chunking>
        <chunking id="2" string="are teammates on the Santa Monica Track Club" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="teammates" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="Santa" />
            <token id="9" string="Monica" />
            <token id="10" string="Track" />
            <token id="11" string="Club" />
          </tokens>
        </chunking>
        <chunking id="3" string="teammates" type="NP">
          <tokens>
            <token id="5" string="teammates" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Santa Monica Track Club" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Santa" />
            <token id="9" string="Monica" />
            <token id="10" string="Track" />
            <token id="11" string="Club" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lewis and Ashford" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
            <token id="2" string="and" />
            <token id="3" string="Ashford" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">teammates</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Lewis</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Lewis</governor>
          <dependent id="3">Ashford</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">teammates</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">teammates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Club</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Club</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Club</governor>
          <dependent id="8">Santa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Club</governor>
          <dependent id="9">Monica</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Club</governor>
          <dependent id="10">Track</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">teammates</governor>
          <dependent id="11">Club</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Santa Monica Track Club" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Santa" />
            <token id="9" string="Monica" />
            <token id="10" string="Track" />
            <token id="11" string="Club" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
        <entity id="3" string="Ashford" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ashford" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>&amp;quot;No way in the world does she take drugs,&amp;quot; Lewis said, pounding a table.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="pounding" lemma="pound" stem="pound" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="table" lemma="table" stem="tabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT No) (NN way)) (PP (IN in) (NP (DT the) (NN world)))) (VP (VBZ does) (S (NP (PRP she)) (VP (VB take) (NP (NNS drugs)))))) (, ,) ('' '') (NP (NNP Lewis)) (VP (VBD said) (, ,) (S (VP (VBG pounding) (NP (DT a) (NN table))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pounding a table" type="VP">
          <tokens>
            <token id="16" string="pounding" />
            <token id="17" string="a" />
            <token id="18" string="table" />
          </tokens>
        </chunking>
        <chunking id="2" string="take drugs" type="VP">
          <tokens>
            <token id="9" string="take" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="said , pounding a table" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="," />
            <token id="16" string="pounding" />
            <token id="17" string="a" />
            <token id="18" string="table" />
          </tokens>
        </chunking>
        <chunking id="5" string="No way" type="NP">
          <tokens>
            <token id="2" string="No" />
            <token id="3" string="way" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lewis" type="NP">
          <tokens>
            <token id="13" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="7" string="a table" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="table" />
          </tokens>
        </chunking>
        <chunking id="8" string="does she take drugs" type="VP">
          <tokens>
            <token id="7" string="does" />
            <token id="8" string="she" />
            <token id="9" string="take" />
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="the world" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="world" />
          </tokens>
        </chunking>
        <chunking id="10" string="No way in the world" type="NP">
          <tokens>
            <token id="2" string="No" />
            <token id="3" string="way" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="world" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="8" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="3">way</governor>
          <dependent id="2">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">does</governor>
          <dependent id="3">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">world</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">world</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">way</governor>
          <dependent id="6">world</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="7">does</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">take</governor>
          <dependent id="8">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">does</governor>
          <dependent id="9">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">take</governor>
          <dependent id="10">drugs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">said</governor>
          <dependent id="16">pounding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">table</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">pounding</governor>
          <dependent id="18">table</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;She is a victim.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (VP (VBZ is) (NP (DT a) (NN victim))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a victim" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="victim" />
          </tokens>
        </chunking>
        <chunking id="2" string="a victim" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="victim" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">victim</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">victim</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">victim</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">victim</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>That&amp;apost;s going to happen.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB happen)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="happen" type="VP">
          <tokens>
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s going to happen" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="4" string="going to happen" type="VP">
          <tokens>
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
        <chunking id="5" string="to happen" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="happen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">going</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">going</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">happen</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">going</governor>
          <dependent id="5">happen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>I don&amp;apost;t think that will hurt her image because Evelyn is clean and she always stood for being clean.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hurt" lemma="hurt" stem="hurt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Evelyn" lemma="Evelyn" stem="evelyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (S (S (NP (DT that)) (VP (MD will) (VP (VB hurt) (NP (PRP$ her) (NN image)) (SBAR (IN because) (S (NP (NNP Evelyn)) (VP (VBZ is) (ADJP (JJ clean)))))))) (CC and) (S (NP (PRP she)) (ADVP (RB always)) (VP (VBD stood) (PP (IN for) (S (VP (VBG being) (ADJP (JJ clean)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Evelyn" type="NP">
          <tokens>
            <token id="11" string="Evelyn" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't think that will hurt her image because Evelyn is clean and she always stood for being clean" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="think" />
            <token id="5" string="that" />
            <token id="6" string="will" />
            <token id="7" string="hurt" />
            <token id="8" string="her" />
            <token id="9" string="image" />
            <token id="10" string="because" />
            <token id="11" string="Evelyn" />
            <token id="12" string="is" />
            <token id="13" string="clean" />
            <token id="14" string="and" />
            <token id="15" string="she" />
            <token id="16" string="always" />
            <token id="17" string="stood" />
            <token id="18" string="for" />
            <token id="19" string="being" />
            <token id="20" string="clean" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="think that will hurt her image because Evelyn is clean and she always stood for being clean" type="VP">
          <tokens>
            <token id="4" string="think" />
            <token id="5" string="that" />
            <token id="6" string="will" />
            <token id="7" string="hurt" />
            <token id="8" string="her" />
            <token id="9" string="image" />
            <token id="10" string="because" />
            <token id="11" string="Evelyn" />
            <token id="12" string="is" />
            <token id="13" string="clean" />
            <token id="14" string="and" />
            <token id="15" string="she" />
            <token id="16" string="always" />
            <token id="17" string="stood" />
            <token id="18" string="for" />
            <token id="19" string="being" />
            <token id="20" string="clean" />
          </tokens>
        </chunking>
        <chunking id="5" string="will hurt her image because Evelyn is clean" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="hurt" />
            <token id="8" string="her" />
            <token id="9" string="image" />
            <token id="10" string="because" />
            <token id="11" string="Evelyn" />
            <token id="12" string="is" />
            <token id="13" string="clean" />
          </tokens>
        </chunking>
        <chunking id="6" string="clean" type="ADJP">
          <tokens>
            <token id="13" string="clean" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="9" string="her image" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="image" />
          </tokens>
        </chunking>
        <chunking id="10" string="stood for being clean" type="VP">
          <tokens>
            <token id="17" string="stood" />
            <token id="18" string="for" />
            <token id="19" string="being" />
            <token id="20" string="clean" />
          </tokens>
        </chunking>
        <chunking id="11" string="because Evelyn is clean" type="SBAR">
          <tokens>
            <token id="10" string="because" />
            <token id="11" string="Evelyn" />
            <token id="12" string="is" />
            <token id="13" string="clean" />
          </tokens>
        </chunking>
        <chunking id="12" string="hurt her image because Evelyn is clean" type="VP">
          <tokens>
            <token id="7" string="hurt" />
            <token id="8" string="her" />
            <token id="9" string="image" />
            <token id="10" string="because" />
            <token id="11" string="Evelyn" />
            <token id="12" string="is" />
            <token id="13" string="clean" />
          </tokens>
        </chunking>
        <chunking id="13" string="is clean" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="clean" />
          </tokens>
        </chunking>
        <chunking id="14" string="being clean" type="VP">
          <tokens>
            <token id="19" string="being" />
            <token id="20" string="clean" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">think</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">think</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">hurt</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">hurt</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">think</governor>
          <dependent id="7">hurt</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">image</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">hurt</governor>
          <dependent id="9">image</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">clean</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">clean</governor>
          <dependent id="11">Evelyn</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">clean</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">hurt</governor>
          <dependent id="13">clean</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">hurt</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">stood</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">stood</governor>
          <dependent id="16">always</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">hurt</governor>
          <dependent id="17">stood</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">clean</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">clean</governor>
          <dependent id="19">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">stood</governor>
          <dependent id="20">clean</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Evelyn" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Evelyn" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>People who know her know it.&amp;quot;</content>
      <tokens>
        <token id="1" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNS People)) (SBAR (WHNP (WP who)) (S (VP (VBP know) (S (NP (PRP$ her)) (VP (VB know) (NP (PRP it))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="know her know it" type="VP">
          <tokens>
            <token id="3" string="know" />
            <token id="4" string="her" />
            <token id="5" string="know" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="People who know her know it . ''" type="NP">
          <tokens>
            <token id="1" string="People" />
            <token id="2" string="who" />
            <token id="3" string="know" />
            <token id="4" string="her" />
            <token id="5" string="know" />
            <token id="6" string="it" />
            <token id="7" string="." />
            <token id="8" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="who know her know it" type="SBAR">
          <tokens>
            <token id="2" string="who" />
            <token id="3" string="know" />
            <token id="4" string="her" />
            <token id="5" string="know" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="People" type="NP">
          <tokens>
            <token id="1" string="People" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="know it" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">People</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">know</governor>
          <dependent id="2">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">People</governor>
          <dependent id="3">know</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">know</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">know</governor>
          <dependent id="6">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>In finishing second at the Olympics, Lewis set a U.S. record of 9.92 seconds.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="finishing" lemma="finish" stem="finish" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="9.92" lemma="9.92" stem="9.92" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (S (VP (VBG finishing) (NP (JJ second)) (PP (IN at) (NP (DT the) (NNPS Olympics)))))) (, ,) (NP (NNP Lewis)) (VP (VBD set) (NP (NP (DT a) (NNP U.S.) (NN record)) (PP (IN of) (NP (CD 9.92) (NNS seconds))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a U.S. record" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="U.S." />
            <token id="12" string="record" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Olympics" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="3" string="set a U.S. record of 9.92 seconds" type="VP">
          <tokens>
            <token id="9" string="set" />
            <token id="10" string="a" />
            <token id="11" string="U.S." />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.92" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="4" string="finishing second at the Olympics" type="VP">
          <tokens>
            <token id="2" string="finishing" />
            <token id="3" string="second" />
            <token id="4" string="at" />
            <token id="5" string="the" />
            <token id="6" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="second" type="NP">
          <tokens>
            <token id="3" string="second" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lewis" type="NP">
          <tokens>
            <token id="8" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="7" string="9.92 seconds" type="NP">
          <tokens>
            <token id="14" string="9.92" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="8" string="a U.S. record of 9.92 seconds" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="U.S." />
            <token id="12" string="record" />
            <token id="13" string="of" />
            <token id="14" string="9.92" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">finishing</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">set</governor>
          <dependent id="2">finishing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">finishing</governor>
          <dependent id="3">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Olympics</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Olympics</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">finishing</governor>
          <dependent id="6">Olympics</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">set</governor>
          <dependent id="8">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">record</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">record</governor>
          <dependent id="11">U.S.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">set</governor>
          <dependent id="12">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">seconds</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">seconds</governor>
          <dependent id="14">9.92</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">record</governor>
          <dependent id="15">seconds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Olympics" />
          </tokens>
        </entity>
        <entity id="3" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Lewis" />
          </tokens>
        </entity>
        <entity id="5" string="9.92 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="9.92" />
            <token id="15" string="seconds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Even before Lewis replaced Johnson as the gold-medal winner two days after the race, the U.S. Olympian said he was happy with his result.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="replaced" lemma="replace" stem="replac" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="gold-medal" lemma="gold-medal" stem="gold-med" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Olympian" lemma="Olympian" stem="olympian" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (IN before) (S (NP (NNP Lewis)) (VP (VBD replaced) (NP (NNP Johnson)) (PP (IN as) (NP (NP (DT the) (JJ gold-medal) (NN winner)) (NP-TMP (CD two) (NNS days)))) (PP (IN after) (NP (DT the) (NN race)))))) (, ,) (NP (DT the) (NNP U.S.) (NNP Olympian)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ happy) (PP (IN with) (NP (PRP$ his) (NN result)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the gold-medal winner" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="gold-medal" />
            <token id="9" string="winner" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="he was happy with his result" type="SBAR">
          <tokens>
            <token id="20" string="he" />
            <token id="21" string="was" />
            <token id="22" string="happy" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="result" />
          </tokens>
        </chunking>
        <chunking id="4" string="Even before Lewis replaced Johnson as the gold-medal winner two days after the race" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="before" />
            <token id="3" string="Lewis" />
            <token id="4" string="replaced" />
            <token id="5" string="Johnson" />
            <token id="6" string="as" />
            <token id="7" string="the" />
            <token id="8" string="gold-medal" />
            <token id="9" string="winner" />
            <token id="10" string="two" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="his result" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="result" />
          </tokens>
        </chunking>
        <chunking id="6" string="said he was happy with his result" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="he" />
            <token id="21" string="was" />
            <token id="22" string="happy" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="result" />
          </tokens>
        </chunking>
        <chunking id="7" string="the gold-medal winner two days" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="gold-medal" />
            <token id="9" string="winner" />
            <token id="10" string="two" />
            <token id="11" string="days" />
          </tokens>
        </chunking>
        <chunking id="8" string="was happy with his result" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="happy" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="result" />
          </tokens>
        </chunking>
        <chunking id="9" string="the U.S. Olympian" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="U.S." />
            <token id="18" string="Olympian" />
          </tokens>
        </chunking>
        <chunking id="10" string="happy with his result" type="ADJP">
          <tokens>
            <token id="22" string="happy" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="result" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lewis" type="NP">
          <tokens>
            <token id="3" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="12" string="replaced Johnson as the gold-medal winner two days after the race" type="VP">
          <tokens>
            <token id="4" string="replaced" />
            <token id="5" string="Johnson" />
            <token id="6" string="as" />
            <token id="7" string="the" />
            <token id="8" string="gold-medal" />
            <token id="9" string="winner" />
            <token id="10" string="two" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="20" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="the race" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">replaced</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">replaced</governor>
          <dependent id="2">before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">replaced</governor>
          <dependent id="3">Lewis</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">said</governor>
          <dependent id="4">replaced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">replaced</governor>
          <dependent id="5">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">winner</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">winner</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">winner</governor>
          <dependent id="8">gold-medal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">replaced</governor>
          <dependent id="9">winner</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">days</governor>
          <dependent id="10">two</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">winner</governor>
          <dependent id="11">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">race</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">race</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">replaced</governor>
          <dependent id="14">race</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Olympian</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Olympian</governor>
          <dependent id="17">U.S.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Olympian</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">happy</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">happy</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="22">happy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">result</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">result</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">happy</governor>
          <dependent id="25">result</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="two days" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="two" />
            <token id="11" string="days" />
          </tokens>
        </entity>
        <entity id="3" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="U.S." />
          </tokens>
        </entity>
        <entity id="4" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lewis" />
          </tokens>
        </entity>
        <entity id="5" string="Olympian" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Olympian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>&amp;quot;I&amp;apost;ve come to grips with the fact that I&amp;apost;m the best I can be and I can&amp;apost;t ask for anything more,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="grips" lemma="grip" stem="grip" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP 've) (VP (VBN come) (PP (TO to) (NP (NP (NNS grips)) (PP (IN with) (NP (DT the) (NN fact))))) (SBAR (IN that) (S (S (NP (PRP I)) (VP (VBP 'm) (NP (NP (DT the) (JJS best)) (SBAR (S (NP (PRP I)) (VP (MD can) (VP (VB be)))))))) (CC and) (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB ask) (PP (IN for) (NP (NN anything))) (ADVP (RBR more)))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="grips" type="NP">
          <tokens>
            <token id="6" string="grips" />
          </tokens>
        </chunking>
        <chunking id="2" string="that I 'm the best I can be and I ca n't ask for anything more" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="I" />
            <token id="12" string="'m" />
            <token id="13" string="the" />
            <token id="14" string="best" />
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
            <token id="18" string="and" />
            <token id="19" string="I" />
            <token id="20" string="ca" />
            <token id="21" string="n't" />
            <token id="22" string="ask" />
            <token id="23" string="for" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="3" string="be" type="VP">
          <tokens>
            <token id="17" string="be" />
          </tokens>
        </chunking>
        <chunking id="4" string="grips with the fact" type="NP">
          <tokens>
            <token id="6" string="grips" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
          </tokens>
        </chunking>
        <chunking id="5" string="the fact" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="fact" />
          </tokens>
        </chunking>
        <chunking id="6" string="'m the best I can be" type="VP">
          <tokens>
            <token id="12" string="'m" />
            <token id="13" string="the" />
            <token id="14" string="best" />
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="the best" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="9" string="ca n't ask for anything more" type="VP">
          <tokens>
            <token id="20" string="ca" />
            <token id="21" string="n't" />
            <token id="22" string="ask" />
            <token id="23" string="for" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="10" string="can be" type="VP">
          <tokens>
            <token id="16" string="can" />
            <token id="17" string="be" />
          </tokens>
        </chunking>
        <chunking id="11" string="anything" type="NP">
          <tokens>
            <token id="24" string="anything" />
          </tokens>
        </chunking>
        <chunking id="12" string="'ve come to grips with the fact that I 'm the best I can be and I ca n't ask for anything more" type="VP">
          <tokens>
            <token id="3" string="'ve" />
            <token id="4" string="come" />
            <token id="5" string="to" />
            <token id="6" string="grips" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
            <token id="10" string="that" />
            <token id="11" string="I" />
            <token id="12" string="'m" />
            <token id="13" string="the" />
            <token id="14" string="best" />
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
            <token id="18" string="and" />
            <token id="19" string="I" />
            <token id="20" string="ca" />
            <token id="21" string="n't" />
            <token id="22" string="ask" />
            <token id="23" string="for" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="13" string="come to grips with the fact that I 'm the best I can be and I ca n't ask for anything more" type="VP">
          <tokens>
            <token id="4" string="come" />
            <token id="5" string="to" />
            <token id="6" string="grips" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
            <token id="10" string="that" />
            <token id="11" string="I" />
            <token id="12" string="'m" />
            <token id="13" string="the" />
            <token id="14" string="best" />
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
            <token id="18" string="and" />
            <token id="19" string="I" />
            <token id="20" string="ca" />
            <token id="21" string="n't" />
            <token id="22" string="ask" />
            <token id="23" string="for" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="14" string="ask for anything more" type="VP">
          <tokens>
            <token id="22" string="ask" />
            <token id="23" string="for" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="28" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="the best I can be" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="best" />
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="I can be" type="SBAR">
          <tokens>
            <token id="15" string="I" />
            <token id="16" string="can" />
            <token id="17" string="be" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">come</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">come</governor>
          <dependent id="3">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="4">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">grips</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">come</governor>
          <dependent id="6">grips</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">fact</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">fact</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">grips</governor>
          <dependent id="9">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">best</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">best</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">best</governor>
          <dependent id="12">'m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">best</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">come</governor>
          <dependent id="14">best</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">be</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">be</governor>
          <dependent id="16">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">best</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">best</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">ask</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">ask</governor>
          <dependent id="20">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">ask</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">best</governor>
          <dependent id="22">ask</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">anything</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">ask</governor>
          <dependent id="24">anything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">ask</governor>
          <dependent id="25">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m doing what is right.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (VP (VBG doing) (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADJP (RB right))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m doing what is right" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="doing" />
            <token id="5" string="what" />
            <token id="6" string="is" />
            <token id="7" string="right" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="what is right" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="is" />
            <token id="7" string="right" />
          </tokens>
        </chunking>
        <chunking id="4" string="doing what is right" type="VP">
          <tokens>
            <token id="4" string="doing" />
            <token id="5" string="what" />
            <token id="6" string="is" />
            <token id="7" string="right" />
          </tokens>
        </chunking>
        <chunking id="5" string="right" type="ADJP">
          <tokens>
            <token id="7" string="right" />
          </tokens>
        </chunking>
        <chunking id="6" string="is right" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="right" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">doing</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">doing</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">doing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">right</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">right</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">doing</governor>
          <dependent id="7">right</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>I have to feel there is some merit to that.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="merit" lemma="merit" stem="merit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP have) (S (VP (TO to) (VP (VB feel) (SBAR (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT some) (NN merit)) (PP (TO to) (NP (DT that))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="5" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="some merit" type="NP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="merit" />
          </tokens>
        </chunking>
        <chunking id="4" string="have to feel there is some merit to that" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="to" />
            <token id="4" string="feel" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="to feel there is some merit to that" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="feel" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="there is some merit to that" type="SBAR">
          <tokens>
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="8" string="is some merit to that" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="9" string="feel there is some merit to that" type="VP">
          <tokens>
            <token id="4" string="feel" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="some merit to that" type="NP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="merit" />
            <token id="9" string="to" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">have</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">feel</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">have</governor>
          <dependent id="4">feel</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="6">is</governor>
          <dependent id="5">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">feel</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">merit</governor>
          <dependent id="7">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="8">merit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">that</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">merit</governor>
          <dependent id="10">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>It didn&amp;apost;t ease the pain of not winning and feeling he (Johnson) was on drugs.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="ease" lemma="ease" stem="eas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pain" lemma="pain" stem="pain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="feeling" lemma="feel" stem="feel" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD did) (RB n't) (VP (VB ease) (SBAR (S (NP (NP (NP (DT the) (NN pain)) (PP (IN of) (S (RB not) (VP (VBG winning) (CC and) (VBG feeling) (NP (PRP he)))))) (PRN (-LRB- -LRB-) (NP (NNP Johnson)) (-RRB- -RRB-))) (VP (VBD was) (PP (IN on) (NP (NNS drugs)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was on drugs" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="on" />
            <token id="18" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the pain of not winning and feeling he" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pain" />
            <token id="7" string="of" />
            <token id="8" string="not" />
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="4" string="the pain of not winning and feeling he -LRB- Johnson -RRB- was on drugs" type="SBAR">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pain" />
            <token id="7" string="of" />
            <token id="8" string="not" />
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
            <token id="13" string="(" />
            <token id="14" string="Johnson" />
            <token id="15" string=")" />
            <token id="16" string="was" />
            <token id="17" string="on" />
            <token id="18" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="winning and feeling he" type="VP">
          <tokens>
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="drugs" type="NP">
          <tokens>
            <token id="18" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="the pain" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pain" />
          </tokens>
        </chunking>
        <chunking id="8" string="did n't ease the pain of not winning and feeling he -LRB- Johnson -RRB- was on drugs" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="ease" />
            <token id="5" string="the" />
            <token id="6" string="pain" />
            <token id="7" string="of" />
            <token id="8" string="not" />
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
            <token id="13" string="(" />
            <token id="14" string="Johnson" />
            <token id="15" string=")" />
            <token id="16" string="was" />
            <token id="17" string="on" />
            <token id="18" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="ease the pain of not winning and feeling he -LRB- Johnson -RRB- was on drugs" type="VP">
          <tokens>
            <token id="4" string="ease" />
            <token id="5" string="the" />
            <token id="6" string="pain" />
            <token id="7" string="of" />
            <token id="8" string="not" />
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
            <token id="13" string="(" />
            <token id="14" string="Johnson" />
            <token id="15" string=")" />
            <token id="16" string="was" />
            <token id="17" string="on" />
            <token id="18" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="10" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="11" string="the pain of not winning and feeling he -LRB- Johnson -RRB-" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pain" />
            <token id="7" string="of" />
            <token id="8" string="not" />
            <token id="9" string="winning" />
            <token id="10" string="and" />
            <token id="11" string="feeling" />
            <token id="12" string="he" />
            <token id="13" string="(" />
            <token id="14" string="Johnson" />
            <token id="15" string=")" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">ease</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">ease</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">ease</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">ease</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">pain</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">drugs</governor>
          <dependent id="6">pain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">winning</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">winning</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">pain</governor>
          <dependent id="9">winning</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">winning</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">winning</governor>
          <dependent id="11">feeling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">winning</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">pain</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">drugs</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">drugs</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">ease</governor>
          <dependent id="18">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>But it made me feel like I&amp;apost;m putting something back into track and field because I&amp;apost;m setting an example.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="putting" lemma="put" stem="put" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="setting" lemma="set" stem="set" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBD made) (S (NP (PRP me)) (VP (VB feel) (SBAR (IN like) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG putting) (NP (NN something)) (ADVP (RB back)) (PP (IN into) (NP (NN track) (CC and) (NN field))))))))) (SBAR (IN because) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG setting) (NP (DT an) (NN example))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="because I 'm setting an example" type="SBAR">
          <tokens>
            <token id="16" string="because" />
            <token id="17" string="I" />
            <token id="18" string="'m" />
            <token id="19" string="setting" />
            <token id="20" string="an" />
            <token id="21" string="example" />
          </tokens>
        </chunking>
        <chunking id="2" string="putting something back into track and field" type="VP">
          <tokens>
            <token id="9" string="putting" />
            <token id="10" string="something" />
            <token id="11" string="back" />
            <token id="12" string="into" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
        <chunking id="3" string="like I 'm putting something back into track and field" type="SBAR">
          <tokens>
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="putting" />
            <token id="10" string="something" />
            <token id="11" string="back" />
            <token id="12" string="into" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="setting an example" type="VP">
          <tokens>
            <token id="19" string="setting" />
            <token id="20" string="an" />
            <token id="21" string="example" />
          </tokens>
        </chunking>
        <chunking id="7" string="something" type="NP">
          <tokens>
            <token id="10" string="something" />
          </tokens>
        </chunking>
        <chunking id="8" string="track and field" type="NP">
          <tokens>
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
        <chunking id="9" string="'m setting an example" type="VP">
          <tokens>
            <token id="18" string="'m" />
            <token id="19" string="setting" />
            <token id="20" string="an" />
            <token id="21" string="example" />
          </tokens>
        </chunking>
        <chunking id="10" string="an example" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="example" />
          </tokens>
        </chunking>
        <chunking id="11" string="feel like I 'm putting something back into track and field" type="VP">
          <tokens>
            <token id="5" string="feel" />
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="putting" />
            <token id="10" string="something" />
            <token id="11" string="back" />
            <token id="12" string="into" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
        <chunking id="12" string="made me feel like I 'm putting something back into track and field because I 'm setting an example" type="VP">
          <tokens>
            <token id="3" string="made" />
            <token id="4" string="me" />
            <token id="5" string="feel" />
            <token id="6" string="like" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="putting" />
            <token id="10" string="something" />
            <token id="11" string="back" />
            <token id="12" string="into" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="because" />
            <token id="17" string="I" />
            <token id="18" string="'m" />
            <token id="19" string="setting" />
            <token id="20" string="an" />
            <token id="21" string="example" />
          </tokens>
        </chunking>
        <chunking id="13" string="me" type="NP">
          <tokens>
            <token id="4" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="'m putting something back into track and field" type="VP">
          <tokens>
            <token id="8" string="'m" />
            <token id="9" string="putting" />
            <token id="10" string="something" />
            <token id="11" string="back" />
            <token id="12" string="into" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">made</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">made</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">feel</governor>
          <dependent id="4">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">made</governor>
          <dependent id="5">feel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">putting</governor>
          <dependent id="6">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">putting</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">putting</governor>
          <dependent id="8">'m</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">feel</governor>
          <dependent id="9">putting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">putting</governor>
          <dependent id="10">something</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">putting</governor>
          <dependent id="11">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">track</governor>
          <dependent id="12">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">putting</governor>
          <dependent id="13">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">track</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">track</governor>
          <dependent id="15">field</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">setting</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">setting</governor>
          <dependent id="17">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">setting</governor>
          <dependent id="18">'m</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">made</governor>
          <dependent id="19">setting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">example</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">setting</governor>
          <dependent id="21">example</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>Lewis called for Johnson to also become a role model.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD called) (PP (IN for) (NP (NNP Johnson))) (S (VP (TO to) (VP (ADVP (RB also)) (VB become) (NP (DT a) (NN role) (NN model)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to also become a role model" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="also" />
            <token id="7" string="become" />
            <token id="8" string="a" />
            <token id="9" string="role" />
            <token id="10" string="model" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="a role model" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="role" />
            <token id="10" string="model" />
          </tokens>
        </chunking>
        <chunking id="4" string="called for Johnson to also become a role model" type="VP">
          <tokens>
            <token id="2" string="called" />
            <token id="3" string="for" />
            <token id="4" string="Johnson" />
            <token id="5" string="to" />
            <token id="6" string="also" />
            <token id="7" string="become" />
            <token id="8" string="a" />
            <token id="9" string="role" />
            <token id="10" string="model" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="6" string="also become a role model" type="VP">
          <tokens>
            <token id="6" string="also" />
            <token id="7" string="become" />
            <token id="8" string="a" />
            <token id="9" string="role" />
            <token id="10" string="model" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">called</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Johnson</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">called</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">become</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">become</governor>
          <dependent id="6">also</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">called</governor>
          <dependent id="7">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">model</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">model</governor>
          <dependent id="9">role</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">become</governor>
          <dependent id="10">model</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>&amp;quot;I think Ben is 110% irresponsible in not coming out and telling kids to stay off drugs,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="110" lemma="110" stem="110" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="7" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="8" string="irresponsible" lemma="irresponsible" stem="irrespons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="kids" lemma="kid" stem="kid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (NNP Ben)) (VP (VBZ is) (ADJP (NP (CD 110) (NN %)) (JJ irresponsible) (PP (IN in) (S (RB not) (VP (VP (VBG coming) (ADVP (RB out))) (CC and) (VP (VBG telling) (NP (NNS kids)) (S (VP (TO to) (VP (VB stay) (PRT (RP off)) (NP (NNS drugs))))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drugs" type="NP">
          <tokens>
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="110 % irresponsible in not coming out and telling kids to stay off drugs" type="ADJP">
          <tokens>
            <token id="6" string="110" />
            <token id="7" string="%" />
            <token id="8" string="irresponsible" />
            <token id="9" string="in" />
            <token id="10" string="not" />
            <token id="11" string="coming" />
            <token id="12" string="out" />
            <token id="13" string="and" />
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ben" type="NP">
          <tokens>
            <token id="4" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="5" string="is 110 % irresponsible in not coming out and telling kids to stay off drugs" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="110" />
            <token id="7" string="%" />
            <token id="8" string="irresponsible" />
            <token id="9" string="in" />
            <token id="10" string="not" />
            <token id="11" string="coming" />
            <token id="12" string="out" />
            <token id="13" string="and" />
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="coming out and telling kids to stay off drugs" type="VP">
          <tokens>
            <token id="11" string="coming" />
            <token id="12" string="out" />
            <token id="13" string="and" />
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="telling kids to stay off drugs" type="VP">
          <tokens>
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="to stay off drugs" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="stay off drugs" type="VP">
          <tokens>
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ben is 110 % irresponsible in not coming out and telling kids to stay off drugs" type="SBAR">
          <tokens>
            <token id="4" string="Ben" />
            <token id="5" string="is" />
            <token id="6" string="110" />
            <token id="7" string="%" />
            <token id="8" string="irresponsible" />
            <token id="9" string="in" />
            <token id="10" string="not" />
            <token id="11" string="coming" />
            <token id="12" string="out" />
            <token id="13" string="and" />
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="11" string="think Ben is 110 % irresponsible in not coming out and telling kids to stay off drugs" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="Ben" />
            <token id="5" string="is" />
            <token id="6" string="110" />
            <token id="7" string="%" />
            <token id="8" string="irresponsible" />
            <token id="9" string="in" />
            <token id="10" string="not" />
            <token id="11" string="coming" />
            <token id="12" string="out" />
            <token id="13" string="and" />
            <token id="14" string="telling" />
            <token id="15" string="kids" />
            <token id="16" string="to" />
            <token id="17" string="stay" />
            <token id="18" string="off" />
            <token id="19" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="coming out" type="VP">
          <tokens>
            <token id="11" string="coming" />
            <token id="12" string="out" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="110 %" type="NP">
          <tokens>
            <token id="6" string="110" />
            <token id="7" string="%" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="kids" type="NP">
          <tokens>
            <token id="15" string="kids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">irresponsible</governor>
          <dependent id="4">Ben</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">irresponsible</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">%</governor>
          <dependent id="6">110</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="8">irresponsible</governor>
          <dependent id="7">%</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="8">irresponsible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">coming</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">coming</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">irresponsible</governor>
          <dependent id="11">coming</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">coming</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">coming</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">coming</governor>
          <dependent id="14">telling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">telling</governor>
          <dependent id="15">kids</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">stay</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">telling</governor>
          <dependent id="17">stay</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">stay</governor>
          <dependent id="18">off</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">stay</governor>
          <dependent id="19">drugs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Ben" />
          </tokens>
        </entity>
        <entity id="3" string="110 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="6" string="110" />
            <token id="7" string="%" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>&amp;quot;He needs to stand up and say, &amp;apost;Don&amp;apost;t do it.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="needs" lemma="need" stem="need" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP He)) (VP (VBZ needs) (S (VP (TO to) (VP (VP (VB stand) (PRT (RP up))) (CC and) (VP (VB say))))))) (, ,) (VP (`` `) (VBP Do) (RB n't) (VP (VB do))) (NP (PRP it)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="needs to stand up and say" type="VP">
          <tokens>
            <token id="3" string="needs" />
            <token id="4" string="to" />
            <token id="5" string="stand" />
            <token id="6" string="up" />
            <token id="7" string="and" />
            <token id="8" string="say" />
          </tokens>
        </chunking>
        <chunking id="2" string="to stand up and say" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="stand" />
            <token id="6" string="up" />
            <token id="7" string="and" />
            <token id="8" string="say" />
          </tokens>
        </chunking>
        <chunking id="3" string="stand up" type="VP">
          <tokens>
            <token id="5" string="stand" />
            <token id="6" string="up" />
          </tokens>
        </chunking>
        <chunking id="4" string="do" type="VP">
          <tokens>
            <token id="13" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="stand up and say" type="VP">
          <tokens>
            <token id="5" string="stand" />
            <token id="6" string="up" />
            <token id="7" string="and" />
            <token id="8" string="say" />
          </tokens>
        </chunking>
        <chunking id="7" string="say" type="VP">
          <tokens>
            <token id="8" string="say" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="` Do n't do" type="VP">
          <tokens>
            <token id="10" string="'" />
            <token id="11" string="Do" />
            <token id="12" string="n't" />
            <token id="13" string="do" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">needs</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">do</governor>
          <dependent id="3">needs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">stand</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">needs</governor>
          <dependent id="5">stand</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">stand</governor>
          <dependent id="6">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">stand</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">stand</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">do</governor>
          <dependent id="11">Do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">do</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">do</governor>
          <dependent id="14">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Look what happened to me whether I knew it or not, make sure you know.</content>
      <tokens>
        <token id="1" string="Look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VB Look) (SBAR (WHNP (WP what)) (S (VP (VBD happened) (PP (TO to) (NP (PRP me))) (SBAR (IN whether) (S (NP (PRP I)) (VP (VBD knew) (NP (PRP it)))) (CC or) (RB not))))))) (, ,) (VP (VBP make) (ADJP (JJ sure) (SBAR (S (NP (PRP you)) (VP (VBP know)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="knew it" type="VP">
          <tokens>
            <token id="8" string="knew" />
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="make sure you know" type="VP">
          <tokens>
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="you" />
            <token id="16" string="know" />
          </tokens>
        </chunking>
        <chunking id="3" string="happened to me whether I knew it or not" type="VP">
          <tokens>
            <token id="3" string="happened" />
            <token id="4" string="to" />
            <token id="5" string="me" />
            <token id="6" string="whether" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="it" />
            <token id="10" string="or" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="Look what happened to me whether I knew it or not" type="VP">
          <tokens>
            <token id="1" string="Look" />
            <token id="2" string="what" />
            <token id="3" string="happened" />
            <token id="4" string="to" />
            <token id="5" string="me" />
            <token id="6" string="whether" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="it" />
            <token id="10" string="or" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="7" string="what happened to me whether I knew it or not" type="SBAR">
          <tokens>
            <token id="2" string="what" />
            <token id="3" string="happened" />
            <token id="4" string="to" />
            <token id="5" string="me" />
            <token id="6" string="whether" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="it" />
            <token id="10" string="or" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="8" string="you know" type="SBAR">
          <tokens>
            <token id="15" string="you" />
            <token id="16" string="know" />
          </tokens>
        </chunking>
        <chunking id="9" string="me" type="NP">
          <tokens>
            <token id="5" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="whether I knew it or not" type="SBAR">
          <tokens>
            <token id="6" string="whether" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="it" />
            <token id="10" string="or" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="11" string="know" type="VP">
          <tokens>
            <token id="16" string="know" />
          </tokens>
        </chunking>
        <chunking id="12" string="sure you know" type="ADJP">
          <tokens>
            <token id="14" string="sure" />
            <token id="15" string="you" />
            <token id="16" string="know" />
          </tokens>
        </chunking>
        <chunking id="13" string="you" type="NP">
          <tokens>
            <token id="15" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="13">make</governor>
          <dependent id="1">Look</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">happened</governor>
          <dependent id="2">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Look</governor>
          <dependent id="3">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">me</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">happened</governor>
          <dependent id="5">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">knew</governor>
          <dependent id="6">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">knew</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">happened</governor>
          <dependent id="8">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">knew</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">knew</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">knew</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">make</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">make</governor>
          <dependent id="14">sure</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">know</governor>
          <dependent id="15">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">sure</governor>
          <dependent id="16">know</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>Don&amp;apost;t take it unless you know what it is.&amp;apost;</content>
      <tokens>
        <token id="1" string="Do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="unless" lemma="unless" stem="unless" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBP Do) (RB n't) (VP (VB take) (NP (PRP it)) (SBAR (IN unless) (S (NP (PRP you)) (VP (VBP know) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VBZ is))))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Do n't take it unless you know what it is" type="VP">
          <tokens>
            <token id="1" string="Do" />
            <token id="2" string="n't" />
            <token id="3" string="take" />
            <token id="4" string="it" />
            <token id="5" string="unless" />
            <token id="6" string="you" />
            <token id="7" string="know" />
            <token id="8" string="what" />
            <token id="9" string="it" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="2" string="is" type="VP">
          <tokens>
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="unless you know what it is" type="SBAR">
          <tokens>
            <token id="5" string="unless" />
            <token id="6" string="you" />
            <token id="7" string="know" />
            <token id="8" string="what" />
            <token id="9" string="it" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="5" string="know what it is" type="VP">
          <tokens>
            <token id="7" string="know" />
            <token id="8" string="what" />
            <token id="9" string="it" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="6" string="take it unless you know what it is" type="VP">
          <tokens>
            <token id="3" string="take" />
            <token id="4" string="it" />
            <token id="5" string="unless" />
            <token id="6" string="you" />
            <token id="7" string="know" />
            <token id="8" string="what" />
            <token id="9" string="it" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
        <chunking id="7" string="you" type="NP">
          <tokens>
            <token id="6" string="you" />
          </tokens>
        </chunking>
        <chunking id="8" string="what it is" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="it" />
            <token id="10" string="is" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="3">take</governor>
          <dependent id="1">Do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">take</governor>
          <dependent id="2">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">take</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">know</governor>
          <dependent id="5">unless</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">know</governor>
          <dependent id="6">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">take</governor>
          <dependent id="7">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">is</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">know</governor>
          <dependent id="10">is</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>&amp;quot;But he is perpetuating continued drug use.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="perpetuating" lemma="perpetuate" stem="perpetu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="continued" lemma="continue" stem="continu" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP he)) (VP (VBZ is) (VP (VBG perpetuating) (S (NP (VBN continued) (NN drug) (NN use))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is perpetuating continued drug use" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="perpetuating" />
            <token id="6" string="continued" />
            <token id="7" string="drug" />
            <token id="8" string="use" />
          </tokens>
        </chunking>
        <chunking id="2" string="perpetuating continued drug use" type="VP">
          <tokens>
            <token id="5" string="perpetuating" />
            <token id="6" string="continued" />
            <token id="7" string="drug" />
            <token id="8" string="use" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="4" string="continued drug use" type="NP">
          <tokens>
            <token id="6" string="continued" />
            <token id="7" string="drug" />
            <token id="8" string="use" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">perpetuating</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">perpetuating</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">perpetuating</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">perpetuating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">use</governor>
          <dependent id="6">continued</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">use</governor>
          <dependent id="7">drug</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">perpetuating</governor>
          <dependent id="8">use</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>I think he&amp;apost;s just lying to himself.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lying" lemma="lie" stem="ly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP he)) (VP (VBZ 's) (ADVP (RB just)) (VP (VBG lying) (PP (TO to) (NP (PRP himself)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="think he 's just lying to himself" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="he" />
            <token id="4" string="'s" />
            <token id="5" string="just" />
            <token id="6" string="lying" />
            <token id="7" string="to" />
            <token id="8" string="himself" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s just lying to himself" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="just" />
            <token id="6" string="lying" />
            <token id="7" string="to" />
            <token id="8" string="himself" />
          </tokens>
        </chunking>
        <chunking id="3" string="he 's just lying to himself" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="'s" />
            <token id="5" string="just" />
            <token id="6" string="lying" />
            <token id="7" string="to" />
            <token id="8" string="himself" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="lying to himself" type="VP">
          <tokens>
            <token id="6" string="lying" />
            <token id="7" string="to" />
            <token id="8" string="himself" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="himself" type="NP">
          <tokens>
            <token id="8" string="himself" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">lying</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">lying</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">lying</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="6">lying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">himself</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lying</governor>
          <dependent id="8">himself</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>The biggest thing about drug use is denial.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="biggest" lemma="biggest" stem="biggest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="denial" lemma="denial" stem="denial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJS biggest) (NN thing)) (PP (IN about) (NP (NN drug) (NN use)))) (VP (VBZ is) (NP (NN denial))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="denial" type="NP">
          <tokens>
            <token id="8" string="denial" />
          </tokens>
        </chunking>
        <chunking id="2" string="drug use" type="NP">
          <tokens>
            <token id="5" string="drug" />
            <token id="6" string="use" />
          </tokens>
        </chunking>
        <chunking id="3" string="The biggest thing about drug use" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="biggest" />
            <token id="3" string="thing" />
            <token id="4" string="about" />
            <token id="5" string="drug" />
            <token id="6" string="use" />
          </tokens>
        </chunking>
        <chunking id="4" string="The biggest thing" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="biggest" />
            <token id="3" string="thing" />
          </tokens>
        </chunking>
        <chunking id="5" string="is denial" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="denial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">thing</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">thing</governor>
          <dependent id="2">biggest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">denial</governor>
          <dependent id="3">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">use</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">use</governor>
          <dependent id="5">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">thing</governor>
          <dependent id="6">use</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">denial</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">denial</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="58" has_coreference="false">
      <content>Somebody takes cocaine because they want to get high.</content>
      <tokens>
        <token id="1" string="Somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cocaine" lemma="cocaine" stem="cocain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Somebody)) (VP (VBZ takes) (NP (NN cocaine)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBP want) (S (VP (TO to) (VP (VB get) (ADJP (JJ high))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="high" type="ADJP">
          <tokens>
            <token id="9" string="high" />
          </tokens>
        </chunking>
        <chunking id="3" string="takes cocaine because they want to get high" type="VP">
          <tokens>
            <token id="2" string="takes" />
            <token id="3" string="cocaine" />
            <token id="4" string="because" />
            <token id="5" string="they" />
            <token id="6" string="want" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
        <chunking id="4" string="cocaine" type="NP">
          <tokens>
            <token id="3" string="cocaine" />
          </tokens>
        </chunking>
        <chunking id="5" string="Somebody" type="NP">
          <tokens>
            <token id="1" string="Somebody" />
          </tokens>
        </chunking>
        <chunking id="6" string="to get high" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
        <chunking id="7" string="because they want to get high" type="SBAR">
          <tokens>
            <token id="4" string="because" />
            <token id="5" string="they" />
            <token id="6" string="want" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
        <chunking id="8" string="want to get high" type="VP">
          <tokens>
            <token id="6" string="want" />
            <token id="7" string="to" />
            <token id="8" string="get" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
        <chunking id="9" string="get high" type="VP">
          <tokens>
            <token id="8" string="get" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">takes</governor>
          <dependent id="1">Somebody</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">takes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">takes</governor>
          <dependent id="3">cocaine</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">want</governor>
          <dependent id="4">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">want</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">takes</governor>
          <dependent id="6">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">get</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">want</governor>
          <dependent id="8">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">get</governor>
          <dependent id="9">high</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="59" has_coreference="false">
      <content>Some people take steroids because they want to run faster.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="faster" lemma="faster" stem="faster" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (NNS people)) (VP (VBP take) (NP (NNS steroids)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBP want) (S (VP (TO to) (VP (VB run) (ADVP (RBR faster))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="run faster" type="VP">
          <tokens>
            <token id="9" string="run" />
            <token id="10" string="faster" />
          </tokens>
        </chunking>
        <chunking id="3" string="take steroids because they want to run faster" type="VP">
          <tokens>
            <token id="3" string="take" />
            <token id="4" string="steroids" />
            <token id="5" string="because" />
            <token id="6" string="they" />
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="faster" />
          </tokens>
        </chunking>
        <chunking id="4" string="want to run faster" type="VP">
          <tokens>
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="faster" />
          </tokens>
        </chunking>
        <chunking id="5" string="to run faster" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="faster" />
          </tokens>
        </chunking>
        <chunking id="6" string="Some people" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="steroids" type="NP">
          <tokens>
            <token id="4" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="8" string="because they want to run faster" type="SBAR">
          <tokens>
            <token id="5" string="because" />
            <token id="6" string="they" />
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="faster" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">people</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">take</governor>
          <dependent id="2">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">take</governor>
          <dependent id="4">steroids</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">want</governor>
          <dependent id="5">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">want</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">take</governor>
          <dependent id="7">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">run</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">want</governor>
          <dependent id="9">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">run</governor>
          <dependent id="10">faster</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>It&amp;apost;s the same thing.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (NP (DT the) (JJ same) (NN thing))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the same thing" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="same" />
            <token id="5" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s the same thing" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="the" />
            <token id="4" string="same" />
            <token id="5" string="thing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">thing</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">thing</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">thing</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">thing</governor>
          <dependent id="4">same</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">thing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="61" has_coreference="false">
      <content>You&amp;apost;re trying to cheat somehow.&amp;quot;</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="cheat" lemma="cheat" stem="cheat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="somehow" lemma="somehow" stem="somehow" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (VBP 're) (VP (VBG trying) (S (VP (TO to) (VP (VB cheat) (ADVP (RB somehow))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'re trying to cheat somehow" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="trying" />
            <token id="4" string="to" />
            <token id="5" string="cheat" />
            <token id="6" string="somehow" />
          </tokens>
        </chunking>
        <chunking id="2" string="trying to cheat somehow" type="VP">
          <tokens>
            <token id="3" string="trying" />
            <token id="4" string="to" />
            <token id="5" string="cheat" />
            <token id="6" string="somehow" />
          </tokens>
        </chunking>
        <chunking id="3" string="cheat somehow" type="VP">
          <tokens>
            <token id="5" string="cheat" />
            <token id="6" string="somehow" />
          </tokens>
        </chunking>
        <chunking id="4" string="to cheat somehow" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="cheat" />
            <token id="6" string="somehow" />
          </tokens>
        </chunking>
        <chunking id="5" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">trying</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">trying</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">cheat</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">trying</governor>
          <dependent id="5">cheat</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">cheat</governor>
          <dependent id="6">somehow</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>Lewis, who won four gold medals at the 1984 Summer Games and has been one of the great sprinters and long jumpers in track and field, said he is determined to help the sport&amp;apost;s image.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="6" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="medals" lemma="medal" stem="medal" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="11" string="Summer" lemma="Summer" stem="summer" pos="NNPS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="true" />
        <token id="12" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="sprinters" lemma="sprinter" stem="sprinter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="jumpers" lemma="jumper" stem="jumper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="determined" lemma="determine" stem="determin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Lewis)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBD won) (NP (CD four) (NN gold) (NNS medals)) (PP (IN at) (NP (DT the) (CD 1984) (NNPS Summer) (NNPS Games)))) (CC and) (VP (VBZ has) (VP (VBN been) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJ great) (NNS sprinters)) (CC and) (NP (JJ long) (NNS jumpers))))) (PP (IN in) (NP (NN track) (CC and) (NN field)))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ is) (VP (VBN determined) (S (VP (TO to) (VP (VB help) (NP (NP (DT the) (NN sport) (POS 's)) (NN image)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="determined to help the sport 's image" type="VP">
          <tokens>
            <token id="32" string="determined" />
            <token id="33" string="to" />
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="2" string="is determined to help the sport 's image" type="VP">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="determined" />
            <token id="33" string="to" />
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="3" string="four gold medals" type="NP">
          <tokens>
            <token id="5" string="four" />
            <token id="6" string="gold" />
            <token id="7" string="medals" />
          </tokens>
        </chunking>
        <chunking id="4" string="been one of the great sprinters and long jumpers in track and field" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
            <token id="24" string="in" />
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="the great sprinters" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
          </tokens>
        </chunking>
        <chunking id="7" string="who won four gold medals at the 1984 Summer Games and has been one of the great sprinters and long jumpers in track and field" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="won" />
            <token id="5" string="four" />
            <token id="6" string="gold" />
            <token id="7" string="medals" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="1984" />
            <token id="11" string="Summer" />
            <token id="12" string="Games" />
            <token id="13" string="and" />
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
            <token id="24" string="in" />
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="8" string="one of the great sprinters and long jumpers" type="NP">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
          </tokens>
        </chunking>
        <chunking id="9" string="he is determined to help the sport 's image" type="SBAR">
          <tokens>
            <token id="30" string="he" />
            <token id="31" string="is" />
            <token id="32" string="determined" />
            <token id="33" string="to" />
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="10" string="won four gold medals at the 1984 Summer Games" type="VP">
          <tokens>
            <token id="4" string="won" />
            <token id="5" string="four" />
            <token id="6" string="gold" />
            <token id="7" string="medals" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="1984" />
            <token id="11" string="Summer" />
            <token id="12" string="Games" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lewis , who won four gold medals at the 1984 Summer Games and has been one of the great sprinters and long jumpers in track and field ," type="NP">
          <tokens>
            <token id="1" string="Lewis" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="won" />
            <token id="5" string="four" />
            <token id="6" string="gold" />
            <token id="7" string="medals" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="1984" />
            <token id="11" string="Summer" />
            <token id="12" string="Games" />
            <token id="13" string="and" />
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
            <token id="24" string="in" />
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
            <token id="28" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="track and field" type="NP">
          <tokens>
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="13" string="to help the sport 's image" type="VP">
          <tokens>
            <token id="33" string="to" />
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="14" string="the sport 's image" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="15" string="said he is determined to help the sport 's image" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="he" />
            <token id="31" string="is" />
            <token id="32" string="determined" />
            <token id="33" string="to" />
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="16" string="the sport 's" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="won four gold medals at the 1984 Summer Games and has been one of the great sprinters and long jumpers in track and field" type="VP">
          <tokens>
            <token id="4" string="won" />
            <token id="5" string="four" />
            <token id="6" string="gold" />
            <token id="7" string="medals" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="1984" />
            <token id="11" string="Summer" />
            <token id="12" string="Games" />
            <token id="13" string="and" />
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
            <token id="24" string="in" />
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="18" string="has been one of the great sprinters and long jumpers in track and field" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
            <token id="24" string="in" />
            <token id="25" string="track" />
            <token id="26" string="and" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="19" string="help the sport 's image" type="VP">
          <tokens>
            <token id="34" string="help" />
            <token id="35" string="the" />
            <token id="36" string="sport" />
            <token id="37" string="'s" />
            <token id="38" string="image" />
          </tokens>
        </chunking>
        <chunking id="20" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="21" string="the great sprinters and long jumpers" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="great" />
            <token id="20" string="sprinters" />
            <token id="21" string="and" />
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
          </tokens>
        </chunking>
        <chunking id="22" string="long jumpers" type="NP">
          <tokens>
            <token id="22" string="long" />
            <token id="23" string="jumpers" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="30" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="the 1984 Summer Games" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="1984" />
            <token id="11" string="Summer" />
            <token id="12" string="Games" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">won</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Lewis</governor>
          <dependent id="4">won</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">medals</governor>
          <dependent id="5">four</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">medals</governor>
          <dependent id="6">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">won</governor>
          <dependent id="7">medals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Games</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Games</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Games</governor>
          <dependent id="10">1984</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Games</governor>
          <dependent id="11">Summer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">won</governor>
          <dependent id="12">Games</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">won</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">one</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">one</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">won</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">sprinters</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sprinters</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sprinters</governor>
          <dependent id="19">great</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">one</governor>
          <dependent id="20">sprinters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">sprinters</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">jumpers</governor>
          <dependent id="22">long</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">sprinters</governor>
          <dependent id="23">jumpers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">track</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">one</governor>
          <dependent id="25">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">track</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">track</governor>
          <dependent id="27">field</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">determined</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">determined</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="32">determined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">help</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">determined</governor>
          <dependent id="34">help</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">sport</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">image</governor>
          <dependent id="36">sport</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">sport</governor>
          <dependent id="37">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">help</governor>
          <dependent id="38">image</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="four" />
          </tokens>
        </entity>
        <entity id="4" string="Games" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Games" />
          </tokens>
        </entity>
        <entity id="5" string="Summer" type="SET" score="0.0">
          <tokens>
            <token id="11" string="Summer" />
          </tokens>
        </entity>
        <entity id="6" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>&amp;quot;That&amp;apost;s what people don&amp;apost;t realize,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="realize" lemma="realize" stem="realiz" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT That)) (VP (VBZ 's) (SBAR (WHNP (WP what)) (S (NP (NNS people)) (VP (VBP do) (RB n't) (VP (VB realize))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="what people do n't realize" type="SBAR">
          <tokens>
            <token id="4" string="what" />
            <token id="5" string="people" />
            <token id="6" string="do" />
            <token id="7" string="n't" />
            <token id="8" string="realize" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't realize" type="VP">
          <tokens>
            <token id="6" string="do" />
            <token id="7" string="n't" />
            <token id="8" string="realize" />
          </tokens>
        </chunking>
        <chunking id="4" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="realize" type="VP">
          <tokens>
            <token id="8" string="realize" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s what people do n't realize" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="what" />
            <token id="5" string="people" />
            <token id="6" string="do" />
            <token id="7" string="n't" />
            <token id="8" string="realize" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">'s</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">realize</governor>
          <dependent id="4">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">realize</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">realize</governor>
          <dependent id="6">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">realize</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">'s</governor>
          <dependent id="8">realize</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>&amp;quot;I could leave it all alone but the thing is, I want track to be a better sport than when I came.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="leave" lemma="leave" stem="leav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD could) (VP (VB leave) (NP (PRP it)) (ADVP (DT all) (RB alone))))) (CC but) (S (NP (DT the) (NN thing)) (VP (VBZ is) (, ,) (SBAR (S (NP (PRP I)) (VP (VBP want) (NP (NN track)) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (JJR better) (NN sport)) (PP (IN than) (SBAR (WHADVP (WRB when)) (S (NP (PRP I)) (VP (VBD came)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when I came" type="SBAR">
          <tokens>
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="2" string="a better sport than when I came" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be a better sport than when I came" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="is , I want track to be a better sport than when I came" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="," />
            <token id="13" string="I" />
            <token id="14" string="want" />
            <token id="15" string="track" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="22" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="I want track to be a better sport than when I came" type="SBAR">
          <tokens>
            <token id="13" string="I" />
            <token id="14" string="want" />
            <token id="15" string="track" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="9" string="a better sport" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
          </tokens>
        </chunking>
        <chunking id="10" string="could leave it all alone" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="leave" />
            <token id="5" string="it" />
            <token id="6" string="all" />
            <token id="7" string="alone" />
          </tokens>
        </chunking>
        <chunking id="11" string="want track to be a better sport than when I came" type="VP">
          <tokens>
            <token id="14" string="want" />
            <token id="15" string="track" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="12" string="leave it all alone" type="VP">
          <tokens>
            <token id="4" string="leave" />
            <token id="5" string="it" />
            <token id="6" string="all" />
            <token id="7" string="alone" />
          </tokens>
        </chunking>
        <chunking id="13" string="be a better sport than when I came" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="a" />
            <token id="19" string="better" />
            <token id="20" string="sport" />
            <token id="21" string="than" />
            <token id="22" string="when" />
            <token id="23" string="I" />
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="14" string="came" type="VP">
          <tokens>
            <token id="24" string="came" />
          </tokens>
        </chunking>
        <chunking id="15" string="track" type="NP">
          <tokens>
            <token id="15" string="track" />
          </tokens>
        </chunking>
        <chunking id="16" string="the thing" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="thing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">leave</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">leave</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">leave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">leave</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">alone</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">leave</governor>
          <dependent id="7">alone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">leave</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">thing</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">is</governor>
          <dependent id="10">thing</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">leave</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">want</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">is</governor>
          <dependent id="14">want</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">want</governor>
          <dependent id="15">track</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">sport</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">sport</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sport</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sport</governor>
          <dependent id="19">better</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">want</governor>
          <dependent id="20">sport</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">came</governor>
          <dependent id="21">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">came</governor>
          <dependent id="22">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">came</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">sport</governor>
          <dependent id="24">came</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>If anybody gets what they deserve in track and field, it&amp;apost;s me.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="anybody" lemma="anybody" stem="anybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="deserve" lemma="deserve" stem="deserv" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (NN anybody)) (VP (VBZ gets) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP deserve) (PP (IN in) (NP (NN track) (CC and) (NN field))))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (NP (PRP me))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If anybody gets what they deserve in track and field" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="anybody" />
            <token id="3" string="gets" />
            <token id="4" string="what" />
            <token id="5" string="they" />
            <token id="6" string="deserve" />
            <token id="7" string="in" />
            <token id="8" string="track" />
            <token id="9" string="and" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s me" type="VP">
          <tokens>
            <token id="13" string="'s" />
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="anybody" type="NP">
          <tokens>
            <token id="2" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="5" string="me" type="NP">
          <tokens>
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="what they deserve in track and field" type="SBAR">
          <tokens>
            <token id="4" string="what" />
            <token id="5" string="they" />
            <token id="6" string="deserve" />
            <token id="7" string="in" />
            <token id="8" string="track" />
            <token id="9" string="and" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="deserve in track and field" type="VP">
          <tokens>
            <token id="6" string="deserve" />
            <token id="7" string="in" />
            <token id="8" string="track" />
            <token id="9" string="and" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
        <chunking id="9" string="gets what they deserve in track and field" type="VP">
          <tokens>
            <token id="3" string="gets" />
            <token id="4" string="what" />
            <token id="5" string="they" />
            <token id="6" string="deserve" />
            <token id="7" string="in" />
            <token id="8" string="track" />
            <token id="9" string="and" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
        <chunking id="10" string="track and field" type="NP">
          <tokens>
            <token id="8" string="track" />
            <token id="9" string="and" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">gets</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">gets</governor>
          <dependent id="2">anybody</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">me</governor>
          <dependent id="3">gets</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">deserve</governor>
          <dependent id="4">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">deserve</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">gets</governor>
          <dependent id="6">deserve</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">track</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">deserve</governor>
          <dependent id="8">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">track</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">track</governor>
          <dependent id="10">field</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">me</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">me</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>I make the most money, I get the appearances.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="appearances" lemma="appearance" stem="appear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP make) (ADVP (DT the) (RBS most)) (NP (NN money)))) (, ,) (NP (PRP I)) (VP (VBP get) (NP (DT the) (NNS appearances))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the appearances" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="appearances" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="money" type="NP">
          <tokens>
            <token id="5" string="money" />
          </tokens>
        </chunking>
        <chunking id="4" string="make the most money" type="VP">
          <tokens>
            <token id="2" string="make" />
            <token id="3" string="the" />
            <token id="4" string="most" />
            <token id="5" string="money" />
          </tokens>
        </chunking>
        <chunking id="5" string="get the appearances" type="VP">
          <tokens>
            <token id="8" string="get" />
            <token id="9" string="the" />
            <token id="10" string="appearances" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">make</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">get</governor>
          <dependent id="2">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">most</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">make</governor>
          <dependent id="4">most</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">make</governor>
          <dependent id="5">money</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">get</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">appearances</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">get</governor>
          <dependent id="10">appearances</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>But I still believe that through it all I want to help every single person whether they make $50 a meet or near what I make.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="20" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP I)) (ADVP (RB still)) (VP (VBP believe) (SBAR (SBAR (IN that) (S (PP (IN through) (NP (PRP it) (DT all))) (NP (PRP I)) (VP (VBP want) (S (VP (TO to) (VP (VB help) (NP (DT every) (JJ single) (NN person)) (SBAR (IN whether) (S (NP (PRP they)) (VP (VBP make) (NP (NP (ADJP ($ $) (CD 50)) (DT a)) (SBAR (S (VP (VBP meet)))))))))))))) (CC or) (SBAR (WHPP (IN near) (WHNP (WP what))) (S (NP (PRP I)) (VP (VBP make)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that through it all I want to help every single person whether they make $ 50 a meet or near what I make" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="through" />
            <token id="7" string="it" />
            <token id="8" string="all" />
            <token id="9" string="I" />
            <token id="10" string="want" />
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
            <token id="23" string="or" />
            <token id="24" string="near" />
            <token id="25" string="what" />
            <token id="26" string="I" />
            <token id="27" string="make" />
          </tokens>
        </chunking>
        <chunking id="2" string="believe that through it all I want to help every single person whether they make $ 50 a meet or near what I make" type="VP">
          <tokens>
            <token id="4" string="believe" />
            <token id="5" string="that" />
            <token id="6" string="through" />
            <token id="7" string="it" />
            <token id="8" string="all" />
            <token id="9" string="I" />
            <token id="10" string="want" />
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
            <token id="23" string="or" />
            <token id="24" string="near" />
            <token id="25" string="what" />
            <token id="26" string="I" />
            <token id="27" string="make" />
          </tokens>
        </chunking>
        <chunking id="3" string="$ 50" type="ADJP">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="50" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="that through it all I want to help every single person whether they make $ 50 a meet" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="through" />
            <token id="7" string="it" />
            <token id="8" string="all" />
            <token id="9" string="I" />
            <token id="10" string="want" />
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="6" string="make $ 50 a meet" type="VP">
          <tokens>
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="7" string="every single person" type="NP">
          <tokens>
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
          </tokens>
        </chunking>
        <chunking id="8" string="to help every single person whether they make $ 50 a meet" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="9" string="$ 50 a meet" type="NP">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="17" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="want to help every single person whether they make $ 50 a meet" type="VP">
          <tokens>
            <token id="10" string="want" />
            <token id="11" string="to" />
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="12" string="whether they make $ 50 a meet" type="SBAR">
          <tokens>
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="13" string="it all" type="NP">
          <tokens>
            <token id="7" string="it" />
            <token id="8" string="all" />
          </tokens>
        </chunking>
        <chunking id="14" string="meet" type="SBAR">
          <tokens>
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="15" string="near what I make" type="SBAR">
          <tokens>
            <token id="24" string="near" />
            <token id="25" string="what" />
            <token id="26" string="I" />
            <token id="27" string="make" />
          </tokens>
        </chunking>
        <chunking id="16" string="help every single person whether they make $ 50 a meet" type="VP">
          <tokens>
            <token id="12" string="help" />
            <token id="13" string="every" />
            <token id="14" string="single" />
            <token id="15" string="person" />
            <token id="16" string="whether" />
            <token id="17" string="they" />
            <token id="18" string="make" />
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
            <token id="22" string="meet" />
          </tokens>
        </chunking>
        <chunking id="17" string="$ 50 a" type="NP">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="50" />
            <token id="21" string="a" />
          </tokens>
        </chunking>
        <chunking id="18" string="make" type="VP">
          <tokens>
            <token id="27" string="make" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">believe</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">believe</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">believe</governor>
          <dependent id="3">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">want</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">it</governor>
          <dependent id="6">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">want</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">it</governor>
          <dependent id="8">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">want</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">believe</governor>
          <dependent id="10">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">help</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">want</governor>
          <dependent id="12">help</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">person</governor>
          <dependent id="13">every</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">person</governor>
          <dependent id="14">single</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">help</governor>
          <dependent id="15">person</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">make</governor>
          <dependent id="16">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">make</governor>
          <dependent id="17">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">help</governor>
          <dependent id="18">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">make</governor>
          <dependent id="19">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">$</governor>
          <dependent id="20">50</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">$</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">$</governor>
          <dependent id="22">meet</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">want</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">what</governor>
          <dependent id="24">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">make</governor>
          <dependent id="25">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">make</governor>
          <dependent id="26">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">want</governor>
          <dependent id="27">make</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 50" type="MONEY" score="0.0">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="50" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>Lewis said his deep-rooted conviction comes from his parents, who raised him to stand by his beliefs.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="deep-rooted" lemma="deep-rooted" stem="deep-root" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="conviction" lemma="conviction" stem="convict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="raised" lemma="raise" stem="rais" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="beliefs" lemma="belief" stem="belief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (JJ deep-rooted) (NN conviction)) (VP (VBZ comes) (PP (IN from) (NP (NP (PRP$ his) (NNS parents)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD raised) (S (NP (PRP him)) (VP (TO to) (VP (VB stand) (PP (IN by) (NP (PRP$ his) (NNS beliefs))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his parents , who raised him to stand by his beliefs" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="parents" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="2" string="said his deep-rooted conviction comes from his parents , who raised him to stand by his beliefs" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="deep-rooted" />
            <token id="5" string="conviction" />
            <token id="6" string="comes" />
            <token id="7" string="from" />
            <token id="8" string="his" />
            <token id="9" string="parents" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="3" string="his beliefs" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="comes from his parents , who raised him to stand by his beliefs" type="VP">
          <tokens>
            <token id="6" string="comes" />
            <token id="7" string="from" />
            <token id="8" string="his" />
            <token id="9" string="parents" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="6" string="raised him to stand by his beliefs" type="VP">
          <tokens>
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="7" string="stand by his beliefs" type="VP">
          <tokens>
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="8" string="who raised him to stand by his beliefs" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="9" string="his deep-rooted conviction comes from his parents , who raised him to stand by his beliefs" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="deep-rooted" />
            <token id="5" string="conviction" />
            <token id="6" string="comes" />
            <token id="7" string="from" />
            <token id="8" string="his" />
            <token id="9" string="parents" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="raised" />
            <token id="13" string="him" />
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="10" string="to stand by his beliefs" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="stand" />
            <token id="16" string="by" />
            <token id="17" string="his" />
            <token id="18" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="11" string="his deep-rooted conviction" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="deep-rooted" />
            <token id="5" string="conviction" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="13" string="his parents" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">conviction</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">conviction</governor>
          <dependent id="4">deep-rooted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">comes</governor>
          <dependent id="5">conviction</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">parents</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">parents</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">comes</governor>
          <dependent id="9">parents</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">raised</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">parents</governor>
          <dependent id="12">raised</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">raised</governor>
          <dependent id="13">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">stand</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">raised</governor>
          <dependent id="15">stand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">beliefs</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">beliefs</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">stand</governor>
          <dependent id="18">beliefs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Lewis said their philosophy was inspired by the late Dr. Martin Luther King, who once said it is important to make such sacrifices.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="inspired" lemma="inspire" stem="inspir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Luther" lemma="Luther" stem="luther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="sacrifices" lemma="sacrifice" stem="sacrific" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD said) (SBAR (S (NP (PRP$ their) (NN philosophy)) (VP (VBD was) (VP (VBN inspired) (PP (IN by) (NP (NP (DT the) (JJ late) (NNP Dr.) (NNP Martin) (NNP Luther) (NNP King)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB once)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ important) (S (VP (TO to) (VP (VB make) (NP (JJ such) (NNS sacrifices))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="inspired by the late Dr. Martin Luther King , who once said it is important to make such sacrifices" type="VP">
          <tokens>
            <token id="6" string="inspired" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="2" string="the late Dr. Martin Luther King , who once said it is important to make such sacrifices" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="3" string="it is important to make such sacrifices" type="SBAR">
          <tokens>
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="4" string="is important to make such sacrifices" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="5" string="make such sacrifices" type="VP">
          <tokens>
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="6" string="such sacrifices" type="NP">
          <tokens>
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="7" string="the late Dr. Martin Luther King" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="said it is important to make such sacrifices" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="10" string="to make such sacrifices" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="11" string="who once said it is important to make such sacrifices" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="12" string="said their philosophy was inspired by the late Dr. Martin Luther King , who once said it is important to make such sacrifices" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="their" />
            <token id="4" string="philosophy" />
            <token id="5" string="was" />
            <token id="6" string="inspired" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="13" string="important to make such sacrifices" type="ADJP">
          <tokens>
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="15" string="their philosophy was inspired by the late Dr. Martin Luther King , who once said it is important to make such sacrifices" type="SBAR">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="philosophy" />
            <token id="5" string="was" />
            <token id="6" string="inspired" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="16" string="was inspired by the late Dr. Martin Luther King , who once said it is important to make such sacrifices" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="inspired" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="late" />
            <token id="10" string="Dr." />
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="once" />
            <token id="17" string="said" />
            <token id="18" string="it" />
            <token id="19" string="is" />
            <token id="20" string="important" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="such" />
            <token id="24" string="sacrifices" />
          </tokens>
        </chunking>
        <chunking id="17" string="their philosophy" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="philosophy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">philosophy</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">inspired</governor>
          <dependent id="4">philosophy</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">inspired</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">inspired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">King</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">King</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">King</governor>
          <dependent id="9">late</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">King</governor>
          <dependent id="10">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">King</governor>
          <dependent id="11">Martin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">King</governor>
          <dependent id="12">Luther</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">inspired</governor>
          <dependent id="13">King</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">said</governor>
          <dependent id="16">once</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">King</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">important</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">important</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="20">important</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">make</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">important</governor>
          <dependent id="22">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">sacrifices</governor>
          <dependent id="23">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">make</governor>
          <dependent id="24">sacrifices</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="Martin Luther King" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Martin" />
            <token id="12" string="Luther" />
            <token id="13" string="King" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>&amp;quot;That people cannot sacrifice for something in their life, whether it is a small insignificant thing to others or a big thing to the world, what&amp;apost;s the use of living?&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sacrifice" lemma="sacrifice" stem="sacrific" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="insignificant" lemma="insignificant" stem="insignific" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT That) (NNS people)) (VP (MD can) (RB not) (VP (VB sacrifice) (PP (IN for) (NP (NN something))) (PP (IN in) (NP (PRP$ their) (NN life))) (, ,) (SBAR (IN whether) (S (NP (PRP it)) (VP (VBZ is) (NP (DT a) (JJ small) (JJ insignificant) (NN thing)) (PP (TO to) (NP (NP (NNS others)) (CC or) (NP (DT a) (JJ big) (NN thing)))) (PP (TO to) (NP (NP (DT the) (NN world)) (, ,) (SBAR (WHNP (WP what)) (S (VP (VBZ 's) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NN living)))))))))))))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="living" type="NP">
          <tokens>
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="2" string="That people" type="NP">
          <tokens>
            <token id="2" string="That" />
            <token id="3" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="what 's the use of living" type="SBAR">
          <tokens>
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="a small insignificant thing" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="insignificant" />
            <token id="19" string="thing" />
          </tokens>
        </chunking>
        <chunking id="6" string="can not sacrifice for something in their life , whether it is a small insignificant thing to others or a big thing to the world , what 's the use of living" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="not" />
            <token id="6" string="sacrifice" />
            <token id="7" string="for" />
            <token id="8" string="something" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="life" />
            <token id="12" string="," />
            <token id="13" string="whether" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="insignificant" />
            <token id="19" string="thing" />
            <token id="20" string="to" />
            <token id="21" string="others" />
            <token id="22" string="or" />
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="," />
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="7" string="the world" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="world" />
          </tokens>
        </chunking>
        <chunking id="8" string="something" type="NP">
          <tokens>
            <token id="8" string="something" />
          </tokens>
        </chunking>
        <chunking id="9" string="whether it is a small insignificant thing to others or a big thing to the world , what 's the use of living" type="SBAR">
          <tokens>
            <token id="13" string="whether" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="insignificant" />
            <token id="19" string="thing" />
            <token id="20" string="to" />
            <token id="21" string="others" />
            <token id="22" string="or" />
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="," />
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="10" string="is a small insignificant thing to others or a big thing to the world , what 's the use of living" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="insignificant" />
            <token id="19" string="thing" />
            <token id="20" string="to" />
            <token id="21" string="others" />
            <token id="22" string="or" />
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="," />
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="11" string="the world , what 's the use of living" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="," />
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s the use of living" type="VP">
          <tokens>
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="13" string="their life" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="life" />
          </tokens>
        </chunking>
        <chunking id="14" string="a big thing" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
          </tokens>
        </chunking>
        <chunking id="15" string="the use of living" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="16" string="others or a big thing" type="NP">
          <tokens>
            <token id="21" string="others" />
            <token id="22" string="or" />
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
          </tokens>
        </chunking>
        <chunking id="17" string="the use" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="use" />
          </tokens>
        </chunking>
        <chunking id="18" string="sacrifice for something in their life , whether it is a small insignificant thing to others or a big thing to the world , what 's the use of living" type="VP">
          <tokens>
            <token id="6" string="sacrifice" />
            <token id="7" string="for" />
            <token id="8" string="something" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="life" />
            <token id="12" string="," />
            <token id="13" string="whether" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="insignificant" />
            <token id="19" string="thing" />
            <token id="20" string="to" />
            <token id="21" string="others" />
            <token id="22" string="or" />
            <token id="23" string="a" />
            <token id="24" string="big" />
            <token id="25" string="thing" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="world" />
            <token id="29" string="," />
            <token id="30" string="what" />
            <token id="31" string="'s" />
            <token id="32" string="the" />
            <token id="33" string="use" />
            <token id="34" string="of" />
            <token id="35" string="living" />
          </tokens>
        </chunking>
        <chunking id="19" string="others" type="NP">
          <tokens>
            <token id="21" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">people</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sacrifice</governor>
          <dependent id="3">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">sacrifice</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">sacrifice</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">sacrifice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">something</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sacrifice</governor>
          <dependent id="8">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">life</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">life</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sacrifice</governor>
          <dependent id="11">life</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">thing</governor>
          <dependent id="13">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">thing</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">thing</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">thing</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">thing</governor>
          <dependent id="17">small</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">thing</governor>
          <dependent id="18">insignificant</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">sacrifice</governor>
          <dependent id="19">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">others</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">thing</governor>
          <dependent id="21">others</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">others</governor>
          <dependent id="22">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">thing</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">thing</governor>
          <dependent id="24">big</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">others</governor>
          <dependent id="25">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">world</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">world</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">thing</governor>
          <dependent id="28">world</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">use</governor>
          <dependent id="30">what</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">use</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">use</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">world</governor>
          <dependent id="33">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">living</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">use</governor>
          <dependent id="35">living</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Lewis asked.</content>
      <tokens>
        <token id="1" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lewis)) (VP (VBD asked)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lewis" type="NP">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked" type="VP">
          <tokens>
            <token id="2" string="asked" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">asked</governor>
          <dependent id="1">Lewis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">asked</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>&amp;quot;I feel if I can&amp;apost;t sacrifice myself for the betterment of other people in track and field, well, then I cannot leave a legacy that will be remembered.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="sacrifice" lemma="sacrifice" stem="sacrific" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="myself" lemma="myself" stem="myself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="betterment" lemma="betterment" stem="better" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="leave" lemma="leave" stem="leav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="legacy" lemma="legacy" stem="legaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="remembered" lemma="remember" stem="rememb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP feel) (S (SBAR (IN if) (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB sacrifice) (NP (PRP myself)) (PP (IN for) (NP (NP (DT the) (NN betterment)) (PP (IN of) (NP (NP (JJ other) (NNS people)) (PP (IN in) (NP (NN track) (CC and) (NN field))))))))))) (, ,) (INTJ (RB well)) (, ,) (ADVP (RB then)) (NP (PRP I)) (VP (MD can) (RB not) (VP (VB leave) (NP (NP (DT a) (NN legacy)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB be) (VP (VBN remembered))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a legacy" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="legacy" />
          </tokens>
        </chunking>
        <chunking id="2" string="ca n't sacrifice myself for the betterment of other people in track and field" type="VP">
          <tokens>
            <token id="6" string="ca" />
            <token id="7" string="n't" />
            <token id="8" string="sacrifice" />
            <token id="9" string="myself" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="betterment" />
            <token id="13" string="of" />
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="feel if I ca n't sacrifice myself for the betterment of other people in track and field , well , then I can not leave a legacy that will be remembered" type="VP">
          <tokens>
            <token id="3" string="feel" />
            <token id="4" string="if" />
            <token id="5" string="I" />
            <token id="6" string="ca" />
            <token id="7" string="n't" />
            <token id="8" string="sacrifice" />
            <token id="9" string="myself" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="betterment" />
            <token id="13" string="of" />
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
            <token id="20" string="," />
            <token id="21" string="well" />
            <token id="22" string="," />
            <token id="23" string="then" />
            <token id="24" string="I" />
            <token id="25" string="can" />
            <token id="26" string="not" />
            <token id="27" string="leave" />
            <token id="28" string="a" />
            <token id="29" string="legacy" />
            <token id="30" string="that" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="5" string="myself" type="NP">
          <tokens>
            <token id="9" string="myself" />
          </tokens>
        </chunking>
        <chunking id="6" string="sacrifice myself for the betterment of other people in track and field" type="VP">
          <tokens>
            <token id="8" string="sacrifice" />
            <token id="9" string="myself" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="betterment" />
            <token id="13" string="of" />
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="7" string="if I ca n't sacrifice myself for the betterment of other people in track and field" type="SBAR">
          <tokens>
            <token id="4" string="if" />
            <token id="5" string="I" />
            <token id="6" string="ca" />
            <token id="7" string="n't" />
            <token id="8" string="sacrifice" />
            <token id="9" string="myself" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="betterment" />
            <token id="13" string="of" />
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="8" string="the betterment of other people in track and field" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="betterment" />
            <token id="13" string="of" />
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="9" string="the betterment" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="betterment" />
          </tokens>
        </chunking>
        <chunking id="10" string="track and field" type="NP">
          <tokens>
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="11" string="other people in track and field" type="NP">
          <tokens>
            <token id="14" string="other" />
            <token id="15" string="people" />
            <token id="16" string="in" />
            <token id="17" string="track" />
            <token id="18" string="and" />
            <token id="19" string="field" />
          </tokens>
        </chunking>
        <chunking id="12" string="leave a legacy that will be remembered" type="VP">
          <tokens>
            <token id="27" string="leave" />
            <token id="28" string="a" />
            <token id="29" string="legacy" />
            <token id="30" string="that" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="13" string="other people" type="NP">
          <tokens>
            <token id="14" string="other" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="14" string="a legacy that will be remembered" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="legacy" />
            <token id="30" string="that" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="15" string="that will be remembered" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="16" string="remembered" type="VP">
          <tokens>
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="17" string="will be remembered" type="VP">
          <tokens>
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="18" string="be remembered" type="VP">
          <tokens>
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
        <chunking id="19" string="can not leave a legacy that will be remembered" type="VP">
          <tokens>
            <token id="25" string="can" />
            <token id="26" string="not" />
            <token id="27" string="leave" />
            <token id="28" string="a" />
            <token id="29" string="legacy" />
            <token id="30" string="that" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="remembered" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">feel</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">feel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">sacrifice</governor>
          <dependent id="4">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">sacrifice</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">sacrifice</governor>
          <dependent id="6">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">sacrifice</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">leave</governor>
          <dependent id="8">sacrifice</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">sacrifice</governor>
          <dependent id="9">myself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">betterment</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">betterment</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">sacrifice</governor>
          <dependent id="12">betterment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">people</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">people</governor>
          <dependent id="14">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">betterment</governor>
          <dependent id="15">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">track</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">people</governor>
          <dependent id="17">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">track</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">track</governor>
          <dependent id="19">field</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="27">leave</governor>
          <dependent id="21">well</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">I</governor>
          <dependent id="23">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">leave</governor>
          <dependent id="24">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">leave</governor>
          <dependent id="25">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">leave</governor>
          <dependent id="26">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">feel</governor>
          <dependent id="27">leave</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">legacy</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">leave</governor>
          <dependent id="29">legacy</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">remembered</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">remembered</governor>
          <dependent id="31">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">remembered</governor>
          <dependent id="32">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">legacy</governor>
          <dependent id="33">remembered</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="Carl Lewis" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="He" id_sentence="2" />
        <mention ids_tokens="14" string="Lewis" id_sentence="2" />
        <mention ids_tokens="27" string="he" id_sentence="2" />
        <mention ids_tokens="2" string="I" id_sentence="4" />
        <mention ids_tokens="8" string="I" id_sentence="4" />
        <mention ids_tokens="2" string="Lewis" id_sentence="5" />
        <mention ids_tokens="18" string="Lewis" id_sentence="8" />
        <mention ids_tokens="14" string="Lewis" id_sentence="9" />
        <mention ids_tokens="1" string="Lewis" id_sentence="10" />
        <mention ids_tokens="25-26" string="Lewis'" id_sentence="11" />
        <mention ids_tokens="1" string="Lewis" id_sentence="15" />
        <mention ids_tokens="14" string="Lewis" id_sentence="17" />
        <mention ids_tokens="1" string="Lewis" id_sentence="18" />
        <mention ids_tokens="7" string="Lewis" id_sentence="19" />
        <mention ids_tokens="12" string="I" id_sentence="21" />
        <mention ids_tokens="30" string="Lewis" id_sentence="21" />
        <mention ids_tokens="1" string="Lewis" id_sentence="22" />
        <mention ids_tokens="20" string="Lewis" id_sentence="25" />
        <mention ids_tokens="1" string="Lewis" id_sentence="29" />
        <mention ids_tokens="1" string="He" id_sentence="30" />
        <mention ids_tokens="11" string="Lewis" id_sentence="31" />
        <mention ids_tokens="1" string="I" id_sentence="33" />
        <mention ids_tokens="1" string="I" id_sentence="34" />
        <mention ids_tokens="1" string="Lewis" id_sentence="35" />
        <mention ids_tokens="10" string="his" id_sentence="35" />
        <mention ids_tokens="2" string="Lewis" id_sentence="36" />
        <mention ids_tokens="1-3" string="Lewis and Ashford" id_sentence="37" />
        <mention ids_tokens="1" string="Lewis" id_sentence="37" />
        <mention ids_tokens="5-11" string="teammates on the Santa Monica Track Club" id_sentence="37" />
        <mention ids_tokens="13" string="Lewis" id_sentence="38" />
        <mention ids_tokens="8" string="Lewis" id_sentence="43" />
        <mention ids_tokens="3" string="Lewis" id_sentence="44" />
        <mention ids_tokens="20" string="he" id_sentence="44" />
        <mention ids_tokens="24" string="his" id_sentence="44" />
        <mention ids_tokens="2" string="I" id_sentence="45" />
        <mention ids_tokens="11" string="I" id_sentence="45" />
        <mention ids_tokens="15" string="I" id_sentence="45" />
        <mention ids_tokens="19" string="I" id_sentence="45" />
        <mention ids_tokens="28" string="he" id_sentence="45" />
        <mention ids_tokens="2" string="I" id_sentence="46" />
        <mention ids_tokens="1" string="I" id_sentence="47" />
        <mention ids_tokens="4" string="me" id_sentence="49" />
        <mention ids_tokens="7" string="I" id_sentence="49" />
        <mention ids_tokens="17" string="I" id_sentence="49" />
        <mention ids_tokens="1" string="Lewis" id_sentence="50" />
        <mention ids_tokens="2" string="I" id_sentence="51" />
        <mention ids_tokens="22" string="he" id_sentence="51" />
        <mention ids_tokens="5" string="me" id_sentence="53" />
        <mention ids_tokens="7" string="I" id_sentence="53" />
        <mention ids_tokens="1" string="I" id_sentence="56" />
        <mention ids_tokens="1-27" string="Lewis , who won four gold medals at the 1984 Summer Games and has been one of the great sprinters and long jumpers in track and field" id_sentence="62" />
        <mention ids_tokens="1" string="Lewis" id_sentence="62" />
        <mention ids_tokens="30" string="he" id_sentence="62" />
        <mention ids_tokens="11" string="he" id_sentence="63" />
        <mention ids_tokens="2" string="I" id_sentence="64" />
        <mention ids_tokens="13" string="I" id_sentence="64" />
        <mention ids_tokens="23" string="I" id_sentence="64" />
        <mention ids_tokens="14" string="me" id_sentence="65" />
        <mention ids_tokens="1" string="I" id_sentence="66" />
        <mention ids_tokens="7" string="I" id_sentence="66" />
        <mention ids_tokens="2" string="I" id_sentence="67" />
        <mention ids_tokens="9" string="I" id_sentence="67" />
        <mention ids_tokens="26" string="I" id_sentence="67" />
        <mention ids_tokens="1" string="Lewis" id_sentence="68" />
        <mention ids_tokens="3" string="his" id_sentence="68" />
        <mention ids_tokens="8" string="his" id_sentence="68" />
        <mention ids_tokens="13" string="him" id_sentence="68" />
        <mention ids_tokens="17" string="his" id_sentence="68" />
        <mention ids_tokens="1" string="Lewis" id_sentence="69" />
        <mention ids_tokens="1" string="Lewis" id_sentence="71" />
        <mention ids_tokens="2" string="I" id_sentence="72" />
        <mention ids_tokens="5" string="I" id_sentence="72" />
        <mention ids_tokens="9" string="myself" id_sentence="72" />
        <mention ids_tokens="24" string="I" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="6-7" string="Ben Johnson" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11-12" string="Johnson's" id_sentence="5" />
        <mention ids_tokens="24" string="Johnson" id_sentence="6" />
        <mention ids_tokens="9" string="Johnson" id_sentence="7" />
        <mention ids_tokens="7" string="Johnson" id_sentence="8" />
        <mention ids_tokens="6-21" string="Johnson , who set a world record of 9.79 seconds in winning the 100-meter gold medal" id_sentence="10" />
        <mention ids_tokens="6" string="Johnson" id_sentence="10" />
        <mention ids_tokens="11-13" string="Ben Johnson's" id_sentence="11" />
        <mention ids_tokens="4" string="Ben" id_sentence="13" />
        <mention ids_tokens="2-3" string="Johnson's" id_sentence="16" />
        <mention ids_tokens="14" string="his" id_sentence="16" />
        <mention ids_tokens="1" string="He" id_sentence="17" />
        <mention ids_tokens="14-15" string="Johnson's" id_sentence="18" />
        <mention ids_tokens="12" string="Johnson" id_sentence="20" />
        <mention ids_tokens="8" string="he" id_sentence="21" />
        <mention ids_tokens="15" string="Johnson" id_sentence="22" />
        <mention ids_tokens="7" string="Johnson" id_sentence="23" />
        <mention ids_tokens="2" string="He" id_sentence="25" />
        <mention ids_tokens="5" string="Johnson" id_sentence="44" />
        <mention ids_tokens="14" string="Johnson" id_sentence="48" />
        <mention ids_tokens="4" string="Johnson" id_sentence="50" />
        <mention ids_tokens="4" string="Ben" id_sentence="51" />
        <mention ids_tokens="2" string="He" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="7" string="right" id_sentence="46" />
      <mentions>
        <mention ids_tokens="10" string="that" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="10-11" string="performance-enhancing drugs" id_sentence="1" />
      <mentions>
        <mention ids_tokens="27" string="drugs" id_sentence="18" />
        <mention ids_tokens="10" string="drugs" id_sentence="21" />
        <mention ids_tokens="7" string="drugs" id_sentence="28" />
        <mention ids_tokens="10" string="drugs" id_sentence="38" />
        <mention ids_tokens="18" string="drugs" id_sentence="48" />
        <mention ids_tokens="19" string="drugs" id_sentence="51" />
        <mention ids_tokens="14" string="it" id_sentence="52" />
        <mention ids_tokens="9" string="it" id_sentence="53" />
        <mention ids_tokens="4" string="it" id_sentence="54" />
        <mention ids_tokens="9" string="it" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10" string="some merit to that" id_sentence="47" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="48" />
        <mention ids_tokens="2" string="it" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="20-21-22" string="the Seoul Olympics" id_sentence="1" />
      <mentions>
        <mention ids_tokens="5-6" string="the Olympics" id_sentence="43" />
        <mention ids_tokens="6" string="Olympics" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="19" string="Sunday" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="30-31" string="a sponsor" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="he" id_sentence="4" />
        <mention ids_tokens="18" string="he" id_sentence="4" />
        <mention ids_tokens="23" string="he" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="10" type="PRONOMINAL">
      <referenced ids_tokens="15" string="you" id_sentence="53" />
      <mentions>
        <mention ids_tokens="3" string="he" id_sentence="55" />
        <mention ids_tokens="3" string="he" id_sentence="56" />
        <mention ids_tokens="8" string="himself" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23-24-25-26" string="a positive result for the banned anabolic steroid stanozolol" id_sentence="5" />
      <mentions>
        <mention ids_tokens="24-25" string="his result" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="14-15" string="Charlie Francis" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="Francis" id_sentence="7" />
        <mention ids_tokens="3" string="his" id_sentence="7" />
        <mention ids_tokens="3-4" string="Francis'" id_sentence="8" />
        <mention ids_tokens="1" string="Francis" id_sentence="9" />
        <mention ids_tokens="7" string="him" id_sentence="9" />
        <mention ids_tokens="2" string="Charlie" id_sentence="13" />
        <mention ids_tokens="21" string="Francis" id_sentence="18" />
        <mention ids_tokens="24" string="his" id_sentence="18" />
        <mention ids_tokens="5-6" string="Francis'" id_sentence="22" />
        <mention ids_tokens="18-19" string="Francis'" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="continued drug use" id_sentence="55" />
      <mentions>
        <mention ids_tokens="5-6" string="drug use" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12" string="a Canadian inquiry into drug use in sport Monday at Toronto" id_sentence="6" />
      <mentions>
        <mention ids_tokens="21-23" string="the Canadian inquiry" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="The biggest thing about drug use" id_sentence="57" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="60" />
        <mention ids_tokens="3-5" string="the same thing" id_sentence="60" />
        <mention ids_tokens="9-10" string="the thing" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="6-7" string="the fact" id_sentence="7" />
      <mentions>
        <mention ids_tokens="25" string="it" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="5" string="four" id_sentence="62" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="64" />
        <mention ids_tokens="12" string="it" id_sentence="65" />
        <mention ids_tokens="7-8" string="it all" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="four gold medals" id_sentence="62" />
      <mentions>
        <mention ids_tokens="2" string="That" id_sentence="63" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15" string="a world record of 9.79 seconds" id_sentence="10" />
      <mentions>
        <mention ids_tokens="3-4" string="the record" id_sentence="17" />
        <mention ids_tokens="7-8" string="the record" id_sentence="20" />
        <mention ids_tokens="3" string="it" id_sentence="21" />
        <mention ids_tokens="18-19" string="the record" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="8-9" string="his parents" id_sentence="68" />
      <mentions>
        <mention ids_tokens="3" string="their" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="29" type="LIST">
      <referenced ids_tokens="2-3-4" string="Charlie and Ben" id_sentence="13" />
      <mentions>
        <mention ids_tokens="3" string="their" id_sentence="14" />
        <mention ids_tokens="8" string="they" id_sentence="14" />
        <mention ids_tokens="12" string="themselves" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="6-7-8-9" string="the 1987 World Championships" id_sentence="17" />
      <mentions>
        <mention ids_tokens="29-31" string="the World Championships" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="the 1987 race" id_sentence="20" />
      <mentions>
        <mention ids_tokens="13-14" string="the race" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="26-27" string="the sport" id_sentence="21" />
      <mentions>
        <mention ids_tokens="35-37" string="the sport's" id_sentence="62" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="10-11" string="such drugs" id_sentence="23" />
      <mentions>
        <mention ids_tokens="1-2" string="The drugs" id_sentence="24" />
        <mention ids_tokens="11" string="it" id_sentence="25" />
        <mention ids_tokens="17" string="it" id_sentence="25" />
        <mention ids_tokens="2" string="That" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="11-12" string="some athletes" id_sentence="24" />
      <mentions>
        <mention ids_tokens="14" string="they" id_sentence="25" />
        <mention ids_tokens="1" string="They" id_sentence="27" />
        <mention ids_tokens="1" string="That" id_sentence="28" />
        <mention ids_tokens="4" string="they" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="2-3" string="That people" id_sentence="70" />
      <mentions>
        <mention ids_tokens="5" string="people" id_sentence="27" />
        <mention ids_tokens="5" string="people" id_sentence="63" />
        <mention ids_tokens="5" string="they" id_sentence="65" />
        <mention ids_tokens="17" string="they" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="8-9" string="a problem" id_sentence="32" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="33" />
        <mention ids_tokens="5" string="it" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="4-5" string="Evelyn Ashford" id_sentence="36" />
      <mentions>
        <mention ids_tokens="3" string="Ashford" id_sentence="37" />
        <mention ids_tokens="8" string="she" id_sentence="38" />
        <mention ids_tokens="2" string="She" id_sentence="39" />
        <mention ids_tokens="4-5" string="a victim" id_sentence="39" />
        <mention ids_tokens="8" string="her" id_sentence="41" />
        <mention ids_tokens="11" string="Evelyn" id_sentence="41" />
        <mention ids_tokens="15" string="she" id_sentence="41" />
        <mention ids_tokens="4" string="her" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6" string="No way in the world" id_sentence="38" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="5-6" string="the world" id_sentence="38" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="40" />
        <mention ids_tokens="5" string="that" id_sentence="41" />
        <mention ids_tokens="6" string="it" id_sentence="42" />
        <mention ids_tokens="27-35" string="the world , what's the use of living" id_sentence="70" />
      </mentions>
    </coreference>
  </coreferences>
</document>
