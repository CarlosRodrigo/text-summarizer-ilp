<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06191081">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>A panel that investigated the Los Angeles Police Department after officers were videotaped beating a motorist has decided not to seek Chief Daryl Gates&amp;apost; resignation and neither blamed nor cleared him.; But the 10-member commission, which was to release its report today, found racist and sexist remarks scattered throughout 90,000 pages of computer messages, sources said.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="investigated" lemma="investigate" stem="investig" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="videotaped" lemma="videotaped" stem="videotap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="beating" lemma="beat" stem="beat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="motorist" lemma="motorist" stem="motorist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="decided" lemma="decide" stem="decid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="seek" lemma="seek" stem="seek" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="23" string="Daryl" lemma="Daryl" stem="daryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="resignation" lemma="resignation" stem="resign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="neither" lemma="neither" stem="neither" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="blamed" lemma="blame" stem="blame" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="cleared" lemma="clear" stem="clear" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="him." lemma="him." stem="him." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="10-member" lemma="10-member" stem="10-member" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="release" lemma="release" stem="releas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="racist" lemma="racist" stem="racist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="sexist" lemma="sexist" stem="sexist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="remarks" lemma="remark" stem="remark" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="scattered" lemma="scatter" stem="scatter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="throughout" lemma="throughout" stem="throughout" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="90,000" lemma="90,000" stem="90,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="55" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="56" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="57" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="58" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="59" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (NP (DT A) (NN panel)) (SBAR (WHNP (WDT that)) (S (VP (VBD investigated) (NP (DT the) (NNP Los) (NNP Angeles) (NNP Police) (NNP Department)) (PP (IN after) (NP (NNS officers))))))) (VP (VBD were) (ADJP (JJ videotaped) (SBAR (S (S (VP (VBG beating) (SBAR (S (NP (DT a) (NN motorist)) (VP (VBZ has) (VP (VBN decided) (S (RB not) (VP (TO to) (VP (VB seek) (NP (NP (NNP Chief) (NNP Daryl) (NNP Gates) (POS ')) (NN resignation))))))))))) (CC and) (S (VP (CC neither) (VP (VBN blamed) (CC nor) (VBN cleared) (NP (NN him.)))))))))) (: ;) (CC But) (S (NP (NP (DT the) (JJ 10-member) (NN commission)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (S (VP (TO to) (VP (VB release) (NP (PRP$ its) (NN report)) (NP-TMP (NN today)))))))) (, ,)) (VP (VBD found) (NP (NP (ADJP (NN racist) (CC and) (JJ sexist)) (NNS remarks)) (VP (VBN scattered) (PP (IN throughout) (NP (NP (CD 90,000) (NNS pages)) (PP (IN of) (NP (NN computer) (NNS messages)))))))))) (, ,) (NP (NNS sources)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="beating a motorist has decided not to seek Chief Daryl Gates ' resignation" type="VP">
          <tokens>
            <token id="14" string="beating" />
            <token id="15" string="a" />
            <token id="16" string="motorist" />
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="2" string="investigated the Los Angeles Police Department after officers" type="VP">
          <tokens>
            <token id="4" string="investigated" />
            <token id="5" string="the" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="Police" />
            <token id="9" string="Department" />
            <token id="10" string="after" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="90,000 pages of computer messages" type="NP">
          <tokens>
            <token id="54" string="90,000" />
            <token id="55" string="pages" />
            <token id="56" string="of" />
            <token id="57" string="computer" />
            <token id="58" string="messages" />
          </tokens>
        </chunking>
        <chunking id="4" string="racist and sexist remarks scattered throughout 90,000 pages of computer messages" type="NP">
          <tokens>
            <token id="48" string="racist" />
            <token id="49" string="and" />
            <token id="50" string="sexist" />
            <token id="51" string="remarks" />
            <token id="52" string="scattered" />
            <token id="53" string="throughout" />
            <token id="54" string="90,000" />
            <token id="55" string="pages" />
            <token id="56" string="of" />
            <token id="57" string="computer" />
            <token id="58" string="messages" />
          </tokens>
        </chunking>
        <chunking id="5" string="to seek Chief Daryl Gates ' resignation" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="6" string="seek Chief Daryl Gates ' resignation" type="VP">
          <tokens>
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="7" string="were videotaped beating a motorist has decided not to seek Chief Daryl Gates ' resignation and neither blamed nor cleared him." type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="videotaped" />
            <token id="14" string="beating" />
            <token id="15" string="a" />
            <token id="16" string="motorist" />
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
            <token id="27" string="and" />
            <token id="28" string="neither" />
            <token id="29" string="blamed" />
            <token id="30" string="nor" />
            <token id="31" string="cleared" />
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="8" string="videotaped beating a motorist has decided not to seek Chief Daryl Gates ' resignation and neither blamed nor cleared him." type="ADJP">
          <tokens>
            <token id="13" string="videotaped" />
            <token id="14" string="beating" />
            <token id="15" string="a" />
            <token id="16" string="motorist" />
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
            <token id="27" string="and" />
            <token id="28" string="neither" />
            <token id="29" string="blamed" />
            <token id="30" string="nor" />
            <token id="31" string="cleared" />
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="9" string="neither blamed nor cleared him." type="VP">
          <tokens>
            <token id="28" string="neither" />
            <token id="29" string="blamed" />
            <token id="30" string="nor" />
            <token id="31" string="cleared" />
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="10" string="beating a motorist has decided not to seek Chief Daryl Gates ' resignation and neither blamed nor cleared him." type="SBAR">
          <tokens>
            <token id="14" string="beating" />
            <token id="15" string="a" />
            <token id="16" string="motorist" />
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
            <token id="27" string="and" />
            <token id="28" string="neither" />
            <token id="29" string="blamed" />
            <token id="30" string="nor" />
            <token id="31" string="cleared" />
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="11" string="its report" type="NP">
          <tokens>
            <token id="43" string="its" />
            <token id="44" string="report" />
          </tokens>
        </chunking>
        <chunking id="12" string="racist and sexist remarks" type="NP">
          <tokens>
            <token id="48" string="racist" />
            <token id="49" string="and" />
            <token id="50" string="sexist" />
            <token id="51" string="remarks" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 10-member commission , which was to release its report today ," type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="10-member" />
            <token id="37" string="commission" />
            <token id="38" string="," />
            <token id="39" string="which" />
            <token id="40" string="was" />
            <token id="41" string="to" />
            <token id="42" string="release" />
            <token id="43" string="its" />
            <token id="44" string="report" />
            <token id="45" string="today" />
            <token id="46" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="Police" />
            <token id="9" string="Department" />
          </tokens>
        </chunking>
        <chunking id="15" string="decided not to seek Chief Daryl Gates ' resignation" type="VP">
          <tokens>
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="16" string="found racist and sexist remarks scattered throughout 90,000 pages of computer messages" type="VP">
          <tokens>
            <token id="47" string="found" />
            <token id="48" string="racist" />
            <token id="49" string="and" />
            <token id="50" string="sexist" />
            <token id="51" string="remarks" />
            <token id="52" string="scattered" />
            <token id="53" string="throughout" />
            <token id="54" string="90,000" />
            <token id="55" string="pages" />
            <token id="56" string="of" />
            <token id="57" string="computer" />
            <token id="58" string="messages" />
          </tokens>
        </chunking>
        <chunking id="17" string="that investigated the Los Angeles Police Department after officers" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="investigated" />
            <token id="5" string="the" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="Police" />
            <token id="9" string="Department" />
            <token id="10" string="after" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="18" string="which was to release its report today" type="SBAR">
          <tokens>
            <token id="39" string="which" />
            <token id="40" string="was" />
            <token id="41" string="to" />
            <token id="42" string="release" />
            <token id="43" string="its" />
            <token id="44" string="report" />
            <token id="45" string="today" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 10-member commission" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="10-member" />
            <token id="37" string="commission" />
          </tokens>
        </chunking>
        <chunking id="20" string="90,000 pages" type="NP">
          <tokens>
            <token id="54" string="90,000" />
            <token id="55" string="pages" />
          </tokens>
        </chunking>
        <chunking id="21" string="a motorist has decided not to seek Chief Daryl Gates ' resignation" type="SBAR">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="motorist" />
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="22" string="Chief Daryl Gates '" type="NP">
          <tokens>
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
          </tokens>
        </chunking>
        <chunking id="23" string="computer messages" type="NP">
          <tokens>
            <token id="57" string="computer" />
            <token id="58" string="messages" />
          </tokens>
        </chunking>
        <chunking id="24" string="a motorist" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="motorist" />
          </tokens>
        </chunking>
        <chunking id="25" string="sources" type="NP">
          <tokens>
            <token id="60" string="sources" />
          </tokens>
        </chunking>
        <chunking id="26" string="A panel that investigated the Los Angeles Police Department after officers" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="panel" />
            <token id="3" string="that" />
            <token id="4" string="investigated" />
            <token id="5" string="the" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="Police" />
            <token id="9" string="Department" />
            <token id="10" string="after" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="27" string="A panel" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="panel" />
          </tokens>
        </chunking>
        <chunking id="28" string="Chief Daryl Gates ' resignation" type="NP">
          <tokens>
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="29" string="him." type="NP">
          <tokens>
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="30" string="has decided not to seek Chief Daryl Gates ' resignation" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="decided" />
            <token id="19" string="not" />
            <token id="20" string="to" />
            <token id="21" string="seek" />
            <token id="22" string="Chief" />
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
            <token id="25" string="'" />
            <token id="26" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="31" string="was to release its report today" type="VP">
          <tokens>
            <token id="40" string="was" />
            <token id="41" string="to" />
            <token id="42" string="release" />
            <token id="43" string="its" />
            <token id="44" string="report" />
            <token id="45" string="today" />
          </tokens>
        </chunking>
        <chunking id="32" string="to release its report today" type="VP">
          <tokens>
            <token id="41" string="to" />
            <token id="42" string="release" />
            <token id="43" string="its" />
            <token id="44" string="report" />
            <token id="45" string="today" />
          </tokens>
        </chunking>
        <chunking id="33" string="release its report today" type="VP">
          <tokens>
            <token id="42" string="release" />
            <token id="43" string="its" />
            <token id="44" string="report" />
            <token id="45" string="today" />
          </tokens>
        </chunking>
        <chunking id="34" string="blamed nor cleared him." type="VP">
          <tokens>
            <token id="29" string="blamed" />
            <token id="30" string="nor" />
            <token id="31" string="cleared" />
            <token id="32" string="him." />
          </tokens>
        </chunking>
        <chunking id="35" string="racist and sexist" type="ADJP">
          <tokens>
            <token id="48" string="racist" />
            <token id="49" string="and" />
            <token id="50" string="sexist" />
          </tokens>
        </chunking>
        <chunking id="36" string="said" type="VP">
          <tokens>
            <token id="61" string="said" />
          </tokens>
        </chunking>
        <chunking id="37" string="officers" type="NP">
          <tokens>
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="38" string="scattered throughout 90,000 pages of computer messages" type="VP">
          <tokens>
            <token id="52" string="scattered" />
            <token id="53" string="throughout" />
            <token id="54" string="90,000" />
            <token id="55" string="pages" />
            <token id="56" string="of" />
            <token id="57" string="computer" />
            <token id="58" string="messages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">panel</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">videotaped</governor>
          <dependent id="2">panel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">investigated</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">panel</governor>
          <dependent id="4">investigated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Department</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Department</governor>
          <dependent id="6">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Department</governor>
          <dependent id="7">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Department</governor>
          <dependent id="8">Police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">investigated</governor>
          <dependent id="9">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">officers</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">investigated</governor>
          <dependent id="11">officers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">videotaped</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="61">said</governor>
          <dependent id="13">videotaped</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">videotaped</governor>
          <dependent id="14">beating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">motorist</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">decided</governor>
          <dependent id="16">motorist</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">decided</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">beating</governor>
          <dependent id="18">decided</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">seek</governor>
          <dependent id="19">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">seek</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">decided</governor>
          <dependent id="21">seek</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Gates</governor>
          <dependent id="22">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Gates</governor>
          <dependent id="23">Daryl</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">resignation</governor>
          <dependent id="24">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Gates</governor>
          <dependent id="25">'</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">seek</governor>
          <dependent id="26">resignation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">beating</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">blamed</governor>
          <dependent id="28">neither</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">beating</governor>
          <dependent id="29">blamed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">blamed</governor>
          <dependent id="30">nor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">blamed</governor>
          <dependent id="31">cleared</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">blamed</governor>
          <dependent id="32">him.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">videotaped</governor>
          <dependent id="34">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">commission</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">commission</governor>
          <dependent id="36">10-member</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="47">found</governor>
          <dependent id="37">commission</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">was</governor>
          <dependent id="39">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="37">commission</governor>
          <dependent id="40">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">release</governor>
          <dependent id="41">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">was</governor>
          <dependent id="42">release</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="44">report</governor>
          <dependent id="43">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">release</governor>
          <dependent id="44">report</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="42">release</governor>
          <dependent id="45">today</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">videotaped</governor>
          <dependent id="47">found</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">remarks</governor>
          <dependent id="48">racist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="48">racist</governor>
          <dependent id="49">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="48">racist</governor>
          <dependent id="50">sexist</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="47">found</governor>
          <dependent id="51">remarks</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="51">remarks</governor>
          <dependent id="52">scattered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">pages</governor>
          <dependent id="53">throughout</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="55">pages</governor>
          <dependent id="54">90,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="52">scattered</governor>
          <dependent id="55">pages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="58">messages</governor>
          <dependent id="56">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="58">messages</governor>
          <dependent id="57">computer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="55">pages</governor>
          <dependent id="58">messages</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="61">said</governor>
          <dependent id="60">sources</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="61">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Daryl Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Daryl" />
            <token id="24" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="Police" />
            <token id="9" string="Department" />
          </tokens>
        </entity>
        <entity id="3" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="22" string="Chief" />
          </tokens>
        </entity>
        <entity id="4" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="45" string="today" />
          </tokens>
        </entity>
        <entity id="5" string="90,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="54" string="90,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>A source speaking on the condition of anonymity said the panel report did not focus on Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="speaking" lemma="speaking" stem="speak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="anonymity" lemma="anonymity" stem="anonym" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="focus" lemma="focus" stem="focu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="resign" lemma="resign" stem="resign" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="33" string="created" lemma="create" stem="creat" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="climate" lemma="climate" stem="climat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="condoned" lemma="condone" stem="condon" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN source) (NN speaking)) (PP (IN on) (NP (NP (DT the) (NN condition)) (PP (IN of) (NP (NN anonymity)))))) (VP (VBD said) (SBAR (S (NP (DT the) (NN panel) (NN report)) (VP (VBD did) (RB not) (VP (VB focus) (PP (IN on) (NP (NP (NNP Gates)) (: --) (SBAR (WHNP (WP who)) (S (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD would) (VP (VB resign) (SBAR (IN if) (S (NP (DT the) (NN commission)) (VP (VBD agreed) (PP (IN with) (NP (PRP$ his) (NNS critics))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD created) (NP (DT a) (NN climate)) (PP (IN within) (NP (NP (DT the) (NN department)) (SBAR (WHNP (WDT that)) (S (VP (VBD condoned) (NP (NN racism) (CC and) (NN brutality))))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the commission" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="the department that condoned racism and brutality" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="said the panel report did not focus on Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="the" />
            <token id="11" string="panel" />
            <token id="12" string="report" />
            <token id="13" string="did" />
            <token id="14" string="not" />
            <token id="15" string="focus" />
            <token id="16" string="on" />
            <token id="17" string="Gates" />
            <token id="18" string="--" />
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="focus on Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="15" string="focus" />
            <token id="16" string="on" />
            <token id="17" string="Gates" />
            <token id="18" string="--" />
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="6" string="Gates" type="NP">
          <tokens>
            <token id="17" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="7" string="the condition" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="condition" />
          </tokens>
        </chunking>
        <chunking id="8" string="the panel report did not focus on Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="panel" />
            <token id="12" string="report" />
            <token id="13" string="did" />
            <token id="14" string="not" />
            <token id="15" string="focus" />
            <token id="16" string="on" />
            <token id="17" string="Gates" />
            <token id="18" string="--" />
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="the panel report" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="panel" />
            <token id="12" string="report" />
          </tokens>
        </chunking>
        <chunking id="11" string="condoned racism and brutality" type="VP">
          <tokens>
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he created a climate within the department that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="A source speaking" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="source" />
            <token id="3" string="speaking" />
          </tokens>
        </chunking>
        <chunking id="14" string="a climate" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="climate" />
          </tokens>
        </chunking>
        <chunking id="15" string="Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="NP">
          <tokens>
            <token id="17" string="Gates" />
            <token id="18" string="--" />
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="16" string="who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="17" string="his critics" type="NP">
          <tokens>
            <token id="29" string="his" />
            <token id="30" string="critics" />
          </tokens>
        </chunking>
        <chunking id="18" string="said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="19" string="A source speaking on the condition of anonymity" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="source" />
            <token id="3" string="speaking" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="condition" />
            <token id="7" string="of" />
            <token id="8" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="20" string="the department" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="department" />
          </tokens>
        </chunking>
        <chunking id="21" string="if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="22" string="racism and brutality" type="NP">
          <tokens>
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="23" string="anonymity" type="NP">
          <tokens>
            <token id="8" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="24" string="agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="25" string="would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="26" string="that condoned racism and brutality" type="SBAR">
          <tokens>
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="27" string="created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="28" string="resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="29" string="the condition of anonymity" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="condition" />
            <token id="7" string="of" />
            <token id="8" string="anonymity" />
          </tokens>
        </chunking>
        <chunking id="30" string="did not focus on Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" type="VP">
          <tokens>
            <token id="13" string="did" />
            <token id="14" string="not" />
            <token id="15" string="focus" />
            <token id="16" string="on" />
            <token id="17" string="Gates" />
            <token id="18" string="--" />
            <token id="19" string="who" />
            <token id="20" string="said" />
            <token id="21" string="he" />
            <token id="22" string="would" />
            <token id="23" string="resign" />
            <token id="24" string="if" />
            <token id="25" string="the" />
            <token id="26" string="commission" />
            <token id="27" string="agreed" />
            <token id="28" string="with" />
            <token id="29" string="his" />
            <token id="30" string="critics" />
            <token id="31" string="that" />
            <token id="32" string="he" />
            <token id="33" string="created" />
            <token id="34" string="a" />
            <token id="35" string="climate" />
            <token id="36" string="within" />
            <token id="37" string="the" />
            <token id="38" string="department" />
            <token id="39" string="that" />
            <token id="40" string="condoned" />
            <token id="41" string="racism" />
            <token id="42" string="and" />
            <token id="43" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">speaking</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">speaking</governor>
          <dependent id="2">source</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="3">speaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">condition</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">condition</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">speaking</governor>
          <dependent id="6">condition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">anonymity</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">condition</governor>
          <dependent id="8">anonymity</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">report</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">report</governor>
          <dependent id="11">panel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">focus</governor>
          <dependent id="12">report</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">focus</governor>
          <dependent id="13">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">focus</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="15">focus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Gates</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">focus</governor>
          <dependent id="17">Gates</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">Gates</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">resign</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">resign</governor>
          <dependent id="22">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="23">resign</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">agreed</governor>
          <dependent id="24">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">commission</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">agreed</governor>
          <dependent id="26">commission</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">resign</governor>
          <dependent id="27">agreed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">critics</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">critics</governor>
          <dependent id="29">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">agreed</governor>
          <dependent id="30">critics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">created</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">created</governor>
          <dependent id="32">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">agreed</governor>
          <dependent id="33">created</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">climate</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">created</governor>
          <dependent id="35">climate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">department</governor>
          <dependent id="36">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">department</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">created</governor>
          <dependent id="38">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">condoned</governor>
          <dependent id="39">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="38">department</governor>
          <dependent id="40">condoned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">condoned</governor>
          <dependent id="41">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">racism</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">racism</governor>
          <dependent id="43">brutality</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The report &amp;quot;deals with management issues, not directly with the chief of police,&amp;quot; the source said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="deals" lemma="deal" stem="deal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="directly" lemma="directly" stem="directli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN report) (`` ``) (NNS deals)) (PP (PP (IN with) (NP (NN management) (NNS issues))) (, ,) (RB not) (ADVP (RB directly)) (PP (IN with) (NP (NP (DT the) (NN chief)) (PP (IN of) (NP (NN police))))))) (, ,) ('' '') (NP (DT the) (NN source)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The report `` deals with management issues , not directly with the chief of police" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
            <token id="3" string="&quot;" />
            <token id="4" string="deals" />
            <token id="5" string="with" />
            <token id="6" string="management" />
            <token id="7" string="issues" />
            <token id="8" string="," />
            <token id="9" string="not" />
            <token id="10" string="directly" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="chief" />
            <token id="14" string="of" />
            <token id="15" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="police" type="NP">
          <tokens>
            <token id="15" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="the chief" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="management issues" type="NP">
          <tokens>
            <token id="6" string="management" />
            <token id="7" string="issues" />
          </tokens>
        </chunking>
        <chunking id="5" string="The report `` deals" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
            <token id="3" string="&quot;" />
            <token id="4" string="deals" />
          </tokens>
        </chunking>
        <chunking id="6" string="the chief of police" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="chief" />
            <token id="14" string="of" />
            <token id="15" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="the source" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="source" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">deals</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">deals</governor>
          <dependent id="2">report</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="4">deals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">issues</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">issues</governor>
          <dependent id="6">management</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">directly</governor>
          <dependent id="7">issues</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">directly</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">deals</governor>
          <dependent id="10">directly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">chief</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">chief</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">directly</governor>
          <dependent id="13">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">police</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">chief</governor>
          <dependent id="15">police</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">source</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">source</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Commission members and others who had seen the report declined comment Monday.</content>
      <tokens>
        <token id="1" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Commission) (NNS members)) (CC and) (NP (NP (NNS others)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN seen) (NP (DT the) (NN report)))))))) (VP (VBD declined) (NP (NN comment)) (NP-TMP (NNP Monday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who had seen the report" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="seen" />
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="2" string="had seen the report" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="seen" />
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="others who had seen the report" type="NP">
          <tokens>
            <token id="4" string="others" />
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="seen" />
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="Commission members and others who had seen the report" type="NP">
          <tokens>
            <token id="1" string="Commission" />
            <token id="2" string="members" />
            <token id="3" string="and" />
            <token id="4" string="others" />
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="seen" />
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="declined comment Monday" type="VP">
          <tokens>
            <token id="10" string="declined" />
            <token id="11" string="comment" />
            <token id="12" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="6" string="seen the report" type="VP">
          <tokens>
            <token id="7" string="seen" />
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="7" string="comment" type="NP">
          <tokens>
            <token id="11" string="comment" />
          </tokens>
        </chunking>
        <chunking id="8" string="Commission members" type="NP">
          <tokens>
            <token id="1" string="Commission" />
            <token id="2" string="members" />
          </tokens>
        </chunking>
        <chunking id="9" string="the report" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="report" />
          </tokens>
        </chunking>
        <chunking id="10" string="others" type="NP">
          <tokens>
            <token id="4" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">members</governor>
          <dependent id="1">Commission</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">declined</governor>
          <dependent id="2">members</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">members</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">members</governor>
          <dependent id="4">others</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">seen</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">seen</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">others</governor>
          <dependent id="7">seen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">report</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">seen</governor>
          <dependent id="9">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">declined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">declined</governor>
          <dependent id="11">comment</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">declined</governor>
          <dependent id="12">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Gates also wouldn&amp;apost;t comment.</content>
      <tokens>
        <token id="1" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="comment" lemma="comment" stem="comment" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Gates)) (ADVP (RB also)) (VP (MD would) (RB n't) (VP (VB comment))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Gates" type="NP">
          <tokens>
            <token id="1" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="2" string="would n't comment" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="n't" />
            <token id="5" string="comment" />
          </tokens>
        </chunking>
        <chunking id="3" string="comment" type="VP">
          <tokens>
            <token id="5" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">comment</governor>
          <dependent id="1">Gates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">comment</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">comment</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">comment</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">comment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Mayor Tom Bradley, who has asked Gates to step down, said through a spokesman he believed the report focused on police management, excessive force and civilian control.</content>
      <tokens>
        <token id="1" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Tom" lemma="Tom" stem="tom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Bradley" lemma="Bradley" stem="bradlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="step" lemma="step" stem="step" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="believed" lemma="believe" stem="believ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="focused" lemma="focus" stem="focus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="civilian" lemma="civilian" stem="civilian" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mayor) (NNP Tom) (NNP Bradley)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN asked) (S (NP (NNP Gates)) (VP (TO to) (VP (VB step) (ADVP (RB down))))))))) (, ,)) (VP (VBD said) (PP (IN through) (NP (NP (DT a) (NN spokesman)) (SBAR (S (NP (PRP he)) (VP (VBD believed) (SBAR (S (NP (DT the) (NN report)) (VP (VBD focused) (PP (IN on) (NP (NP (NN police) (NN management)) (, ,) (NP (JJ excessive) (NN force)) (CC and) (NP (JJ civilian) (NN control))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police management" type="NP">
          <tokens>
            <token id="23" string="police" />
            <token id="24" string="management" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mayor Tom Bradley , who has asked Gates to step down ," type="NP">
          <tokens>
            <token id="1" string="Mayor" />
            <token id="2" string="Tom" />
            <token id="3" string="Bradley" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="asked" />
            <token id="8" string="Gates" />
            <token id="9" string="to" />
            <token id="10" string="step" />
            <token id="11" string="down" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="civilian control" type="NP">
          <tokens>
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="4" string="believed the report focused on police management , excessive force and civilian control" type="VP">
          <tokens>
            <token id="18" string="believed" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="5" string="police management , excessive force and civilian control" type="NP">
          <tokens>
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="6" string="excessive force" type="NP">
          <tokens>
            <token id="26" string="excessive" />
            <token id="27" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="a spokesman he believed the report focused on police management , excessive force and civilian control" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="spokesman" />
            <token id="17" string="he" />
            <token id="18" string="believed" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="8" string="who has asked Gates to step down" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="asked" />
            <token id="8" string="Gates" />
            <token id="9" string="to" />
            <token id="10" string="step" />
            <token id="11" string="down" />
          </tokens>
        </chunking>
        <chunking id="9" string="Gates" type="NP">
          <tokens>
            <token id="8" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="10" string="asked Gates to step down" type="VP">
          <tokens>
            <token id="7" string="asked" />
            <token id="8" string="Gates" />
            <token id="9" string="to" />
            <token id="10" string="step" />
            <token id="11" string="down" />
          </tokens>
        </chunking>
        <chunking id="11" string="focused on police management , excessive force and civilian control" type="VP">
          <tokens>
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="12" string="to step down" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="step" />
            <token id="11" string="down" />
          </tokens>
        </chunking>
        <chunking id="13" string="a spokesman" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="14" string="has asked Gates to step down" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="asked" />
            <token id="8" string="Gates" />
            <token id="9" string="to" />
            <token id="10" string="step" />
            <token id="11" string="down" />
          </tokens>
        </chunking>
        <chunking id="15" string="the report focused on police management , excessive force and civilian control" type="SBAR">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mayor Tom Bradley" type="NP">
          <tokens>
            <token id="1" string="Mayor" />
            <token id="2" string="Tom" />
            <token id="3" string="Bradley" />
          </tokens>
        </chunking>
        <chunking id="17" string="step down" type="VP">
          <tokens>
            <token id="10" string="step" />
            <token id="11" string="down" />
          </tokens>
        </chunking>
        <chunking id="18" string="he believed the report focused on police management , excessive force and civilian control" type="SBAR">
          <tokens>
            <token id="17" string="he" />
            <token id="18" string="believed" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="the report" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="report" />
          </tokens>
        </chunking>
        <chunking id="21" string="said through a spokesman he believed the report focused on police management , excessive force and civilian control" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="through" />
            <token id="15" string="a" />
            <token id="16" string="spokesman" />
            <token id="17" string="he" />
            <token id="18" string="believed" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="focused" />
            <token id="22" string="on" />
            <token id="23" string="police" />
            <token id="24" string="management" />
            <token id="25" string="," />
            <token id="26" string="excessive" />
            <token id="27" string="force" />
            <token id="28" string="and" />
            <token id="29" string="civilian" />
            <token id="30" string="control" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Bradley</governor>
          <dependent id="1">Mayor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bradley</governor>
          <dependent id="2">Tom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="3">Bradley</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">asked</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">asked</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Bradley</governor>
          <dependent id="7">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">asked</governor>
          <dependent id="8">Gates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">step</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">asked</governor>
          <dependent id="10">step</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">step</governor>
          <dependent id="11">down</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">spokesman</governor>
          <dependent id="14">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">spokesman</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="16">spokesman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">believed</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">spokesman</governor>
          <dependent id="18">believed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">report</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">focused</governor>
          <dependent id="20">report</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">believed</governor>
          <dependent id="21">focused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">management</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">management</governor>
          <dependent id="23">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">focused</governor>
          <dependent id="24">management</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">force</governor>
          <dependent id="26">excessive</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">management</governor>
          <dependent id="27">force</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">management</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">control</governor>
          <dependent id="29">civilian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">management</governor>
          <dependent id="30">control</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Tom Bradley" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Tom" />
            <token id="3" string="Bradley" />
          </tokens>
        </entity>
        <entity id="3" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Mayor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>Sources familiar with testimony and evidence presented to the panel told the Los Angeles Times that a number of racially derogatory messages sent on police car computer terminals have been cataloged.</content>
      <tokens>
        <token id="1" string="Sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="familiar" lemma="familiar" stem="familiar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="presented" lemma="present" stem="present" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="racially" lemma="racially" stem="racial" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="derogatory" lemma="derogatory" stem="derogatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="terminals" lemma="terminal" stem="termin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="cataloged" lemma="catalog" stem="catalog" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Sources)) (ADJP (JJ familiar) (PP (IN with) (NP (NN testimony) (CC and) (NN evidence))))) (VP (VBD presented) (PP (TO to) (NP (NP (DT the) (NN panel)) (SBAR (S (VP (VBD told) (NP (DT the) (NNP Los) (NNP Angeles) (NNP Times)) (SBAR (IN that) (S (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NP (ADJP (RB racially) (JJ derogatory)) (NNS messages)) (VP (VBN sent) (PP (IN on) (NP (NN police) (NN car) (NN computer) (NNS terminals))))))) (VP (VBP have) (VP (VBN been) (VP (VBN cataloged)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="racially derogatory" type="ADJP">
          <tokens>
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sources" type="NP">
          <tokens>
            <token id="1" string="Sources" />
          </tokens>
        </chunking>
        <chunking id="3" string="familiar with testimony and evidence" type="ADJP">
          <tokens>
            <token id="2" string="familiar" />
            <token id="3" string="with" />
            <token id="4" string="testimony" />
            <token id="5" string="and" />
            <token id="6" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="the panel told the Los Angeles Times that a number of racially derogatory messages sent on police car computer terminals have been cataloged" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="panel" />
            <token id="11" string="told" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Times" />
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="5" string="sent on police car computer terminals" type="VP">
          <tokens>
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Los Angeles Times" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Times" />
          </tokens>
        </chunking>
        <chunking id="7" string="that a number of racially derogatory messages sent on police car computer terminals have been cataloged" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="8" string="been cataloged" type="VP">
          <tokens>
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="9" string="a number of racially derogatory messages sent on police car computer terminals" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
          </tokens>
        </chunking>
        <chunking id="10" string="police car computer terminals" type="NP">
          <tokens>
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
          </tokens>
        </chunking>
        <chunking id="11" string="cataloged" type="VP">
          <tokens>
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="12" string="the panel" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="panel" />
          </tokens>
        </chunking>
        <chunking id="13" string="a number" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="number" />
          </tokens>
        </chunking>
        <chunking id="14" string="have been cataloged" type="VP">
          <tokens>
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="15" string="presented to the panel told the Los Angeles Times that a number of racially derogatory messages sent on police car computer terminals have been cataloged" type="VP">
          <tokens>
            <token id="7" string="presented" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="panel" />
            <token id="11" string="told" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Times" />
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="16" string="racially derogatory messages" type="NP">
          <tokens>
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
          </tokens>
        </chunking>
        <chunking id="17" string="racially derogatory messages sent on police car computer terminals" type="NP">
          <tokens>
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
          </tokens>
        </chunking>
        <chunking id="18" string="Sources familiar with testimony and evidence" type="NP">
          <tokens>
            <token id="1" string="Sources" />
            <token id="2" string="familiar" />
            <token id="3" string="with" />
            <token id="4" string="testimony" />
            <token id="5" string="and" />
            <token id="6" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="19" string="told the Los Angeles Times that a number of racially derogatory messages sent on police car computer terminals have been cataloged" type="SBAR">
          <tokens>
            <token id="11" string="told" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Times" />
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="racially" />
            <token id="21" string="derogatory" />
            <token id="22" string="messages" />
            <token id="23" string="sent" />
            <token id="24" string="on" />
            <token id="25" string="police" />
            <token id="26" string="car" />
            <token id="27" string="computer" />
            <token id="28" string="terminals" />
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="cataloged" />
          </tokens>
        </chunking>
        <chunking id="20" string="testimony and evidence" type="NP">
          <tokens>
            <token id="4" string="testimony" />
            <token id="5" string="and" />
            <token id="6" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">presented</governor>
          <dependent id="1">Sources</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Sources</governor>
          <dependent id="2">familiar</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">testimony</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">familiar</governor>
          <dependent id="4">testimony</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">testimony</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">testimony</governor>
          <dependent id="6">evidence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">presented</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">panel</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">panel</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">presented</governor>
          <dependent id="10">panel</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">panel</governor>
          <dependent id="11">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Times</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Times</governor>
          <dependent id="13">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Times</governor>
          <dependent id="14">Angeles</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">told</governor>
          <dependent id="15">Times</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">cataloged</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">number</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">cataloged</governor>
          <dependent id="18">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">messages</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">derogatory</governor>
          <dependent id="20">racially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">messages</governor>
          <dependent id="21">derogatory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">number</governor>
          <dependent id="22">messages</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">messages</governor>
          <dependent id="23">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">terminals</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">terminals</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">terminals</governor>
          <dependent id="26">car</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">terminals</governor>
          <dependent id="27">computer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">sent</governor>
          <dependent id="28">terminals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">cataloged</governor>
          <dependent id="29">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">cataloged</governor>
          <dependent id="30">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">told</governor>
          <dependent id="31">cataloged</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Times" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>One message, for which no context was provided, read: &amp;quot;It&amp;apost;s monkey slapping time.&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="context" lemma="context" stem="context" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="provided" lemma="provide" stem="provid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="read" lemma="read" stem="read" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="monkey" lemma="monkey" stem="monkei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="slapping" lemma="slapping" stem="slap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (CD One) (NN message)) (, ,) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT no) (NN context)) (VP (VBD was) (VP (VBN provided))))) (, ,)) (VP (VBN read))) (: :) (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (NN monkey) (NN slapping) (NN time)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="read" type="VP">
          <tokens>
            <token id="11" string="read" />
          </tokens>
        </chunking>
        <chunking id="2" string="was provided" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="provided" />
          </tokens>
        </chunking>
        <chunking id="3" string="provided" type="VP">
          <tokens>
            <token id="9" string="provided" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s monkey slapping time" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="monkey" />
            <token id="17" string="slapping" />
            <token id="18" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="One message , for which no context was provided ," type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="message" />
            <token id="3" string="," />
            <token id="4" string="for" />
            <token id="5" string="which" />
            <token id="6" string="no" />
            <token id="7" string="context" />
            <token id="8" string="was" />
            <token id="9" string="provided" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="no context" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="context" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="14" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="monkey slapping time" type="NP">
          <tokens>
            <token id="16" string="monkey" />
            <token id="17" string="slapping" />
            <token id="18" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="for which no context was provided" type="SBAR">
          <tokens>
            <token id="4" string="for" />
            <token id="5" string="which" />
            <token id="6" string="no" />
            <token id="7" string="context" />
            <token id="8" string="was" />
            <token id="9" string="provided" />
          </tokens>
        </chunking>
        <chunking id="10" string="One message" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="message" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">message</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">read</governor>
          <dependent id="2">message</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">which</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">provided</governor>
          <dependent id="5">which</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">context</governor>
          <dependent id="6">no</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">provided</governor>
          <dependent id="7">context</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">provided</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">message</governor>
          <dependent id="9">provided</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">read</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">time</governor>
          <dependent id="14">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">time</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">time</governor>
          <dependent id="16">monkey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">time</governor>
          <dependent id="17">slapping</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">read</governor>
          <dependent id="18">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>; The commission examined 90,000 pages of computer messages and found examples of racially and sexually &amp;quot;offensive&amp;quot; remarks scattered throughout.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="examined" lemma="examine" stem="examin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="90,000" lemma="90,000" stem="90,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="examples" lemma="example" stem="exampl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="racially" lemma="racially" stem="racial" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sexually" lemma="sexually" stem="sexual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="offensive" lemma="offensive" stem="offens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="remarks" lemma="remark" stem="remark" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="scattered" lemma="scatter" stem="scatter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="throughout" lemma="throughout" stem="throughout" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (DT The) (NN commission)) (VP (VP (VBN examined) (NP (NP (CD 90,000) (NNS pages)) (PP (IN of) (NP (NN computer) (NNS messages))))) (CC and) (VP (VBN found) (S (NP (NP (NNS examples)) (PP (IN of) (NP (RB racially) (CC and) (RB sexually)))) (NP (NP (`` ``) (JJ offensive) ('' '') (NNS remarks)) (VP (VBN scattered) (PP (IN throughout))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="90,000 pages" type="NP">
          <tokens>
            <token id="5" string="90,000" />
            <token id="6" string="pages" />
          </tokens>
        </chunking>
        <chunking id="2" string="90,000 pages of computer messages" type="NP">
          <tokens>
            <token id="5" string="90,000" />
            <token id="6" string="pages" />
            <token id="7" string="of" />
            <token id="8" string="computer" />
            <token id="9" string="messages" />
          </tokens>
        </chunking>
        <chunking id="3" string="The commission" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="commission" />
          </tokens>
        </chunking>
        <chunking id="4" string="computer messages" type="NP">
          <tokens>
            <token id="8" string="computer" />
            <token id="9" string="messages" />
          </tokens>
        </chunking>
        <chunking id="5" string="racially and sexually" type="NP">
          <tokens>
            <token id="14" string="racially" />
            <token id="15" string="and" />
            <token id="16" string="sexually" />
          </tokens>
        </chunking>
        <chunking id="6" string="scattered throughout" type="VP">
          <tokens>
            <token id="21" string="scattered" />
            <token id="22" string="throughout" />
          </tokens>
        </chunking>
        <chunking id="7" string="examined 90,000 pages of computer messages and found examples of racially and sexually `` offensive '' remarks scattered throughout" type="VP">
          <tokens>
            <token id="4" string="examined" />
            <token id="5" string="90,000" />
            <token id="6" string="pages" />
            <token id="7" string="of" />
            <token id="8" string="computer" />
            <token id="9" string="messages" />
            <token id="10" string="and" />
            <token id="11" string="found" />
            <token id="12" string="examples" />
            <token id="13" string="of" />
            <token id="14" string="racially" />
            <token id="15" string="and" />
            <token id="16" string="sexually" />
            <token id="17" string="&quot;" />
            <token id="18" string="offensive" />
            <token id="19" string="&quot;" />
            <token id="20" string="remarks" />
            <token id="21" string="scattered" />
            <token id="22" string="throughout" />
          </tokens>
        </chunking>
        <chunking id="8" string="examined 90,000 pages of computer messages" type="VP">
          <tokens>
            <token id="4" string="examined" />
            <token id="5" string="90,000" />
            <token id="6" string="pages" />
            <token id="7" string="of" />
            <token id="8" string="computer" />
            <token id="9" string="messages" />
          </tokens>
        </chunking>
        <chunking id="9" string="found examples of racially and sexually `` offensive '' remarks scattered throughout" type="VP">
          <tokens>
            <token id="11" string="found" />
            <token id="12" string="examples" />
            <token id="13" string="of" />
            <token id="14" string="racially" />
            <token id="15" string="and" />
            <token id="16" string="sexually" />
            <token id="17" string="&quot;" />
            <token id="18" string="offensive" />
            <token id="19" string="&quot;" />
            <token id="20" string="remarks" />
            <token id="21" string="scattered" />
            <token id="22" string="throughout" />
          </tokens>
        </chunking>
        <chunking id="10" string="examples" type="NP">
          <tokens>
            <token id="12" string="examples" />
          </tokens>
        </chunking>
        <chunking id="11" string="`` offensive '' remarks scattered throughout" type="NP">
          <tokens>
            <token id="17" string="&quot;" />
            <token id="18" string="offensive" />
            <token id="19" string="&quot;" />
            <token id="20" string="remarks" />
            <token id="21" string="scattered" />
            <token id="22" string="throughout" />
          </tokens>
        </chunking>
        <chunking id="12" string="examples of racially and sexually" type="NP">
          <tokens>
            <token id="12" string="examples" />
            <token id="13" string="of" />
            <token id="14" string="racially" />
            <token id="15" string="and" />
            <token id="16" string="sexually" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` offensive '' remarks" type="NP">
          <tokens>
            <token id="17" string="&quot;" />
            <token id="18" string="offensive" />
            <token id="19" string="&quot;" />
            <token id="20" string="remarks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">commission</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">examined</governor>
          <dependent id="3">commission</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">examined</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">pages</governor>
          <dependent id="5">90,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">examined</governor>
          <dependent id="6">pages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">messages</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">messages</governor>
          <dependent id="8">computer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">pages</governor>
          <dependent id="9">messages</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">examined</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">examined</governor>
          <dependent id="11">found</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">remarks</governor>
          <dependent id="12">examples</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">racially</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">examples</governor>
          <dependent id="14">racially</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">racially</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">racially</governor>
          <dependent id="16">sexually</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">remarks</governor>
          <dependent id="18">offensive</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">found</governor>
          <dependent id="20">remarks</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">remarks</governor>
          <dependent id="21">scattered</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">scattered</governor>
          <dependent id="22">throughout</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="90,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>In one section encompassing several thousand messages, 260 such remarks were discovered, one source said.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="encompassing" lemma="encompass" stem="encompass" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="thousand" lemma="thousand" stem="thousand" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="260" lemma="260" stem="260" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="remarks" lemma="remark" stem="remark" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="discovered" lemma="discover" stem="discov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NP (CD one) (NN section)) (VP (VBG encompassing) (NP (QP (JJ several) (CD thousand)) (NNS messages))))) (, ,) (NP (CD 260) (JJ such) (NNS remarks)) (VP (VBD were) (VP (VBN discovered)))) (, ,) (NP (CD one) (NN source)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="several thousand messages" type="NP">
          <tokens>
            <token id="5" string="several" />
            <token id="6" string="thousand" />
            <token id="7" string="messages" />
          </tokens>
        </chunking>
        <chunking id="2" string="one section" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="section" />
          </tokens>
        </chunking>
        <chunking id="3" string="were discovered" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="discovered" />
          </tokens>
        </chunking>
        <chunking id="4" string="one source" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="source" />
          </tokens>
        </chunking>
        <chunking id="5" string="260 such remarks" type="NP">
          <tokens>
            <token id="9" string="260" />
            <token id="10" string="such" />
            <token id="11" string="remarks" />
          </tokens>
        </chunking>
        <chunking id="6" string="one section encompassing several thousand messages" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="section" />
            <token id="4" string="encompassing" />
            <token id="5" string="several" />
            <token id="6" string="thousand" />
            <token id="7" string="messages" />
          </tokens>
        </chunking>
        <chunking id="7" string="encompassing several thousand messages" type="VP">
          <tokens>
            <token id="4" string="encompassing" />
            <token id="5" string="several" />
            <token id="6" string="thousand" />
            <token id="7" string="messages" />
          </tokens>
        </chunking>
        <chunking id="8" string="discovered" type="VP">
          <tokens>
            <token id="13" string="discovered" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">section</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">section</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">discovered</governor>
          <dependent id="3">section</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">section</governor>
          <dependent id="4">encompassing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">thousand</governor>
          <dependent id="5">several</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">messages</governor>
          <dependent id="6">thousand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">encompassing</governor>
          <dependent id="7">messages</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">remarks</governor>
          <dependent id="9">260</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">remarks</governor>
          <dependent id="10">such</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">discovered</governor>
          <dependent id="11">remarks</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">discovered</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="13">discovered</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">source</governor>
          <dependent id="15">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">source</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="260" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="260" />
          </tokens>
        </entity>
        <entity id="3" string="thousand" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="thousand" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>In the days after the March 3 nightstick beating of Rodney G. King, the Police Department released transcripts of computer messages that one of the officers at the scene sent to a another officer.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="nightstick" lemma="nightstick" stem="nightstick" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="G." lemma="G." stem="g." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="released" lemma="release" stem="releas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="transcripts" lemma="transcript" stem="transcript" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (NNS days)) (PP (IN after) (NP (NP (DT the) (NNP March) (CD 3) (NN nightstick) (NN beating)) (PP (IN of) (NP (NNP Rodney) (NNP G.) (NNP King))))))) (, ,) (NP (DT the) (NNP Police) (NNP Department)) (VP (VBD released) (NP (NP (NNS transcripts)) (PP (IN of) (NP (NN computer) (NNS messages))) (SBAR (WHNP (WDT that)) (S (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NNS officers)) (PP (IN at) (NP (DT the) (NN scene)))))) (VP (VBN sent) (PP (TO to) (NP (DT a) (DT another) (NN officer)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that one of the officers at the scene sent to a another officer" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="officers" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="scene" />
            <token id="31" string="sent" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="another" />
            <token id="35" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="transcripts" type="NP">
          <tokens>
            <token id="19" string="transcripts" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="24" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="the March 3 nightstick beating" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="March" />
            <token id="7" string="3" />
            <token id="8" string="nightstick" />
            <token id="9" string="beating" />
          </tokens>
        </chunking>
        <chunking id="5" string="transcripts of computer messages that one of the officers at the scene sent to a another officer" type="NP">
          <tokens>
            <token id="19" string="transcripts" />
            <token id="20" string="of" />
            <token id="21" string="computer" />
            <token id="22" string="messages" />
            <token id="23" string="that" />
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="officers" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="scene" />
            <token id="31" string="sent" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="another" />
            <token id="35" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="computer messages" type="NP">
          <tokens>
            <token id="21" string="computer" />
            <token id="22" string="messages" />
          </tokens>
        </chunking>
        <chunking id="7" string="the days after the March 3 nightstick beating of Rodney G. King" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="days" />
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="March" />
            <token id="7" string="3" />
            <token id="8" string="nightstick" />
            <token id="9" string="beating" />
            <token id="10" string="of" />
            <token id="11" string="Rodney" />
            <token id="12" string="G." />
            <token id="13" string="King" />
          </tokens>
        </chunking>
        <chunking id="8" string="one of the officers at the scene" type="NP">
          <tokens>
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="officers" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="scene" />
          </tokens>
        </chunking>
        <chunking id="9" string="the scene" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="scene" />
          </tokens>
        </chunking>
        <chunking id="10" string="sent to a another officer" type="VP">
          <tokens>
            <token id="31" string="sent" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="another" />
            <token id="35" string="officer" />
          </tokens>
        </chunking>
        <chunking id="11" string="a another officer" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="another" />
            <token id="35" string="officer" />
          </tokens>
        </chunking>
        <chunking id="12" string="Rodney G. King" type="NP">
          <tokens>
            <token id="11" string="Rodney" />
            <token id="12" string="G." />
            <token id="13" string="King" />
          </tokens>
        </chunking>
        <chunking id="13" string="the March 3 nightstick beating of Rodney G. King" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="March" />
            <token id="7" string="3" />
            <token id="8" string="nightstick" />
            <token id="9" string="beating" />
            <token id="10" string="of" />
            <token id="11" string="Rodney" />
            <token id="12" string="G." />
            <token id="13" string="King" />
          </tokens>
        </chunking>
        <chunking id="14" string="released transcripts of computer messages that one of the officers at the scene sent to a another officer" type="VP">
          <tokens>
            <token id="18" string="released" />
            <token id="19" string="transcripts" />
            <token id="20" string="of" />
            <token id="21" string="computer" />
            <token id="22" string="messages" />
            <token id="23" string="that" />
            <token id="24" string="one" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="officers" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="scene" />
            <token id="31" string="sent" />
            <token id="32" string="to" />
            <token id="33" string="a" />
            <token id="34" string="another" />
            <token id="35" string="officer" />
          </tokens>
        </chunking>
        <chunking id="15" string="the officers" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="officers" />
          </tokens>
        </chunking>
        <chunking id="16" string="the officers at the scene" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="officers" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="scene" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Police Department" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Police" />
            <token id="17" string="Department" />
          </tokens>
        </chunking>
        <chunking id="18" string="the days" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="days" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">days</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">days</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">released</governor>
          <dependent id="3">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">beating</governor>
          <dependent id="4">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">beating</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">beating</governor>
          <dependent id="6">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">beating</governor>
          <dependent id="7">3</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">beating</governor>
          <dependent id="8">nightstick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">days</governor>
          <dependent id="9">beating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">King</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">King</governor>
          <dependent id="11">Rodney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">King</governor>
          <dependent id="12">G.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">beating</governor>
          <dependent id="13">King</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Department</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Department</governor>
          <dependent id="16">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">released</governor>
          <dependent id="17">Department</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">released</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">released</governor>
          <dependent id="19">transcripts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">messages</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">messages</governor>
          <dependent id="21">computer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">transcripts</governor>
          <dependent id="22">messages</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">sent</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">sent</governor>
          <dependent id="24">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">officers</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">officers</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">one</governor>
          <dependent id="27">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">scene</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">scene</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">officers</governor>
          <dependent id="30">scene</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">transcripts</governor>
          <dependent id="31">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">officer</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="35">officer</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">officer</governor>
          <dependent id="34">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">sent</governor>
          <dependent id="35">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rodney G. King" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Rodney" />
            <token id="12" string="G." />
            <token id="13" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="the days" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="days" />
          </tokens>
        </entity>
        <entity id="4" string="March 3" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="March" />
            <token id="7" string="3" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The transcripts contained a reference to an earlier incident involving black people, using the phrase &amp;quot;gorillas in the mist.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="transcripts" lemma="transcript" stem="transcript" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="contained" lemma="contain" stem="contain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reference" lemma="reference" stem="refer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="earlier" lemma="earlier" stem="earlier" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="involving" lemma="involve" stem="involv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="phrase" lemma="phrase" stem="phrase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="gorillas" lemma="gorilla" stem="gorilla" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="mist" lemma="mist" stem="mist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS transcripts)) (VP (VBD contained) (NP (DT a) (NN reference)) (PP (TO to) (NP (DT an) (JJR earlier) (NN incident))) (S (VP (VBG involving) (NP (JJ black) (NNS people)))) (, ,) (S (VP (VBG using) (S (NP (DT the) (NN phrase)) (`` ``) (NP (NP (NNS gorillas)) (PP (IN in) (NP (DT the) (NN mist)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="contained a reference to an earlier incident involving black people , using the phrase `` gorillas in the mist" type="VP">
          <tokens>
            <token id="3" string="contained" />
            <token id="4" string="a" />
            <token id="5" string="reference" />
            <token id="6" string="to" />
            <token id="7" string="an" />
            <token id="8" string="earlier" />
            <token id="9" string="incident" />
            <token id="10" string="involving" />
            <token id="11" string="black" />
            <token id="12" string="people" />
            <token id="13" string="," />
            <token id="14" string="using" />
            <token id="15" string="the" />
            <token id="16" string="phrase" />
            <token id="17" string="&quot;" />
            <token id="18" string="gorillas" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mist" />
          </tokens>
        </chunking>
        <chunking id="2" string="black people" type="NP">
          <tokens>
            <token id="11" string="black" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="using the phrase `` gorillas in the mist" type="VP">
          <tokens>
            <token id="14" string="using" />
            <token id="15" string="the" />
            <token id="16" string="phrase" />
            <token id="17" string="&quot;" />
            <token id="18" string="gorillas" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mist" />
          </tokens>
        </chunking>
        <chunking id="4" string="the mist" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="mist" />
          </tokens>
        </chunking>
        <chunking id="5" string="The transcripts" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="transcripts" />
          </tokens>
        </chunking>
        <chunking id="6" string="the phrase" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="phrase" />
          </tokens>
        </chunking>
        <chunking id="7" string="an earlier incident" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="earlier" />
            <token id="9" string="incident" />
          </tokens>
        </chunking>
        <chunking id="8" string="gorillas in the mist" type="NP">
          <tokens>
            <token id="18" string="gorillas" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mist" />
          </tokens>
        </chunking>
        <chunking id="9" string="a reference" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="reference" />
          </tokens>
        </chunking>
        <chunking id="10" string="involving black people" type="VP">
          <tokens>
            <token id="10" string="involving" />
            <token id="11" string="black" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="gorillas" type="NP">
          <tokens>
            <token id="18" string="gorillas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">transcripts</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">contained</governor>
          <dependent id="2">transcripts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">contained</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">reference</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">contained</governor>
          <dependent id="5">reference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">incident</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">incident</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">incident</governor>
          <dependent id="8">earlier</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">contained</governor>
          <dependent id="9">incident</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">contained</governor>
          <dependent id="10">involving</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">people</governor>
          <dependent id="11">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">involving</governor>
          <dependent id="12">people</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">contained</governor>
          <dependent id="14">using</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">phrase</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">gorillas</governor>
          <dependent id="16">phrase</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">using</governor>
          <dependent id="18">gorillas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">mist</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">mist</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">gorillas</governor>
          <dependent id="21">mist</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>; At the same time, secret testimony by as many as a dozen black police officers told of numerous instances of racial harassment within the ranks and the existence of a double standard in the treatment of minority suspects.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="secret" lemma="secret" stem="secret" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dozen" lemma="dozen" stem="dozen" pos="NN" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="instances" lemma="instance" stem="instanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="harassment" lemma="harassment" stem="harass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ranks" lemma="rank" stem="rank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="existence" lemma="existence" stem="exist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="double" lemma="double" stem="doubl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="standard" lemma="standard" stem="standard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="treatment" lemma="treatment" stem="treatment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN At) (NP (DT the) (JJ same) (NN time))) (, ,) (NP (NP (JJ secret) (NN testimony)) (PP (IN by) (NP (ADJP (RB as) (JJ many) (PP (IN as) (NP (DT a) (NN dozen)))) (JJ black) (NN police) (NNS officers)))) (VP (VBD told) (PP (IN of) (NP (NP (JJ numerous) (NNS instances)) (PP (IN of) (NP (JJ racial) (NN harassment))))) (PP (IN within) (NP (NP (DT the) (NNS ranks)) (CC and) (NP (NP (DT the) (NN existence)) (PP (IN of) (NP (NP (DT a) (JJ double) (NN standard)) (PP (IN in) (NP (NP (DT the) (NN treatment)) (PP (IN of) (NP (NN minority) (NNS suspects))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the treatment of minority suspects" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="treatment" />
            <token id="38" string="of" />
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="2" string="the treatment" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="3" string="secret testimony by as many as a dozen black police officers" type="NP">
          <tokens>
            <token id="7" string="secret" />
            <token id="8" string="testimony" />
            <token id="9" string="by" />
            <token id="10" string="as" />
            <token id="11" string="many" />
            <token id="12" string="as" />
            <token id="13" string="a" />
            <token id="14" string="dozen" />
            <token id="15" string="black" />
            <token id="16" string="police" />
            <token id="17" string="officers" />
          </tokens>
        </chunking>
        <chunking id="4" string="a double standard in the treatment of minority suspects" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="double" />
            <token id="34" string="standard" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="treatment" />
            <token id="38" string="of" />
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="5" string="minority suspects" type="NP">
          <tokens>
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="6" string="the same time" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="same" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="told of numerous instances of racial harassment within the ranks and the existence of a double standard in the treatment of minority suspects" type="VP">
          <tokens>
            <token id="18" string="told" />
            <token id="19" string="of" />
            <token id="20" string="numerous" />
            <token id="21" string="instances" />
            <token id="22" string="of" />
            <token id="23" string="racial" />
            <token id="24" string="harassment" />
            <token id="25" string="within" />
            <token id="26" string="the" />
            <token id="27" string="ranks" />
            <token id="28" string="and" />
            <token id="29" string="the" />
            <token id="30" string="existence" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="double" />
            <token id="34" string="standard" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="treatment" />
            <token id="38" string="of" />
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="8" string="as many as a dozen black police officers" type="NP">
          <tokens>
            <token id="10" string="as" />
            <token id="11" string="many" />
            <token id="12" string="as" />
            <token id="13" string="a" />
            <token id="14" string="dozen" />
            <token id="15" string="black" />
            <token id="16" string="police" />
            <token id="17" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the existence" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="existence" />
          </tokens>
        </chunking>
        <chunking id="10" string="a double standard" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="double" />
            <token id="34" string="standard" />
          </tokens>
        </chunking>
        <chunking id="11" string="racial harassment" type="NP">
          <tokens>
            <token id="23" string="racial" />
            <token id="24" string="harassment" />
          </tokens>
        </chunking>
        <chunking id="12" string="the existence of a double standard in the treatment of minority suspects" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="existence" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="double" />
            <token id="34" string="standard" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="treatment" />
            <token id="38" string="of" />
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="13" string="a dozen" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="dozen" />
          </tokens>
        </chunking>
        <chunking id="14" string="the ranks" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="ranks" />
          </tokens>
        </chunking>
        <chunking id="15" string="as many as a dozen" type="ADJP">
          <tokens>
            <token id="10" string="as" />
            <token id="11" string="many" />
            <token id="12" string="as" />
            <token id="13" string="a" />
            <token id="14" string="dozen" />
          </tokens>
        </chunking>
        <chunking id="16" string="secret testimony" type="NP">
          <tokens>
            <token id="7" string="secret" />
            <token id="8" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="17" string="the ranks and the existence of a double standard in the treatment of minority suspects" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="ranks" />
            <token id="28" string="and" />
            <token id="29" string="the" />
            <token id="30" string="existence" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="double" />
            <token id="34" string="standard" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="treatment" />
            <token id="38" string="of" />
            <token id="39" string="minority" />
            <token id="40" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="18" string="numerous instances of racial harassment" type="NP">
          <tokens>
            <token id="20" string="numerous" />
            <token id="21" string="instances" />
            <token id="22" string="of" />
            <token id="23" string="racial" />
            <token id="24" string="harassment" />
          </tokens>
        </chunking>
        <chunking id="19" string="numerous instances" type="NP">
          <tokens>
            <token id="20" string="numerous" />
            <token id="21" string="instances" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">time</governor>
          <dependent id="2">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">time</governor>
          <dependent id="4">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">told</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">testimony</governor>
          <dependent id="7">secret</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">told</governor>
          <dependent id="8">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">officers</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">many</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">officers</governor>
          <dependent id="11">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">dozen</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">dozen</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">many</governor>
          <dependent id="14">dozen</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">officers</governor>
          <dependent id="15">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">officers</governor>
          <dependent id="16">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">testimony</governor>
          <dependent id="17">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">told</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">instances</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">instances</governor>
          <dependent id="20">numerous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">told</governor>
          <dependent id="21">instances</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">harassment</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">harassment</governor>
          <dependent id="23">racial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">instances</governor>
          <dependent id="24">harassment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">ranks</governor>
          <dependent id="25">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">ranks</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">told</governor>
          <dependent id="27">ranks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">ranks</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">existence</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">ranks</governor>
          <dependent id="30">existence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">standard</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">standard</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">standard</governor>
          <dependent id="33">double</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">existence</governor>
          <dependent id="34">standard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">treatment</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">treatment</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">standard</governor>
          <dependent id="37">treatment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">suspects</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">suspects</governor>
          <dependent id="39">minority</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">treatment</governor>
          <dependent id="40">suspects</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="dozen" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="dozen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>In one instance, officers said they found racial epithets spray-painted on the lockers inside police stations and concluded that other officers had put them there.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="instance" lemma="instance" stem="instanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="epithets" lemma="epithet" stem="epithet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="spray-painted" lemma="spray-paint" stem="spray-paint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="lockers" lemma="locker" stem="locker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="inside" lemma="inside" stem="insid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="stations" lemma="station" stem="station" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD one) (NN instance))) (, ,) (NP (NNS officers)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VP (VBD found) (NP (NP (JJ racial) (NNS epithets)) (VP (VBN spray-painted) (PP (IN on) (NP (NP (DT the) (NNS lockers)) (PP (IN inside) (NP (NN police) (NNS stations)))))))) (CC and) (VP (VBD concluded) (SBAR (IN that) (S (NP (JJ other) (NNS officers)) (VP (VBD had) (VP (VBN put) (S (NP (PRP them)) (ADVP (RB there)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they found racial epithets spray-painted on the lockers inside police stations and concluded that other officers had put them there" type="SBAR">
          <tokens>
            <token id="7" string="they" />
            <token id="8" string="found" />
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
            <token id="18" string="and" />
            <token id="19" string="concluded" />
            <token id="20" string="that" />
            <token id="21" string="other" />
            <token id="22" string="officers" />
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="one instance" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="instance" />
          </tokens>
        </chunking>
        <chunking id="3" string="the lockers" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="lockers" />
          </tokens>
        </chunking>
        <chunking id="4" string="found racial epithets spray-painted on the lockers inside police stations" type="VP">
          <tokens>
            <token id="8" string="found" />
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
          </tokens>
        </chunking>
        <chunking id="5" string="spray-painted on the lockers inside police stations" type="VP">
          <tokens>
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
          </tokens>
        </chunking>
        <chunking id="6" string="racial epithets spray-painted on the lockers inside police stations" type="NP">
          <tokens>
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
          </tokens>
        </chunking>
        <chunking id="7" string="had put them there" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="25" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="said they found racial epithets spray-painted on the lockers inside police stations and concluded that other officers had put them there" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="they" />
            <token id="8" string="found" />
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
            <token id="18" string="and" />
            <token id="19" string="concluded" />
            <token id="20" string="that" />
            <token id="21" string="other" />
            <token id="22" string="officers" />
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="put them there" type="VP">
          <tokens>
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="the lockers inside police stations" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
          </tokens>
        </chunking>
        <chunking id="13" string="concluded that other officers had put them there" type="VP">
          <tokens>
            <token id="19" string="concluded" />
            <token id="20" string="that" />
            <token id="21" string="other" />
            <token id="22" string="officers" />
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="14" string="racial epithets" type="NP">
          <tokens>
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
          </tokens>
        </chunking>
        <chunking id="15" string="police stations" type="NP">
          <tokens>
            <token id="16" string="police" />
            <token id="17" string="stations" />
          </tokens>
        </chunking>
        <chunking id="16" string="that other officers had put them there" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="other" />
            <token id="22" string="officers" />
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="17" string="officers" type="NP">
          <tokens>
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="18" string="found racial epithets spray-painted on the lockers inside police stations and concluded that other officers had put them there" type="VP">
          <tokens>
            <token id="8" string="found" />
            <token id="9" string="racial" />
            <token id="10" string="epithets" />
            <token id="11" string="spray-painted" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="lockers" />
            <token id="15" string="inside" />
            <token id="16" string="police" />
            <token id="17" string="stations" />
            <token id="18" string="and" />
            <token id="19" string="concluded" />
            <token id="20" string="that" />
            <token id="21" string="other" />
            <token id="22" string="officers" />
            <token id="23" string="had" />
            <token id="24" string="put" />
            <token id="25" string="them" />
            <token id="26" string="there" />
          </tokens>
        </chunking>
        <chunking id="19" string="other officers" type="NP">
          <tokens>
            <token id="21" string="other" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">instance</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">instance</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">said</governor>
          <dependent id="3">instance</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">found</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="8">found</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">epithets</governor>
          <dependent id="9">racial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">found</governor>
          <dependent id="10">epithets</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">epithets</governor>
          <dependent id="11">spray-painted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">lockers</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">lockers</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">spray-painted</governor>
          <dependent id="14">lockers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">stations</governor>
          <dependent id="15">inside</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">stations</governor>
          <dependent id="16">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">lockers</governor>
          <dependent id="17">stations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">found</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">found</governor>
          <dependent id="19">concluded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">put</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">officers</governor>
          <dependent id="21">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">put</governor>
          <dependent id="22">officers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">put</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">concluded</governor>
          <dependent id="24">put</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">put</governor>
          <dependent id="25">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">them</governor>
          <dependent id="26">there</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>In another, an officer testified behind closed doors that he was present when a caravan of patrol cars raced through a housing project with &amp;quot;Ride of the Valkyries&amp;quot; blaring from loudspeakers -- a scene reminiscent of the movie &amp;quot;Apocalypse Now.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="closed" lemma="closed" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="doors" lemma="door" stem="door" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="present" lemma="present" stem="present" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="caravan" lemma="caravan" stem="caravan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="cars" lemma="car" stem="car" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="raced" lemma="race" stem="race" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="housing" lemma="housing" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Ride" lemma="ride" stem="ride" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Valkyries" lemma="Valkyries" stem="valkyri" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="blaring" lemma="blare" stem="blare" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="loudspeakers" lemma="loudspeaker" stem="loudspeak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="reminiscent" lemma="reminiscent" stem="reminisc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Apocalypse" lemma="Apocalypse" stem="apocalyps" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="44" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT another))) (, ,) (NP (DT an) (NN officer)) (VP (VBD testified) (PP (IN behind) (NP (JJ closed) (NNS doors))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ present)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT a) (NN caravan)) (PP (IN of) (NP (NN patrol) (NNS cars)))) (VP (VBD raced) (PP (IN through) (NP (DT a) (NN housing) (NN project))) (PP (IN with) (NP (`` ``) (NP (NN Ride)) (PP (IN of) (NP (DT the) (NNPS Valkyries))) ('' '') (VP (VBG blaring) (PP (IN from) (NP (NP (NP (NNS loudspeakers)) (PRN (: --) (S (NP (DT a) (NN scene)) (ADJP (JJ reminiscent))))) (PP (IN of) (NP (NP (DT the) (NN movie)) (`` ``) (NP (NNP Apocalypse)))))) (ADVP (RB Now)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a caravan" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="caravan" />
          </tokens>
        </chunking>
        <chunking id="2" string="loudspeakers -- a scene reminiscent of the movie `` Apocalypse" type="NP">
          <tokens>
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
          </tokens>
        </chunking>
        <chunking id="3" string="the movie" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="movie" />
          </tokens>
        </chunking>
        <chunking id="4" string="a housing project" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
          </tokens>
        </chunking>
        <chunking id="5" string="raced through a housing project with `` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="VP">
          <tokens>
            <token id="20" string="raced" />
            <token id="21" string="through" />
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
            <token id="25" string="with" />
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="6" string="a caravan of patrol cars" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="caravan" />
            <token id="17" string="of" />
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="7" string="loudspeakers -- a scene reminiscent" type="NP">
          <tokens>
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ride" type="NP">
          <tokens>
            <token id="27" string="Ride" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Valkyries" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
          </tokens>
        </chunking>
        <chunking id="11" string="present" type="ADJP">
          <tokens>
            <token id="13" string="present" />
          </tokens>
        </chunking>
        <chunking id="12" string="when a caravan of patrol cars raced through a housing project with `` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="a" />
            <token id="16" string="caravan" />
            <token id="17" string="of" />
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
            <token id="20" string="raced" />
            <token id="21" string="through" />
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
            <token id="25" string="with" />
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="NP">
          <tokens>
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="14" string="reminiscent" type="ADJP">
          <tokens>
            <token id="38" string="reminiscent" />
          </tokens>
        </chunking>
        <chunking id="15" string="Apocalypse" type="NP">
          <tokens>
            <token id="43" string="Apocalypse" />
          </tokens>
        </chunking>
        <chunking id="16" string="another" type="NP">
          <tokens>
            <token id="2" string="another" />
          </tokens>
        </chunking>
        <chunking id="17" string="patrol cars" type="NP">
          <tokens>
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="18" string="closed doors" type="NP">
          <tokens>
            <token id="8" string="closed" />
            <token id="9" string="doors" />
          </tokens>
        </chunking>
        <chunking id="19" string="testified behind closed doors that he was present when a caravan of patrol cars raced through a housing project with `` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="VP">
          <tokens>
            <token id="6" string="testified" />
            <token id="7" string="behind" />
            <token id="8" string="closed" />
            <token id="9" string="doors" />
            <token id="10" string="that" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="present" />
            <token id="14" string="when" />
            <token id="15" string="a" />
            <token id="16" string="caravan" />
            <token id="17" string="of" />
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
            <token id="20" string="raced" />
            <token id="21" string="through" />
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
            <token id="25" string="with" />
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="20" string="blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="VP">
          <tokens>
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="21" string="was present when a caravan of patrol cars raced through a housing project with `` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="present" />
            <token id="14" string="when" />
            <token id="15" string="a" />
            <token id="16" string="caravan" />
            <token id="17" string="of" />
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
            <token id="20" string="raced" />
            <token id="21" string="through" />
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
            <token id="25" string="with" />
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
        <chunking id="22" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="23" string="loudspeakers" type="NP">
          <tokens>
            <token id="34" string="loudspeakers" />
          </tokens>
        </chunking>
        <chunking id="24" string="an officer" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="officer" />
          </tokens>
        </chunking>
        <chunking id="25" string="a scene" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="scene" />
          </tokens>
        </chunking>
        <chunking id="26" string="the movie `` Apocalypse" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
          </tokens>
        </chunking>
        <chunking id="27" string="that he was present when a caravan of patrol cars raced through a housing project with `` Ride of the Valkyries '' blaring from loudspeakers -- a scene reminiscent of the movie `` Apocalypse Now" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="present" />
            <token id="14" string="when" />
            <token id="15" string="a" />
            <token id="16" string="caravan" />
            <token id="17" string="of" />
            <token id="18" string="patrol" />
            <token id="19" string="cars" />
            <token id="20" string="raced" />
            <token id="21" string="through" />
            <token id="22" string="a" />
            <token id="23" string="housing" />
            <token id="24" string="project" />
            <token id="25" string="with" />
            <token id="26" string="&quot;" />
            <token id="27" string="Ride" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Valkyries" />
            <token id="31" string="&quot;" />
            <token id="32" string="blaring" />
            <token id="33" string="from" />
            <token id="34" string="loudspeakers" />
            <token id="35" string="--" />
            <token id="36" string="a" />
            <token id="37" string="scene" />
            <token id="38" string="reminiscent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="movie" />
            <token id="42" string="&quot;" />
            <token id="43" string="Apocalypse" />
            <token id="44" string="Now" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">another</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">testified</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">officer</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">testified</governor>
          <dependent id="5">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">testified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">doors</governor>
          <dependent id="7">behind</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">doors</governor>
          <dependent id="8">closed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">testified</governor>
          <dependent id="9">doors</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">present</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">present</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">present</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">testified</governor>
          <dependent id="13">present</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">raced</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">caravan</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">raced</governor>
          <dependent id="16">caravan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">cars</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">cars</governor>
          <dependent id="18">patrol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">caravan</governor>
          <dependent id="19">cars</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">present</governor>
          <dependent id="20">raced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">project</governor>
          <dependent id="21">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">project</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">project</governor>
          <dependent id="23">housing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">raced</governor>
          <dependent id="24">project</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Ride</governor>
          <dependent id="25">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">raced</governor>
          <dependent id="27">Ride</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Valkyries</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">Valkyries</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Ride</governor>
          <dependent id="30">Valkyries</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">Ride</governor>
          <dependent id="32">blaring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">loudspeakers</governor>
          <dependent id="33">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">blaring</governor>
          <dependent id="34">loudspeakers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">scene</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">reminiscent</governor>
          <dependent id="37">scene</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">loudspeakers</governor>
          <dependent id="38">reminiscent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">movie</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">movie</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">loudspeakers</governor>
          <dependent id="41">movie</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="41">movie</governor>
          <dependent id="43">Apocalypse</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">blaring</governor>
          <dependent id="44">Now</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Apocalypse" type="MISC" score="0.0">
          <tokens>
            <token id="43" string="Apocalypse" />
          </tokens>
        </entity>
        <entity id="2" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="44" string="Now" />
          </tokens>
        </entity>
        <entity id="3" string="present" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="present" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>; The officers testified before the commission after being assured that their identities would be kept confidential.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assured" lemma="assure" stem="assur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="identities" lemma="identity" stem="ident" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="kept" lemma="keep" stem="kept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="confidential" lemma="confidential" stem="confidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (DT The) (NNS officers)) (VP (VBD testified) (PP (IN before) (NP (DT the) (NN commission))) (PP (IN after) (S (VP (VBG being) (VP (VBN assured) (SBAR (IN that) (S (NP (PRP$ their) (NNS identities)) (VP (MD would) (VP (VB be) (VP (VBN kept) (S (ADJP (JJ confidential))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confidential" type="ADJP">
          <tokens>
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="assured that their identities would be kept confidential" type="VP">
          <tokens>
            <token id="10" string="assured" />
            <token id="11" string="that" />
            <token id="12" string="their" />
            <token id="13" string="identities" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="4" string="that their identities would be kept confidential" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="their" />
            <token id="13" string="identities" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="5" string="would be kept confidential" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="6" string="The officers" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="be kept confidential" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="8" string="their identities" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="identities" />
          </tokens>
        </chunking>
        <chunking id="9" string="kept confidential" type="VP">
          <tokens>
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="10" string="testified before the commission after being assured that their identities would be kept confidential" type="VP">
          <tokens>
            <token id="4" string="testified" />
            <token id="5" string="before" />
            <token id="6" string="the" />
            <token id="7" string="commission" />
            <token id="8" string="after" />
            <token id="9" string="being" />
            <token id="10" string="assured" />
            <token id="11" string="that" />
            <token id="12" string="their" />
            <token id="13" string="identities" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="11" string="being assured that their identities would be kept confidential" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="assured" />
            <token id="11" string="that" />
            <token id="12" string="their" />
            <token id="13" string="identities" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="kept" />
            <token id="17" string="confidential" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officers</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">testified</governor>
          <dependent id="3">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">testified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">commission</governor>
          <dependent id="5">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">commission</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">testified</governor>
          <dependent id="7">commission</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">assured</governor>
          <dependent id="8">after</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">assured</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">testified</governor>
          <dependent id="10">assured</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">kept</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">identities</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">kept</governor>
          <dependent id="13">identities</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">kept</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">kept</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">assured</governor>
          <dependent id="16">kept</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">kept</governor>
          <dependent id="17">confidential</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>The American Civil Liberties Union and other groups called for Gates to resign after the March 3 incident in which white police officers repeatedly struck King with batons, kicked him and shocked him with a stun gun after pulling him over for speeding.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Civil" lemma="Civil" stem="civil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Liberties" lemma="Liberties" stem="liberti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Union" lemma="Union" stem="union" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="resign" lemma="resign" stem="resign" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="repeatedly" lemma="repeatedly" stem="repeatedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="struck" lemma="strike" stem="struck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="batons" lemma="baton" stem="baton" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="kicked" lemma="kick" stem="kick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="shocked" lemma="shock" stem="shock" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="stun" lemma="stun" stem="stun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="gun" lemma="gun" stem="gun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="pulling" lemma="pull" stem="pull" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="speeding" lemma="speeding" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP American) (NNP Civil) (NNP Liberties) (NNP Union)) (CC and) (NP (JJ other) (NNS groups))) (VP (VBN called) (PP (IN for) (NP (NNP Gates))) (S (VP (TO to) (VP (VB resign) (PP (IN after) (NP (NP (DT the) (NNP March) (CD 3) (NN incident)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (JJ white) (NN police) (NNS officers)) (ADVP (RB repeatedly)) (VP (VP (VBD struck) (NP (NNP King)) (PP (IN with) (NP (NNS batons)))) (, ,) (VP (VBD kicked) (NP (PRP him))) (CC and) (VP (VBD shocked) (NP (PRP him)) (PP (IN with) (NP (DT a) (JJ stun) (NN gun))) (PP (IN after) (S (VP (VBG pulling) (NP (PRP him)) (PP (IN over) (PP (IN for) (NP (NN speeding))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="resign after the March 3 incident in which white police officers repeatedly struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="VP">
          <tokens>
            <token id="13" string="resign" />
            <token id="14" string="after" />
            <token id="15" string="the" />
            <token id="16" string="March" />
            <token id="17" string="3" />
            <token id="18" string="incident" />
            <token id="19" string="in" />
            <token id="20" string="which" />
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
            <token id="24" string="repeatedly" />
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="2" string="struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="VP">
          <tokens>
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="3" string="shocked him with a stun gun after pulling him over for speeding" type="VP">
          <tokens>
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="4" string="speeding" type="NP">
          <tokens>
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="5" string="The American Civil Liberties Union" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="American" />
            <token id="3" string="Civil" />
            <token id="4" string="Liberties" />
            <token id="5" string="Union" />
          </tokens>
        </chunking>
        <chunking id="6" string="the March 3 incident" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="March" />
            <token id="17" string="3" />
            <token id="18" string="incident" />
          </tokens>
        </chunking>
        <chunking id="7" string="the March 3 incident in which white police officers repeatedly struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="March" />
            <token id="17" string="3" />
            <token id="18" string="incident" />
            <token id="19" string="in" />
            <token id="20" string="which" />
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
            <token id="24" string="repeatedly" />
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="8" string="in which white police officers repeatedly struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="SBAR">
          <tokens>
            <token id="19" string="in" />
            <token id="20" string="which" />
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
            <token id="24" string="repeatedly" />
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="9" string="The American Civil Liberties Union and other groups" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="American" />
            <token id="3" string="Civil" />
            <token id="4" string="Liberties" />
            <token id="5" string="Union" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="groups" />
          </tokens>
        </chunking>
        <chunking id="10" string="to resign after the March 3 incident in which white police officers repeatedly struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="resign" />
            <token id="14" string="after" />
            <token id="15" string="the" />
            <token id="16" string="March" />
            <token id="17" string="3" />
            <token id="18" string="incident" />
            <token id="19" string="in" />
            <token id="20" string="which" />
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
            <token id="24" string="repeatedly" />
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="11" string="him" type="NP">
          <tokens>
            <token id="31" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="other groups" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="groups" />
          </tokens>
        </chunking>
        <chunking id="13" string="kicked him" type="VP">
          <tokens>
            <token id="30" string="kicked" />
            <token id="31" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="Gates" type="NP">
          <tokens>
            <token id="11" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="15" string="pulling him over for speeding" type="VP">
          <tokens>
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="16" string="called for Gates to resign after the March 3 incident in which white police officers repeatedly struck King with batons , kicked him and shocked him with a stun gun after pulling him over for speeding" type="VP">
          <tokens>
            <token id="9" string="called" />
            <token id="10" string="for" />
            <token id="11" string="Gates" />
            <token id="12" string="to" />
            <token id="13" string="resign" />
            <token id="14" string="after" />
            <token id="15" string="the" />
            <token id="16" string="March" />
            <token id="17" string="3" />
            <token id="18" string="incident" />
            <token id="19" string="in" />
            <token id="20" string="which" />
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
            <token id="24" string="repeatedly" />
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
            <token id="29" string="," />
            <token id="30" string="kicked" />
            <token id="31" string="him" />
            <token id="32" string="and" />
            <token id="33" string="shocked" />
            <token id="34" string="him" />
            <token id="35" string="with" />
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
            <token id="39" string="after" />
            <token id="40" string="pulling" />
            <token id="41" string="him" />
            <token id="42" string="over" />
            <token id="43" string="for" />
            <token id="44" string="speeding" />
          </tokens>
        </chunking>
        <chunking id="17" string="King" type="NP">
          <tokens>
            <token id="26" string="King" />
          </tokens>
        </chunking>
        <chunking id="18" string="batons" type="NP">
          <tokens>
            <token id="28" string="batons" />
          </tokens>
        </chunking>
        <chunking id="19" string="struck King with batons" type="VP">
          <tokens>
            <token id="25" string="struck" />
            <token id="26" string="King" />
            <token id="27" string="with" />
            <token id="28" string="batons" />
          </tokens>
        </chunking>
        <chunking id="20" string="a stun gun" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="stun" />
            <token id="38" string="gun" />
          </tokens>
        </chunking>
        <chunking id="21" string="white police officers" type="NP">
          <tokens>
            <token id="21" string="white" />
            <token id="22" string="police" />
            <token id="23" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Union</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Union</governor>
          <dependent id="2">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Union</governor>
          <dependent id="3">Civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Union</governor>
          <dependent id="4">Liberties</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">called</governor>
          <dependent id="5">Union</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">Union</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">groups</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Union</governor>
          <dependent id="8">groups</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Gates</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">called</governor>
          <dependent id="11">Gates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">resign</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">called</governor>
          <dependent id="13">resign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">incident</governor>
          <dependent id="14">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">incident</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">incident</governor>
          <dependent id="16">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">incident</governor>
          <dependent id="17">3</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">resign</governor>
          <dependent id="18">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">which</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">struck</governor>
          <dependent id="20">which</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">officers</governor>
          <dependent id="21">white</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">officers</governor>
          <dependent id="22">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">struck</governor>
          <dependent id="23">officers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">struck</governor>
          <dependent id="24">repeatedly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">incident</governor>
          <dependent id="25">struck</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">struck</governor>
          <dependent id="26">King</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">batons</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">struck</governor>
          <dependent id="28">batons</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">struck</governor>
          <dependent id="30">kicked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">kicked</governor>
          <dependent id="31">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">struck</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">struck</governor>
          <dependent id="33">shocked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">shocked</governor>
          <dependent id="34">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">gun</governor>
          <dependent id="35">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">gun</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">gun</governor>
          <dependent id="37">stun</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">shocked</governor>
          <dependent id="38">gun</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">pulling</governor>
          <dependent id="39">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">shocked</governor>
          <dependent id="40">pulling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">pulling</governor>
          <dependent id="41">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">speeding</governor>
          <dependent id="42">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">speeding</governor>
          <dependent id="43">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">pulling</governor>
          <dependent id="44">speeding</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Civil Liberties Union" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="American" />
            <token id="3" string="Civil" />
            <token id="4" string="Liberties" />
            <token id="5" string="Union" />
          </tokens>
        </entity>
        <entity id="2" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="26" string="King" />
          </tokens>
        </entity>
        <entity id="3" string="March 3" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="March" />
            <token id="17" string="3" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>King, 26, is black.</content>
      <tokens>
        <token id="1" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP King)) (, ,) (NP (CD 26)) (, ,)) (VP (VBZ is) (ADJP (JJ black))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is black" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="black" />
          </tokens>
        </chunking>
        <chunking id="2" string="26" type="NP">
          <tokens>
            <token id="3" string="26" />
          </tokens>
        </chunking>
        <chunking id="3" string="King" type="NP">
          <tokens>
            <token id="1" string="King" />
          </tokens>
        </chunking>
        <chunking id="4" string="black" type="ADJP">
          <tokens>
            <token id="6" string="black" />
          </tokens>
        </chunking>
        <chunking id="5" string="King , 26 ," type="NP">
          <tokens>
            <token id="1" string="King" />
            <token id="2" string="," />
            <token id="3" string="26" />
            <token id="4" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">black</governor>
          <dependent id="1">King</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">King</governor>
          <dependent id="3">26</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">black</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">black</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="26" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="26" />
          </tokens>
        </entity>
        <entity id="2" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>A bystander&amp;apost;s videotape of the beating prompted a federal investigation of police brutality.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="bystander" lemma="bystander" stem="bystand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT A) (NN bystander) (POS 's)) (NN videotape)) (PP (IN of) (NP (DT the) (NN beating)))) (VP (VBD prompted) (NP (NP (DT a) (JJ federal) (NN investigation)) (PP (IN of) (NP (NN police) (NN brutality))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A bystander 's videotape of the beating" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="bystander" />
            <token id="3" string="'s" />
            <token id="4" string="videotape" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="beating" />
          </tokens>
        </chunking>
        <chunking id="2" string="A bystander 's videotape" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="bystander" />
            <token id="3" string="'s" />
            <token id="4" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="3" string="a federal investigation" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the beating" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="beating" />
          </tokens>
        </chunking>
        <chunking id="5" string="police brutality" type="NP">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="6" string="prompted a federal investigation of police brutality" type="VP">
          <tokens>
            <token id="8" string="prompted" />
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="investigation" />
            <token id="12" string="of" />
            <token id="13" string="police" />
            <token id="14" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="7" string="A bystander 's" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="bystander" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="a federal investigation of police brutality" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="investigation" />
            <token id="12" string="of" />
            <token id="13" string="police" />
            <token id="14" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">bystander</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">videotape</governor>
          <dependent id="2">bystander</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">bystander</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">prompted</governor>
          <dependent id="4">videotape</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">beating</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">beating</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">videotape</governor>
          <dependent id="7">beating</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">prompted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">investigation</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">investigation</governor>
          <dependent id="10">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">prompted</governor>
          <dependent id="11">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">brutality</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">brutality</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">investigation</governor>
          <dependent id="14">brutality</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>Four officers were charged in the case.</content>
      <tokens>
        <token id="1" string="Four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD Four) (NNS officers)) (VP (VBD were) (VP (VBN charged) (PP (IN in) (NP (DT the) (NN case))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Four officers" type="NP">
          <tokens>
            <token id="1" string="Four" />
            <token id="2" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="charged in the case" type="VP">
          <tokens>
            <token id="4" string="charged" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="were charged in the case" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="charged" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">officers</governor>
          <dependent id="1">Four</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">charged</governor>
          <dependent id="2">officers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">charged</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">charged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">case</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">charged</governor>
          <dependent id="7">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Four" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>The commission, appointed by Gates and Bradley, held five public hearings, interviewed city leaders and reviewed more than 1 million pages of documents during its three-month investigation.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Bradley" lemma="Bradley" stem="bradlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="interviewed" lemma="interview" stem="interview" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="reviewed" lemma="review" stem="review" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="documents" lemma="document" stem="document" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="three-month" lemma="three-month" stem="three-month" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN commission)) (, ,) (VP (VBN appointed) (PP (IN by) (NP (NNP Gates) (CC and) (NNP Bradley)))) (, ,)) (VP (VP (VBD held) (NP (CD five) (JJ public) (NNS hearings))) (, ,) (VP (VBD interviewed) (NP (NN city) (NNS leaders))) (CC and) (VP (VBN reviewed) (NP (NP (QP (JJR more) (IN than) (CD 1) (CD million)) (NNS pages)) (PP (IN of) (NP (NNS documents)))) (PP (IN during) (NP (PRP$ its) (JJ three-month) (NN investigation))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more than 1 million pages" type="NP">
          <tokens>
            <token id="20" string="more" />
            <token id="21" string="than" />
            <token id="22" string="1" />
            <token id="23" string="million" />
            <token id="24" string="pages" />
          </tokens>
        </chunking>
        <chunking id="2" string="held five public hearings , interviewed city leaders and reviewed more than 1 million pages of documents during its three-month investigation" type="VP">
          <tokens>
            <token id="10" string="held" />
            <token id="11" string="five" />
            <token id="12" string="public" />
            <token id="13" string="hearings" />
            <token id="14" string="," />
            <token id="15" string="interviewed" />
            <token id="16" string="city" />
            <token id="17" string="leaders" />
            <token id="18" string="and" />
            <token id="19" string="reviewed" />
            <token id="20" string="more" />
            <token id="21" string="than" />
            <token id="22" string="1" />
            <token id="23" string="million" />
            <token id="24" string="pages" />
            <token id="25" string="of" />
            <token id="26" string="documents" />
            <token id="27" string="during" />
            <token id="28" string="its" />
            <token id="29" string="three-month" />
            <token id="30" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="3" string="five public hearings" type="NP">
          <tokens>
            <token id="11" string="five" />
            <token id="12" string="public" />
            <token id="13" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="4" string="The commission" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="commission" />
          </tokens>
        </chunking>
        <chunking id="5" string="documents" type="NP">
          <tokens>
            <token id="26" string="documents" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than 1 million pages of documents" type="NP">
          <tokens>
            <token id="20" string="more" />
            <token id="21" string="than" />
            <token id="22" string="1" />
            <token id="23" string="million" />
            <token id="24" string="pages" />
            <token id="25" string="of" />
            <token id="26" string="documents" />
          </tokens>
        </chunking>
        <chunking id="7" string="its three-month investigation" type="NP">
          <tokens>
            <token id="28" string="its" />
            <token id="29" string="three-month" />
            <token id="30" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="The commission , appointed by Gates and Bradley ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="commission" />
            <token id="3" string="," />
            <token id="4" string="appointed" />
            <token id="5" string="by" />
            <token id="6" string="Gates" />
            <token id="7" string="and" />
            <token id="8" string="Bradley" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="city leaders" type="NP">
          <tokens>
            <token id="16" string="city" />
            <token id="17" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="10" string="reviewed more than 1 million pages of documents during its three-month investigation" type="VP">
          <tokens>
            <token id="19" string="reviewed" />
            <token id="20" string="more" />
            <token id="21" string="than" />
            <token id="22" string="1" />
            <token id="23" string="million" />
            <token id="24" string="pages" />
            <token id="25" string="of" />
            <token id="26" string="documents" />
            <token id="27" string="during" />
            <token id="28" string="its" />
            <token id="29" string="three-month" />
            <token id="30" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="Gates and Bradley" type="NP">
          <tokens>
            <token id="6" string="Gates" />
            <token id="7" string="and" />
            <token id="8" string="Bradley" />
          </tokens>
        </chunking>
        <chunking id="12" string="held five public hearings" type="VP">
          <tokens>
            <token id="10" string="held" />
            <token id="11" string="five" />
            <token id="12" string="public" />
            <token id="13" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="13" string="interviewed city leaders" type="VP">
          <tokens>
            <token id="15" string="interviewed" />
            <token id="16" string="city" />
            <token id="17" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="14" string="appointed by Gates and Bradley" type="VP">
          <tokens>
            <token id="4" string="appointed" />
            <token id="5" string="by" />
            <token id="6" string="Gates" />
            <token id="7" string="and" />
            <token id="8" string="Bradley" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">commission</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">held</governor>
          <dependent id="2">commission</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">commission</governor>
          <dependent id="4">appointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Gates</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">appointed</governor>
          <dependent id="6">Gates</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Gates</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Gates</governor>
          <dependent id="8">Bradley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">held</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">hearings</governor>
          <dependent id="11">five</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">hearings</governor>
          <dependent id="12">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">held</governor>
          <dependent id="13">hearings</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">held</governor>
          <dependent id="15">interviewed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">leaders</governor>
          <dependent id="16">city</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">interviewed</governor>
          <dependent id="17">leaders</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">held</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">held</governor>
          <dependent id="19">reviewed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">million</governor>
          <dependent id="20">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="20">more</governor>
          <dependent id="21">than</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">million</governor>
          <dependent id="22">1</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">pages</governor>
          <dependent id="23">million</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">reviewed</governor>
          <dependent id="24">pages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">documents</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">pages</governor>
          <dependent id="26">documents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">investigation</governor>
          <dependent id="27">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">investigation</governor>
          <dependent id="28">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">investigation</governor>
          <dependent id="29">three-month</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">reviewed</governor>
          <dependent id="30">investigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Bradley" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Bradley" />
          </tokens>
        </entity>
        <entity id="3" string="three-month" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="three-month" />
          </tokens>
        </entity>
        <entity id="4" string="1 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="1" />
            <token id="23" string="million" />
          </tokens>
        </entity>
        <entity id="5" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>It was headed by former Deputy Secretary of State Warren Christopher.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="headed" lemma="head" stem="head" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Deputy" lemma="Deputy" stem="deputi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Secretary" lemma="Secretary" stem="secretari" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Warren" lemma="Warren" stem="warren" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (VP (VBN headed) (PP (IN by) (NP (NP (JJ former) (NNP Deputy) (NNP Secretary)) (PP (IN of) (NP (NNP State) (NNP Warren) (NNP Christopher))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="headed by former Deputy Secretary of State Warren Christopher" type="VP">
          <tokens>
            <token id="3" string="headed" />
            <token id="4" string="by" />
            <token id="5" string="former" />
            <token id="6" string="Deputy" />
            <token id="7" string="Secretary" />
            <token id="8" string="of" />
            <token id="9" string="State" />
            <token id="10" string="Warren" />
            <token id="11" string="Christopher" />
          </tokens>
        </chunking>
        <chunking id="2" string="State Warren Christopher" type="NP">
          <tokens>
            <token id="9" string="State" />
            <token id="10" string="Warren" />
            <token id="11" string="Christopher" />
          </tokens>
        </chunking>
        <chunking id="3" string="was headed by former Deputy Secretary of State Warren Christopher" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="headed" />
            <token id="4" string="by" />
            <token id="5" string="former" />
            <token id="6" string="Deputy" />
            <token id="7" string="Secretary" />
            <token id="8" string="of" />
            <token id="9" string="State" />
            <token id="10" string="Warren" />
            <token id="11" string="Christopher" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="former Deputy Secretary of State Warren Christopher" type="NP">
          <tokens>
            <token id="5" string="former" />
            <token id="6" string="Deputy" />
            <token id="7" string="Secretary" />
            <token id="8" string="of" />
            <token id="9" string="State" />
            <token id="10" string="Warren" />
            <token id="11" string="Christopher" />
          </tokens>
        </chunking>
        <chunking id="6" string="former Deputy Secretary" type="NP">
          <tokens>
            <token id="5" string="former" />
            <token id="6" string="Deputy" />
            <token id="7" string="Secretary" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">headed</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">headed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">headed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Secretary</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Secretary</governor>
          <dependent id="5">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Secretary</governor>
          <dependent id="6">Deputy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">headed</governor>
          <dependent id="7">Secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Christopher</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Christopher</governor>
          <dependent id="9">State</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Christopher</governor>
          <dependent id="10">Warren</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Secretary</governor>
          <dependent id="11">Christopher</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="State" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="State" />
          </tokens>
        </entity>
        <entity id="2" string="Warren Christopher" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Warren" />
            <token id="11" string="Christopher" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Gates was appointed by the Police Commission and cannot be fired by the mayor.</content>
      <tokens>
        <token id="1" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fired" lemma="fire" stem="fire" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Gates)) (VP (VP (VBD was) (VP (VBN appointed) (PP (IN by) (NP (DT the) (NNP Police) (NNP Commission))))) (CC and) (VP (MD can) (RB not) (VP (VB be) (VP (VBN fired) (PP (IN by) (NP (DT the) (NN mayor))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Gates" type="NP">
          <tokens>
            <token id="1" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="2" string="can not be fired by the mayor" type="VP">
          <tokens>
            <token id="9" string="can" />
            <token id="10" string="not" />
            <token id="11" string="be" />
            <token id="12" string="fired" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="3" string="be fired by the mayor" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="fired" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="4" string="the mayor" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="5" string="was appointed by the Police Commission and can not be fired by the mayor" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="appointed" />
            <token id="4" string="by" />
            <token id="5" string="the" />
            <token id="6" string="Police" />
            <token id="7" string="Commission" />
            <token id="8" string="and" />
            <token id="9" string="can" />
            <token id="10" string="not" />
            <token id="11" string="be" />
            <token id="12" string="fired" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Police Commission" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Police" />
            <token id="7" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="7" string="fired by the mayor" type="VP">
          <tokens>
            <token id="12" string="fired" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="8" string="was appointed by the Police Commission" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="appointed" />
            <token id="4" string="by" />
            <token id="5" string="the" />
            <token id="6" string="Police" />
            <token id="7" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="9" string="appointed by the Police Commission" type="VP">
          <tokens>
            <token id="3" string="appointed" />
            <token id="4" string="by" />
            <token id="5" string="the" />
            <token id="6" string="Police" />
            <token id="7" string="Commission" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">appointed</governor>
          <dependent id="1">Gates</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">appointed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">appointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Commission</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Commission</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Commission</governor>
          <dependent id="6">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">appointed</governor>
          <dependent id="7">Commission</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">appointed</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">fired</governor>
          <dependent id="9">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">fired</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">fired</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">appointed</governor>
          <dependent id="12">fired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">mayor</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">mayor</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">fired</governor>
          <dependent id="15">mayor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Police Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Police" />
            <token id="7" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The Police Commission consists of five civilians appointed by the mayor.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="consists" lemma="consist" stem="consist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="civilians" lemma="civilian" stem="civilian" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Police) (NNP Commission)) (VP (VBZ consists) (PP (IN of) (NP (NP (CD five) (NNS civilians)) (VP (VBN appointed) (PP (IN by) (NP (DT the) (NN mayor))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Police Commission" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Police" />
            <token id="3" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="the mayor" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="3" string="five civilians appointed by the mayor" type="NP">
          <tokens>
            <token id="6" string="five" />
            <token id="7" string="civilians" />
            <token id="8" string="appointed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="4" string="appointed by the mayor" type="VP">
          <tokens>
            <token id="8" string="appointed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="5" string="five civilians" type="NP">
          <tokens>
            <token id="6" string="five" />
            <token id="7" string="civilians" />
          </tokens>
        </chunking>
        <chunking id="6" string="consists of five civilians appointed by the mayor" type="VP">
          <tokens>
            <token id="4" string="consists" />
            <token id="5" string="of" />
            <token id="6" string="five" />
            <token id="7" string="civilians" />
            <token id="8" string="appointed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="mayor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Commission</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Commission</governor>
          <dependent id="2">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">consists</governor>
          <dependent id="3">Commission</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">consists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">civilians</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">civilians</governor>
          <dependent id="6">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">consists</governor>
          <dependent id="7">civilians</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">civilians</governor>
          <dependent id="8">appointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">mayor</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">mayor</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">appointed</governor>
          <dependent id="11">mayor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Police" />
            <token id="3" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The chief has civil-service protection and can be removed only by the Police Commission for misconduct.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="civil-service" lemma="civil-service" stem="civil-servic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="protection" lemma="protection" stem="protect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="removed" lemma="remove" stem="remov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN chief)) (VP (VP (VBZ has) (NP (JJ civil-service) (NN protection))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN removed) (ADVP (RB only)) (PP (IN by) (NP (NP (DT the) (NNP Police) (NNP Commission)) (PP (IN for) (NP (NN misconduct))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="removed only by the Police Commission for misconduct" type="VP">
          <tokens>
            <token id="9" string="removed" />
            <token id="10" string="only" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
            <token id="15" string="for" />
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="2" string="misconduct" type="NP">
          <tokens>
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="3" string="has civil-service protection" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="civil-service" />
            <token id="5" string="protection" />
          </tokens>
        </chunking>
        <chunking id="4" string="The chief" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="chief" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Police Commission" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="6" string="has civil-service protection and can be removed only by the Police Commission for misconduct" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="civil-service" />
            <token id="5" string="protection" />
            <token id="6" string="and" />
            <token id="7" string="can" />
            <token id="8" string="be" />
            <token id="9" string="removed" />
            <token id="10" string="only" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
            <token id="15" string="for" />
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="7" string="be removed only by the Police Commission for misconduct" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="removed" />
            <token id="10" string="only" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
            <token id="15" string="for" />
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="8" string="civil-service protection" type="NP">
          <tokens>
            <token id="4" string="civil-service" />
            <token id="5" string="protection" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Police Commission for misconduct" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
            <token id="15" string="for" />
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="10" string="can be removed only by the Police Commission for misconduct" type="VP">
          <tokens>
            <token id="7" string="can" />
            <token id="8" string="be" />
            <token id="9" string="removed" />
            <token id="10" string="only" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
            <token id="15" string="for" />
            <token id="16" string="misconduct" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">chief</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">has</governor>
          <dependent id="2">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">protection</governor>
          <dependent id="4">civil-service</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">has</governor>
          <dependent id="5">protection</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">has</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">removed</governor>
          <dependent id="7">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">removed</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">has</governor>
          <dependent id="9">removed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">removed</governor>
          <dependent id="10">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Commission</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Commission</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Commission</governor>
          <dependent id="13">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">removed</governor>
          <dependent id="14">Commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">misconduct</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Commission</governor>
          <dependent id="16">misconduct</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Police" />
            <token id="14" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Geoffrey Taylor Gibbs, who sits on the board of John M. Langston Bar Association, which represents about 900 African American lawyers, said black and Latino neighborhoods are depending on the commission to confirm their view that the white, male-dominated Police Department has subjected them to years of brutality and ignored their complaints.</content>
      <tokens>
        <token id="1" string="Geoffrey" lemma="Geoffrey" stem="geoffrei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Gibbs" lemma="Gibbs" stem="gibb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sits" lemma="sit" stem="sit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Langston" lemma="Langston" stem="langston" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Bar" lemma="Bar" stem="bar" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="represents" lemma="represent" stem="repres" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="900" lemma="900" stem="900" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="African" lemma="african" stem="african" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="22" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="23" string="lawyers" lemma="lawyer" stem="lawyer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Latino" lemma="latino" stem="latino" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="neighborhoods" lemma="neighborhood" stem="neighborhood" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="depending" lemma="depend" stem="depend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="confirm" lemma="confirm" stem="confirm" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="male-dominated" lemma="male-dominated" stem="male-domin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="45" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="46" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="subjected" lemma="subject" stem="subject" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="51" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="ignored" lemma="ignore" stem="ignor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Geoffrey) (NNP Taylor) (NNP Gibbs)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ sits) (PP (IN on) (NP (NP (DT the) (NN board)) (PP (IN of) (NP (NP (NNP John) (NNP M.) (NNP Langston) (NNP Bar) (NNP Association)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ represents) (PP (IN about) (NP (CD 900) (JJ African) (JJ American) (NNS lawyers))))))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (JJ black) (CC and) (NN Latino) (NNS neighborhoods)) (VP (VBP are) (VP (VBG depending) (PP (IN on) (NP (DT the) (NN commission))) (S (VP (TO to) (VP (VB confirm) (NP (PRP$ their) (NN view)) (SBAR (IN that) (S (NP (DT the) (JJ white) (, ,) (JJ male-dominated) (NNP Police) (NNP Department)) (VP (VP (VBZ has) (VP (VBN subjected) (NP (PRP them)) (PP (TO to) (NP (NP (NNS years)) (PP (IN of) (NP (NN brutality))))))) (CC and) (VP (VBD ignored) (NP (PRP$ their) (NNS complaints)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sits on the board of John M. Langston Bar Association , which represents about 900 African American lawyers" type="VP">
          <tokens>
            <token id="6" string="sits" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="board" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="years of brutality" type="NP">
          <tokens>
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="has subjected them to years of brutality" type="VP">
          <tokens>
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="which represents about 900 African American lawyers" type="SBAR">
          <tokens>
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="6" string="Geoffrey Taylor Gibbs" type="NP">
          <tokens>
            <token id="1" string="Geoffrey" />
            <token id="2" string="Taylor" />
            <token id="3" string="Gibbs" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="48" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="represents about 900 African American lawyers" type="VP">
          <tokens>
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="9" string="to confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="10" string="their view" type="NP">
          <tokens>
            <token id="37" string="their" />
            <token id="38" string="view" />
          </tokens>
        </chunking>
        <chunking id="11" string="the board" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="board" />
          </tokens>
        </chunking>
        <chunking id="12" string="said black and Latino neighborhoods are depending on the commission to confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="25" string="said" />
            <token id="26" string="black" />
            <token id="27" string="and" />
            <token id="28" string="Latino" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="are" />
            <token id="31" string="depending" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="commission" />
            <token id="35" string="to" />
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="13" string="ignored their complaints" type="VP">
          <tokens>
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="14" string="depending on the commission to confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="31" string="depending" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="commission" />
            <token id="35" string="to" />
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="15" string="that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="SBAR">
          <tokens>
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="16" string="who sits on the board of John M. Langston Bar Association , which represents about 900 African American lawyers" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="sits" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="board" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="17" string="brutality" type="NP">
          <tokens>
            <token id="52" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="18" string="their complaints" type="NP">
          <tokens>
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="19" string="are depending on the commission to confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="30" string="are" />
            <token id="31" string="depending" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="commission" />
            <token id="35" string="to" />
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="20" string="John M. Langston Bar Association , which represents about 900 African American lawyers" type="NP">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="21" string="years" type="NP">
          <tokens>
            <token id="50" string="years" />
          </tokens>
        </chunking>
        <chunking id="22" string="Geoffrey Taylor Gibbs , who sits on the board of John M. Langston Bar Association , which represents about 900 African American lawyers ," type="NP">
          <tokens>
            <token id="1" string="Geoffrey" />
            <token id="2" string="Taylor" />
            <token id="3" string="Gibbs" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="sits" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="board" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="23" string="900 African American lawyers" type="NP">
          <tokens>
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="24" string="the white , male-dominated Police Department" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
          </tokens>
        </chunking>
        <chunking id="25" string="black and Latino neighborhoods" type="NP">
          <tokens>
            <token id="26" string="black" />
            <token id="27" string="and" />
            <token id="28" string="Latino" />
            <token id="29" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="26" string="confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="27" string="John M. Langston Bar Association" type="NP">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
          </tokens>
        </chunking>
        <chunking id="28" string="the board of John M. Langston Bar Association , which represents about 900 African American lawyers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="board" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="represents" />
            <token id="19" string="about" />
            <token id="20" string="900" />
            <token id="21" string="African" />
            <token id="22" string="American" />
            <token id="23" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="29" string="has subjected them to years of brutality and ignored their complaints" type="VP">
          <tokens>
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="30" string="black and Latino neighborhoods are depending on the commission to confirm their view that the white , male-dominated Police Department has subjected them to years of brutality and ignored their complaints" type="SBAR">
          <tokens>
            <token id="26" string="black" />
            <token id="27" string="and" />
            <token id="28" string="Latino" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="are" />
            <token id="31" string="depending" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="commission" />
            <token id="35" string="to" />
            <token id="36" string="confirm" />
            <token id="37" string="their" />
            <token id="38" string="view" />
            <token id="39" string="that" />
            <token id="40" string="the" />
            <token id="41" string="white" />
            <token id="42" string="," />
            <token id="43" string="male-dominated" />
            <token id="44" string="Police" />
            <token id="45" string="Department" />
            <token id="46" string="has" />
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
            <token id="53" string="and" />
            <token id="54" string="ignored" />
            <token id="55" string="their" />
            <token id="56" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="31" string="subjected them to years of brutality" type="VP">
          <tokens>
            <token id="47" string="subjected" />
            <token id="48" string="them" />
            <token id="49" string="to" />
            <token id="50" string="years" />
            <token id="51" string="of" />
            <token id="52" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Gibbs</governor>
          <dependent id="1">Geoffrey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Gibbs</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="3">Gibbs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sits</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Gibbs</governor>
          <dependent id="6">sits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">board</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">board</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sits</governor>
          <dependent id="9">board</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Association</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Association</governor>
          <dependent id="11">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Association</governor>
          <dependent id="12">M.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Association</governor>
          <dependent id="13">Langston</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Association</governor>
          <dependent id="14">Bar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">board</governor>
          <dependent id="15">Association</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">represents</governor>
          <dependent id="17">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Association</governor>
          <dependent id="18">represents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">lawyers</governor>
          <dependent id="19">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">lawyers</governor>
          <dependent id="20">900</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">lawyers</governor>
          <dependent id="21">African</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">lawyers</governor>
          <dependent id="22">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">represents</governor>
          <dependent id="23">lawyers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">neighborhoods</governor>
          <dependent id="26">black</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">black</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">black</governor>
          <dependent id="28">Latino</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">depending</governor>
          <dependent id="29">neighborhoods</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">depending</governor>
          <dependent id="30">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="31">depending</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">commission</governor>
          <dependent id="32">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">commission</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">depending</governor>
          <dependent id="34">commission</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">confirm</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">depending</governor>
          <dependent id="36">confirm</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">view</governor>
          <dependent id="37">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">confirm</governor>
          <dependent id="38">view</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="47">subjected</governor>
          <dependent id="39">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">Department</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">Department</governor>
          <dependent id="41">white</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">Department</governor>
          <dependent id="43">male-dominated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">Department</governor>
          <dependent id="44">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="47">subjected</governor>
          <dependent id="45">Department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="47">subjected</governor>
          <dependent id="46">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">confirm</governor>
          <dependent id="47">subjected</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="47">subjected</governor>
          <dependent id="48">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">years</governor>
          <dependent id="49">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">subjected</governor>
          <dependent id="50">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">brutality</governor>
          <dependent id="51">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="50">years</governor>
          <dependent id="52">brutality</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="47">subjected</governor>
          <dependent id="53">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="47">subjected</governor>
          <dependent id="54">ignored</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="56">complaints</governor>
          <dependent id="55">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="54">ignored</governor>
          <dependent id="56">complaints</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="44" string="Police" />
            <token id="45" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="John M. Langston Bar Association" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="M." />
            <token id="13" string="Langston" />
            <token id="14" string="Bar" />
            <token id="15" string="Association" />
          </tokens>
        </entity>
        <entity id="3" string="900" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="900" />
          </tokens>
        </entity>
        <entity id="4" string="African" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="African" />
          </tokens>
        </entity>
        <entity id="5" string="Geoffrey Taylor Gibbs" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Geoffrey" />
            <token id="2" string="Taylor" />
            <token id="3" string="Gibbs" />
          </tokens>
        </entity>
        <entity id="6" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="American" />
          </tokens>
        </entity>
        <entity id="7" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="50" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;quot;People are looking to the commission,&amp;quot; said Gibbs.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Gibbs" lemma="Gibbs" stem="gibb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NNS People)) (VP (VBP are) (VP (VBG looking) (PP (TO to) (NP (DT the) (NN commission)))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Gibbs)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="looking to the commission" type="VP">
          <tokens>
            <token id="4" string="looking" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="are looking to the commission" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="looking" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="commission" />
          </tokens>
        </chunking>
        <chunking id="4" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="5" string="Gibbs" type="NP">
          <tokens>
            <token id="11" string="Gibbs" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">looking</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">looking</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="4">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">commission</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">commission</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">looking</governor>
          <dependent id="7">commission</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="11">Gibbs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gibbs" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Gibbs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>&amp;quot;If they don&amp;apost;t say this is a problem, then all of their recommendations won&amp;apost;t mean a thing.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP they)) (VP (VBP do) (RB n't) (VP (VB say))))) (S (NP (DT this)) (VP (VBZ is) (NP (DT a) (NN problem)))) (, ,) (RB then) (S (NP (NP (DT all)) (PP (IN of) (NP (PRP$ their) (NNS recommendations)))) (VP (MD wo) (RB n't) (VP (VB mean) (NP (DT a) (NN thing))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="13" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="a thing" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="their recommendations" type="NP">
          <tokens>
            <token id="15" string="their" />
            <token id="16" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="4" string="say" type="VP">
          <tokens>
            <token id="6" string="say" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="7" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a problem" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="problem" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="all of their recommendations" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="of" />
            <token id="15" string="their" />
            <token id="16" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="9" string="wo n't mean a thing" type="VP">
          <tokens>
            <token id="17" string="wo" />
            <token id="18" string="n't" />
            <token id="19" string="mean" />
            <token id="20" string="a" />
            <token id="21" string="thing" />
          </tokens>
        </chunking>
        <chunking id="10" string="mean a thing" type="VP">
          <tokens>
            <token id="19" string="mean" />
            <token id="20" string="a" />
            <token id="21" string="thing" />
          </tokens>
        </chunking>
        <chunking id="11" string="If they do n't say" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="they" />
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="say" />
          </tokens>
        </chunking>
        <chunking id="12" string="do n't say" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="say" />
          </tokens>
        </chunking>
        <chunking id="13" string="a problem" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">say</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">say</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">say</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">say</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">problem</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">problem</governor>
          <dependent id="7">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">problem</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">problem</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">problem</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">mean</governor>
          <dependent id="12">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">mean</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">recommendations</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">recommendations</governor>
          <dependent id="15">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">all</governor>
          <dependent id="16">recommendations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">mean</governor>
          <dependent id="17">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">mean</governor>
          <dependent id="18">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="10">problem</governor>
          <dependent id="19">mean</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">thing</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">mean</governor>
          <dependent id="21">thing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>; But Ramona Ripston, head of the Los Angeles ACLU, said it does not matter whether the report names Gates.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Ramona" lemma="Ramona" stem="ramona" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Ripston" lemma="Ripston" stem="ripston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="ACLU" lemma="ACLU" stem="aclu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="matter" lemma="matter" stem="matter" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (CC But) (NP (NP (NNP Ramona) (NNP Ripston)) (, ,) (NP (NP (NN head)) (PP (IN of) (NP (DT the) (NNP Los) (NNP Angeles) (NNP ACLU)))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBZ does) (RB not) (VP (VB matter) (SBAR (IN whether) (S (NP (DT the) (NN report) (NNS names)) (NP (NNP Gates)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="head of the Los Angeles ACLU" type="NP">
          <tokens>
            <token id="6" string="head" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="ACLU" />
          </tokens>
        </chunking>
        <chunking id="2" string="said it does not matter whether the report names Gates" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="it" />
            <token id="15" string="does" />
            <token id="16" string="not" />
            <token id="17" string="matter" />
            <token id="18" string="whether" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ramona Ripston , head of the Los Angeles ACLU ," type="NP">
          <tokens>
            <token id="3" string="Ramona" />
            <token id="4" string="Ripston" />
            <token id="5" string="," />
            <token id="6" string="head" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="ACLU" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="matter whether the report names Gates" type="VP">
          <tokens>
            <token id="17" string="matter" />
            <token id="18" string="whether" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="does not matter whether the report names Gates" type="VP">
          <tokens>
            <token id="15" string="does" />
            <token id="16" string="not" />
            <token id="17" string="matter" />
            <token id="18" string="whether" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="7" string="head" type="NP">
          <tokens>
            <token id="6" string="head" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gates" type="NP">
          <tokens>
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Los Angeles ACLU" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="ACLU" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ramona Ripston" type="NP">
          <tokens>
            <token id="3" string="Ramona" />
            <token id="4" string="Ripston" />
          </tokens>
        </chunking>
        <chunking id="11" string="it does not matter whether the report names Gates" type="SBAR">
          <tokens>
            <token id="14" string="it" />
            <token id="15" string="does" />
            <token id="16" string="not" />
            <token id="17" string="matter" />
            <token id="18" string="whether" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="12" string="the report names" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
          </tokens>
        </chunking>
        <chunking id="13" string="whether the report names Gates" type="SBAR">
          <tokens>
            <token id="18" string="whether" />
            <token id="19" string="the" />
            <token id="20" string="report" />
            <token id="21" string="names" />
            <token id="22" string="Gates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="13">said</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Ripston</governor>
          <dependent id="3">Ramona</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="4">Ripston</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Ripston</governor>
          <dependent id="6">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">ACLU</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">ACLU</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">ACLU</governor>
          <dependent id="9">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">ACLU</governor>
          <dependent id="10">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">head</governor>
          <dependent id="11">ACLU</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">matter</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">matter</governor>
          <dependent id="15">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">matter</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="17">matter</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">Gates</governor>
          <dependent id="18">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">names</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">names</governor>
          <dependent id="20">report</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">Gates</governor>
          <dependent id="21">names</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">matter</governor>
          <dependent id="22">Gates</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Ramona Ripston" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ramona" />
            <token id="4" string="Ripston" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles ACLU" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="ACLU" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>&amp;quot;If they find a series of things the matter with the department,&amp;quot; she said, &amp;quot;don&amp;apost;t you think it&amp;apost;s going to point a finger at Gates whether they name him or not?&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="find" lemma="find" stem="find" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="point" lemma="point" stem="point" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="finger" lemma="finger" stem="finger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="name" lemma="name" stem="name" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP they)) (VP (VBP find) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NNS things)))) (NP-TMP (NP (DT the) (NN matter)) (PP (IN with) (NP (DT the) (NN department))))))) (PRN (, ,) ('' '') (S (NP (PRP she)) (VP (VBD said))) (, ,)) (`` ``) (VP (VBP do) (RB n't) (NP (NP (PRP you)) (SBAR (S (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB point) (NP (DT a) (NN finger)) (PP (IN at) (NP (NNP Gates))) (SBAR (IN whether) (S (NP (PRP they)) (VP (VBP name) (NP (PRP him)))) (CC or) (RB not)))))))))))))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="find a series of things the matter with the department" type="VP">
          <tokens>
            <token id="4" string="find" />
            <token id="5" string="a" />
            <token id="6" string="series" />
            <token id="7" string="of" />
            <token id="8" string="things" />
            <token id="9" string="the" />
            <token id="10" string="matter" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="a finger" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="finger" />
          </tokens>
        </chunking>
        <chunking id="3" string="to point a finger at Gates whether they name him or not" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="name him" type="VP">
          <tokens>
            <token id="35" string="name" />
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="think it 's going to point a finger at Gates whether they name him or not" type="SBAR">
          <tokens>
            <token id="23" string="think" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="16" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="it 's going to point a finger at Gates whether they name him or not" type="SBAR">
          <tokens>
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="9" string="do n't you think it 's going to point a finger at Gates whether they name him or not" type="VP">
          <tokens>
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="you" />
            <token id="23" string="think" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="10" string="Gates" type="NP">
          <tokens>
            <token id="32" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="11" string="you think it 's going to point a finger at Gates whether they name him or not" type="NP">
          <tokens>
            <token id="22" string="you" />
            <token id="23" string="think" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s going to point a finger at Gates whether they name him or not" type="VP">
          <tokens>
            <token id="25" string="'s" />
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="13" string="If they find a series of things the matter with the department" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="they" />
            <token id="4" string="find" />
            <token id="5" string="a" />
            <token id="6" string="series" />
            <token id="7" string="of" />
            <token id="8" string="things" />
            <token id="9" string="the" />
            <token id="10" string="matter" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="whether they name him or not" type="SBAR">
          <tokens>
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="15" string="a series of things" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="series" />
            <token id="7" string="of" />
            <token id="8" string="things" />
          </tokens>
        </chunking>
        <chunking id="16" string="him" type="NP">
          <tokens>
            <token id="36" string="him" />
          </tokens>
        </chunking>
        <chunking id="17" string="point a finger at Gates whether they name him or not" type="VP">
          <tokens>
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="18" string="a series" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="series" />
          </tokens>
        </chunking>
        <chunking id="19" string="the matter" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="matter" />
          </tokens>
        </chunking>
        <chunking id="20" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="21" string="going to point a finger at Gates whether they name him or not" type="VP">
          <tokens>
            <token id="26" string="going" />
            <token id="27" string="to" />
            <token id="28" string="point" />
            <token id="29" string="a" />
            <token id="30" string="finger" />
            <token id="31" string="at" />
            <token id="32" string="Gates" />
            <token id="33" string="whether" />
            <token id="34" string="they" />
            <token id="35" string="name" />
            <token id="36" string="him" />
            <token id="37" string="or" />
            <token id="38" string="not" />
          </tokens>
        </chunking>
        <chunking id="22" string="the department" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="department" />
          </tokens>
        </chunking>
        <chunking id="23" string="things" type="NP">
          <tokens>
            <token id="8" string="things" />
          </tokens>
        </chunking>
        <chunking id="24" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="25" string="you" type="NP">
          <tokens>
            <token id="22" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">find</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">find</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">do</governor>
          <dependent id="4">find</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">series</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">find</governor>
          <dependent id="6">series</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">things</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">series</governor>
          <dependent id="8">things</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">matter</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">find</governor>
          <dependent id="10">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">department</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">department</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">matter</governor>
          <dependent id="13">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">do</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">do</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">do</governor>
          <dependent id="22">you</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">you</governor>
          <dependent id="23">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">going</governor>
          <dependent id="24">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">going</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">think</governor>
          <dependent id="26">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">point</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">going</governor>
          <dependent id="28">point</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">finger</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">point</governor>
          <dependent id="30">finger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Gates</governor>
          <dependent id="31">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">point</governor>
          <dependent id="32">Gates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">name</governor>
          <dependent id="33">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">name</governor>
          <dependent id="34">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">point</governor>
          <dependent id="35">name</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">name</governor>
          <dependent id="36">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">name</governor>
          <dependent id="37">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">name</governor>
          <dependent id="38">not</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="the Los Angeles Police Department" id_sentence="1" />
      <mentions>
        <mention ids_tokens="15-17" string="the Police Department" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="2-3" string="The officers" id_sentence="16" />
      <mentions>
        <mention ids_tokens="11" string="officers" id_sentence="1" />
        <mention ids_tokens="5" string="officers" id_sentence="14" />
        <mention ids_tokens="7" string="they" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="15-16" string="a motorist" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21" string="he" id_sentence="2" />
        <mention ids_tokens="29" string="his" id_sentence="2" />
        <mention ids_tokens="32" string="he" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="the panel report" id_sentence="2" />
      <mentions>
        <mention ids_tokens="8-9" string="the report" id_sentence="4" />
        <mention ids_tokens="19-20" string="the report" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43" string="Gates -- who said he would resign if the commission agreed with his critics that he created a climate within the department that condoned racism and brutality" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="Gates" id_sentence="5" />
        <mention ids_tokens="8" string="Gates" id_sentence="6" />
        <mention ids_tokens="11" string="Gates" id_sentence="17" />
        <mention ids_tokens="6" string="Gates" id_sentence="21" />
        <mention ids_tokens="1" string="Gates" id_sentence="23" />
        <mention ids_tokens="22" string="Gates" id_sentence="29" />
        <mention ids_tokens="32" string="Gates" id_sentence="30" />
        <mention ids_tokens="36" string="him" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="25-26" string="the commission" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-8" string="The commission , appointed by Gates and Bradley" id_sentence="21" />
        <mention ids_tokens="28" string="its" id_sentence="21" />
        <mention ids_tokens="1" string="It" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="37-38-39-40-41-42-43" string="the department that condoned racism and brutality" id_sentence="2" />
      <mentions>
        <mention ids_tokens="12-13" string="the department" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="the chief of police" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-2" string="The chief" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="1" string="Mayor" id_sentence="6" />
      <mentions>
        <mention ids_tokens="14-15" string="the mayor" id_sentence="23" />
        <mention ids_tokens="10-11" string="the mayor" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="2-3" string="Tom Bradley" id_sentence="6" />
      <mentions>
        <mention ids_tokens="8" string="Bradley" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12-13" string="the March 3 nightstick beating of Rodney G. King" id_sentence="11" />
      <mentions>
        <mention ids_tokens="6-7" string="the beating" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The transcripts" id_sentence="12" />
      <mentions>
        <mention ids_tokens="19-35" string="transcripts of computer messages that one of the officers at the scene sent to a another officer" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="11-12" string="black people" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2" string="People" id_sentence="27" />
        <mention ids_tokens="3" string="they" id_sentence="28" />
        <mention ids_tokens="3" string="they" id_sentence="30" />
        <mention ids_tokens="22-38" string="you think it's going to point a finger at Gates whether they name him or not" id_sentence="30" />
        <mention ids_tokens="34" string="they" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="26" string="King" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1-3" string="King , 26" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Geoffrey Taylor Gibbs" id_sentence="26" />
      <mentions>
        <mention ids_tokens="11" string="Gibbs" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="3-4" string="Ramona Ripston" id_sentence="29" />
      <mentions>
        <mention ids_tokens="16" string="she" id_sentence="30" />
      </mentions>
    </coreference>
  </coreferences>
</document>
