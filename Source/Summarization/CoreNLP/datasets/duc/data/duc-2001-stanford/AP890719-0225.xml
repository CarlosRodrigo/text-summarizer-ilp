<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890719-0225">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Simply put, the question was who should be counted as a person and who, if anybody, should not.</content>
      <tokens>
        <token id="1" string="Simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="anybody" lemma="anybody" stem="anybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (ADVP (RB Simply)) (VBN put))) (, ,) (NP (DT the) (NN question)) (VP (VBD was) (NP (SBAR (WHNP (WP who)) (S (VP (MD should) (VP (VB be) (VP (VBN counted) (PP (IN as) (NP (DT a) (NN person)))))))) (CC and) (SBAR (WHNP (WP who)) (S (PRN (, ,) (SBAR (IN if) (FRAG (NP (NN anybody)))) (, ,)) (VP (MD should) (RB not)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the question" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="question" />
          </tokens>
        </chunking>
        <chunking id="2" string="who should be counted as a person" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="should" />
            <token id="9" string="be" />
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
          </tokens>
        </chunking>
        <chunking id="3" string="anybody" type="NP">
          <tokens>
            <token id="18" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="4" string="should not" type="VP">
          <tokens>
            <token id="20" string="should" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="5" string="be counted as a person" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="Simply put" type="VP">
          <tokens>
            <token id="1" string="Simply" />
            <token id="2" string="put" />
          </tokens>
        </chunking>
        <chunking id="7" string="should be counted as a person" type="VP">
          <tokens>
            <token id="8" string="should" />
            <token id="9" string="be" />
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
          </tokens>
        </chunking>
        <chunking id="8" string="a person" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="person" />
          </tokens>
        </chunking>
        <chunking id="9" string="who , if anybody , should not" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="," />
            <token id="17" string="if" />
            <token id="18" string="anybody" />
            <token id="19" string="," />
            <token id="20" string="should" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="10" string="if anybody" type="SBAR">
          <tokens>
            <token id="17" string="if" />
            <token id="18" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="11" string="who should be counted as a person and who , if anybody , should not" type="NP">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="should" />
            <token id="9" string="be" />
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="," />
            <token id="17" string="if" />
            <token id="18" string="anybody" />
            <token id="19" string="," />
            <token id="20" string="should" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="12" string="was who should be counted as a person and who , if anybody , should not" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="who" />
            <token id="8" string="should" />
            <token id="9" string="be" />
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="," />
            <token id="17" string="if" />
            <token id="18" string="anybody" />
            <token id="19" string="," />
            <token id="20" string="should" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="13" string="counted as a person" type="VP">
          <tokens>
            <token id="10" string="counted" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="person" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">put</governor>
          <dependent id="1">Simply</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">counted</governor>
          <dependent id="2">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">question</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">counted</governor>
          <dependent id="5">question</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">counted</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">counted</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">counted</governor>
          <dependent id="8">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">counted</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">person</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">person</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">counted</governor>
          <dependent id="13">person</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">counted</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">should</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">anybody</governor>
          <dependent id="17">if</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">should</governor>
          <dependent id="18">anybody</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">counted</governor>
          <dependent id="20">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">should</governor>
          <dependent id="21">not</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>But there&amp;apost;s nothing simple about it.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="simple" lemma="simple" stem="simpl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (EX there)) (VP (VBZ 's) (ADJP (NN nothing) (JJ simple) (PP (IN about) (NP (PRP it))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s nothing simple about it" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="nothing" />
            <token id="5" string="simple" />
            <token id="6" string="about" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing simple about it" type="ADJP">
          <tokens>
            <token id="4" string="nothing" />
            <token id="5" string="simple" />
            <token id="6" string="about" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">'s</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">'s</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">simple</governor>
          <dependent id="4">nothing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">'s</governor>
          <dependent id="5">simple</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">it</governor>
          <dependent id="6">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">simple</governor>
          <dependent id="7">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The Senate voted one answer and, in effect, invited the Supreme Court to decide whether it was right or wrong.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="invited" lemma="invite" stem="invit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Senate)) (VP (VP (VBD voted) (NP (CD one) (NN answer))) (CC and) (PRN (, ,) (PP (IN in) (NP (NN effect))) (, ,)) (VP (VBN invited) (S (NP (DT the) (NNP Supreme) (NNP Court)) (VP (TO to) (VP (VB decide) (SBAR (IN whether) (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ right) (CC or) (JJ wrong)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="invited the Supreme Court to decide whether it was right or wrong" type="VP">
          <tokens>
            <token id="11" string="invited" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="to" />
            <token id="16" string="decide" />
            <token id="17" string="whether" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="2" string="to decide whether it was right or wrong" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="decide" />
            <token id="17" string="whether" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="was right or wrong" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="5" string="right or wrong" type="ADJP">
          <tokens>
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Senate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="7" string="voted one answer" type="VP">
          <tokens>
            <token id="3" string="voted" />
            <token id="4" string="one" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
        <chunking id="8" string="decide whether it was right or wrong" type="VP">
          <tokens>
            <token id="16" string="decide" />
            <token id="17" string="whether" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="9" string="voted one answer and , in effect , invited the Supreme Court to decide whether it was right or wrong" type="VP">
          <tokens>
            <token id="3" string="voted" />
            <token id="4" string="one" />
            <token id="5" string="answer" />
            <token id="6" string="and" />
            <token id="7" string="," />
            <token id="8" string="in" />
            <token id="9" string="effect" />
            <token id="10" string="," />
            <token id="11" string="invited" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="to" />
            <token id="16" string="decide" />
            <token id="17" string="whether" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Supreme Court" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
          </tokens>
        </chunking>
        <chunking id="11" string="effect" type="NP">
          <tokens>
            <token id="9" string="effect" />
          </tokens>
        </chunking>
        <chunking id="12" string="whether it was right or wrong" type="SBAR">
          <tokens>
            <token id="17" string="whether" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="right" />
            <token id="21" string="or" />
            <token id="22" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="13" string="one answer" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">voted</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">voted</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">answer</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">voted</governor>
          <dependent id="5">answer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">voted</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">effect</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">voted</governor>
          <dependent id="9">effect</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">voted</governor>
          <dependent id="11">invited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Court</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Court</governor>
          <dependent id="13">Supreme</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">invited</governor>
          <dependent id="14">Court</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">decide</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">invited</governor>
          <dependent id="16">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">right</governor>
          <dependent id="17">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">right</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">right</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">decide</governor>
          <dependent id="20">right</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">right</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">right</governor>
          <dependent id="22">wrong</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>That happened because in the arithmetic of congressional reapportionment, every question becomes complex, contentious and politically charged.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="arithmetic" lemma="arithmetic" stem="arithmet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="complex" lemma="complex" stem="complex" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="contentious" lemma="contentious" stem="contenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBD happened) (SBAR (IN because) (S (PP (IN in) (NP (NP (DT the) (NN arithmetic)) (PP (IN of) (NP (JJ congressional) (NN reapportionment))))) (, ,) (NP (DT every) (NN question)) (VP (VBZ becomes) (ADJP (JJ complex)) (, ,) (ADJP (ADJP (JJ contentious)) (CC and) (ADJP (RB politically) (VBN charged))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="the arithmetic" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="arithmetic" />
          </tokens>
        </chunking>
        <chunking id="3" string="every question" type="NP">
          <tokens>
            <token id="11" string="every" />
            <token id="12" string="question" />
          </tokens>
        </chunking>
        <chunking id="4" string="politically charged" type="ADJP">
          <tokens>
            <token id="18" string="politically" />
            <token id="19" string="charged" />
          </tokens>
        </chunking>
        <chunking id="5" string="happened because in the arithmetic of congressional reapportionment , every question becomes complex , contentious and politically charged" type="VP">
          <tokens>
            <token id="2" string="happened" />
            <token id="3" string="because" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="arithmetic" />
            <token id="7" string="of" />
            <token id="8" string="congressional" />
            <token id="9" string="reapportionment" />
            <token id="10" string="," />
            <token id="11" string="every" />
            <token id="12" string="question" />
            <token id="13" string="becomes" />
            <token id="14" string="complex" />
            <token id="15" string="," />
            <token id="16" string="contentious" />
            <token id="17" string="and" />
            <token id="18" string="politically" />
            <token id="19" string="charged" />
          </tokens>
        </chunking>
        <chunking id="6" string="complex" type="ADJP">
          <tokens>
            <token id="14" string="complex" />
          </tokens>
        </chunking>
        <chunking id="7" string="contentious and politically charged" type="ADJP">
          <tokens>
            <token id="16" string="contentious" />
            <token id="17" string="and" />
            <token id="18" string="politically" />
            <token id="19" string="charged" />
          </tokens>
        </chunking>
        <chunking id="8" string="congressional reapportionment" type="NP">
          <tokens>
            <token id="8" string="congressional" />
            <token id="9" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="9" string="becomes complex , contentious and politically charged" type="VP">
          <tokens>
            <token id="13" string="becomes" />
            <token id="14" string="complex" />
            <token id="15" string="," />
            <token id="16" string="contentious" />
            <token id="17" string="and" />
            <token id="18" string="politically" />
            <token id="19" string="charged" />
          </tokens>
        </chunking>
        <chunking id="10" string="the arithmetic of congressional reapportionment" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="arithmetic" />
            <token id="7" string="of" />
            <token id="8" string="congressional" />
            <token id="9" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="11" string="contentious" type="ADJP">
          <tokens>
            <token id="16" string="contentious" />
          </tokens>
        </chunking>
        <chunking id="12" string="because in the arithmetic of congressional reapportionment , every question becomes complex , contentious and politically charged" type="SBAR">
          <tokens>
            <token id="3" string="because" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="arithmetic" />
            <token id="7" string="of" />
            <token id="8" string="congressional" />
            <token id="9" string="reapportionment" />
            <token id="10" string="," />
            <token id="11" string="every" />
            <token id="12" string="question" />
            <token id="13" string="becomes" />
            <token id="14" string="complex" />
            <token id="15" string="," />
            <token id="16" string="contentious" />
            <token id="17" string="and" />
            <token id="18" string="politically" />
            <token id="19" string="charged" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">happened</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">happened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">becomes</governor>
          <dependent id="3">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">arithmetic</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">arithmetic</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">becomes</governor>
          <dependent id="6">arithmetic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">reapportionment</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">reapportionment</governor>
          <dependent id="8">congressional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">arithmetic</governor>
          <dependent id="9">reapportionment</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">question</governor>
          <dependent id="11">every</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">becomes</governor>
          <dependent id="12">question</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">happened</governor>
          <dependent id="13">becomes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">becomes</governor>
          <dependent id="14">complex</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">becomes</governor>
          <dependent id="16">contentious</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">contentious</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">charged</governor>
          <dependent id="18">politically</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">contentious</governor>
          <dependent id="19">charged</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The point at issue in Senate debate on a new immigration bill was whether illegal aliens should be counted in the process that will reallocate House seats among states after the 1990 census.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="reallocate" lemma="reallocate" stem="realloc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="27" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="33" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN point)) (PP (IN at) (NP (NP (NN issue)) (PP (IN in) (NP (NP (NNP Senate) (NN debate)) (PP (IN on) (NP (DT a) (JJ new) (NN immigration) (NN bill)))))))) (VP (VBD was) (SBAR (IN whether) (S (NP (JJ illegal) (NNS aliens)) (VP (MD should) (VP (VB be) (VP (VBN counted) (PP (IN in) (NP (NP (DT the) (NN process)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB reallocate) (NP (NNP House) (NNS seats)) (PP (IN among) (NP (NNS states))) (PP (IN after) (NP (DT the) (CD 1990) (NN census))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was whether illegal aliens should be counted in the process that will reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="whether" />
            <token id="15" string="illegal" />
            <token id="16" string="aliens" />
            <token id="17" string="should" />
            <token id="18" string="be" />
            <token id="19" string="counted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="15" string="illegal" />
            <token id="16" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="should be counted in the process that will reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="17" string="should" />
            <token id="18" string="be" />
            <token id="19" string="counted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="House seats" type="NP">
          <tokens>
            <token id="26" string="House" />
            <token id="27" string="seats" />
          </tokens>
        </chunking>
        <chunking id="5" string="will reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="6" string="issue" type="NP">
          <tokens>
            <token id="4" string="issue" />
          </tokens>
        </chunking>
        <chunking id="7" string="counted in the process that will reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="19" string="counted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1990 census" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="9" string="states" type="NP">
          <tokens>
            <token id="29" string="states" />
          </tokens>
        </chunking>
        <chunking id="10" string="whether illegal aliens should be counted in the process that will reallocate House seats among states after the 1990 census" type="SBAR">
          <tokens>
            <token id="14" string="whether" />
            <token id="15" string="illegal" />
            <token id="16" string="aliens" />
            <token id="17" string="should" />
            <token id="18" string="be" />
            <token id="19" string="counted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="11" string="be counted in the process that will reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="counted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="12" string="reallocate House seats among states after the 1990 census" type="VP">
          <tokens>
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="13" string="that will reallocate House seats among states after the 1990 census" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="Senate debate" type="NP">
          <tokens>
            <token id="6" string="Senate" />
            <token id="7" string="debate" />
          </tokens>
        </chunking>
        <chunking id="15" string="the process" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="16" string="Senate debate on a new immigration bill" type="NP">
          <tokens>
            <token id="6" string="Senate" />
            <token id="7" string="debate" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="new" />
            <token id="11" string="immigration" />
            <token id="12" string="bill" />
          </tokens>
        </chunking>
        <chunking id="17" string="a new immigration bill" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="new" />
            <token id="11" string="immigration" />
            <token id="12" string="bill" />
          </tokens>
        </chunking>
        <chunking id="18" string="the process that will reallocate House seats among states after the 1990 census" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="process" />
            <token id="23" string="that" />
            <token id="24" string="will" />
            <token id="25" string="reallocate" />
            <token id="26" string="House" />
            <token id="27" string="seats" />
            <token id="28" string="among" />
            <token id="29" string="states" />
            <token id="30" string="after" />
            <token id="31" string="the" />
            <token id="32" string="1990" />
            <token id="33" string="census" />
          </tokens>
        </chunking>
        <chunking id="19" string="The point at issue in Senate debate on a new immigration bill" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="point" />
            <token id="3" string="at" />
            <token id="4" string="issue" />
            <token id="5" string="in" />
            <token id="6" string="Senate" />
            <token id="7" string="debate" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="new" />
            <token id="11" string="immigration" />
            <token id="12" string="bill" />
          </tokens>
        </chunking>
        <chunking id="20" string="The point" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="point" />
          </tokens>
        </chunking>
        <chunking id="21" string="issue in Senate debate on a new immigration bill" type="NP">
          <tokens>
            <token id="4" string="issue" />
            <token id="5" string="in" />
            <token id="6" string="Senate" />
            <token id="7" string="debate" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="new" />
            <token id="11" string="immigration" />
            <token id="12" string="bill" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">point</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">was</governor>
          <dependent id="2">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">issue</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">point</governor>
          <dependent id="4">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">debate</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">debate</governor>
          <dependent id="6">Senate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">issue</governor>
          <dependent id="7">debate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">bill</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">bill</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">bill</governor>
          <dependent id="10">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">bill</governor>
          <dependent id="11">immigration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">debate</governor>
          <dependent id="12">bill</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">counted</governor>
          <dependent id="14">whether</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">aliens</governor>
          <dependent id="15">illegal</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">counted</governor>
          <dependent id="16">aliens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">counted</governor>
          <dependent id="17">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">counted</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">was</governor>
          <dependent id="19">counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">process</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">process</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">counted</governor>
          <dependent id="22">process</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">reallocate</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">reallocate</governor>
          <dependent id="24">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">process</governor>
          <dependent id="25">reallocate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">seats</governor>
          <dependent id="26">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">reallocate</governor>
          <dependent id="27">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">states</governor>
          <dependent id="28">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">reallocate</governor>
          <dependent id="29">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">census</governor>
          <dependent id="30">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">census</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">census</governor>
          <dependent id="32">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">reallocate</governor>
          <dependent id="33">census</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>There could be enough of them to shift seats away from at least five states to Sun Belt states with large numbers of illegal residents.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shift" lemma="shift" stem="shift" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="15" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Sun" lemma="Sun" stem="sun" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Belt" lemma="Belt" stem="belt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="states" lemma="state" stem="state" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (MD could) (VP (VB be) (ADJP (RB enough) (PP (IN of) (NP (PRP them)))) (S (VP (TO to) (VP (VB shift) (NP (NNS seats)) (ADVP (RB away) (PP (IN from) (NP (QP (IN at) (JJS least) (CD five)) (NNS states)))) (PP (TO to) (NP (NP (NNP Sun) (NNP Belt)) (SBAR (S (VP (VBZ states) (PP (IN with) (NP (NP (JJ large) (NNS numbers)) (PP (IN of) (NP (JJ illegal) (NNS residents))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="enough of them" type="ADJP">
          <tokens>
            <token id="4" string="enough" />
            <token id="5" string="of" />
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="could be enough of them to shift seats away from at least five states to Sun Belt states with large numbers of illegal residents" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="be" />
            <token id="4" string="enough" />
            <token id="5" string="of" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="shift" />
            <token id="9" string="seats" />
            <token id="10" string="away" />
            <token id="11" string="from" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="five" />
            <token id="15" string="states" />
            <token id="16" string="to" />
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="3" string="large numbers of illegal residents" type="NP">
          <tokens>
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="4" string="large numbers" type="NP">
          <tokens>
            <token id="21" string="large" />
            <token id="22" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="5" string="be enough of them to shift seats away from at least five states to Sun Belt states with large numbers of illegal residents" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="enough" />
            <token id="5" string="of" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="shift" />
            <token id="9" string="seats" />
            <token id="10" string="away" />
            <token id="11" string="from" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="five" />
            <token id="15" string="states" />
            <token id="16" string="to" />
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="illegal residents" type="NP">
          <tokens>
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="7" string="at least five states" type="NP">
          <tokens>
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="five" />
            <token id="15" string="states" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sun Belt" type="NP">
          <tokens>
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="shift seats away from at least five states to Sun Belt states with large numbers of illegal residents" type="VP">
          <tokens>
            <token id="8" string="shift" />
            <token id="9" string="seats" />
            <token id="10" string="away" />
            <token id="11" string="from" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="five" />
            <token id="15" string="states" />
            <token id="16" string="to" />
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="11" string="seats" type="NP">
          <tokens>
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="12" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sun Belt states with large numbers of illegal residents" type="NP">
          <tokens>
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="14" string="to shift seats away from at least five states to Sun Belt states with large numbers of illegal residents" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="shift" />
            <token id="9" string="seats" />
            <token id="10" string="away" />
            <token id="11" string="from" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="five" />
            <token id="15" string="states" />
            <token id="16" string="to" />
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="15" string="states with large numbers of illegal residents" type="SBAR">
          <tokens>
            <token id="19" string="states" />
            <token id="20" string="with" />
            <token id="21" string="large" />
            <token id="22" string="numbers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="4">enough</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">enough</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">enough</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">enough</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">them</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">enough</governor>
          <dependent id="6">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">shift</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">enough</governor>
          <dependent id="8">shift</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">shift</governor>
          <dependent id="9">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">states</governor>
          <dependent id="10">away</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">away</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">least</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="14">five</governor>
          <dependent id="13">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">states</governor>
          <dependent id="14">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shift</governor>
          <dependent id="15">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Belt</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Belt</governor>
          <dependent id="17">Sun</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shift</governor>
          <dependent id="18">Belt</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Belt</governor>
          <dependent id="19">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">numbers</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">numbers</governor>
          <dependent id="21">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">states</governor>
          <dependent id="22">numbers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">residents</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">residents</governor>
          <dependent id="24">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">numbers</governor>
          <dependent id="25">residents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sun Belt" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Sun" />
            <token id="18" string="Belt" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Nobody is certain because counting illegal aliens is a hard thing to do, given the fact that they don&amp;apost;t want to be spotted by the government.</content>
      <tokens>
        <token id="1" string="Nobody" lemma="nobody" stem="nobodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="spotted" lemma="spot" stem="spot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Nobody)) (VP (VBZ is) (ADJP (JJ certain)) (SBAR (IN because) (S (NP (VBG counting) (JJ illegal) (NNS aliens)) (VP (VBZ is) (NP (DT a) (JJ hard) (NN thing) (S (VP (TO to) (VP (VB do) (, ,) (PP (VBN given) (NP (NP (DT the) (NN fact)) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP do) (RB n't) (VP (VB want) (S (VP (TO to) (VP (VB be) (VP (VBN spotted) (PP (IN by) (NP (DT the) (NN government))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="want to be spotted by the government" type="VP">
          <tokens>
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="2" string="is certain because counting illegal aliens is a hard thing to do , given the fact that they do n't want to be spotted by the government" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="certain" />
            <token id="4" string="because" />
            <token id="5" string="counting" />
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="hard" />
            <token id="11" string="thing" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="3" string="do , given the fact that they do n't want to be spotted by the government" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="4" string="spotted by the government" type="VP">
          <tokens>
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="5" string="a hard thing to do , given the fact that they do n't want to be spotted by the government" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="hard" />
            <token id="11" string="thing" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="6" string="Nobody" type="NP">
          <tokens>
            <token id="1" string="Nobody" />
          </tokens>
        </chunking>
        <chunking id="7" string="the fact" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="fact" />
          </tokens>
        </chunking>
        <chunking id="8" string="because counting illegal aliens is a hard thing to do , given the fact that they do n't want to be spotted by the government" type="SBAR">
          <tokens>
            <token id="4" string="because" />
            <token id="5" string="counting" />
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="hard" />
            <token id="11" string="thing" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="counting illegal aliens" type="NP">
          <tokens>
            <token id="5" string="counting" />
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="11" string="be spotted by the government" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="12" string="that they do n't want to be spotted by the government" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="13" string="the government" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="14" string="to do , given the fact that they do n't want to be spotted by the government" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="15" string="the fact that they do n't want to be spotted by the government" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="16" string="is a hard thing to do , given the fact that they do n't want to be spotted by the government" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="hard" />
            <token id="11" string="thing" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="," />
            <token id="15" string="given" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="they" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="17" string="to be spotted by the government" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
        <chunking id="18" string="certain" type="ADJP">
          <tokens>
            <token id="3" string="certain" />
          </tokens>
        </chunking>
        <chunking id="19" string="do n't want to be spotted by the government" type="VP">
          <tokens>
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="want" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="spotted" />
            <token id="26" string="by" />
            <token id="27" string="the" />
            <token id="28" string="government" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">certain</governor>
          <dependent id="1">Nobody</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">certain</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">certain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">thing</governor>
          <dependent id="4">because</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">aliens</governor>
          <dependent id="5">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">aliens</governor>
          <dependent id="6">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">thing</governor>
          <dependent id="7">aliens</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">thing</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">thing</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">thing</governor>
          <dependent id="10">hard</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">certain</governor>
          <dependent id="11">thing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">do</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">thing</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">fact</governor>
          <dependent id="15">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fact</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">do</governor>
          <dependent id="17">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">want</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">want</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">want</governor>
          <dependent id="20">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">want</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">fact</governor>
          <dependent id="22">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">spotted</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">spotted</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">want</governor>
          <dependent id="25">spotted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">government</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">government</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">spotted</governor>
          <dependent id="28">government</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Then again, the Census Bureau maintains that not including them, and still coming up with an accurate 1990 population count, would be even more difficult.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="maintains" lemma="maintain" stem="maintain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="accurate" lemma="accurate" stem="accur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (ADVP (RB again)) (, ,) (NP (DT the) (NNP Census) (NNP Bureau)) (VP (VBZ maintains) (SBAR (IN that) (S (S (UCP (PP (RB not) (VBG including) (NP (PRP them))) (, ,) (CC and) (S (VP (ADVP (RB still)) (VBG coming) (PRT (RP up)) (PP (IN with) (NP (DT an) (ADJP (JJ accurate) (NP-TMP (CD 1990))) (NN population) (NN count))))))) (, ,) (VP (MD would) (VP (VB be) (ADJP (RB even) (RBR more) (JJ difficult))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an accurate 1990 population count" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="accurate" />
            <token id="20" string="1990" />
            <token id="21" string="population" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Census Bureau" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Census" />
            <token id="6" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="3" string="maintains that not including them , and still coming up with an accurate 1990 population count , would be even more difficult" type="VP">
          <tokens>
            <token id="7" string="maintains" />
            <token id="8" string="that" />
            <token id="9" string="not" />
            <token id="10" string="including" />
            <token id="11" string="them" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="still" />
            <token id="15" string="coming" />
            <token id="16" string="up" />
            <token id="17" string="with" />
            <token id="18" string="an" />
            <token id="19" string="accurate" />
            <token id="20" string="1990" />
            <token id="21" string="population" />
            <token id="22" string="count" />
            <token id="23" string="," />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="even" />
            <token id="27" string="more" />
            <token id="28" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="4" string="accurate 1990" type="ADJP">
          <tokens>
            <token id="19" string="accurate" />
            <token id="20" string="1990" />
          </tokens>
        </chunking>
        <chunking id="5" string="still coming up with an accurate 1990 population count" type="VP">
          <tokens>
            <token id="14" string="still" />
            <token id="15" string="coming" />
            <token id="16" string="up" />
            <token id="17" string="with" />
            <token id="18" string="an" />
            <token id="19" string="accurate" />
            <token id="20" string="1990" />
            <token id="21" string="population" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="6" string="even more difficult" type="ADJP">
          <tokens>
            <token id="26" string="even" />
            <token id="27" string="more" />
            <token id="28" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="7" string="that not including them , and still coming up with an accurate 1990 population count , would be even more difficult" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="not" />
            <token id="10" string="including" />
            <token id="11" string="them" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="still" />
            <token id="15" string="coming" />
            <token id="16" string="up" />
            <token id="17" string="with" />
            <token id="18" string="an" />
            <token id="19" string="accurate" />
            <token id="20" string="1990" />
            <token id="21" string="population" />
            <token id="22" string="count" />
            <token id="23" string="," />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="even" />
            <token id="27" string="more" />
            <token id="28" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="11" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="would be even more difficult" type="VP">
          <tokens>
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="even" />
            <token id="27" string="more" />
            <token id="28" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="10" string="be even more difficult" type="VP">
          <tokens>
            <token id="25" string="be" />
            <token id="26" string="even" />
            <token id="27" string="more" />
            <token id="28" string="difficult" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">maintains</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">maintains</governor>
          <dependent id="2">again</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Bureau</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Bureau</governor>
          <dependent id="5">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">maintains</governor>
          <dependent id="6">Bureau</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">maintains</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">difficult</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">them</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">them</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">difficult</governor>
          <dependent id="11">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">them</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">coming</governor>
          <dependent id="14">still</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">them</governor>
          <dependent id="15">coming</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="15">coming</governor>
          <dependent id="16">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">count</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">count</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">count</governor>
          <dependent id="19">accurate</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">accurate</governor>
          <dependent id="20">1990</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">count</governor>
          <dependent id="21">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">coming</governor>
          <dependent id="22">count</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">difficult</governor>
          <dependent id="24">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">difficult</governor>
          <dependent id="25">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">difficult</governor>
          <dependent id="26">even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">difficult</governor>
          <dependent id="27">more</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">maintains</governor>
          <dependent id="28">difficult</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1990" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Census" />
            <token id="6" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``A census of only legal residents cannot be done as accurately as a census of all residents,&amp;apost;&amp;apost; according to Census Bureau testimony to Congress.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="accurately" lemma="accurately" stem="accur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="25" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT A) (NN census)) (PP (IN of) (NP (JJ only) (JJ legal) (NNS residents)))) (VP (MD can) (RB not) (VP (VB be) (VP (VBN done) (ADVP (IN as) (RB accurately)) (PP (IN as) (NP (NP (DT a) (NN census)) (PP (IN of) (NP (DT all) (NNS residents))))) (, ,) ('' '') (PP (VBG according) (PP (TO to) (NP (NP (NNP Census) (NNP Bureau) (NN testimony)) (PP (TO to) (NP (NNP Congress))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Census Bureau testimony" type="NP">
          <tokens>
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
            <token id="26" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="2" string="be done as accurately as a census of all residents , '' according to Census Bureau testimony to Congress" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="done" />
            <token id="12" string="as" />
            <token id="13" string="accurately" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="census" />
            <token id="17" string="of" />
            <token id="18" string="all" />
            <token id="19" string="residents" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="according" />
            <token id="23" string="to" />
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
            <token id="26" string="testimony" />
            <token id="27" string="to" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="3" string="done as accurately as a census of all residents , '' according to Census Bureau testimony to Congress" type="VP">
          <tokens>
            <token id="11" string="done" />
            <token id="12" string="as" />
            <token id="13" string="accurately" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="census" />
            <token id="17" string="of" />
            <token id="18" string="all" />
            <token id="19" string="residents" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="according" />
            <token id="23" string="to" />
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
            <token id="26" string="testimony" />
            <token id="27" string="to" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="4" string="A census" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="only legal residents" type="NP">
          <tokens>
            <token id="5" string="only" />
            <token id="6" string="legal" />
            <token id="7" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="all residents" type="NP">
          <tokens>
            <token id="18" string="all" />
            <token id="19" string="residents" />
          </tokens>
        </chunking>
        <chunking id="7" string="a census of all residents" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="census" />
            <token id="17" string="of" />
            <token id="18" string="all" />
            <token id="19" string="residents" />
          </tokens>
        </chunking>
        <chunking id="8" string="A census of only legal residents" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="census" />
            <token id="4" string="of" />
            <token id="5" string="only" />
            <token id="6" string="legal" />
            <token id="7" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="Census Bureau testimony to Congress" type="NP">
          <tokens>
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
            <token id="26" string="testimony" />
            <token id="27" string="to" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="10" string="can not be done as accurately as a census of all residents , '' according to Census Bureau testimony to Congress" type="VP">
          <tokens>
            <token id="8" string="can" />
            <token id="9" string="not" />
            <token id="10" string="be" />
            <token id="11" string="done" />
            <token id="12" string="as" />
            <token id="13" string="accurately" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="census" />
            <token id="17" string="of" />
            <token id="18" string="all" />
            <token id="19" string="residents" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="according" />
            <token id="23" string="to" />
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
            <token id="26" string="testimony" />
            <token id="27" string="to" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="a census" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="census" />
          </tokens>
        </chunking>
        <chunking id="12" string="Congress" type="NP">
          <tokens>
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">census</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">done</governor>
          <dependent id="3">census</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">residents</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">residents</governor>
          <dependent id="5">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">residents</governor>
          <dependent id="6">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">census</governor>
          <dependent id="7">residents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">done</governor>
          <dependent id="8">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">done</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">done</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">done</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">accurately</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">done</governor>
          <dependent id="13">accurately</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">census</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">census</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">done</governor>
          <dependent id="16">census</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">residents</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">residents</governor>
          <dependent id="18">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">census</governor>
          <dependent id="19">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">testimony</governor>
          <dependent id="22">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="22">according</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">testimony</governor>
          <dependent id="24">Census</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">testimony</governor>
          <dependent id="25">Bureau</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">done</governor>
          <dependent id="26">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Congress</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">testimony</governor>
          <dependent id="28">Congress</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Census" />
            <token id="25" string="Bureau" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>After the 1980 census, the government estimated that there were 2.57 million people in the United States illegally.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="estimated" lemma="estimate" stem="estim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="2.57" lemma="2.57" stem="2.57" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="illegally" lemma="illegally" stem="illeg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (DT the) (CD 1980) (NN census))) (, ,) (NP (DT the) (NN government)) (VP (VBD estimated) (SBAR (IN that) (S (NP (EX there)) (VP (VBD were) (NP (NP (QP (CD 2.57) (CD million)) (NNS people)) (PP (IN in) (NP (DT the) (NNP United) (NNPS States)))) (ADVP (RB illegally)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="the United States" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </chunking>
        <chunking id="3" string="were 2.57 million people in the United States illegally" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="2.57" />
            <token id="13" string="million" />
            <token id="14" string="people" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
            <token id="19" string="illegally" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1980 census" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1980" />
            <token id="4" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="estimated that there were 2.57 million people in the United States illegally" type="VP">
          <tokens>
            <token id="8" string="estimated" />
            <token id="9" string="that" />
            <token id="10" string="there" />
            <token id="11" string="were" />
            <token id="12" string="2.57" />
            <token id="13" string="million" />
            <token id="14" string="people" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
            <token id="19" string="illegally" />
          </tokens>
        </chunking>
        <chunking id="6" string="the government" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="government" />
          </tokens>
        </chunking>
        <chunking id="7" string="2.57 million people in the United States" type="NP">
          <tokens>
            <token id="12" string="2.57" />
            <token id="13" string="million" />
            <token id="14" string="people" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </chunking>
        <chunking id="8" string="2.57 million people" type="NP">
          <tokens>
            <token id="12" string="2.57" />
            <token id="13" string="million" />
            <token id="14" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="that there were 2.57 million people in the United States illegally" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="there" />
            <token id="11" string="were" />
            <token id="12" string="2.57" />
            <token id="13" string="million" />
            <token id="14" string="people" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
            <token id="19" string="illegally" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">census</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">census</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">census</governor>
          <dependent id="3">1980</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">estimated</governor>
          <dependent id="4">census</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">government</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">estimated</governor>
          <dependent id="7">government</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">estimated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">were</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="11">were</governor>
          <dependent id="10">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">estimated</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">million</governor>
          <dependent id="12">2.57</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">people</governor>
          <dependent id="13">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">were</governor>
          <dependent id="14">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">States</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">States</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">States</governor>
          <dependent id="17">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">people</governor>
          <dependent id="18">States</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">were</governor>
          <dependent id="19">illegally</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </entity>
        <entity id="2" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1980" />
          </tokens>
        </entity>
        <entity id="3" string="2.57 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="2.57" />
            <token id="13" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>There were other guesses, some of them far higher.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="guesses" lemma="guess" stem="guess" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="higher" lemma="higher" stem="higher" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBD were) (NP (NP (JJ other) (NNS guesses)) (, ,) (NP (NP (DT some)) (PP (IN of) (NP (PRP them))))) (ADVP (RB far) (RBR higher))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="were other guesses , some of them far higher" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="other" />
            <token id="4" string="guesses" />
            <token id="5" string="," />
            <token id="6" string="some" />
            <token id="7" string="of" />
            <token id="8" string="them" />
            <token id="9" string="far" />
            <token id="10" string="higher" />
          </tokens>
        </chunking>
        <chunking id="3" string="some of them" type="NP">
          <tokens>
            <token id="6" string="some" />
            <token id="7" string="of" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="other guesses , some of them" type="NP">
          <tokens>
            <token id="3" string="other" />
            <token id="4" string="guesses" />
            <token id="5" string="," />
            <token id="6" string="some" />
            <token id="7" string="of" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="6" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="other guesses" type="NP">
          <tokens>
            <token id="3" string="other" />
            <token id="4" string="guesses" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="8" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">were</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">guesses</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">were</governor>
          <dependent id="4">guesses</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">guesses</governor>
          <dependent id="6">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">them</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">some</governor>
          <dependent id="8">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">higher</governor>
          <dependent id="9">far</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">were</governor>
          <dependent id="10">higher</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The government made no attempt to count them out in the redistricting process; indeed, the two previous administrations decided that the Constitution required that the census cover illegal aliens along with citizens.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="redistricting" lemma="redistricting" stem="redistrict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="indeed" lemma="indeed" stem="inde" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="previous" lemma="previous" stem="previou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="administrations" lemma="administration" stem="administr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="required" lemma="require" stem="requir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="cover" lemma="cover" stem="cover" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN government)) (VP (VBD made) (NP (DT no) (NN attempt) (S (VP (TO to) (VP (VB count) (NP (PRP them)) (PRT (RP out)) (PP (IN in) (NP (DT the) (NN redistricting) (NN process))))))))) (: ;) (S (ADVP (RB indeed)) (, ,) (NP (DT the) (CD two) (JJ previous) (NNS administrations)) (VP (VBD decided) (SBAR (IN that) (S (NP (DT the) (NNP Constitution)) (VP (VBD required) (PP (IN that) (NP (DT the) (NN census) (NN cover))) (PP (ADVP (NP (JJ illegal) (NNS aliens)) (IN along)) (IN with) (NP (NNS citizens)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="30" string="illegal" />
            <token id="31" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="the two previous administrations" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="two" />
            <token id="19" string="previous" />
            <token id="20" string="administrations" />
          </tokens>
        </chunking>
        <chunking id="3" string="the census cover" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="census" />
            <token id="29" string="cover" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="them" type="NP">
          <tokens>
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="count them out in the redistricting process" type="VP">
          <tokens>
            <token id="7" string="count" />
            <token id="8" string="them" />
            <token id="9" string="out" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="redistricting" />
            <token id="13" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="no attempt to count them out in the redistricting process" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="attempt" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="them" />
            <token id="9" string="out" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="redistricting" />
            <token id="13" string="process" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the Constitution required that the census cover illegal aliens along with citizens" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="the" />
            <token id="24" string="Constitution" />
            <token id="25" string="required" />
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="census" />
            <token id="29" string="cover" />
            <token id="30" string="illegal" />
            <token id="31" string="aliens" />
            <token id="32" string="along" />
            <token id="33" string="with" />
            <token id="34" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="9" string="The government" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="government" />
          </tokens>
        </chunking>
        <chunking id="10" string="decided that the Constitution required that the census cover illegal aliens along with citizens" type="VP">
          <tokens>
            <token id="21" string="decided" />
            <token id="22" string="that" />
            <token id="23" string="the" />
            <token id="24" string="Constitution" />
            <token id="25" string="required" />
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="census" />
            <token id="29" string="cover" />
            <token id="30" string="illegal" />
            <token id="31" string="aliens" />
            <token id="32" string="along" />
            <token id="33" string="with" />
            <token id="34" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="11" string="to count them out in the redistricting process" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="them" />
            <token id="9" string="out" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="redistricting" />
            <token id="13" string="process" />
          </tokens>
        </chunking>
        <chunking id="12" string="made no attempt to count them out in the redistricting process" type="VP">
          <tokens>
            <token id="3" string="made" />
            <token id="4" string="no" />
            <token id="5" string="attempt" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="them" />
            <token id="9" string="out" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="redistricting" />
            <token id="13" string="process" />
          </tokens>
        </chunking>
        <chunking id="13" string="the redistricting process" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="redistricting" />
            <token id="13" string="process" />
          </tokens>
        </chunking>
        <chunking id="14" string="required that the census cover illegal aliens along with citizens" type="VP">
          <tokens>
            <token id="25" string="required" />
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="census" />
            <token id="29" string="cover" />
            <token id="30" string="illegal" />
            <token id="31" string="aliens" />
            <token id="32" string="along" />
            <token id="33" string="with" />
            <token id="34" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="15" string="citizens" type="NP">
          <tokens>
            <token id="34" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">government</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">made</governor>
          <dependent id="2">government</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">made</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">attempt</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">made</governor>
          <dependent id="5">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">count</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">attempt</governor>
          <dependent id="7">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">count</governor>
          <dependent id="8">them</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">count</governor>
          <dependent id="9">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">process</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">process</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">process</governor>
          <dependent id="12">redistricting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">count</governor>
          <dependent id="13">process</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">decided</governor>
          <dependent id="15">indeed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">administrations</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">administrations</governor>
          <dependent id="18">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">administrations</governor>
          <dependent id="19">previous</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">decided</governor>
          <dependent id="20">administrations</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">made</governor>
          <dependent id="21">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">required</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Constitution</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">required</governor>
          <dependent id="24">Constitution</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">decided</governor>
          <dependent id="25">required</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">cover</governor>
          <dependent id="26">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">cover</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">cover</governor>
          <dependent id="28">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">required</governor>
          <dependent id="29">cover</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">aliens</governor>
          <dependent id="30">illegal</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">citizens</governor>
          <dependent id="31">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">aliens</governor>
          <dependent id="32">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">citizens</governor>
          <dependent id="33">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">required</governor>
          <dependent id="34">citizens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>There is not likely to be any change in that prior to the 1990 census next spring.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="prior" lemma="prior" stem="prior" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (RB not) (ADJP (JJ likely) (S (VP (TO to) (VP (VB be) (NP (NP (DT any) (NN change)) (PP (IN in) (NP (NP (DT that)) (ADVP (JJ prior) (PP (TO to) (NP (DT the) (CD 1990) (NN census)))) (NP-TMP (JJ next) (NN spring)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any change in that prior to the 1990 census next spring" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="change" />
            <token id="9" string="in" />
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="likely to be any change in that prior to the 1990 census next spring" type="ADJP">
          <tokens>
            <token id="4" string="likely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="any" />
            <token id="8" string="change" />
            <token id="9" string="in" />
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
        <chunking id="4" string="be any change in that prior to the 1990 census next spring" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="any" />
            <token id="8" string="change" />
            <token id="9" string="in" />
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
        <chunking id="5" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="6" string="is not likely to be any change in that prior to the 1990 census next spring" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="not" />
            <token id="4" string="likely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="any" />
            <token id="8" string="change" />
            <token id="9" string="in" />
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be any change in that prior to the 1990 census next spring" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="any" />
            <token id="8" string="change" />
            <token id="9" string="in" />
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1990 census" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="9" string="any change" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="change" />
          </tokens>
        </chunking>
        <chunking id="10" string="that prior to the 1990 census next spring" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="prior" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="1990" />
            <token id="15" string="census" />
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="2">is</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">is</governor>
          <dependent id="4">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">change</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">change</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">change</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">likely</governor>
          <dependent id="8">change</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">that</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">change</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">that</governor>
          <dependent id="11">prior</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">census</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">census</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">census</governor>
          <dependent id="14">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">prior</governor>
          <dependent id="15">census</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">spring</governor>
          <dependent id="16">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">that</governor>
          <dependent id="17">spring</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="next spring" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="next" />
            <token id="17" string="spring" />
          </tokens>
        </entity>
        <entity id="2" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>The Senate has passed an immigration bill including an amendment that would cut illegal aliens from the redistricting numbers, but it is not likely to clear Congress before the next year&amp;apost;s national head count.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="passed" lemma="pass" stem="pass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="cut" lemma="cut" stem="cut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="redistricting" lemma="redistricting" stem="redistrict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP Senate)) (VP (VBZ has) (VP (VBN passed) (NP (NP (DT an) (NN immigration) (NN bill)) (PP (VBG including) (NP (NP (DT an) (NN amendment)) (SBAR (WHNP (WDT that)) (S (VP (MD would) (VP (VB cut) (NP (JJ illegal) (NNS aliens)) (PP (IN from) (NP (DT the) (NN redistricting) (NNS numbers))))))))))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (JJ likely) (PP (TO to) (NP (JJ clear) (NNP Congress)))) (PP (IN before) (NP (NP (DT the) (JJ next) (NN year) (POS 's)) (JJ national) (NN head) (NN count))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would cut illegal aliens from the redistricting numbers" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="likely to clear Congress" type="ADJP">
          <tokens>
            <token id="25" string="likely" />
            <token id="26" string="to" />
            <token id="27" string="clear" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="4" string="that would cut illegal aliens from the redistricting numbers" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="5" string="is not likely to clear Congress before the next year 's national head count" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="not" />
            <token id="25" string="likely" />
            <token id="26" string="to" />
            <token id="27" string="clear" />
            <token id="28" string="Congress" />
            <token id="29" string="before" />
            <token id="30" string="the" />
            <token id="31" string="next" />
            <token id="32" string="year" />
            <token id="33" string="'s" />
            <token id="34" string="national" />
            <token id="35" string="head" />
            <token id="36" string="count" />
          </tokens>
        </chunking>
        <chunking id="6" string="the next year 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="next" />
            <token id="32" string="year" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="an immigration bill including an amendment that would cut illegal aliens from the redistricting numbers" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="immigration" />
            <token id="7" string="bill" />
            <token id="8" string="including" />
            <token id="9" string="an" />
            <token id="10" string="amendment" />
            <token id="11" string="that" />
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="22" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="an immigration bill" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="immigration" />
            <token id="7" string="bill" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Senate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="11" string="clear Congress" type="NP">
          <tokens>
            <token id="27" string="clear" />
            <token id="28" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="12" string="the redistricting numbers" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="13" string="an amendment" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="14" string="cut illegal aliens from the redistricting numbers" type="VP">
          <tokens>
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="15" string="the next year 's national head count" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="next" />
            <token id="32" string="year" />
            <token id="33" string="'s" />
            <token id="34" string="national" />
            <token id="35" string="head" />
            <token id="36" string="count" />
          </tokens>
        </chunking>
        <chunking id="16" string="has passed an immigration bill including an amendment that would cut illegal aliens from the redistricting numbers" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="passed" />
            <token id="5" string="an" />
            <token id="6" string="immigration" />
            <token id="7" string="bill" />
            <token id="8" string="including" />
            <token id="9" string="an" />
            <token id="10" string="amendment" />
            <token id="11" string="that" />
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="17" string="passed an immigration bill including an amendment that would cut illegal aliens from the redistricting numbers" type="VP">
          <tokens>
            <token id="4" string="passed" />
            <token id="5" string="an" />
            <token id="6" string="immigration" />
            <token id="7" string="bill" />
            <token id="8" string="including" />
            <token id="9" string="an" />
            <token id="10" string="amendment" />
            <token id="11" string="that" />
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="18" string="an amendment that would cut illegal aliens from the redistricting numbers" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="amendment" />
            <token id="11" string="that" />
            <token id="12" string="would" />
            <token id="13" string="cut" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="redistricting" />
            <token id="19" string="numbers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">passed</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">passed</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">passed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">bill</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">bill</governor>
          <dependent id="6">immigration</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">passed</governor>
          <dependent id="7">bill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">amendment</governor>
          <dependent id="8">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">amendment</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">bill</governor>
          <dependent id="10">amendment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">cut</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">cut</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">amendment</governor>
          <dependent id="13">cut</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">aliens</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">cut</governor>
          <dependent id="15">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">numbers</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">numbers</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">numbers</governor>
          <dependent id="18">redistricting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">cut</governor>
          <dependent id="19">numbers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">passed</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">likely</governor>
          <dependent id="22">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">likely</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">likely</governor>
          <dependent id="24">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">passed</governor>
          <dependent id="25">likely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Congress</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">Congress</governor>
          <dependent id="27">clear</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">likely</governor>
          <dependent id="28">Congress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">count</governor>
          <dependent id="29">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">year</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">year</governor>
          <dependent id="31">next</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">count</governor>
          <dependent id="32">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">year</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">count</governor>
          <dependent id="34">national</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">count</governor>
          <dependent id="35">head</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">likely</governor>
          <dependent id="36">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the next year" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="next" />
            <token id="32" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="3" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Sen. Richard Shelby, D-Ala., proposed, and won, the immigration bill amendment that is supposed to exclude illegal aliens from the redistricting process.</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="D-Ala." lemma="D-Ala." stem="d-ala." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="proposed" lemma="propose" stem="propos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="supposed" lemma="suppose" stem="suppos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="exclude" lemma="exclude" stem="exclud" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="redistricting" lemma="redistricting" stem="redistrict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Sen.) (NNP Richard) (NNP Shelby)) (, ,) (NP (NNP D-Ala.)) (, ,)) (VP (VP (VBD proposed)) (, ,) (CC and) (VP (VBD won)) (, ,) (S (NP (NP (DT the) (NN immigration) (NN bill) (NN amendment)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN supposed) (S (VP (TO to) (VP (VB exclude) (NP (JJ illegal) (NNS aliens)) (PP (IN from) (NP (DT the) (NN redistricting) (NN process))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the immigration bill amendment" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="immigration" />
            <token id="14" string="bill" />
            <token id="15" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="D-Ala." type="NP">
          <tokens>
            <token id="5" string="D-Ala." />
          </tokens>
        </chunking>
        <chunking id="4" string="the immigration bill amendment that is supposed to exclude illegal aliens from the redistricting process" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="immigration" />
            <token id="14" string="bill" />
            <token id="15" string="amendment" />
            <token id="16" string="that" />
            <token id="17" string="is" />
            <token id="18" string="supposed" />
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="5" string="is supposed to exclude illegal aliens from the redistricting process" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="supposed" />
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="6" string="to exclude illegal aliens from the redistricting process" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sen. Richard Shelby" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Richard" />
            <token id="3" string="Shelby" />
          </tokens>
        </chunking>
        <chunking id="8" string="proposed , and won , the immigration bill amendment that is supposed to exclude illegal aliens from the redistricting process" type="VP">
          <tokens>
            <token id="7" string="proposed" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="won" />
            <token id="11" string="," />
            <token id="12" string="the" />
            <token id="13" string="immigration" />
            <token id="14" string="bill" />
            <token id="15" string="amendment" />
            <token id="16" string="that" />
            <token id="17" string="is" />
            <token id="18" string="supposed" />
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="9" string="won" type="VP">
          <tokens>
            <token id="10" string="won" />
          </tokens>
        </chunking>
        <chunking id="10" string="that is supposed to exclude illegal aliens from the redistricting process" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="is" />
            <token id="18" string="supposed" />
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="11" string="supposed to exclude illegal aliens from the redistricting process" type="VP">
          <tokens>
            <token id="18" string="supposed" />
            <token id="19" string="to" />
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="12" string="proposed" type="VP">
          <tokens>
            <token id="7" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="13" string="exclude illegal aliens from the redistricting process" type="VP">
          <tokens>
            <token id="20" string="exclude" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="14" string="the redistricting process" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="redistricting" />
            <token id="26" string="process" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sen. Richard Shelby , D-Ala. ," type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Richard" />
            <token id="3" string="Shelby" />
            <token id="4" string="," />
            <token id="5" string="D-Ala." />
            <token id="6" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Shelby</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Shelby</governor>
          <dependent id="2">Richard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">proposed</governor>
          <dependent id="3">Shelby</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Shelby</governor>
          <dependent id="5">D-Ala.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">proposed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">proposed</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">proposed</governor>
          <dependent id="10">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">amendment</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">amendment</governor>
          <dependent id="13">immigration</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">amendment</governor>
          <dependent id="14">bill</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">proposed</governor>
          <dependent id="15">amendment</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">supposed</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">supposed</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">amendment</governor>
          <dependent id="18">supposed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">exclude</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">supposed</governor>
          <dependent id="20">exclude</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">aliens</governor>
          <dependent id="21">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">exclude</governor>
          <dependent id="22">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">process</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">process</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">process</governor>
          <dependent id="25">redistricting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">exclude</governor>
          <dependent id="26">process</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Richard Shelby" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Richard" />
            <token id="3" string="Shelby" />
          </tokens>
        </entity>
        <entity id="2" string="D-Ala." type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="D-Ala." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>It would give Secretary of Commerce Robert Mosbacher the assignment of adjusting the census figures so that illegal aliens don&amp;apost;t count for purposes of redistributing House seats.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Secretary" lemma="Secretary" stem="secretari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Mosbacher" lemma="Mosbacher" stem="mosbach" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assignment" lemma="assignment" stem="assign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="adjusting" lemma="adjust" stem="adjust" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="purposes" lemma="purpose" stem="purpos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="redistributing" lemma="redistribute" stem="redistribut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (MD would) (VP (VB give) (NP (NP (NNP Secretary)) (PP (IN of) (NP (NNP Commerce) (NNP Robert) (NNP Mosbacher)))) (NP (NP (DT the) (NN assignment)) (PP (IN of) (S (VP (VBG adjusting) (NP (DT the) (NN census) (NNS figures)) (SBAR (IN so) (IN that) (S (NP (JJ illegal) (NNS aliens)) (VP (VBP do) (RB n't) (VP (VB count) (PP (IN for) (NP (NP (NNS purposes)) (PP (IN of) (S (VP (VBG redistributing) (NP (NNP House) (NNS seats))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="House seats" type="NP">
          <tokens>
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="3" string="would give Secretary of Commerce Robert Mosbacher the assignment of adjusting the census figures so that illegal aliens do n't count for purposes of redistributing House seats" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="give" />
            <token id="4" string="Secretary" />
            <token id="5" string="of" />
            <token id="6" string="Commerce" />
            <token id="7" string="Robert" />
            <token id="8" string="Mosbacher" />
            <token id="9" string="the" />
            <token id="10" string="assignment" />
            <token id="11" string="of" />
            <token id="12" string="adjusting" />
            <token id="13" string="the" />
            <token id="14" string="census" />
            <token id="15" string="figures" />
            <token id="16" string="so" />
            <token id="17" string="that" />
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="4" string="purposes of redistributing House seats" type="NP">
          <tokens>
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="5" string="Secretary of Commerce Robert Mosbacher" type="NP">
          <tokens>
            <token id="4" string="Secretary" />
            <token id="5" string="of" />
            <token id="6" string="Commerce" />
            <token id="7" string="Robert" />
            <token id="8" string="Mosbacher" />
          </tokens>
        </chunking>
        <chunking id="6" string="so that illegal aliens do n't count for purposes of redistributing House seats" type="SBAR">
          <tokens>
            <token id="16" string="so" />
            <token id="17" string="that" />
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="7" string="redistributing House seats" type="VP">
          <tokens>
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="8" string="the assignment of adjusting the census figures so that illegal aliens do n't count for purposes of redistributing House seats" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="assignment" />
            <token id="11" string="of" />
            <token id="12" string="adjusting" />
            <token id="13" string="the" />
            <token id="14" string="census" />
            <token id="15" string="figures" />
            <token id="16" string="so" />
            <token id="17" string="that" />
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="9" string="the assignment" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="assignment" />
          </tokens>
        </chunking>
        <chunking id="10" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="11" string="Secretary" type="NP">
          <tokens>
            <token id="4" string="Secretary" />
          </tokens>
        </chunking>
        <chunking id="12" string="do n't count for purposes of redistributing House seats" type="VP">
          <tokens>
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="13" string="count for purposes of redistributing House seats" type="VP">
          <tokens>
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="14" string="Commerce Robert Mosbacher" type="NP">
          <tokens>
            <token id="6" string="Commerce" />
            <token id="7" string="Robert" />
            <token id="8" string="Mosbacher" />
          </tokens>
        </chunking>
        <chunking id="15" string="adjusting the census figures so that illegal aliens do n't count for purposes of redistributing House seats" type="VP">
          <tokens>
            <token id="12" string="adjusting" />
            <token id="13" string="the" />
            <token id="14" string="census" />
            <token id="15" string="figures" />
            <token id="16" string="so" />
            <token id="17" string="that" />
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="16" string="purposes" type="NP">
          <tokens>
            <token id="24" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="17" string="give Secretary of Commerce Robert Mosbacher the assignment of adjusting the census figures so that illegal aliens do n't count for purposes of redistributing House seats" type="VP">
          <tokens>
            <token id="3" string="give" />
            <token id="4" string="Secretary" />
            <token id="5" string="of" />
            <token id="6" string="Commerce" />
            <token id="7" string="Robert" />
            <token id="8" string="Mosbacher" />
            <token id="9" string="the" />
            <token id="10" string="assignment" />
            <token id="11" string="of" />
            <token id="12" string="adjusting" />
            <token id="13" string="the" />
            <token id="14" string="census" />
            <token id="15" string="figures" />
            <token id="16" string="so" />
            <token id="17" string="that" />
            <token id="18" string="illegal" />
            <token id="19" string="aliens" />
            <token id="20" string="do" />
            <token id="21" string="n't" />
            <token id="22" string="count" />
            <token id="23" string="for" />
            <token id="24" string="purposes" />
            <token id="25" string="of" />
            <token id="26" string="redistributing" />
            <token id="27" string="House" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="18" string="the census figures" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="census" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">give</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">give</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="3">give</governor>
          <dependent id="4">Secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Mosbacher</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Mosbacher</governor>
          <dependent id="6">Commerce</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Mosbacher</governor>
          <dependent id="7">Robert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Secretary</governor>
          <dependent id="8">Mosbacher</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">assignment</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">give</governor>
          <dependent id="10">assignment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">adjusting</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">assignment</governor>
          <dependent id="12">adjusting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">figures</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">figures</governor>
          <dependent id="14">census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">adjusting</governor>
          <dependent id="15">figures</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">count</governor>
          <dependent id="16">so</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">so</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">aliens</governor>
          <dependent id="18">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">count</governor>
          <dependent id="19">aliens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">count</governor>
          <dependent id="20">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">count</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">adjusting</governor>
          <dependent id="22">count</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">purposes</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">count</governor>
          <dependent id="24">purposes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">redistributing</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">purposes</governor>
          <dependent id="26">redistributing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">seats</governor>
          <dependent id="27">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">redistributing</governor>
          <dependent id="28">seats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Robert Mosbacher" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Robert" />
            <token id="8" string="Mosbacher" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>It does not come with instructions, so the department would have to figure out how.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="instructions" lemma="instruction" stem="instruct" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="figure" lemma="figure" stem="figur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ does) (RB not) (VP (VBN come) (PP (IN with) (NP (NNS instructions)))))) (, ,) (IN so) (S (NP (DT the) (NN department)) (VP (MD would) (VP (VB have) (S (VP (TO to) (VP (VB figure) (PRT (RP out)) (FRAG (WHADVP (WRB how))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="instructions" type="NP">
          <tokens>
            <token id="6" string="instructions" />
          </tokens>
        </chunking>
        <chunking id="2" string="have to figure out how" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="to" />
            <token id="14" string="figure" />
            <token id="15" string="out" />
            <token id="16" string="how" />
          </tokens>
        </chunking>
        <chunking id="3" string="to figure out how" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="figure" />
            <token id="15" string="out" />
            <token id="16" string="how" />
          </tokens>
        </chunking>
        <chunking id="4" string="figure out how" type="VP">
          <tokens>
            <token id="14" string="figure" />
            <token id="15" string="out" />
            <token id="16" string="how" />
          </tokens>
        </chunking>
        <chunking id="5" string="the department" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="department" />
          </tokens>
        </chunking>
        <chunking id="6" string="does not come with instructions" type="VP">
          <tokens>
            <token id="2" string="does" />
            <token id="3" string="not" />
            <token id="4" string="come" />
            <token id="5" string="with" />
            <token id="6" string="instructions" />
          </tokens>
        </chunking>
        <chunking id="7" string="would have to figure out how" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="have" />
            <token id="13" string="to" />
            <token id="14" string="figure" />
            <token id="15" string="out" />
            <token id="16" string="how" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="come with instructions" type="VP">
          <tokens>
            <token id="4" string="come" />
            <token id="5" string="with" />
            <token id="6" string="instructions" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="16" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">come</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">come</governor>
          <dependent id="2">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">come</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">instructions</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">come</governor>
          <dependent id="6">instructions</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">come</governor>
          <dependent id="8">so</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">department</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">have</governor>
          <dependent id="10">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">have</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">come</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">figure</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">have</governor>
          <dependent id="14">figure</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">figure</governor>
          <dependent id="15">out</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">figure</governor>
          <dependent id="16">how</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Shelby&amp;apost;s amendment says only that the secretary is to ``make such adjustments in total population figures as may be necessary, using such methods and procedures as the secretary determines feasible and appropriate&amp;apost;&amp;apost; to keep illegal aliens from being counted in congressional reapportionment.</content>
      <tokens>
        <token id="1" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="adjustments" lemma="adjustment" stem="adjust" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="necessary" lemma="necessary" stem="necessari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="methods" lemma="method" stem="method" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="procedures" lemma="procedure" stem="procedur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="determines" lemma="determine" stem="determin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="feasible" lemma="feasible" stem="feasibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="appropriate" lemma="appropriate" stem="appropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Shelby) (POS 's)) (NN amendment)) (VP (VBZ says) (SBAR (RB only) (IN that) (S (NP (DT the) (NN secretary)) (VP (VBZ is) (S (VP (TO to) (`` ``) (VP (VB make) (NP (NP (JJ such) (NNS adjustments)) (PP (IN in) (NP (JJ total) (NN population) (NNS figures)))) (SBAR (IN as) (S (VP (MD may) (VP (VB be) (ADJP (JJ necessary)) (, ,) (S (VP (VBG using) (NP (JJ such) (NX (NX (NNS methods)) (CC and) (NX (NNS procedures)))) (SBAR (IN as) (S (NP (DT the) (NN secretary)) (VP (VBZ determines) (ADJP (JJ feasible) (CC and) (JJ appropriate))))))))))) ('' '') (S (VP (TO to) (VP (VB keep) (NP (JJ illegal) (NNS aliens)) (PP (IN from) (S (VP (VBG being) (VP (VBN counted) (PP (IN in) (NP (JJ congressional) (NN reapportionment))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="make such adjustments in total population figures as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate '' to keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="12" string="make" />
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
            <token id="36" string="''" />
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="such adjustments" type="NP">
          <tokens>
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
          </tokens>
        </chunking>
        <chunking id="4" string="necessary" type="ADJP">
          <tokens>
            <token id="22" string="necessary" />
          </tokens>
        </chunking>
        <chunking id="5" string="keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="6" string="as the secretary determines feasible and appropriate" type="SBAR">
          <tokens>
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="7" string="Shelby 's amendment" type="NP">
          <tokens>
            <token id="1" string="Shelby" />
            <token id="2" string="'s" />
            <token id="3" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="8" string="be necessary , using such methods and procedures as the secretary determines feasible and appropriate" type="VP">
          <tokens>
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="9" string="using such methods and procedures as the secretary determines feasible and appropriate" type="VP">
          <tokens>
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="10" string="feasible and appropriate" type="ADJP">
          <tokens>
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="11" string="determines feasible and appropriate" type="VP">
          <tokens>
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="12" string="such methods and procedures" type="NP">
          <tokens>
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
          </tokens>
        </chunking>
        <chunking id="13" string="counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="14" string="being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="15" string="only that the secretary is to `` make such adjustments in total population figures as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate '' to keep illegal aliens from being counted in congressional reapportionment" type="SBAR">
          <tokens>
            <token id="5" string="only" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="secretary" />
            <token id="9" string="is" />
            <token id="10" string="to" />
            <token id="11" string="``" />
            <token id="12" string="make" />
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
            <token id="36" string="''" />
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="16" string="says only that the secretary is to `` make such adjustments in total population figures as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate '' to keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="4" string="says" />
            <token id="5" string="only" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="secretary" />
            <token id="9" string="is" />
            <token id="10" string="to" />
            <token id="11" string="``" />
            <token id="12" string="make" />
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
            <token id="36" string="''" />
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="17" string="total population figures" type="NP">
          <tokens>
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
          </tokens>
        </chunking>
        <chunking id="18" string="as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate" type="SBAR">
          <tokens>
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="19" string="may be necessary , using such methods and procedures as the secretary determines feasible and appropriate" type="VP">
          <tokens>
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="20" string="such adjustments in total population figures" type="NP">
          <tokens>
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
          </tokens>
        </chunking>
        <chunking id="21" string="the secretary" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="secretary" />
          </tokens>
        </chunking>
        <chunking id="22" string="is to `` make such adjustments in total population figures as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate '' to keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="to" />
            <token id="11" string="``" />
            <token id="12" string="make" />
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
            <token id="36" string="''" />
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="23" string="congressional reapportionment" type="NP">
          <tokens>
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="24" string="to keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="25" string="to `` make such adjustments in total population figures as may be necessary , using such methods and procedures as the secretary determines feasible and appropriate '' to keep illegal aliens from being counted in congressional reapportionment" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="``" />
            <token id="12" string="make" />
            <token id="13" string="such" />
            <token id="14" string="adjustments" />
            <token id="15" string="in" />
            <token id="16" string="total" />
            <token id="17" string="population" />
            <token id="18" string="figures" />
            <token id="19" string="as" />
            <token id="20" string="may" />
            <token id="21" string="be" />
            <token id="22" string="necessary" />
            <token id="23" string="," />
            <token id="24" string="using" />
            <token id="25" string="such" />
            <token id="26" string="methods" />
            <token id="27" string="and" />
            <token id="28" string="procedures" />
            <token id="29" string="as" />
            <token id="30" string="the" />
            <token id="31" string="secretary" />
            <token id="32" string="determines" />
            <token id="33" string="feasible" />
            <token id="34" string="and" />
            <token id="35" string="appropriate" />
            <token id="36" string="''" />
            <token id="37" string="to" />
            <token id="38" string="keep" />
            <token id="39" string="illegal" />
            <token id="40" string="aliens" />
            <token id="41" string="from" />
            <token id="42" string="being" />
            <token id="43" string="counted" />
            <token id="44" string="in" />
            <token id="45" string="congressional" />
            <token id="46" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="26" string="Shelby 's" type="NP">
          <tokens>
            <token id="1" string="Shelby" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">amendment</governor>
          <dependent id="1">Shelby</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Shelby</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">says</governor>
          <dependent id="3">amendment</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">says</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">is</governor>
          <dependent id="5">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">is</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">secretary</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="8">secretary</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">says</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">make</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">is</governor>
          <dependent id="12">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">adjustments</governor>
          <dependent id="13">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">make</governor>
          <dependent id="14">adjustments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">figures</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">figures</governor>
          <dependent id="16">total</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">figures</governor>
          <dependent id="17">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">adjustments</governor>
          <dependent id="18">figures</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">necessary</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">necessary</governor>
          <dependent id="20">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">necessary</governor>
          <dependent id="21">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">make</governor>
          <dependent id="22">necessary</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">necessary</governor>
          <dependent id="24">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">methods</governor>
          <dependent id="25">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">using</governor>
          <dependent id="26">methods</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">methods</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">methods</governor>
          <dependent id="28">procedures</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">determines</governor>
          <dependent id="29">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">secretary</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">determines</governor>
          <dependent id="31">secretary</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">using</governor>
          <dependent id="32">determines</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">determines</governor>
          <dependent id="33">feasible</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">feasible</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">feasible</governor>
          <dependent id="35">appropriate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">keep</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">make</governor>
          <dependent id="38">keep</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">aliens</governor>
          <dependent id="39">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">keep</governor>
          <dependent id="40">aliens</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">counted</governor>
          <dependent id="41">from</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="43">counted</governor>
          <dependent id="42">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">keep</governor>
          <dependent id="43">counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">reapportionment</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">reapportionment</governor>
          <dependent id="45">congressional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">counted</governor>
          <dependent id="46">reapportionment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Shelby" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Shelby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>That task would be perilous politically, since it would involve taking House seats away from some states and giving them to others, all on the basis of estimates.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="task" lemma="task" stem="task" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="perilous" lemma="perilous" stem="peril" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="involve" lemma="involve" stem="involv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="estimates" lemma="estimate" stem="estim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN task)) (VP (MD would) (VP (VB be) (ADJP (JJ perilous) (RB politically)) (, ,) (SBAR (IN since) (S (NP (PRP it)) (VP (MD would) (VP (VB involve) (S (VP (VP (VBG taking) (NP (NNP House) (NNS seats)) (ADVP (RB away)) (PP (IN from) (NP (DT some) (NNS states)))) (CC and) (VP (VBG giving) (NP (PRP them)) (PP (TO to) (NP (NP (NNS others)) (, ,) (NP (NP (DT all)) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NNS estimates))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="House seats" type="NP">
          <tokens>
            <token id="13" string="House" />
            <token id="14" string="seats" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="25" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="4" string="would involve taking House seats away from some states and giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="involve" />
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="others , all on the basis of estimates" type="NP">
          <tokens>
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="7" string="That task" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="task" />
          </tokens>
        </chunking>
        <chunking id="8" string="would be perilous politically , since it would involve taking House seats away from some states and giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="be" />
            <token id="5" string="perilous" />
            <token id="6" string="politically" />
            <token id="7" string="," />
            <token id="8" string="since" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="involve" />
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="21" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="some states" type="NP">
          <tokens>
            <token id="17" string="some" />
            <token id="18" string="states" />
          </tokens>
        </chunking>
        <chunking id="11" string="be perilous politically , since it would involve taking House seats away from some states and giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="perilous" />
            <token id="6" string="politically" />
            <token id="7" string="," />
            <token id="8" string="since" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="involve" />
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="12" string="the basis" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="basis" />
          </tokens>
        </chunking>
        <chunking id="13" string="perilous politically" type="ADJP">
          <tokens>
            <token id="5" string="perilous" />
            <token id="6" string="politically" />
          </tokens>
        </chunking>
        <chunking id="14" string="taking House seats away from some states and giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="15" string="taking House seats away from some states" type="VP">
          <tokens>
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
          </tokens>
        </chunking>
        <chunking id="16" string="the basis of estimates" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="17" string="all on the basis of estimates" type="NP">
          <tokens>
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="18" string="estimates" type="NP">
          <tokens>
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="19" string="since it would involve taking House seats away from some states and giving them to others , all on the basis of estimates" type="SBAR">
          <tokens>
            <token id="8" string="since" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="involve" />
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="20" string="involve taking House seats away from some states and giving them to others , all on the basis of estimates" type="VP">
          <tokens>
            <token id="11" string="involve" />
            <token id="12" string="taking" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="away" />
            <token id="16" string="from" />
            <token id="17" string="some" />
            <token id="18" string="states" />
            <token id="19" string="and" />
            <token id="20" string="giving" />
            <token id="21" string="them" />
            <token id="22" string="to" />
            <token id="23" string="others" />
            <token id="24" string="," />
            <token id="25" string="all" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="basis" />
            <token id="29" string="of" />
            <token id="30" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="21" string="others" type="NP">
          <tokens>
            <token id="23" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">task</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">perilous</governor>
          <dependent id="2">task</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">perilous</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">perilous</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">perilous</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">perilous</governor>
          <dependent id="6">politically</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">involve</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">involve</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">involve</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">perilous</governor>
          <dependent id="11">involve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">involve</governor>
          <dependent id="12">taking</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">seats</governor>
          <dependent id="13">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">taking</governor>
          <dependent id="14">seats</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">taking</governor>
          <dependent id="15">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">states</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">states</governor>
          <dependent id="17">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">taking</governor>
          <dependent id="18">states</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">taking</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">taking</governor>
          <dependent id="20">giving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">giving</governor>
          <dependent id="21">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">others</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">giving</governor>
          <dependent id="23">others</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">others</governor>
          <dependent id="25">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">basis</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">basis</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">all</governor>
          <dependent id="28">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">estimates</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">basis</governor>
          <dependent id="30">estimates</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>With 435 seats in the House, every representative gained by a state is a representative lost by another.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="435" lemma="435" stem="435" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="representative" lemma="representative" stem="repres" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="gained" lemma="gain" stem="gain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="representative" lemma="representative" stem="repres" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (CD 435) (NNS seats)) (PP (IN in) (NP (DT the) (NNP House))))) (, ,) (NP (NP (DT every) (NN representative)) (VP (VBN gained) (PP (IN by) (NP (DT a) (NN state))))) (VP (VBZ is) (NP (NP (DT a) (JJ representative)) (VP (VBN lost) (PP (IN by) (NP (DT another)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a representative lost by another" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="a" />
            <token id="16" string="representative" />
            <token id="17" string="lost" />
            <token id="18" string="by" />
            <token id="19" string="another" />
          </tokens>
        </chunking>
        <chunking id="2" string="every representative gained by a state" type="NP">
          <tokens>
            <token id="8" string="every" />
            <token id="9" string="representative" />
            <token id="10" string="gained" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="state" />
          </tokens>
        </chunking>
        <chunking id="3" string="a state" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="state" />
          </tokens>
        </chunking>
        <chunking id="4" string="every representative" type="NP">
          <tokens>
            <token id="8" string="every" />
            <token id="9" string="representative" />
          </tokens>
        </chunking>
        <chunking id="5" string="a representative lost by another" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="representative" />
            <token id="17" string="lost" />
            <token id="18" string="by" />
            <token id="19" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="another" type="NP">
          <tokens>
            <token id="19" string="another" />
          </tokens>
        </chunking>
        <chunking id="7" string="the House" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="House" />
          </tokens>
        </chunking>
        <chunking id="8" string="435 seats" type="NP">
          <tokens>
            <token id="2" string="435" />
            <token id="3" string="seats" />
          </tokens>
        </chunking>
        <chunking id="9" string="gained by a state" type="VP">
          <tokens>
            <token id="10" string="gained" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="state" />
          </tokens>
        </chunking>
        <chunking id="10" string="435 seats in the House" type="NP">
          <tokens>
            <token id="2" string="435" />
            <token id="3" string="seats" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="House" />
          </tokens>
        </chunking>
        <chunking id="11" string="a representative" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="representative" />
          </tokens>
        </chunking>
        <chunking id="12" string="lost by another" type="VP">
          <tokens>
            <token id="17" string="lost" />
            <token id="18" string="by" />
            <token id="19" string="another" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">seats</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">seats</governor>
          <dependent id="2">435</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">representative</governor>
          <dependent id="3">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">House</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">House</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">seats</governor>
          <dependent id="6">House</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">representative</governor>
          <dependent id="8">every</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">representative</governor>
          <dependent id="9">representative</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">representative</governor>
          <dependent id="10">gained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">state</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">state</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">gained</governor>
          <dependent id="13">state</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">representative</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">representative</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">representative</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">representative</governor>
          <dependent id="17">lost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">another</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">lost</governor>
          <dependent id="19">another</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="435" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="435" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Opponents of the Shelby amendment, led by Sen. Edward M. Kennedy, D-Mass., said it was unconstitutional, as well as unworkable.</content>
      <tokens>
        <token id="1" string="Opponents" lemma="opponent" stem="opponent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="led" lemma="lead" stem="led" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="D-Mass." lemma="D-Mass." stem="d-mass." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="unworkable" lemma="unworkable" stem="unwork" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Opponents)) (PP (IN of) (NP (DT the) (NNP Shelby) (NN amendment))) (, ,) (VP (VBN led) (PP (IN by) (NP (NP (NNP Sen.) (NNP Edward) (NNP M.) (NNP Kennedy)) (, ,) (NP (NNP D-Mass.))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ unconstitutional)) (, ,) (SBAR (ADVP (RB as) (RB well)) (IN as) (FRAG (ADJP (JJ unworkable)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said it was unconstitutional , as well as unworkable" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="was" />
            <token id="19" string="unconstitutional" />
            <token id="20" string="," />
            <token id="21" string="as" />
            <token id="22" string="well" />
            <token id="23" string="as" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sen. Edward M. Kennedy , D-Mass." type="NP">
          <tokens>
            <token id="9" string="Sen." />
            <token id="10" string="Edward" />
            <token id="11" string="M." />
            <token id="12" string="Kennedy" />
            <token id="13" string="," />
            <token id="14" string="D-Mass." />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="D-Mass." type="NP">
          <tokens>
            <token id="14" string="D-Mass." />
          </tokens>
        </chunking>
        <chunking id="5" string="Opponents of the Shelby amendment , led by Sen. Edward M. Kennedy , D-Mass. ," type="NP">
          <tokens>
            <token id="1" string="Opponents" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="Shelby" />
            <token id="5" string="amendment" />
            <token id="6" string="," />
            <token id="7" string="led" />
            <token id="8" string="by" />
            <token id="9" string="Sen." />
            <token id="10" string="Edward" />
            <token id="11" string="M." />
            <token id="12" string="Kennedy" />
            <token id="13" string="," />
            <token id="14" string="D-Mass." />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the Shelby amendment" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Shelby" />
            <token id="5" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="7" string="was unconstitutional , as well as unworkable" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="unconstitutional" />
            <token id="20" string="," />
            <token id="21" string="as" />
            <token id="22" string="well" />
            <token id="23" string="as" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="8" string="unworkable" type="ADJP">
          <tokens>
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="9" string="led by Sen. Edward M. Kennedy , D-Mass." type="VP">
          <tokens>
            <token id="7" string="led" />
            <token id="8" string="by" />
            <token id="9" string="Sen." />
            <token id="10" string="Edward" />
            <token id="11" string="M." />
            <token id="12" string="Kennedy" />
            <token id="13" string="," />
            <token id="14" string="D-Mass." />
          </tokens>
        </chunking>
        <chunking id="10" string="Opponents" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
          </tokens>
        </chunking>
        <chunking id="11" string="Sen. Edward M. Kennedy" type="NP">
          <tokens>
            <token id="9" string="Sen." />
            <token id="10" string="Edward" />
            <token id="11" string="M." />
            <token id="12" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="12" string="it was unconstitutional , as well as unworkable" type="SBAR">
          <tokens>
            <token id="17" string="it" />
            <token id="18" string="was" />
            <token id="19" string="unconstitutional" />
            <token id="20" string="," />
            <token id="21" string="as" />
            <token id="22" string="well" />
            <token id="23" string="as" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="13" string="as well as unworkable" type="SBAR">
          <tokens>
            <token id="21" string="as" />
            <token id="22" string="well" />
            <token id="23" string="as" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="14" string="unconstitutional" type="ADJP">
          <tokens>
            <token id="19" string="unconstitutional" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="1">Opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">amendment</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">amendment</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">amendment</governor>
          <dependent id="4">Shelby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Opponents</governor>
          <dependent id="5">amendment</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Opponents</governor>
          <dependent id="7">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Kennedy</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Kennedy</governor>
          <dependent id="9">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Kennedy</governor>
          <dependent id="10">Edward</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Kennedy</governor>
          <dependent id="11">M.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">led</governor>
          <dependent id="12">Kennedy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Kennedy</governor>
          <dependent id="14">D-Mass.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">unconstitutional</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">unconstitutional</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="19">unconstitutional</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">unworkable</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">as</governor>
          <dependent id="22">well</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">unworkable</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">unconstitutional</governor>
          <dependent id="24">unworkable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Edward M. Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Edward" />
            <token id="11" string="M." />
            <token id="12" string="Kennedy" />
          </tokens>
        </entity>
        <entity id="2" string="D-Mass." type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="D-Mass." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``The framers of the Constitution intended to count all persons,&amp;apost;&amp;apost; Kennedy said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="framers" lemma="framer" stem="framer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="intended" lemma="intend" stem="intend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT The) (NNS framers)) (PP (IN of) (NP (DT the) (NNP Constitution)))) (VP (VBD intended) (S (VP (TO to) (VP (VB count) (NP (DT all) (NNS persons))))))) (, ,) ('' '') (NP (NNP Kennedy)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kennedy" type="NP">
          <tokens>
            <token id="14" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="2" string="count all persons" type="VP">
          <tokens>
            <token id="9" string="count" />
            <token id="10" string="all" />
            <token id="11" string="persons" />
          </tokens>
        </chunking>
        <chunking id="3" string="The framers of the Constitution" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="framers" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="intended to count all persons" type="VP">
          <tokens>
            <token id="7" string="intended" />
            <token id="8" string="to" />
            <token id="9" string="count" />
            <token id="10" string="all" />
            <token id="11" string="persons" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Constitution" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="6" string="to count all persons" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="count" />
            <token id="10" string="all" />
            <token id="11" string="persons" />
          </tokens>
        </chunking>
        <chunking id="7" string="all persons" type="NP">
          <tokens>
            <token id="10" string="all" />
            <token id="11" string="persons" />
          </tokens>
        </chunking>
        <chunking id="8" string="The framers" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="framers" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">framers</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">intended</governor>
          <dependent id="3">framers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Constitution</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Constitution</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">framers</governor>
          <dependent id="6">Constitution</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="7">intended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">count</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">intended</governor>
          <dependent id="9">count</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">persons</governor>
          <dependent id="10">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">count</governor>
          <dependent id="11">persons</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Kennedy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Kennedy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The Constitution itself says the apportionment of the House is to be determined on the basis of ``the whole number of free persons,&amp;apost;&amp;apost; excluding Indians and counting every five slaves as three persons.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="determined" lemma="determine" stem="determin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="excluding" lemma="exclude" stem="exclud" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Indians" lemma="Indians" stem="indian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="33" string="slaves" lemma="slave" stem="slave" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="36" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Constitution)) (SBAR (S (NP (PRP itself)) (VP (VBZ says) (NP (NP (DT the) (NN apportionment)) (PP (IN of) (NP (DT the) (NNP House)))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB be) (VP (VBN determined) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (`` ``) (NP (DT the) (JJ whole) (NN number)) (PP (IN of) (NP (JJ free) (NNS persons))) (, ,) ('' '') (VP (VP (VBG excluding) (NP (NNPS Indians))) (CC and) (VP (VBG counting) (NP (NP (DT every) (CD five) (NNS slaves)) (PP (IN as) (NP (CD three) (NNS persons))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="determined on the basis of `` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="13" string="determined" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="basis" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="2" string="the apportionment" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="3" string="says the apportionment of the House" type="VP">
          <tokens>
            <token id="4" string="says" />
            <token id="5" string="the" />
            <token id="6" string="apportionment" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be determined on the basis of `` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="determined" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="basis" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Constitution itself says the apportionment of the House" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Constitution" />
            <token id="3" string="itself" />
            <token id="4" string="says" />
            <token id="5" string="the" />
            <token id="6" string="apportionment" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="6" string="the House" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="7" string="the whole number" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
          </tokens>
        </chunking>
        <chunking id="8" string="free persons" type="NP">
          <tokens>
            <token id="23" string="free" />
            <token id="24" string="persons" />
          </tokens>
        </chunking>
        <chunking id="9" string="`` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="NP">
          <tokens>
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="10" string="itself says the apportionment of the House" type="SBAR">
          <tokens>
            <token id="3" string="itself" />
            <token id="4" string="says" />
            <token id="5" string="the" />
            <token id="6" string="apportionment" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="11" string="excluding Indians and counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="12" string="three persons" type="NP">
          <tokens>
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Constitution" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="14" string="be determined on the basis of `` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="determined" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="basis" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="15" string="is to be determined on the basis of `` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="determined" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="basis" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="16" string="the basis" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="basis" />
          </tokens>
        </chunking>
        <chunking id="17" string="itself" type="NP">
          <tokens>
            <token id="3" string="itself" />
          </tokens>
        </chunking>
        <chunking id="18" string="Indians" type="NP">
          <tokens>
            <token id="28" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="19" string="the apportionment of the House" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="apportionment" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="20" string="every five slaves" type="NP">
          <tokens>
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
          </tokens>
        </chunking>
        <chunking id="21" string="counting every five slaves as three persons" type="VP">
          <tokens>
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="22" string="excluding Indians" type="VP">
          <tokens>
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="23" string="the basis of `` the whole number of free persons , '' excluding Indians and counting every five slaves as three persons" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="basis" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="the" />
            <token id="20" string="whole" />
            <token id="21" string="number" />
            <token id="22" string="of" />
            <token id="23" string="free" />
            <token id="24" string="persons" />
            <token id="25" string="," />
            <token id="26" string="''" />
            <token id="27" string="excluding" />
            <token id="28" string="Indians" />
            <token id="29" string="and" />
            <token id="30" string="counting" />
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
        <chunking id="24" string="every five slaves as three persons" type="NP">
          <tokens>
            <token id="31" string="every" />
            <token id="32" string="five" />
            <token id="33" string="slaves" />
            <token id="34" string="as" />
            <token id="35" string="three" />
            <token id="36" string="persons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Constitution</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="2">Constitution</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">says</governor>
          <dependent id="3">itself</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Constitution</governor>
          <dependent id="4">says</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">apportionment</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">says</governor>
          <dependent id="6">apportionment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">House</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">House</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">apportionment</governor>
          <dependent id="9">House</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">determined</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">determined</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">is</governor>
          <dependent id="13">determined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">basis</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">basis</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">determined</governor>
          <dependent id="16">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">number</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">number</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">number</governor>
          <dependent id="20">whole</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">basis</governor>
          <dependent id="21">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">persons</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">persons</governor>
          <dependent id="23">free</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">number</governor>
          <dependent id="24">persons</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">number</governor>
          <dependent id="27">excluding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">excluding</governor>
          <dependent id="28">Indians</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">excluding</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">excluding</governor>
          <dependent id="30">counting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">slaves</governor>
          <dependent id="31">every</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">slaves</governor>
          <dependent id="32">five</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">counting</governor>
          <dependent id="33">slaves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">persons</governor>
          <dependent id="34">as</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">persons</governor>
          <dependent id="35">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">slaves</governor>
          <dependent id="36">persons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Indians" type="MISC" score="0.0">
          <tokens>
            <token id="28" string="Indians" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="32" string="five" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="35" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>That was amended after the Civil War to say that the apportionment of House seats will be based on ``the whole number of persons in each state.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="amended" lemma="amend" stem="amend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="War" lemma="war" stem="war" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="15" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBD was) (ADJP (VBN amended) (PP (IN after) (NP (DT the) (JJ Civil) (NN War) (S (VP (TO to) (VP (VB say) (SBAR (IN that) (S (NP (NP (DT the) (NN apportionment)) (PP (IN of) (NP (NNP House) (NNS seats)))) (VP (MD will) (VP (VB be) (VP (VBN based) (PP (IN on) (`` ``) (NP (NP (DT the) (JJ whole) (NN number)) (PP (IN of) (NP (NP (NNS persons)) (PP (IN in) (NP (DT each) (NN state))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="House seats" type="NP">
          <tokens>
            <token id="14" string="House" />
            <token id="15" string="seats" />
          </tokens>
        </chunking>
        <chunking id="3" string="the apportionment" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="4" string="say that the apportionment of House seats will be based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="9" string="say" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="5" string="the apportionment of House seats" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
          </tokens>
        </chunking>
        <chunking id="6" string="the whole number" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
          </tokens>
        </chunking>
        <chunking id="7" string="amended after the Civil War to say that the apportionment of House seats will be based on `` the whole number of persons in each state" type="ADJP">
          <tokens>
            <token id="3" string="amended" />
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="Civil" />
            <token id="7" string="War" />
            <token id="8" string="to" />
            <token id="9" string="say" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Civil War to say that the apportionment of House seats will be based on `` the whole number of persons in each state" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Civil" />
            <token id="7" string="War" />
            <token id="8" string="to" />
            <token id="9" string="say" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="9" string="to say that the apportionment of House seats will be based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="say" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="10" string="persons" type="NP">
          <tokens>
            <token id="25" string="persons" />
          </tokens>
        </chunking>
        <chunking id="11" string="persons in each state" type="NP">
          <tokens>
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="12" string="the whole number of persons in each state" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="13" string="each state" type="NP">
          <tokens>
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="14" string="that the apportionment of House seats will be based on `` the whole number of persons in each state" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="15" string="will be based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="16" string="based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="17" string="was amended after the Civil War to say that the apportionment of House seats will be based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="amended" />
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="Civil" />
            <token id="7" string="War" />
            <token id="8" string="to" />
            <token id="9" string="say" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="apportionment" />
            <token id="13" string="of" />
            <token id="14" string="House" />
            <token id="15" string="seats" />
            <token id="16" string="will" />
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
        <chunking id="18" string="be based on `` the whole number of persons in each state" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="based" />
            <token id="19" string="on" />
            <token id="20" string="``" />
            <token id="21" string="the" />
            <token id="22" string="whole" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="persons" />
            <token id="26" string="in" />
            <token id="27" string="each" />
            <token id="28" string="state" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">amended</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">amended</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">amended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">War</governor>
          <dependent id="4">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">War</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">War</governor>
          <dependent id="6">Civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">amended</governor>
          <dependent id="7">War</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">say</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">War</governor>
          <dependent id="9">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">based</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">apportionment</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">based</governor>
          <dependent id="12">apportionment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">seats</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">seats</governor>
          <dependent id="14">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">apportionment</governor>
          <dependent id="15">seats</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">based</governor>
          <dependent id="16">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">based</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">say</governor>
          <dependent id="18">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">number</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">number</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">number</governor>
          <dependent id="22">whole</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">based</governor>
          <dependent id="23">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">persons</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">number</governor>
          <dependent id="25">persons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">state</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">state</governor>
          <dependent id="27">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">persons</governor>
          <dependent id="28">state</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Civil War" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Civil" />
            <token id="7" string="War" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Neither the original article nor the amendment mentions citizenship in connection with apportionment, although the term ``citizens&amp;apost;&amp;apost; is used in some other provisions.</content>
      <tokens>
        <token id="1" string="Neither" lemma="neither" stem="neither" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="article" lemma="article" stem="articl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="mentions" lemma="mention" stem="mention" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="citizenship" lemma="citizenship" stem="citizenship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="connection" lemma="connection" stem="connect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="provisions" lemma="provision" stem="provis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CC Neither) (NP (DT the) (JJ original) (NN article)) (CC nor) (NP (DT the) (NN amendment))) (VP (VBZ mentions) (NP (NP (NN citizenship)) (PP (IN in) (NP (NP (NN connection)) (PP (IN with) (NP (NN apportionment)))))) (, ,) (SBAR (IN although) (S (NP (NP (DT the) (NN term)) (`` ``) (NP (NNS citizens)) ('' '')) (VP (VBZ is) (VP (VBN used) (PP (IN in) (NP (DT some) (JJ other) (NNS provisions)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="citizenship" type="NP">
          <tokens>
            <token id="9" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="2" string="the amendment" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="3" string="some other provisions" type="NP">
          <tokens>
            <token id="24" string="some" />
            <token id="25" string="other" />
            <token id="26" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="4" string="mentions citizenship in connection with apportionment , although the term `` citizens '' is used in some other provisions" type="VP">
          <tokens>
            <token id="8" string="mentions" />
            <token id="9" string="citizenship" />
            <token id="10" string="in" />
            <token id="11" string="connection" />
            <token id="12" string="with" />
            <token id="13" string="apportionment" />
            <token id="14" string="," />
            <token id="15" string="although" />
            <token id="16" string="the" />
            <token id="17" string="term" />
            <token id="18" string="``" />
            <token id="19" string="citizens" />
            <token id="20" string="''" />
            <token id="21" string="is" />
            <token id="22" string="used" />
            <token id="23" string="in" />
            <token id="24" string="some" />
            <token id="25" string="other" />
            <token id="26" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="5" string="apportionment" type="NP">
          <tokens>
            <token id="13" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="6" string="connection with apportionment" type="NP">
          <tokens>
            <token id="11" string="connection" />
            <token id="12" string="with" />
            <token id="13" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="7" string="the term `` citizens ''" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="term" />
            <token id="18" string="``" />
            <token id="19" string="citizens" />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="8" string="used in some other provisions" type="VP">
          <tokens>
            <token id="22" string="used" />
            <token id="23" string="in" />
            <token id="24" string="some" />
            <token id="25" string="other" />
            <token id="26" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="9" string="Neither the original article nor the amendment" type="NP">
          <tokens>
            <token id="1" string="Neither" />
            <token id="2" string="the" />
            <token id="3" string="original" />
            <token id="4" string="article" />
            <token id="5" string="nor" />
            <token id="6" string="the" />
            <token id="7" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="10" string="is used in some other provisions" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="used" />
            <token id="23" string="in" />
            <token id="24" string="some" />
            <token id="25" string="other" />
            <token id="26" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="11" string="the original article" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="original" />
            <token id="4" string="article" />
          </tokens>
        </chunking>
        <chunking id="12" string="citizenship in connection with apportionment" type="NP">
          <tokens>
            <token id="9" string="citizenship" />
            <token id="10" string="in" />
            <token id="11" string="connection" />
            <token id="12" string="with" />
            <token id="13" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="13" string="although the term `` citizens '' is used in some other provisions" type="SBAR">
          <tokens>
            <token id="15" string="although" />
            <token id="16" string="the" />
            <token id="17" string="term" />
            <token id="18" string="``" />
            <token id="19" string="citizens" />
            <token id="20" string="''" />
            <token id="21" string="is" />
            <token id="22" string="used" />
            <token id="23" string="in" />
            <token id="24" string="some" />
            <token id="25" string="other" />
            <token id="26" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="14" string="connection" type="NP">
          <tokens>
            <token id="11" string="connection" />
          </tokens>
        </chunking>
        <chunking id="15" string="the term" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="term" />
          </tokens>
        </chunking>
        <chunking id="16" string="citizens" type="NP">
          <tokens>
            <token id="19" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc:preconj">
          <governor id="4">article</governor>
          <dependent id="1">Neither</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">article</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">article</governor>
          <dependent id="3">original</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">mentions</governor>
          <dependent id="4">article</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">article</governor>
          <dependent id="5">nor</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">amendment</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">article</governor>
          <dependent id="7">amendment</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">mentions</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">mentions</governor>
          <dependent id="9">citizenship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">connection</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">citizenship</governor>
          <dependent id="11">connection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">apportionment</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">connection</governor>
          <dependent id="13">apportionment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">used</governor>
          <dependent id="15">although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">term</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">used</governor>
          <dependent id="17">term</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">term</governor>
          <dependent id="19">citizens</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">used</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">mentions</governor>
          <dependent id="22">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">provisions</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">provisions</governor>
          <dependent id="24">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">provisions</governor>
          <dependent id="25">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">used</governor>
          <dependent id="26">provisions</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Opponents of the amendment said that showed the authors of both documents wanted everybody counted for purposes of apportionment.</content>
      <tokens>
        <token id="1" string="Opponents" lemma="opponent" stem="opponent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="authors" lemma="author" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="documents" lemma="document" stem="document" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="purposes" lemma="purpose" stem="purpos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Opponents)) (PP (IN of) (NP (DT the) (NN amendment)))) (VP (VBD said) (SBAR (IN that) (S (VP (VBD showed) (SBAR (S (NP (NP (DT the) (NNS authors)) (PP (IN of) (NP (DT both) (NNS documents)))) (VP (VBD wanted) (NP (NP (NN everybody)) (VP (VBN counted) (PP (IN for) (NP (NP (NNS purposes)) (PP (IN of) (NP (NN apportionment)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="showed the authors of both documents wanted everybody counted for purposes of apportionment" type="VP">
          <tokens>
            <token id="7" string="showed" />
            <token id="8" string="the" />
            <token id="9" string="authors" />
            <token id="10" string="of" />
            <token id="11" string="both" />
            <token id="12" string="documents" />
            <token id="13" string="wanted" />
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="2" string="purposes of apportionment" type="NP">
          <tokens>
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the amendment" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="4" string="everybody" type="NP">
          <tokens>
            <token id="14" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="5" string="Opponents of the amendment" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="6" string="the authors of both documents" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="authors" />
            <token id="10" string="of" />
            <token id="11" string="both" />
            <token id="12" string="documents" />
          </tokens>
        </chunking>
        <chunking id="7" string="apportionment" type="NP">
          <tokens>
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="8" string="the authors" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="authors" />
          </tokens>
        </chunking>
        <chunking id="9" string="counted for purposes of apportionment" type="VP">
          <tokens>
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="10" string="that showed the authors of both documents wanted everybody counted for purposes of apportionment" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="showed" />
            <token id="8" string="the" />
            <token id="9" string="authors" />
            <token id="10" string="of" />
            <token id="11" string="both" />
            <token id="12" string="documents" />
            <token id="13" string="wanted" />
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="11" string="said that showed the authors of both documents wanted everybody counted for purposes of apportionment" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="that" />
            <token id="7" string="showed" />
            <token id="8" string="the" />
            <token id="9" string="authors" />
            <token id="10" string="of" />
            <token id="11" string="both" />
            <token id="12" string="documents" />
            <token id="13" string="wanted" />
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="12" string="both documents" type="NP">
          <tokens>
            <token id="11" string="both" />
            <token id="12" string="documents" />
          </tokens>
        </chunking>
        <chunking id="13" string="everybody counted for purposes of apportionment" type="NP">
          <tokens>
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="14" string="Opponents" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
          </tokens>
        </chunking>
        <chunking id="15" string="purposes" type="NP">
          <tokens>
            <token id="17" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="16" string="wanted everybody counted for purposes of apportionment" type="VP">
          <tokens>
            <token id="13" string="wanted" />
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="17" string="the authors of both documents wanted everybody counted for purposes of apportionment" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="authors" />
            <token id="10" string="of" />
            <token id="11" string="both" />
            <token id="12" string="documents" />
            <token id="13" string="wanted" />
            <token id="14" string="everybody" />
            <token id="15" string="counted" />
            <token id="16" string="for" />
            <token id="17" string="purposes" />
            <token id="18" string="of" />
            <token id="19" string="apportionment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="1">Opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">amendment</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">amendment</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Opponents</governor>
          <dependent id="4">amendment</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">showed</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="7">showed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">authors</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">wanted</governor>
          <dependent id="9">authors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">documents</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">documents</governor>
          <dependent id="11">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">authors</governor>
          <dependent id="12">documents</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">showed</governor>
          <dependent id="13">wanted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">wanted</governor>
          <dependent id="14">everybody</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">everybody</governor>
          <dependent id="15">counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">purposes</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">counted</governor>
          <dependent id="17">purposes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">apportionment</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">purposes</governor>
          <dependent id="19">apportionment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>But Sen. Alan K. Simpson, R-Wyo., said the people who wrote the documents had no concept of illegal aliens because there weren&amp;apost;t any in their time.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="K." lemma="K." stem="k." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Simpson" lemma="Simpson" stem="simpson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="R-Wyo." lemma="R-Wyo." stem="r-wyo." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="documents" lemma="document" stem="document" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Sen.) (NNP Alan) (NNP K.) (NNP Simpson)) (, ,) (NP (NNP R-Wyo.)) (, ,)) (VP (VBD said) (NP (NP (DT the) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBD wrote) (SBAR (S (NP (DT the) (NNS documents)) (VP (VBD had) (NP (NP (DT no) (NN concept)) (PP (IN of) (NP (JJ illegal) (NNS aliens))))))))))) (SBAR (IN because) (S (NP (EX there)) (VP (VBD were) (RB n't) (NP (NP (DT any)) (PP (IN in) (NP (PRP$ their) (NN time)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sen. Alan K. Simpson" type="NP">
          <tokens>
            <token id="2" string="Sen." />
            <token id="3" string="Alan" />
            <token id="4" string="K." />
            <token id="5" string="Simpson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the people who wrote the documents had no concept of illegal aliens" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="wrote" />
            <token id="14" string="the" />
            <token id="15" string="documents" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="4" string="the documents had no concept of illegal aliens" type="SBAR">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="documents" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="5" string="any in their time" type="NP">
          <tokens>
            <token id="26" string="any" />
            <token id="27" string="in" />
            <token id="28" string="their" />
            <token id="29" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="said the people who wrote the documents had no concept of illegal aliens because there were n't any in their time" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="the" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="wrote" />
            <token id="14" string="the" />
            <token id="15" string="documents" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
            <token id="22" string="because" />
            <token id="23" string="there" />
            <token id="24" string="were" />
            <token id="25" string="n't" />
            <token id="26" string="any" />
            <token id="27" string="in" />
            <token id="28" string="their" />
            <token id="29" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="no concept of illegal aliens" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sen. Alan K. Simpson , R-Wyo. ," type="NP">
          <tokens>
            <token id="2" string="Sen." />
            <token id="3" string="Alan" />
            <token id="4" string="K." />
            <token id="5" string="Simpson" />
            <token id="6" string="," />
            <token id="7" string="R-Wyo." />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="who wrote the documents had no concept of illegal aliens" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="wrote" />
            <token id="14" string="the" />
            <token id="15" string="documents" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="10" string="no concept" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="concept" />
          </tokens>
        </chunking>
        <chunking id="11" string="were n't any in their time" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="n't" />
            <token id="26" string="any" />
            <token id="27" string="in" />
            <token id="28" string="their" />
            <token id="29" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="the people" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="their time" type="NP">
          <tokens>
            <token id="28" string="their" />
            <token id="29" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="any" type="NP">
          <tokens>
            <token id="26" string="any" />
          </tokens>
        </chunking>
        <chunking id="15" string="R-Wyo." type="NP">
          <tokens>
            <token id="7" string="R-Wyo." />
          </tokens>
        </chunking>
        <chunking id="16" string="there" type="NP">
          <tokens>
            <token id="23" string="there" />
          </tokens>
        </chunking>
        <chunking id="17" string="because there were n't any in their time" type="SBAR">
          <tokens>
            <token id="22" string="because" />
            <token id="23" string="there" />
            <token id="24" string="were" />
            <token id="25" string="n't" />
            <token id="26" string="any" />
            <token id="27" string="in" />
            <token id="28" string="their" />
            <token id="29" string="time" />
          </tokens>
        </chunking>
        <chunking id="18" string="the documents" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="documents" />
          </tokens>
        </chunking>
        <chunking id="19" string="wrote the documents had no concept of illegal aliens" type="VP">
          <tokens>
            <token id="13" string="wrote" />
            <token id="14" string="the" />
            <token id="15" string="documents" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="20" string="had no concept of illegal aliens" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="concept" />
            <token id="19" string="of" />
            <token id="20" string="illegal" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Simpson</governor>
          <dependent id="2">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Simpson</governor>
          <dependent id="3">Alan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Simpson</governor>
          <dependent id="4">K.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="5">Simpson</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Simpson</governor>
          <dependent id="7">R-Wyo.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">people</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">said</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">wrote</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">people</governor>
          <dependent id="13">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">documents</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">had</governor>
          <dependent id="15">documents</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">wrote</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">concept</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">had</governor>
          <dependent id="18">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">aliens</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">aliens</governor>
          <dependent id="20">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">concept</governor>
          <dependent id="21">aliens</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">were</governor>
          <dependent id="22">because</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="24">were</governor>
          <dependent id="23">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">said</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">were</governor>
          <dependent id="25">n't</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">were</governor>
          <dependent id="26">any</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">time</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">time</governor>
          <dependent id="28">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">any</governor>
          <dependent id="29">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Alan K. Simpson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Alan" />
            <token id="4" string="K." />
            <token id="5" string="Simpson" />
          </tokens>
        </entity>
        <entity id="2" string="R-Wyo." type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="R-Wyo." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>That came later, with immigration restrictions that began in 1875.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="restrictions" lemma="restriction" stem="restrict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1875" lemma="1875" stem="1875" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBD came) (ADVP (RB later)) (, ,) (PP (IN with) (NP (NP (NN immigration) (NNS restrictions)) (SBAR (WHNP (WDT that)) (S (VP (VBD began) (PP (IN in) (NP (CD 1875))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="immigration restrictions" type="NP">
          <tokens>
            <token id="6" string="immigration" />
            <token id="7" string="restrictions" />
          </tokens>
        </chunking>
        <chunking id="3" string="began in 1875" type="VP">
          <tokens>
            <token id="9" string="began" />
            <token id="10" string="in" />
            <token id="11" string="1875" />
          </tokens>
        </chunking>
        <chunking id="4" string="1875" type="NP">
          <tokens>
            <token id="11" string="1875" />
          </tokens>
        </chunking>
        <chunking id="5" string="came later , with immigration restrictions that began in 1875" type="VP">
          <tokens>
            <token id="2" string="came" />
            <token id="3" string="later" />
            <token id="4" string="," />
            <token id="5" string="with" />
            <token id="6" string="immigration" />
            <token id="7" string="restrictions" />
            <token id="8" string="that" />
            <token id="9" string="began" />
            <token id="10" string="in" />
            <token id="11" string="1875" />
          </tokens>
        </chunking>
        <chunking id="6" string="immigration restrictions that began in 1875" type="NP">
          <tokens>
            <token id="6" string="immigration" />
            <token id="7" string="restrictions" />
            <token id="8" string="that" />
            <token id="9" string="began" />
            <token id="10" string="in" />
            <token id="11" string="1875" />
          </tokens>
        </chunking>
        <chunking id="7" string="that began in 1875" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="began" />
            <token id="10" string="in" />
            <token id="11" string="1875" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">came</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">came</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">came</governor>
          <dependent id="3">later</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">restrictions</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">restrictions</governor>
          <dependent id="6">immigration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">came</governor>
          <dependent id="7">restrictions</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">began</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">restrictions</governor>
          <dependent id="9">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1875</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">began</governor>
          <dependent id="11">1875</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1875" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1875" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Sen. Bob Dole of Kansas, the Republican leader, said the question should be put squarely to the Supreme Court.</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Kansas" lemma="Kansas" stem="kansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="9" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="squarely" lemma="squarely" stem="squar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Sen.) (NNP Bob) (NNP Dole)) (PP (IN of) (NP (NNP Kansas)))) (, ,) (NP (DT the) (JJ Republican) (NN leader)) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (NN question)) (VP (MD should) (VP (VB be) (VP (VBN put) (ADVP (RB squarely)) (PP (TO to) (NP (DT the) (NNP Supreme) (NNP Court))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Republican leader" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Republican" />
            <token id="9" string="leader" />
          </tokens>
        </chunking>
        <chunking id="2" string="be put squarely to the Supreme Court" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="put" />
            <token id="17" string="squarely" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="3" string="put squarely to the Supreme Court" type="VP">
          <tokens>
            <token id="16" string="put" />
            <token id="17" string="squarely" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Supreme Court" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="the question" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="question" />
          </tokens>
        </chunking>
        <chunking id="6" string="should be put squarely to the Supreme Court" type="VP">
          <tokens>
            <token id="14" string="should" />
            <token id="15" string="be" />
            <token id="16" string="put" />
            <token id="17" string="squarely" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the question should be put squarely to the Supreme Court" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="the" />
            <token id="13" string="question" />
            <token id="14" string="should" />
            <token id="15" string="be" />
            <token id="16" string="put" />
            <token id="17" string="squarely" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sen. Bob Dole" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Bob" />
            <token id="3" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="9" string="Kansas" type="NP">
          <tokens>
            <token id="5" string="Kansas" />
          </tokens>
        </chunking>
        <chunking id="10" string="the question should be put squarely to the Supreme Court" type="SBAR">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="question" />
            <token id="14" string="should" />
            <token id="15" string="be" />
            <token id="16" string="put" />
            <token id="17" string="squarely" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </chunking>
        <chunking id="11" string="Sen. Bob Dole of Kansas , the Republican leader ," type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Bob" />
            <token id="3" string="Dole" />
            <token id="4" string="of" />
            <token id="5" string="Kansas" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="Republican" />
            <token id="9" string="leader" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="Sen. Bob Dole of Kansas" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Bob" />
            <token id="3" string="Dole" />
            <token id="4" string="of" />
            <token id="5" string="Kansas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Dole</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Dole</governor>
          <dependent id="2">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="3">Dole</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Kansas</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Dole</governor>
          <dependent id="5">Kansas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">leader</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">leader</governor>
          <dependent id="8">Republican</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Dole</governor>
          <dependent id="9">leader</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">question</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">put</governor>
          <dependent id="13">question</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">put</governor>
          <dependent id="14">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">put</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="16">put</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">put</governor>
          <dependent id="17">squarely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Court</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Court</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Court</governor>
          <dependent id="20">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">put</governor>
          <dependent id="21">Court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Supreme" />
            <token id="21" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Bob Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Bob" />
            <token id="3" string="Dole" />
          </tokens>
        </entity>
        <entity id="3" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="Republican" />
          </tokens>
        </entity>
        <entity id="4" string="Kansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Kansas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>He said it is unfair to count illegal aliens in reapportionment.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ unfair) (S (VP (TO to) (VP (VB count) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (NN reapportionment))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to count illegal aliens in reapportionment" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="it is unfair to count illegal aliens in reapportionment" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="unfair" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="4" string="unfair to count illegal aliens in reapportionment" type="ADJP">
          <tokens>
            <token id="5" string="unfair" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="5" string="reapportionment" type="NP">
          <tokens>
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="said it is unfair to count illegal aliens in reapportionment" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="unfair" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="9" string="is unfair to count illegal aliens in reapportionment" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="unfair" />
            <token id="6" string="to" />
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="10" string="count illegal aliens in reapportionment" type="VP">
          <tokens>
            <token id="7" string="count" />
            <token id="8" string="illegal" />
            <token id="9" string="aliens" />
            <token id="10" string="in" />
            <token id="11" string="reapportionment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">unfair</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">unfair</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">unfair</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">count</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">unfair</governor>
          <dependent id="7">count</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">aliens</governor>
          <dependent id="8">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">count</governor>
          <dependent id="9">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">reapportionment</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">count</governor>
          <dependent id="11">reapportionment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``It just does not make any sense,&amp;apost;&amp;apost; Dole said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (ADVP (RB just)) (VP (VBZ does) (RB not) (VP (VB make) (NP (DT any) (NN sense))))) (, ,) ('' '') (NP (NNP Dole)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dole" type="NP">
          <tokens>
            <token id="11" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="2" string="does not make any sense" type="VP">
          <tokens>
            <token id="4" string="does" />
            <token id="5" string="not" />
            <token id="6" string="make" />
            <token id="7" string="any" />
            <token id="8" string="sense" />
          </tokens>
        </chunking>
        <chunking id="3" string="any sense" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="sense" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="make any sense" type="VP">
          <tokens>
            <token id="6" string="make" />
            <token id="7" string="any" />
            <token id="8" string="sense" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">make</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">make</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">make</governor>
          <dependent id="4">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">make</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="6">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">sense</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">make</governor>
          <dependent id="8">sense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Dole</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Dole" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>``It does violate the constitutional principle of one man, one vote.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="violate" lemma="violate" stem="violat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="constitutional" lemma="constitutional" stem="constitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="principle" lemma="principle" stem="principl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ does) (VP (VB violate) (NP (NP (DT the) (JJ constitutional) (NN principle)) (PP (IN of) (NP (NP (CD one) (NN man)) (, ,) (NP (CD one) (NN vote))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="does violate the constitutional principle of one man , one vote" type="VP">
          <tokens>
            <token id="3" string="does" />
            <token id="4" string="violate" />
            <token id="5" string="the" />
            <token id="6" string="constitutional" />
            <token id="7" string="principle" />
            <token id="8" string="of" />
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="vote" />
          </tokens>
        </chunking>
        <chunking id="2" string="one vote" type="NP">
          <tokens>
            <token id="12" string="one" />
            <token id="13" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="violate the constitutional principle of one man , one vote" type="VP">
          <tokens>
            <token id="4" string="violate" />
            <token id="5" string="the" />
            <token id="6" string="constitutional" />
            <token id="7" string="principle" />
            <token id="8" string="of" />
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="vote" />
          </tokens>
        </chunking>
        <chunking id="4" string="one man" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="man" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="the constitutional principle of one man , one vote" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="constitutional" />
            <token id="7" string="principle" />
            <token id="8" string="of" />
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="vote" />
          </tokens>
        </chunking>
        <chunking id="7" string="the constitutional principle" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="constitutional" />
            <token id="7" string="principle" />
          </tokens>
        </chunking>
        <chunking id="8" string="one man , one vote" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="man" />
            <token id="11" string="," />
            <token id="12" string="one" />
            <token id="13" string="vote" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">violate</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">violate</governor>
          <dependent id="3">does</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">violate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">principle</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">principle</governor>
          <dependent id="6">constitutional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">violate</governor>
          <dependent id="7">principle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">man</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">man</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">principle</governor>
          <dependent id="10">man</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">vote</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">man</governor>
          <dependent id="13">vote</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>But opponents of the Shelby measure said apportionment doesn&amp;apost;t involve who votes and who doesn&amp;apost;t.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="measure" lemma="measure" stem="measur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="involve" lemma="involve" stem="involv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="votes" lemma="vote" stem="vote" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNS opponents)) (PP (IN of) (NP (DT the) (NNP Shelby) (NN measure)))) (VP (VBD said) (SBAR (S (NP (NN apportionment)) (VP (VBZ does) (RB n't) (VP (VB involve) (NP (SBAR (WHNP (WP who)) (S (VP (VBZ votes)))) (CC and) (SBAR (WHNP (WP who)) (S (VP (VBZ does) (RB n't)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="opponents" type="NP">
          <tokens>
            <token id="2" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="2" string="involve who votes and who does n't" type="VP">
          <tokens>
            <token id="11" string="involve" />
            <token id="12" string="who" />
            <token id="13" string="votes" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="3" string="apportionment" type="NP">
          <tokens>
            <token id="8" string="apportionment" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Shelby measure" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Shelby" />
            <token id="6" string="measure" />
          </tokens>
        </chunking>
        <chunking id="5" string="who votes" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="votes" />
          </tokens>
        </chunking>
        <chunking id="6" string="does n't involve who votes and who does n't" type="VP">
          <tokens>
            <token id="9" string="does" />
            <token id="10" string="n't" />
            <token id="11" string="involve" />
            <token id="12" string="who" />
            <token id="13" string="votes" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="7" string="who votes and who does n't" type="NP">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="votes" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="8" string="does n't" type="VP">
          <tokens>
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="9" string="opponents of the Shelby measure" type="NP">
          <tokens>
            <token id="2" string="opponents" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="Shelby" />
            <token id="6" string="measure" />
          </tokens>
        </chunking>
        <chunking id="10" string="apportionment does n't involve who votes and who does n't" type="SBAR">
          <tokens>
            <token id="8" string="apportionment" />
            <token id="9" string="does" />
            <token id="10" string="n't" />
            <token id="11" string="involve" />
            <token id="12" string="who" />
            <token id="13" string="votes" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="11" string="votes" type="VP">
          <tokens>
            <token id="13" string="votes" />
          </tokens>
        </chunking>
        <chunking id="12" string="said apportionment does n't involve who votes and who does n't" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="apportionment" />
            <token id="9" string="does" />
            <token id="10" string="n't" />
            <token id="11" string="involve" />
            <token id="12" string="who" />
            <token id="13" string="votes" />
            <token id="14" string="and" />
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
        <chunking id="13" string="who does n't" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="does" />
            <token id="17" string="n't" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="2">opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">measure</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">measure</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">measure</governor>
          <dependent id="5">Shelby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">opponents</governor>
          <dependent id="6">measure</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">involve</governor>
          <dependent id="8">apportionment</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">involve</governor>
          <dependent id="9">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">involve</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">involve</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">votes</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">involve</governor>
          <dependent id="13">votes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">votes</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">does</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">votes</governor>
          <dependent id="16">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">does</governor>
          <dependent id="17">n't</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Shelby" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Shelby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Women couldn&amp;apost;t vote when the Constitution and the 14th Amendment were adopted, but they always were counted.</content>
      <tokens>
        <token id="1" string="Women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="14th" lemma="14th" stem="14th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="11" string="Amendment" lemma="amendment" stem="amendment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="adopted" lemma="adopt" stem="adopt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Women)) (VP (MD could) (RB n't) (VP (VB vote) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NNP Constitution)) (CC and) (NP (DT the) (JJ 14th) (NN Amendment))) (VP (VBD were) (VP (VBN adopted)))))))) (, ,) (CC but) (S (NP (PRP they)) (ADVP (RB always)) (VP (VBD were) (VP (VBN counted)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Women" type="NP">
          <tokens>
            <token id="1" string="Women" />
          </tokens>
        </chunking>
        <chunking id="2" string="when the Constitution and the 14th Amendment were adopted" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="the" />
            <token id="7" string="Constitution" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="were" />
            <token id="13" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Constitution and the 14th Amendment" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Constitution" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 14th Amendment" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="7" string="vote when the Constitution and the 14th Amendment were adopted" type="VP">
          <tokens>
            <token id="4" string="vote" />
            <token id="5" string="when" />
            <token id="6" string="the" />
            <token id="7" string="Constitution" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="were" />
            <token id="13" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="16" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="were counted" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="counted" />
          </tokens>
        </chunking>
        <chunking id="10" string="were adopted" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="11" string="counted" type="VP">
          <tokens>
            <token id="19" string="counted" />
          </tokens>
        </chunking>
        <chunking id="12" string="could n't vote when the Constitution and the 14th Amendment were adopted" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="n't" />
            <token id="4" string="vote" />
            <token id="5" string="when" />
            <token id="6" string="the" />
            <token id="7" string="Constitution" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="were" />
            <token id="13" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="13" string="adopted" type="VP">
          <tokens>
            <token id="13" string="adopted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">vote</governor>
          <dependent id="1">Women</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">vote</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">vote</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">vote</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">adopted</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Constitution</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">adopted</governor>
          <dependent id="7">Constitution</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Constitution</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Amendment</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Amendment</governor>
          <dependent id="10">14th</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Constitution</governor>
          <dependent id="11">Amendment</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">adopted</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">vote</governor>
          <dependent id="13">adopted</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">vote</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">counted</governor>
          <dependent id="16">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">counted</governor>
          <dependent id="17">always</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">counted</governor>
          <dependent id="18">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">vote</governor>
          <dependent id="19">counted</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="10" string="14th" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>Children can&amp;apost;t vote, but they count, too.</content>
      <tokens>
        <token id="1" string="Children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="count" lemma="count" stem="count" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Children)) (VP (MD ca) (RB n't) (VP (VB vote)))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBP count)) (, ,) (ADVP (RB too))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="ca n't vote" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="count" type="VP">
          <tokens>
            <token id="8" string="count" />
          </tokens>
        </chunking>
        <chunking id="4" string="Children" type="NP">
          <tokens>
            <token id="1" string="Children" />
          </tokens>
        </chunking>
        <chunking id="5" string="vote" type="VP">
          <tokens>
            <token id="4" string="vote" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">vote</governor>
          <dependent id="1">Children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">vote</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">vote</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">vote</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">vote</governor>
          <dependent id="6">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">count</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">vote</governor>
          <dependent id="8">count</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">count</governor>
          <dependent id="10">too</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>The amendment was adopted after the Senate voted 58 to 41 against a move to reject it, and 56 to 43 against scuttling it as unconstitutional.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="adopted" lemma="adopt" stem="adopt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="58" lemma="58" stem="58" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="41" lemma="41" stem="41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="move" lemma="move" stem="move" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="reject" lemma="reject" stem="reject" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="56" lemma="56" stem="56" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="43" lemma="43" stem="43" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="scuttling" lemma="scuttle" stem="scuttl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN amendment)) (VP (VBD was) (VP (VBN adopted) (SBAR (IN after) (S (NP (DT the) (NNP Senate)) (VP (VBD voted) (NP (NP (NP (QP (CD 58) (TO to) (CD 41))) (PP (IN against) (NP (DT a) (NN move) (S (VP (TO to) (VP (VB reject) (NP (PRP it)))))))) (, ,) (CC and) (NP (NP (QP (CD 56) (TO to) (CD 43))) (PP (IN against) (S (VP (VBG scuttling) (NP (PRP it)) (PP (IN as) (ADJP (JJ unconstitutional))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="56 to 43 against scuttling it as unconstitutional" type="NP">
          <tokens>
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="2" string="The amendment" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="3" string="58 to 41 against a move to reject it , and 56 to 43 against scuttling it as unconstitutional" type="NP">
          <tokens>
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="4" string="was adopted after the Senate voted 58 to 41 against a move to reject it , and 56 to 43 against scuttling it as unconstitutional" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="adopted" />
            <token id="5" string="after" />
            <token id="6" string="the" />
            <token id="7" string="Senate" />
            <token id="8" string="voted" />
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="5" string="voted 58 to 41 against a move to reject it , and 56 to 43 against scuttling it as unconstitutional" type="VP">
          <tokens>
            <token id="8" string="voted" />
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="6" string="a move to reject it" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="reject it" type="VP">
          <tokens>
            <token id="16" string="reject" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="58 to 41" type="NP">
          <tokens>
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Senate" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="11" string="after the Senate voted 58 to 41 against a move to reject it , and 56 to 43 against scuttling it as unconstitutional" type="SBAR">
          <tokens>
            <token id="5" string="after" />
            <token id="6" string="the" />
            <token id="7" string="Senate" />
            <token id="8" string="voted" />
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="12" string="scuttling it as unconstitutional" type="VP">
          <tokens>
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="13" string="to reject it" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="56 to 43" type="NP">
          <tokens>
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
          </tokens>
        </chunking>
        <chunking id="15" string="adopted after the Senate voted 58 to 41 against a move to reject it , and 56 to 43 against scuttling it as unconstitutional" type="VP">
          <tokens>
            <token id="4" string="adopted" />
            <token id="5" string="after" />
            <token id="6" string="the" />
            <token id="7" string="Senate" />
            <token id="8" string="voted" />
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="56" />
            <token id="21" string="to" />
            <token id="22" string="43" />
            <token id="23" string="against" />
            <token id="24" string="scuttling" />
            <token id="25" string="it" />
            <token id="26" string="as" />
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
        <chunking id="16" string="58 to 41 against a move to reject it" type="NP">
          <tokens>
            <token id="9" string="58" />
            <token id="10" string="to" />
            <token id="11" string="41" />
            <token id="12" string="against" />
            <token id="13" string="a" />
            <token id="14" string="move" />
            <token id="15" string="to" />
            <token id="16" string="reject" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="unconstitutional" type="ADJP">
          <tokens>
            <token id="27" string="unconstitutional" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">amendment</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">adopted</governor>
          <dependent id="2">amendment</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">adopted</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">adopted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">voted</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Senate</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">voted</governor>
          <dependent id="7">Senate</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">adopted</governor>
          <dependent id="8">voted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">41</governor>
          <dependent id="9">58</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">41</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">voted</governor>
          <dependent id="11">41</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">move</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">move</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">41</governor>
          <dependent id="14">move</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">reject</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">move</governor>
          <dependent id="16">reject</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">reject</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">41</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">43</governor>
          <dependent id="20">56</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">43</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">41</governor>
          <dependent id="22">43</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">scuttling</governor>
          <dependent id="23">against</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">43</governor>
          <dependent id="24">scuttling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">scuttling</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">unconstitutional</governor>
          <dependent id="26">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">scuttling</governor>
          <dependent id="27">unconstitutional</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="56" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="56" />
          </tokens>
        </entity>
        <entity id="2" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Senate" />
          </tokens>
        </entity>
        <entity id="3" string="58" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="58" />
          </tokens>
        </entity>
        <entity id="4" string="41" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="41" />
          </tokens>
        </entity>
        <entity id="5" string="43" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="43" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Shelby said that is sure to put the matter into the hands of the courts for a final judgment.</content>
      <tokens>
        <token id="1" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="judgment" lemma="judgment" stem="judgment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Shelby)) (VP (VBD said) (SBAR (S (NP (DT that)) (VP (VBZ is) (ADJP (JJ sure) (S (VP (TO to) (VP (VB put) (NP (DT the) (NN matter)) (PP (IN into) (NP (NP (DT the) (NNS hands)) (PP (IN of) (NP (NP (DT the) (NNS courts)) (PP (IN for) (NP (DT a) (JJ final) (NN judgment))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hands" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="hands" />
          </tokens>
        </chunking>
        <chunking id="2" string="put the matter into the hands of the courts for a final judgment" type="VP">
          <tokens>
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the courts" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="courts" />
          </tokens>
        </chunking>
        <chunking id="4" string="the matter" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="matter" />
          </tokens>
        </chunking>
        <chunking id="5" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="to put the matter into the hands of the courts for a final judgment" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="7" string="the courts for a final judgment" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="8" string="the hands of the courts for a final judgment" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="9" string="said that is sure to put the matter into the hands of the courts for a final judgment" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="is" />
            <token id="5" string="sure" />
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="10" string="that is sure to put the matter into the hands of the courts for a final judgment" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="is" />
            <token id="5" string="sure" />
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="11" string="Shelby" type="NP">
          <tokens>
            <token id="1" string="Shelby" />
          </tokens>
        </chunking>
        <chunking id="12" string="a final judgment" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="13" string="sure to put the matter into the hands of the courts for a final judgment" type="ADJP">
          <tokens>
            <token id="5" string="sure" />
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="14" string="is sure to put the matter into the hands of the courts for a final judgment" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="sure" />
            <token id="6" string="to" />
            <token id="7" string="put" />
            <token id="8" string="the" />
            <token id="9" string="matter" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="hands" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="courts" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="final" />
            <token id="19" string="judgment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Shelby</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">sure</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">sure</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">sure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">put</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">sure</governor>
          <dependent id="7">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">matter</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">put</governor>
          <dependent id="9">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">hands</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">hands</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">put</governor>
          <dependent id="12">hands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">courts</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">courts</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">hands</governor>
          <dependent id="15">courts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">judgment</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">judgment</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">judgment</governor>
          <dependent id="18">final</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">courts</governor>
          <dependent id="19">judgment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Shelby" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Shelby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>``Somebody is going to challenge it ...&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="challenge" lemma="challenge" stem="challeng" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NN Somebody)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB challenge) (NP (PRP it)))))))) (: ...) ('' '') (S (NP (PRP he)) (VP (VBD said))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="going to challenge it" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="challenge" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="to challenge it" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="challenge" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="challenge it" type="VP">
          <tokens>
            <token id="6" string="challenge" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="Somebody" type="NP">
          <tokens>
            <token id="2" string="Somebody" />
          </tokens>
        </chunking>
        <chunking id="5" string="is going to challenge it" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="challenge" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">Somebody</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">challenge</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="6">challenge</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">challenge</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">going</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>``Then, for the first time, we will let the Supreme Court of the United States decide something that we need an answer to ...&amp;apost;&amp;apost;  Walter R. Mears, vice president and columnist for The Associated Press, has reported on Washington and national politics for more than 25 years.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="7" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Walter" lemma="Walter" stem="walter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Mears" lemma="Mears" stem="mear" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="columnist" lemma="columnist" stem="columnist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Associated" lemma="Associated" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="40" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="46" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="51" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="52" string="25" lemma="25" stem="25" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="53" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (ADVP (RB Then)) (, ,) (S (PP (IN for) (NP (DT the) (JJ first) (NN time))) (, ,) (NP (PRP we)) (VP (MD will) (VP (VB let) (S (NP (NP (DT the) (NNP Supreme) (NNP Court)) (PP (IN of) (NP (DT the) (NNP United) (NNPS States)))) (VP (VB decide) (NP (NN something)) (SBAR (IN that) (S (NP (PRP we)) (VP (VBP need) (NP (DT an) (NN answer)) (PP (TO to)))))))))) (: ...) ('' '') (S (NP (NP (NNP Walter) (NNP R.) (NNP Mears)) (, ,) (NP (NP (NN vice) (NN president) (CC and) (NN columnist)) (PP (IN for) (NP (DT The) (NNP Associated) (NNP Press)))) (, ,)) (VP (VBZ has) (VP (VBN reported) (PP (IN on) (NP (NP (NNP Washington)) (CC and) (NP (JJ national) (NNS politics)))) (PP (IN for) (NP (QP (JJR more) (IN than) (CD 25)) (NNS years)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="need an answer to" type="VP">
          <tokens>
            <token id="23" string="need" />
            <token id="24" string="an" />
            <token id="25" string="answer" />
            <token id="26" string="to" />
          </tokens>
        </chunking>
        <chunking id="2" string="Walter R. Mears" type="NP">
          <tokens>
            <token id="29" string="Walter" />
            <token id="30" string="R." />
            <token id="31" string="Mears" />
          </tokens>
        </chunking>
        <chunking id="3" string="vice president and columnist" type="NP">
          <tokens>
            <token id="33" string="vice" />
            <token id="34" string="president" />
            <token id="35" string="and" />
            <token id="36" string="columnist" />
          </tokens>
        </chunking>
        <chunking id="4" string="more than 25 years" type="NP">
          <tokens>
            <token id="50" string="more" />
            <token id="51" string="than" />
            <token id="52" string="25" />
            <token id="53" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="vice president and columnist for The Associated Press" type="NP">
          <tokens>
            <token id="33" string="vice" />
            <token id="34" string="president" />
            <token id="35" string="and" />
            <token id="36" string="columnist" />
            <token id="37" string="for" />
            <token id="38" string="The" />
            <token id="39" string="Associated" />
            <token id="40" string="Press" />
          </tokens>
        </chunking>
        <chunking id="6" string="Washington and national politics" type="NP">
          <tokens>
            <token id="45" string="Washington" />
            <token id="46" string="and" />
            <token id="47" string="national" />
            <token id="48" string="politics" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Associated Press" type="NP">
          <tokens>
            <token id="38" string="The" />
            <token id="39" string="Associated" />
            <token id="40" string="Press" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="9" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="something" type="NP">
          <tokens>
            <token id="20" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="the United States" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </chunking>
        <chunking id="11" string="an answer" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="answer" />
          </tokens>
        </chunking>
        <chunking id="12" string="Walter R. Mears , vice president and columnist for The Associated Press ," type="NP">
          <tokens>
            <token id="29" string="Walter" />
            <token id="30" string="R." />
            <token id="31" string="Mears" />
            <token id="32" string="," />
            <token id="33" string="vice" />
            <token id="34" string="president" />
            <token id="35" string="and" />
            <token id="36" string="columnist" />
            <token id="37" string="for" />
            <token id="38" string="The" />
            <token id="39" string="Associated" />
            <token id="40" string="Press" />
            <token id="41" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="Washington" type="NP">
          <tokens>
            <token id="45" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="14" string="the first time" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="first" />
            <token id="7" string="time" />
          </tokens>
        </chunking>
        <chunking id="15" string="let the Supreme Court of the United States decide something that we need an answer to" type="VP">
          <tokens>
            <token id="11" string="let" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
            <token id="19" string="decide" />
            <token id="20" string="something" />
            <token id="21" string="that" />
            <token id="22" string="we" />
            <token id="23" string="need" />
            <token id="24" string="an" />
            <token id="25" string="answer" />
            <token id="26" string="to" />
          </tokens>
        </chunking>
        <chunking id="16" string="that we need an answer to" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="we" />
            <token id="23" string="need" />
            <token id="24" string="an" />
            <token id="25" string="answer" />
            <token id="26" string="to" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Supreme Court" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
          </tokens>
        </chunking>
        <chunking id="18" string="national politics" type="NP">
          <tokens>
            <token id="47" string="national" />
            <token id="48" string="politics" />
          </tokens>
        </chunking>
        <chunking id="19" string="decide something that we need an answer to" type="VP">
          <tokens>
            <token id="19" string="decide" />
            <token id="20" string="something" />
            <token id="21" string="that" />
            <token id="22" string="we" />
            <token id="23" string="need" />
            <token id="24" string="an" />
            <token id="25" string="answer" />
            <token id="26" string="to" />
          </tokens>
        </chunking>
        <chunking id="20" string="will let the Supreme Court of the United States decide something that we need an answer to" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="let" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
            <token id="19" string="decide" />
            <token id="20" string="something" />
            <token id="21" string="that" />
            <token id="22" string="we" />
            <token id="23" string="need" />
            <token id="24" string="an" />
            <token id="25" string="answer" />
            <token id="26" string="to" />
          </tokens>
        </chunking>
        <chunking id="21" string="reported on Washington and national politics for more than 25 years" type="VP">
          <tokens>
            <token id="43" string="reported" />
            <token id="44" string="on" />
            <token id="45" string="Washington" />
            <token id="46" string="and" />
            <token id="47" string="national" />
            <token id="48" string="politics" />
            <token id="49" string="for" />
            <token id="50" string="more" />
            <token id="51" string="than" />
            <token id="52" string="25" />
            <token id="53" string="years" />
          </tokens>
        </chunking>
        <chunking id="22" string="has reported on Washington and national politics for more than 25 years" type="VP">
          <tokens>
            <token id="42" string="has" />
            <token id="43" string="reported" />
            <token id="44" string="on" />
            <token id="45" string="Washington" />
            <token id="46" string="and" />
            <token id="47" string="national" />
            <token id="48" string="politics" />
            <token id="49" string="for" />
            <token id="50" string="more" />
            <token id="51" string="than" />
            <token id="52" string="25" />
            <token id="53" string="years" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Supreme Court of the United States" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="11">let</governor>
          <dependent id="2">Then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">time</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">time</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">time</governor>
          <dependent id="6">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">let</governor>
          <dependent id="7">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">let</governor>
          <dependent id="9">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">let</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">let</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Court</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Court</governor>
          <dependent id="13">Supreme</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">decide</governor>
          <dependent id="14">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">States</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">States</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">States</governor>
          <dependent id="17">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Court</governor>
          <dependent id="18">States</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">let</governor>
          <dependent id="19">decide</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">decide</governor>
          <dependent id="20">something</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">need</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">need</governor>
          <dependent id="22">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">decide</governor>
          <dependent id="23">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">answer</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">need</governor>
          <dependent id="25">answer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">need</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Mears</governor>
          <dependent id="29">Walter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Mears</governor>
          <dependent id="30">R.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">reported</governor>
          <dependent id="31">Mears</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">president</governor>
          <dependent id="33">vice</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="31">Mears</governor>
          <dependent id="34">president</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">president</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">president</governor>
          <dependent id="36">columnist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">Press</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">Press</governor>
          <dependent id="38">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Press</governor>
          <dependent id="39">Associated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">president</governor>
          <dependent id="40">Press</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="43">reported</governor>
          <dependent id="42">has</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">let</governor>
          <dependent id="43">reported</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">Washington</governor>
          <dependent id="44">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">reported</governor>
          <dependent id="45">Washington</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="45">Washington</governor>
          <dependent id="46">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">politics</governor>
          <dependent id="47">national</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">Washington</governor>
          <dependent id="48">politics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">years</governor>
          <dependent id="49">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="52">25</governor>
          <dependent id="50">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="50">more</governor>
          <dependent id="51">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="53">years</governor>
          <dependent id="52">25</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">reported</governor>
          <dependent id="53">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="45" string="Washington" />
          </tokens>
        </entity>
        <entity id="3" string="Walter R. Mears" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Walter" />
            <token id="30" string="R." />
            <token id="31" string="Mears" />
          </tokens>
        </entity>
        <entity id="4" string="more than 25 years" type="DURATION" score="0.0">
          <tokens>
            <token id="50" string="more" />
            <token id="51" string="than" />
            <token id="52" string="25" />
            <token id="53" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="Associated Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="39" string="Associated" />
            <token id="40" string="Press" />
          </tokens>
        </entity>
        <entity id="6" string="Supreme Court of the United States" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Supreme" />
            <token id="14" string="Court" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="United" />
            <token id="18" string="States" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>End Adv PM Thurs July 20</content>
      <tokens>
        <token id="1" string="End" lemma="End" stem="end" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Adv" lemma="Adv" stem="adv" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="PM" lemma="PM" stem="pm" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Thurs" lemma="Thurs" stem="thur" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP End) (NNP Adv)) (NP (NP (NNP PM) (NNP Thurs)) (NP-TMP (NNP July) (CD 20)))))</syntactictree>
      <chunkings>
        <chunking id="1" string="PM Thurs July 20" type="NP">
          <tokens>
            <token id="3" string="PM" />
            <token id="4" string="Thurs" />
            <token id="5" string="July" />
            <token id="6" string="20" />
          </tokens>
        </chunking>
        <chunking id="2" string="PM Thurs" type="NP">
          <tokens>
            <token id="3" string="PM" />
            <token id="4" string="Thurs" />
          </tokens>
        </chunking>
        <chunking id="3" string="End Adv PM Thurs July 20" type="NP">
          <tokens>
            <token id="1" string="End" />
            <token id="2" string="Adv" />
            <token id="3" string="PM" />
            <token id="4" string="Thurs" />
            <token id="5" string="July" />
            <token id="6" string="20" />
          </tokens>
        </chunking>
        <chunking id="4" string="End Adv" type="NP">
          <tokens>
            <token id="1" string="End" />
            <token id="2" string="Adv" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Adv</governor>
          <dependent id="1">End</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Adv</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Thurs</governor>
          <dependent id="3">PM</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Adv</governor>
          <dependent id="4">Thurs</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">Thurs</governor>
          <dependent id="5">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">July</governor>
          <dependent id="6">20</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thurs July 20" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="Thurs" />
            <token id="5" string="July" />
            <token id="6" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="NOMINAL">
      <referenced ids_tokens="4-5" string="the question" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="1-2" string="The Senate" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="4" />
        <mention ids_tokens="6" string="Senate" id_sentence="5" />
        <mention ids_tokens="22" string="it" id_sentence="14" />
        <mention ids_tokens="17" string="it" id_sentence="36" />
        <mention ids_tokens="25" string="it" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="5-6" string="the House" id_sentence="20" />
      <mentions>
        <mention ids_tokens="26" string="House" id_sentence="5" />
        <mention ids_tokens="27" string="House" id_sentence="16" />
        <mention ids_tokens="13" string="House" id_sentence="19" />
        <mention ids_tokens="14" string="House" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="15-16" string="illegal aliens" id_sentence="5" />
      <mentions>
        <mention ids_tokens="6" string="them" id_sentence="6" />
        <mention ids_tokens="21" string="them" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="26-27" string="House seats" id_sentence="5" />
      <mentions>
        <mention ids_tokens="9" string="seats" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="counting illegal aliens" id_sentence="7" />
      <mentions>
        <mention ids_tokens="11" string="them" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="4-5-6" string="the Census Bureau" id_sentence="8" />
      <mentions>
        <mention ids_tokens="24-25" string="Census Bureau" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="27-28" string="clear Congress" id_sentence="14" />
      <mentions>
        <mention ids_tokens="28" string="Congress" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18" string="2.57 million people in the United States" id_sentence="10" />
      <mentions>
        <mention ids_tokens="8" string="them" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="some of them" id_sentence="11" />
      <mentions>
        <mention ids_tokens="8" string="them" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="23-24" string="the Constitution" id_sentence="12" />
      <mentions>
        <mention ids_tokens="3" string="itself" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="2-3" string="Richard Shelby" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1-2" string="Shelby's" id_sentence="18" />
        <mention ids_tokens="5" string="Shelby" id_sentence="33" />
        <mention ids_tokens="1" string="Shelby" id_sentence="37" />
        <mention ids_tokens="10" string="he" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="5" string="D-Ala." id_sentence="15" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="16" />
        <mention ids_tokens="1" string="It" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8" string="Secretary of Commerce Robert Mosbacher" id_sentence="16" />
      <mentions>
        <mention ids_tokens="7-8" string="the secretary" id_sentence="18" />
        <mention ids_tokens="30-31" string="the secretary" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Shelby 's amendment" id_sentence="18" />
      <mentions>
        <mention ids_tokens="3-5" string="the Shelby amendment" id_sentence="21" />
        <mention ids_tokens="6-7" string="the amendment" id_sentence="25" />
        <mention ids_tokens="3-4" string="the amendment" id_sentence="26" />
        <mention ids_tokens="1-2" string="The amendment" id_sentence="36" />
        <mention ids_tokens="3" string="that" id_sentence="37" />
        <mention ids_tokens="7" string="it" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Edward M. Kennedy" id_sentence="21" />
      <mentions>
        <mention ids_tokens="14" string="Kennedy" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14" string="Opponents of the Shelby amendment , led by Sen. Edward M. Kennedy , D-Mass." id_sentence="21" />
      <mentions>
        <mention ids_tokens="1-4" string="Opponents of the amendment" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="The Constitution itself says the apportionment of the House" id_sentence="23" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="11-12" string="both documents" id_sentence="26" />
      <mentions>
        <mention ids_tokens="14-15" string="the documents" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21" string="the people who wrote the documents had no concept of illegal aliens" id_sentence="27" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="5" string="Kansas" id_sentence="29" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="31" />
        <mention ids_tokens="2" string="It" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Sen. Bob Dole of Kansas" id_sentence="29" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="30" />
        <mention ids_tokens="11" string="Dole" id_sentence="31" />
      </mentions>
    </coreference>
  </coreferences>
</document>
