<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890314-0237">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Inside a small motor home, Joanne Pierluissi raised her sleeve as nurse Mary Perez inserted a needle into the vein above her forearm, drawing blood into a tube for a diabetes test.</content>
      <tokens>
        <token id="1" string="Inside" lemma="inside" stem="inside" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="motor" lemma="motor" stem="motor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Joanne" lemma="Joanne" stem="joann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Pierluissi" lemma="Pierluissi" stem="pierluissi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="raised" lemma="raise" stem="rais" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sleeve" lemma="sleeve" stem="sleev" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="nurse" lemma="nurse" stem="nurs" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Perez" lemma="Perez" stem="perez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="inserted" lemma="insert" stem="insert" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="needle" lemma="needle" stem="needl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="vein" lemma="vein" stem="vein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="above" lemma="above" stem="abov" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="forearm" lemma="forearm" stem="forearm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="drawing" lemma="draw" stem="draw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="tube" lemma="tube" stem="tube" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="34" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Inside) (NP (DT a) (JJ small) (NN motor) (NN home))) (, ,) (NP (NNP Joanne) (NNP Pierluissi)) (VP (VBD raised) (NP (PRP$ her) (NN sleeve)) (SBAR (IN as) (S (NP (NN nurse) (NNP Mary) (NNP Perez)) (VP (VBD inserted) (NP (DT a) (NN needle)) (PP (IN into) (NP (NP (DT the) (NN vein)) (PP (IN above) (NP (PRP$ her) (NN forearm))))) (, ,) (S (VP (VBG drawing) (NP (NN blood)) (PP (IN into) (NP (NP (DT a) (NN tube)) (PP (IN for) (NP (DT a) (NN diabetes) (NN test))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a needle" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="needle" />
          </tokens>
        </chunking>
        <chunking id="2" string="the vein" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="vein" />
          </tokens>
        </chunking>
        <chunking id="3" string="her forearm" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="forearm" />
          </tokens>
        </chunking>
        <chunking id="4" string="drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="5" string="raised her sleeve as nurse Mary Perez inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="9" string="raised" />
            <token id="10" string="her" />
            <token id="11" string="sleeve" />
            <token id="12" string="as" />
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="6" string="blood" type="NP">
          <tokens>
            <token id="27" string="blood" />
          </tokens>
        </chunking>
        <chunking id="7" string="inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="8" string="a diabetes test" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="9" string="as nurse Mary Perez inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="SBAR">
          <tokens>
            <token id="12" string="as" />
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="10" string="her sleeve" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="sleeve" />
          </tokens>
        </chunking>
        <chunking id="11" string="a small motor home" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="small" />
            <token id="4" string="motor" />
            <token id="5" string="home" />
          </tokens>
        </chunking>
        <chunking id="12" string="Joanne Pierluissi" type="NP">
          <tokens>
            <token id="7" string="Joanne" />
            <token id="8" string="Pierluissi" />
          </tokens>
        </chunking>
        <chunking id="13" string="a tube for a diabetes test" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="14" string="the vein above her forearm" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
          </tokens>
        </chunking>
        <chunking id="15" string="a tube" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tube" />
          </tokens>
        </chunking>
        <chunking id="16" string="nurse Mary Perez" type="NP">
          <tokens>
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">home</governor>
          <dependent id="1">Inside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">home</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">home</governor>
          <dependent id="3">small</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">home</governor>
          <dependent id="4">motor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">raised</governor>
          <dependent id="5">home</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Pierluissi</governor>
          <dependent id="7">Joanne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">raised</governor>
          <dependent id="8">Pierluissi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">raised</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">sleeve</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">raised</governor>
          <dependent id="11">sleeve</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">inserted</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Perez</governor>
          <dependent id="13">nurse</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Perez</governor>
          <dependent id="14">Mary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">inserted</governor>
          <dependent id="15">Perez</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">raised</governor>
          <dependent id="16">inserted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">needle</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">inserted</governor>
          <dependent id="18">needle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">vein</governor>
          <dependent id="19">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">vein</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">inserted</governor>
          <dependent id="21">vein</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">forearm</governor>
          <dependent id="22">above</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">forearm</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">vein</governor>
          <dependent id="24">forearm</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">inserted</governor>
          <dependent id="26">drawing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">drawing</governor>
          <dependent id="27">blood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">tube</governor>
          <dependent id="28">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">tube</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">drawing</governor>
          <dependent id="30">tube</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">test</governor>
          <dependent id="31">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">test</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">test</governor>
          <dependent id="33">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">tube</governor>
          <dependent id="34">test</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mary Perez" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
          </tokens>
        </entity>
        <entity id="2" string="Joanne Pierluissi" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Joanne" />
            <token id="8" string="Pierluissi" />
          </tokens>
        </entity>
        <entity id="3" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="33" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>As her daughters watched, Pierluissi, 24, said it was for them, as much as for herself, that she agreed to be tested for the deadly killer of Hispanics.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="daughters" lemma="daughter" stem="daughter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="watched" lemma="watch" stem="watch" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Pierluissi" lemma="pierluissi" stem="pierluissi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="herself" lemma="herself" stem="herself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="deadly" lemma="deadly" stem="deadli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (NP (NP (PRP$ her) (NNS daughters)) (VP (VBN watched)))) (, ,) (NP (NP (NN Pierluissi)) (, ,) (NP (CD 24)) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (PP (IN for) (NP (PRP them))) (, ,) (PP (ADVP (RB as) (RB much)) (IN as) (IN for) (NP (PRP herself))) (, ,) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD agreed) (S (VP (TO to) (VP (VB be) (VP (VBN tested) (PP (IN for) (NP (NP (DT the) (JJ deadly) (NN killer)) (PP (IN of) (NP (NNPS Hispanics)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Pierluissi" type="NP">
          <tokens>
            <token id="6" string="Pierluissi" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="8" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="4" string="Pierluissi , 24 ," type="NP">
          <tokens>
            <token id="6" string="Pierluissi" />
            <token id="7" string="," />
            <token id="8" string="24" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="her daughters watched" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="daughters" />
            <token id="4" string="watched" />
          </tokens>
        </chunking>
        <chunking id="6" string="it was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="SBAR">
          <tokens>
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="9" string="the deadly killer" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="14" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="her daughters" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="daughters" />
          </tokens>
        </chunking>
        <chunking id="13" string="watched" type="VP">
          <tokens>
            <token id="4" string="watched" />
          </tokens>
        </chunking>
        <chunking id="14" string="agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="15" string="said it was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="16" string="tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="17" string="the deadly killer of Hispanics" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="18" string="was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="19" string="herself" type="NP">
          <tokens>
            <token id="20" string="herself" />
          </tokens>
        </chunking>
        <chunking id="20" string="that she agreed to be tested for the deadly killer of Hispanics" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="21" string="Hispanics" type="NP">
          <tokens>
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">daughters</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">daughters</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">said</governor>
          <dependent id="3">daughters</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">daughters</governor>
          <dependent id="4">watched</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="6">Pierluissi</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Pierluissi</governor>
          <dependent id="8">24</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">them</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">them</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">them</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="14">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">much</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">herself</governor>
          <dependent id="17">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">herself</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="18">as</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">them</governor>
          <dependent id="20">herself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">agreed</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">agreed</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">them</governor>
          <dependent id="24">agreed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">tested</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">tested</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">agreed</governor>
          <dependent id="27">tested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">killer</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">killer</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">killer</governor>
          <dependent id="30">deadly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">tested</governor>
          <dependent id="31">killer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Hispanics</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">killer</governor>
          <dependent id="33">Hispanics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pierluissi" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Pierluissi" />
          </tokens>
        </entity>
        <entity id="2" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="24" />
          </tokens>
        </entity>
        <entity id="3" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>Twelve million Americans have some form of diabetes, but it most prevalent among minorities, especially Native Americans, blacks and Hispanics.</content>
      <tokens>
        <token id="1" string="Twelve" lemma="twelve" stem="twelv" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="prevalent" lemma="prevalent" stem="preval" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Native" lemma="native" stem="nativ" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (QP (CD Twelve) (CD million)) (NNPS Americans)) (VP (VBP have) (NP (NP (DT some) (NN form)) (PP (IN of) (NP (NN diabetes)))))) (, ,) (CC but) (S (NP (PRP it)) (ADJP (ADJP (RBS most) (JJ prevalent)) (PP (IN among) (NP (NP (NNS minorities)) (, ,) (NP (RB especially) (JJ Native) (NNPS Americans)) (, ,) (NP (NNS blacks)) (CC and) (NP (NNPS Hispanics)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most prevalent" type="ADJP">
          <tokens>
            <token id="12" string="most" />
            <token id="13" string="prevalent" />
          </tokens>
        </chunking>
        <chunking id="2" string="minorities" type="NP">
          <tokens>
            <token id="15" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="3" string="especially Native Americans" type="NP">
          <tokens>
            <token id="17" string="especially" />
            <token id="18" string="Native" />
            <token id="19" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="blacks" type="NP">
          <tokens>
            <token id="21" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="5" string="Twelve million Americans" type="NP">
          <tokens>
            <token id="1" string="Twelve" />
            <token id="2" string="million" />
            <token id="3" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="most prevalent among minorities , especially Native Americans , blacks and Hispanics" type="ADJP">
          <tokens>
            <token id="12" string="most" />
            <token id="13" string="prevalent" />
            <token id="14" string="among" />
            <token id="15" string="minorities" />
            <token id="16" string="," />
            <token id="17" string="especially" />
            <token id="18" string="Native" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="blacks" />
            <token id="22" string="and" />
            <token id="23" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="8" string="have some form of diabetes" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="some" />
            <token id="6" string="form" />
            <token id="7" string="of" />
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="9" string="some form of diabetes" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="form" />
            <token id="7" string="of" />
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="minorities , especially Native Americans , blacks and Hispanics" type="NP">
          <tokens>
            <token id="15" string="minorities" />
            <token id="16" string="," />
            <token id="17" string="especially" />
            <token id="18" string="Native" />
            <token id="19" string="Americans" />
            <token id="20" string="," />
            <token id="21" string="blacks" />
            <token id="22" string="and" />
            <token id="23" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="11" string="some form" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="form" />
          </tokens>
        </chunking>
        <chunking id="12" string="diabetes" type="NP">
          <tokens>
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="Hispanics" type="NP">
          <tokens>
            <token id="23" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">million</governor>
          <dependent id="1">Twelve</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">Americans</governor>
          <dependent id="2">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">form</governor>
          <dependent id="5">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="6">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">diabetes</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">form</governor>
          <dependent id="8">diabetes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">prevalent</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">prevalent</governor>
          <dependent id="12">most</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="13">prevalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">minorities</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">prevalent</governor>
          <dependent id="15">minorities</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">Americans</governor>
          <dependent id="17">especially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">Americans</governor>
          <dependent id="18">Native</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">minorities</governor>
          <dependent id="19">Americans</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">minorities</governor>
          <dependent id="21">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">minorities</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">minorities</governor>
          <dependent id="23">Hispanics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="Native Americans" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Native" />
            <token id="19" string="Americans" />
          </tokens>
        </entity>
        <entity id="3" string="Twelve million" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Twelve" />
            <token id="2" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="diabetes" />
          </tokens>
        </entity>
        <entity id="5" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="23" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Hispanics are three times as likely to develop diabetes as the general population, and 40 percent of the 700,000 victims in Texas are Mexican-American.</content>
      <tokens>
        <token id="1" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="develop" lemma="develop" stem="develop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="17" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="700,000" lemma="700,000" stem="700,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Mexican-American" lemma="mexican-american" stem="mexican-american" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNPS Hispanics)) (VP (VBP are) (ADVP (NP (CD three) (NNS times)) (IN as)) (ADJP (JJ likely) (S (VP (TO to) (VP (VB develop) (NP (NN diabetes)) (PP (IN as) (NP (DT the) (JJ general) (NN population))))))))) (, ,) (CC and) (S (NP (NP (CD 40) (NN percent)) (PP (IN of) (NP (NP (DT the) (CD 700,000) (NNS victims)) (PP (IN in) (NP (NNP Texas)))))) (VP (VBP are) (ADJP (JJ Mexican-American)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are Mexican-American" type="VP">
          <tokens>
            <token id="24" string="are" />
            <token id="25" string="Mexican-American" />
          </tokens>
        </chunking>
        <chunking id="2" string="three times" type="NP">
          <tokens>
            <token id="3" string="three" />
            <token id="4" string="times" />
          </tokens>
        </chunking>
        <chunking id="3" string="40 percent of the 700,000 victims in Texas" type="NP">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
            <token id="22" string="in" />
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="4" string="are three times as likely to develop diabetes as the general population" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="three" />
            <token id="4" string="times" />
            <token id="5" string="as" />
            <token id="6" string="likely" />
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="5" string="40 percent" type="NP">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 700,000 victims in Texas" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
            <token id="22" string="in" />
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="7" string="likely to develop diabetes as the general population" type="ADJP">
          <tokens>
            <token id="6" string="likely" />
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 700,000 victims" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="9" string="develop diabetes as the general population" type="VP">
          <tokens>
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="10" string="Texas" type="NP">
          <tokens>
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="11" string="the general population" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="to develop diabetes as the general population" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes" type="NP">
          <tokens>
            <token id="9" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="Hispanics" type="NP">
          <tokens>
            <token id="1" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mexican-American" type="ADJP">
          <tokens>
            <token id="25" string="Mexican-American" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">likely</governor>
          <dependent id="1">Hispanics</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">likely</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">times</governor>
          <dependent id="3">three</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">likely</governor>
          <dependent id="4">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">times</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">develop</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">likely</governor>
          <dependent id="8">develop</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">develop</governor>
          <dependent id="9">diabetes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">population</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">population</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">population</governor>
          <dependent id="12">general</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">develop</governor>
          <dependent id="13">population</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">likely</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">percent</governor>
          <dependent id="16">40</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">Mexican-American</governor>
          <dependent id="17">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">victims</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">victims</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">victims</governor>
          <dependent id="20">700,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">percent</governor>
          <dependent id="21">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Texas</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">victims</governor>
          <dependent id="23">Texas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">Mexican-American</governor>
          <dependent id="24">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">likely</governor>
          <dependent id="25">Mexican-American</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="700,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="700,000" />
          </tokens>
        </entity>
        <entity id="2" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Texas" />
          </tokens>
        </entity>
        <entity id="3" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="diabetes" />
          </tokens>
        </entity>
        <entity id="4" string="40 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="three" />
          </tokens>
        </entity>
        <entity id="6" string="Mexican-American" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="Mexican-American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>More than 150,000 Americans die from diabetes each year; another 150,000 deaths are diabetes-related, according to the American Diabetes Association.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="150,000" lemma="150,000" stem="150,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="8" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="true" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="10" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="150,000" lemma="150,000" stem="150,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="diabetes-related" lemma="diabetes-related" stem="diabetes-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Diabetes" lemma="Diabetes" stem="diabet" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 150,000)) (NNPS Americans)) (VP (VB die) (PP (IN from) (NP (NP (NP (NN diabetes)) (NP (DT each) (NN year))) (: ;) (S (NP (DT another) (CD 150,000) (NNS deaths)) (VP (VBP are) (ADJP (JJ diabetes-related)) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (JJ American) (NNP Diabetes) (NNP Association))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the American Diabetes Association" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="2" string="More than 150,000 Americans" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="150,000" />
            <token id="4" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="3" string="diabetes each year" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="each year" type="NP">
          <tokens>
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
            <token id="10" string=";" />
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="6" string="another 150,000 deaths" type="NP">
          <tokens>
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="7" string="die from diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" type="VP">
          <tokens>
            <token id="5" string="die" />
            <token id="6" string="from" />
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
            <token id="10" string=";" />
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="8" string="are diabetes-related , according to the American Diabetes Association" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="9" string="diabetes" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="diabetes-related" type="ADJP">
          <tokens>
            <token id="15" string="diabetes-related" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">150,000</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">Americans</governor>
          <dependent id="3">150,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">die</governor>
          <dependent id="4">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">die</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">diabetes</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">die</governor>
          <dependent id="7">diabetes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">year</governor>
          <dependent id="8">each</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">diabetes</governor>
          <dependent id="9">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">deaths</governor>
          <dependent id="11">another</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">deaths</governor>
          <dependent id="12">150,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">diabetes-related</governor>
          <dependent id="13">deaths</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">diabetes-related</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">diabetes</governor>
          <dependent id="15">diabetes-related</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Association</governor>
          <dependent id="17">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">according</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Association</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Association</governor>
          <dependent id="20">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Association</governor>
          <dependent id="21">Diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">diabetes-related</governor>
          <dependent id="22">Association</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="150,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="150,000" />
          </tokens>
        </entity>
        <entity id="2" string="each year" type="SET" score="0.0">
          <tokens>
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Americans" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="diabetes" />
          </tokens>
        </entity>
        <entity id="5" string="American Diabetes Association" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>No one really knows what sparks it, but researchers believe Hispanics could hold the key.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sparks" lemma="spark" stem="spark" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="hold" lemma="hold" stem="hold" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="key" lemma="key" stem="kei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT No) (NN one)) (ADVP (RB really)) (VP (VBZ knows) (SBAR (WHNP (WP what)) (S (VP (VBZ sparks) (NP (PRP it))))))) (, ,) (CC but) (S (NP (NNS researchers)) (VP (VBP believe) (SBAR (S (NP (NNPS Hispanics)) (VP (MD could) (VP (VB hold) (NP (DT the) (NN key)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hispanics could hold the key" type="SBAR">
          <tokens>
            <token id="12" string="Hispanics" />
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="3" string="believe Hispanics could hold the key" type="VP">
          <tokens>
            <token id="11" string="believe" />
            <token id="12" string="Hispanics" />
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="4" string="could hold the key" type="VP">
          <tokens>
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="5" string="researchers" type="NP">
          <tokens>
            <token id="10" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="6" string="hold the key" type="VP">
          <tokens>
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="7" string="the key" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="8" string="knows what sparks it" type="VP">
          <tokens>
            <token id="4" string="knows" />
            <token id="5" string="what" />
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="what sparks it" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="sparks it" type="VP">
          <tokens>
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="Hispanics" type="NP">
          <tokens>
            <token id="12" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">knows</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">knows</governor>
          <dependent id="3">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sparks</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">knows</governor>
          <dependent id="6">sparks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">sparks</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">knows</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">believe</governor>
          <dependent id="10">researchers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">knows</governor>
          <dependent id="11">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">hold</governor>
          <dependent id="12">Hispanics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">hold</governor>
          <dependent id="13">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">believe</governor>
          <dependent id="14">hold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">key</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">hold</governor>
          <dependent id="16">key</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>San Antonio, the nation&amp;apost;s ninth largest city, with a population that is 50 percent Hispanic, is becoming the base for diabetes studies.</content>
      <tokens>
        <token id="1" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Antonio" lemma="Antonio" stem="antonio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ninth" lemma="ninth" stem="ninth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="17" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="18" string="Hispanic" lemma="Hispanic" stem="hispan" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="becoming" lemma="become" stem="becom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="base" lemma="base" stem="base" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="26" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP San) (NNP Antonio)) (, ,) (NP (NP (NP (DT the) (NN nation) (POS 's)) (JJ ninth) (JJS largest) (NN city)) (, ,) (PP (IN with) (NP (NP (DT a) (NN population)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (CD 50) (NN percent)) (ADJP (NNP Hispanic))))))))) (, ,)) (VP (VBZ is) (VP (VBG becoming) (NP (NP (DT the) (NN base)) (PP (IN for) (NP (NN diabetes) (NNS studies)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="San Antonio" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </chunking>
        <chunking id="2" string="a population" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="3" string="San Antonio , the nation 's ninth largest city , with a population that is 50 percent Hispanic ," type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="the base" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="base" />
          </tokens>
        </chunking>
        <chunking id="5" string="50 percent" type="NP">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="is becoming the base for diabetes studies" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="becoming" />
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="7" string="becoming the base for diabetes studies" type="VP">
          <tokens>
            <token id="21" string="becoming" />
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="8" string="is 50 percent Hispanic" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="9" string="the base for diabetes studies" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="10" string="the nation 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a population that is 50 percent Hispanic" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="12" string="50 percent Hispanic" type="NP">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes studies" type="NP">
          <tokens>
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="14" string="the nation 's ninth largest city" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
          </tokens>
        </chunking>
        <chunking id="15" string="that is 50 percent Hispanic" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="16" string="Hispanic" type="ADJP">
          <tokens>
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="17" string="the nation 's ninth largest city , with a population that is 50 percent Hispanic" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Antonio</governor>
          <dependent id="1">San</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">becoming</governor>
          <dependent id="2">Antonio</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">nation</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">city</governor>
          <dependent id="5">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">nation</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">city</governor>
          <dependent id="7">ninth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">city</governor>
          <dependent id="8">largest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Antonio</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">population</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">population</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">city</governor>
          <dependent id="13">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">percent</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">percent</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">percent</governor>
          <dependent id="16">50</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">population</governor>
          <dependent id="17">percent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">percent</governor>
          <dependent id="18">Hispanic</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">becoming</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">becoming</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">base</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">becoming</governor>
          <dependent id="23">base</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">studies</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">studies</governor>
          <dependent id="25">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">base</governor>
          <dependent id="26">studies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="San Antonio" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </entity>
        <entity id="2" string="50 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
          </tokens>
        </entity>
        <entity id="3" string="ninth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="ninth" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="25" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>San Antonio&amp;apost;s Hispanic makeup led Dr. Ralph DeFronzo to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center.</content>
      <tokens>
        <token id="1" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="Antonio" lemma="Antonio" stem="antonio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="5" string="makeup" lemma="makeup" stem="makeup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Ralph" lemma="Ralph" stem="ralph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="abandon" lemma="abandon" stem="abandon" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="prestigious" lemma="prestigious" stem="prestigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="diabetes" lemma="diabetes" stem="diabet" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="20" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="persuade" lemma="persuade" stem="persuad" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="four-member" lemma="four-member" stem="four-memb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="relocate" lemma="relocate" stem="reloc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Health" lemma="Health" stem="health" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="Science" lemma="Science" stem="scienc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP San) (NNP Antonio) (POS 's)) (JJ Hispanic) (NN makeup)) (VP (VBD led) (S (NP (NNP Dr.) (NNP Ralph) (NNP DeFronzo)) (VP (TO to) (VP (VP (VB abandon) (NP (PRP$ his) (JJ prestigious) (NN position)) (PP (IN as) (NP (DT a) (NNP Yale) (NNP University) (NNP diabetes) (NN researcher)))) (CC and) (VP (VB persuade) (NP (PRP$ his) (JJ four-member) (NN team)) (S (VP (TO to) (VP (VB relocate) (PP (TO to) (NP (NP (DT the) (NNP University)) (PP (IN of) (NP (NNP Texas) (NNP Health) (NNP Science) (NNP Center))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abandon his prestigious position as a Yale University diabetes researcher" type="VP">
          <tokens>
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="2" string="relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="3" string="his prestigious position" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dr. Ralph DeFronzo" type="NP">
          <tokens>
            <token id="7" string="Dr." />
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="5" string="abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="6" string="a Yale University diabetes researcher" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="7" string="San Antonio 's" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="led Dr. Ralph DeFronzo to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="6" string="led" />
            <token id="7" string="Dr." />
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
            <token id="10" string="to" />
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="9" string="San Antonio 's Hispanic makeup" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="'s" />
            <token id="4" string="Hispanic" />
            <token id="5" string="makeup" />
          </tokens>
        </chunking>
        <chunking id="10" string="to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="11" string="Texas Health Science Center" type="NP">
          <tokens>
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="12" string="to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="13" string="his four-member team" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
          </tokens>
        </chunking>
        <chunking id="14" string="persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="15" string="the University" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="University" />
          </tokens>
        </chunking>
        <chunking id="16" string="the University of Texas Health Science Center" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Antonio</governor>
          <dependent id="1">San</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">makeup</governor>
          <dependent id="2">Antonio</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Antonio</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">makeup</governor>
          <dependent id="4">Hispanic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">led</governor>
          <dependent id="5">makeup</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">led</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">DeFronzo</governor>
          <dependent id="7">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">DeFronzo</governor>
          <dependent id="8">Ralph</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">led</governor>
          <dependent id="9">DeFronzo</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">abandon</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">led</governor>
          <dependent id="11">abandon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">position</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">position</governor>
          <dependent id="13">prestigious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">abandon</governor>
          <dependent id="14">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">researcher</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">researcher</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="17">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="18">University</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="19">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">abandon</governor>
          <dependent id="20">researcher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">abandon</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">abandon</governor>
          <dependent id="22">persuade</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">team</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">team</governor>
          <dependent id="24">four-member</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">persuade</governor>
          <dependent id="25">team</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">relocate</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">persuade</governor>
          <dependent id="27">relocate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">University</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">University</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">relocate</governor>
          <dependent id="30">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Center</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="32">Texas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="33">Health</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="34">Science</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">University</governor>
          <dependent id="35">Center</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="San Antonio" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </entity>
        <entity id="2" string="Yale University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Yale" />
            <token id="18" string="University" />
          </tokens>
        </entity>
        <entity id="3" string="University of Texas Health Science Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </entity>
        <entity id="4" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Hispanic" />
          </tokens>
        </entity>
        <entity id="5" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="diabetes" />
          </tokens>
        </entity>
        <entity id="6" string="Ralph DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Epidemiologist Dr. Michael Stern has devoted 10 years to studying Hispanic diabetes and led the grassroots study of the most common form, which develops mostly in obese adults over 40 who may have a family history of the disease.</content>
      <tokens>
        <token id="1" string="Epidemiologist" lemma="Epidemiologist" stem="epidemiologist" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="devoted" lemma="devote" stem="devot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="studying" lemma="study" stem="studi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="grassroots" lemma="grassroot" stem="grassroot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="develops" lemma="develop" stem="develop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="mostly" lemma="mostly" stem="mostli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="obese" lemma="obese" stem="obes" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="adults" lemma="adult" stem="adult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Epidemiologist) (NNP Dr.) (NNP Michael) (NNP Stern)) (VP (VP (VBZ has) (VP (VBN devoted) (NP (CD 10) (NNS years)) (PP (TO to) (S (VP (VBG studying) (NP (JJ Hispanic) (NN diabetes))))))) (CC and) (VP (VBD led) (NP (NP (DT the) (NNS grassroots) (NN study)) (PP (IN of) (NP (NP (DT the) (ADJP (RBS most) (JJ common)) (NN form)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ develops) (ADVP (RB mostly)) (PP (IN in) (NP (NP (JJ obese) (NNS adults)) (PP (IN over) (NP (CD 40))) (SBAR (WHNP (WP who)) (S (VP (MD may) (VP (VB have) (NP (NP (DT a) (NN family) (NN history)) (PP (IN of) (NP (DT the) (NN disease)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most common" type="ADJP">
          <tokens>
            <token id="20" string="most" />
            <token id="21" string="common" />
          </tokens>
        </chunking>
        <chunking id="2" string="who may have a family history of the disease" type="SBAR">
          <tokens>
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="10 years" type="NP">
          <tokens>
            <token id="7" string="10" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most common form , which develops mostly in obese adults over 40 who may have a family history of the disease" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="common" />
            <token id="22" string="form" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="the disease" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="6" string="devoted 10 years to studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="6" string="devoted" />
            <token id="7" string="10" />
            <token id="8" string="years" />
            <token id="9" string="to" />
            <token id="10" string="studying" />
            <token id="11" string="Hispanic" />
            <token id="12" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="7" string="obese adults" type="NP">
          <tokens>
            <token id="28" string="obese" />
            <token id="29" string="adults" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hispanic diabetes" type="NP">
          <tokens>
            <token id="11" string="Hispanic" />
            <token id="12" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="9" string="led the grassroots study of the most common form , which develops mostly in obese adults over 40 who may have a family history of the disease" type="VP">
          <tokens>
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="grassroots" />
            <token id="17" string="study" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="common" />
            <token id="22" string="form" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="which develops mostly in obese adults over 40 who may have a family history of the disease" type="SBAR">
          <tokens>
            <token id="24" string="which" />
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="develops mostly in obese adults over 40 who may have a family history of the disease" type="VP">
          <tokens>
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="a family history" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
          </tokens>
        </chunking>
        <chunking id="13" string="the grassroots study" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="grassroots" />
            <token id="17" string="study" />
          </tokens>
        </chunking>
        <chunking id="14" string="the most common form" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="common" />
            <token id="22" string="form" />
          </tokens>
        </chunking>
        <chunking id="15" string="Epidemiologist Dr. Michael Stern" type="NP">
          <tokens>
            <token id="1" string="Epidemiologist" />
            <token id="2" string="Dr." />
            <token id="3" string="Michael" />
            <token id="4" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="16" string="has devoted 10 years to studying Hispanic diabetes and led the grassroots study of the most common form , which develops mostly in obese adults over 40 who may have a family history of the disease" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="devoted" />
            <token id="7" string="10" />
            <token id="8" string="years" />
            <token id="9" string="to" />
            <token id="10" string="studying" />
            <token id="11" string="Hispanic" />
            <token id="12" string="diabetes" />
            <token id="13" string="and" />
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="grassroots" />
            <token id="17" string="study" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="common" />
            <token id="22" string="form" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="17" string="the grassroots study of the most common form , which develops mostly in obese adults over 40 who may have a family history of the disease" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="grassroots" />
            <token id="17" string="study" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="common" />
            <token id="22" string="form" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="develops" />
            <token id="26" string="mostly" />
            <token id="27" string="in" />
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="18" string="a family history of the disease" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="19" string="studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="10" string="studying" />
            <token id="11" string="Hispanic" />
            <token id="12" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="20" string="40" type="NP">
          <tokens>
            <token id="31" string="40" />
          </tokens>
        </chunking>
        <chunking id="21" string="have a family history of the disease" type="VP">
          <tokens>
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="22" string="has devoted 10 years to studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="devoted" />
            <token id="7" string="10" />
            <token id="8" string="years" />
            <token id="9" string="to" />
            <token id="10" string="studying" />
            <token id="11" string="Hispanic" />
            <token id="12" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="23" string="may have a family history of the disease" type="VP">
          <tokens>
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
        <chunking id="24" string="obese adults over 40 who may have a family history of the disease" type="NP">
          <tokens>
            <token id="28" string="obese" />
            <token id="29" string="adults" />
            <token id="30" string="over" />
            <token id="31" string="40" />
            <token id="32" string="who" />
            <token id="33" string="may" />
            <token id="34" string="have" />
            <token id="35" string="a" />
            <token id="36" string="family" />
            <token id="37" string="history" />
            <token id="38" string="of" />
            <token id="39" string="the" />
            <token id="40" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Stern</governor>
          <dependent id="1">Epidemiologist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Stern</governor>
          <dependent id="2">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Stern</governor>
          <dependent id="3">Michael</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">devoted</governor>
          <dependent id="4">Stern</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">devoted</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">devoted</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">years</governor>
          <dependent id="7">10</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">devoted</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">studying</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">devoted</governor>
          <dependent id="10">studying</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">diabetes</governor>
          <dependent id="11">Hispanic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">studying</governor>
          <dependent id="12">diabetes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">devoted</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">devoted</governor>
          <dependent id="14">led</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">study</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">study</governor>
          <dependent id="16">grassroots</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">led</governor>
          <dependent id="17">study</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">form</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">form</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">common</governor>
          <dependent id="20">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">form</governor>
          <dependent id="21">common</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">study</governor>
          <dependent id="22">form</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">develops</governor>
          <dependent id="24">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">form</governor>
          <dependent id="25">develops</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">develops</governor>
          <dependent id="26">mostly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">adults</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">adults</governor>
          <dependent id="28">obese</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">develops</governor>
          <dependent id="29">adults</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">40</governor>
          <dependent id="30">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">adults</governor>
          <dependent id="31">40</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">have</governor>
          <dependent id="32">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">have</governor>
          <dependent id="33">may</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">adults</governor>
          <dependent id="34">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">history</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">history</governor>
          <dependent id="36">family</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">have</governor>
          <dependent id="37">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">disease</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">disease</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">history</governor>
          <dependent id="40">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Michael" />
            <token id="4" string="Stern" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="40" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="40" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="40" />
          </tokens>
        </entity>
        <entity id="4" string="10 years" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="10" />
            <token id="8" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Hispanic" />
          </tokens>
        </entity>
        <entity id="6" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="12" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Stern said family studies of diabetic patients are brining him closer to finding the gene that triggers the disease, and to a screening test.</content>
      <tokens>
        <token id="1" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="diabetic" lemma="diabetic" stem="diabet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="brining" lemma="brine" stem="brine" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="closer" lemma="closer" stem="closer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="gene" lemma="gene" stem="gene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="triggers" lemma="trigger" stem="trigger" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="screening" lemma="screening" stem="screen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Stern)) (VP (VBD said) (SBAR (S (NP (NP (NN family) (NNS studies)) (PP (IN of) (NP (JJ diabetic) (NNS patients)))) (VP (VBP are) (VP (VBG brining) (S (NP (PRP him)) (ADJP (JJR closer) (PP (PP (TO to) (S (VP (VBG finding) (NP (NP (DT the) (NN gene)) (SBAR (WHNP (WDT that)) (S (VP (VBZ triggers) (NP (DT the) (NN disease))))))))) (, ,) (CC and) (PP (TO to) (NP (DT a) (JJ screening) (NN test))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="family studies" type="NP">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
          </tokens>
        </chunking>
        <chunking id="2" string="a screening test" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="3" string="are brining him closer to finding the gene that triggers the disease , and to a screening test" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="4" string="brining him closer to finding the gene that triggers the disease , and to a screening test" type="VP">
          <tokens>
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="diabetic patients" type="NP">
          <tokens>
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
          </tokens>
        </chunking>
        <chunking id="7" string="closer to finding the gene that triggers the disease , and to a screening test" type="ADJP">
          <tokens>
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="8" string="said family studies of diabetic patients are brining him closer to finding the gene that triggers the disease , and to a screening test" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="triggers the disease" type="VP">
          <tokens>
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="Stern" type="NP">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="12" string="family studies of diabetic patients" type="NP">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
          </tokens>
        </chunking>
        <chunking id="13" string="the gene that triggers the disease" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="14" string="that triggers the disease" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="15" string="finding the gene that triggers the disease" type="VP">
          <tokens>
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="16" string="family studies of diabetic patients are brining him closer to finding the gene that triggers the disease , and to a screening test" type="SBAR">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="screening" />
            <token id="25" string="test" />
          </tokens>
        </chunking>
        <chunking id="17" string="the gene" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="gene" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Stern</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">studies</governor>
          <dependent id="3">family</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">brining</governor>
          <dependent id="4">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">patients</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">patients</governor>
          <dependent id="6">diabetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">studies</governor>
          <dependent id="7">patients</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">brining</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="9">brining</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">closer</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">brining</governor>
          <dependent id="11">closer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">finding</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">closer</governor>
          <dependent id="13">finding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">gene</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">finding</governor>
          <dependent id="15">gene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">triggers</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">gene</governor>
          <dependent id="17">triggers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">disease</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">triggers</governor>
          <dependent id="19">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">finding</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">test</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">test</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">test</governor>
          <dependent id="24">screening</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">finding</governor>
          <dependent id="25">test</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Researchers believe that poor Hispanics&amp;apost; diets of cheap, processed foods, lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes.</content>
      <tokens>
        <token id="1" string="Researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="diets" lemma="diet" stem="diet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cheap" lemma="cheap" stem="cheap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="processed" lemma="process" stem="process" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="foods" lemma="food" stem="food" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="exercise" lemma="exercise" stem="exercis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="infrequent" lemma="infrequent" stem="infrequ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="due" lemma="due" stem="due" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="cultural" lemma="cultural" stem="cultur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="bias" lemma="bias" stem="bia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="increases" lemma="increase" stem="increas" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="acquiring" lemma="acquire" stem="acquir" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Researchers)) (VP (VBP believe) (SBAR (IN that) (S (NP (NP (NP (JJ poor) (NNPS Hispanics) (POS ')) (NNS diets)) (PP (IN of) (NP (NP (ADJP (JJ cheap) (, ,) (VBN processed)) (NNS foods)) (, ,) (NP (NP (NN lack)) (PP (IN of) (NP (NP (NP (UCP (NP (NN exercise)) (CC and) (ADJP (JJ infrequent))) (JJ medical) (NN attention) (NN _)) (PP (CC either) (NP (ADJP (JJ due) (PP (TO to))) (NN poverty)))) (CC or) (NP (NP (DT a) (JJ cultural) (NN bias)) (PP (IN against) (NP (NNS doctors)))))))))) (VP (VBP _) (S (NP (NNS increases)) (NP (NP (PRP$ their) (NN risk)) (PP (IN of) (S (VP (VBG acquiring) (NP (NN diabetes))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="due to" type="ADJP">
          <tokens>
            <token id="23" string="due" />
            <token id="24" string="to" />
          </tokens>
        </chunking>
        <chunking id="2" string="lack" type="NP">
          <tokens>
            <token id="14" string="lack" />
          </tokens>
        </chunking>
        <chunking id="3" string="doctors" type="NP">
          <tokens>
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="4" string="Researchers" type="NP">
          <tokens>
            <token id="1" string="Researchers" />
          </tokens>
        </chunking>
        <chunking id="5" string="cheap , processed foods" type="NP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
          </tokens>
        </chunking>
        <chunking id="6" string="poor Hispanics ' diets" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
          </tokens>
        </chunking>
        <chunking id="7" string="that poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="8" string="diabetes" type="NP">
          <tokens>
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="9" string="infrequent" type="ADJP">
          <tokens>
            <token id="18" string="infrequent" />
          </tokens>
        </chunking>
        <chunking id="10" string="a cultural bias against doctors" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="11" string="their risk of acquiring diabetes" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="12" string="believe that poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes" type="VP">
          <tokens>
            <token id="2" string="believe" />
            <token id="3" string="that" />
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="exercise and infrequent medical attention _" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
          </tokens>
        </chunking>
        <chunking id="14" string="acquiring diabetes" type="VP">
          <tokens>
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="15" string="exercise" type="NP">
          <tokens>
            <token id="16" string="exercise" />
          </tokens>
        </chunking>
        <chunking id="16" string="cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="17" string="exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="18" string="lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="19" string="exercise and infrequent medical attention _ either due to poverty" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="20" string="their risk" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="risk" />
          </tokens>
        </chunking>
        <chunking id="21" string="poor Hispanics '" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="increases" type="NP">
          <tokens>
            <token id="33" string="increases" />
          </tokens>
        </chunking>
        <chunking id="23" string="due to poverty" type="NP">
          <tokens>
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="24" string="a cultural bias" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
          </tokens>
        </chunking>
        <chunking id="25" string="poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="26" string="cheap , processed" type="ADJP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
          </tokens>
        </chunking>
        <chunking id="27" string="_ increases their risk of acquiring diabetes" type="VP">
          <tokens>
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">believe</governor>
          <dependent id="1">Researchers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">_</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Hispanics</governor>
          <dependent id="4">poor</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">diets</governor>
          <dependent id="5">Hispanics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Hispanics</governor>
          <dependent id="6">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">_</governor>
          <dependent id="7">diets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">foods</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">processed</governor>
          <dependent id="9">cheap</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">foods</governor>
          <dependent id="11">processed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">diets</governor>
          <dependent id="12">foods</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">foods</governor>
          <dependent id="14">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">_</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">_</governor>
          <dependent id="16">exercise</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">exercise</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">exercise</governor>
          <dependent id="18">infrequent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">_</governor>
          <dependent id="19">medical</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">_</governor>
          <dependent id="20">attention</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">lack</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">poverty</governor>
          <dependent id="22">either</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">poverty</governor>
          <dependent id="23">due</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">due</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">_</governor>
          <dependent id="25">poverty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">_</governor>
          <dependent id="26">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">bias</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">bias</governor>
          <dependent id="28">cultural</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">_</governor>
          <dependent id="29">bias</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">doctors</governor>
          <dependent id="30">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">bias</governor>
          <dependent id="31">doctors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">believe</governor>
          <dependent id="32">_</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">risk</governor>
          <dependent id="33">increases</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">risk</governor>
          <dependent id="34">their</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">_</governor>
          <dependent id="35">risk</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">acquiring</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">risk</governor>
          <dependent id="37">acquiring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">acquiring</governor>
          <dependent id="38">diabetes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="38" string="diabetes" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Educating elementary-school-age children about healthy diets would help reduce the number of diabetes cases, DeFronzo said.</content>
      <tokens>
        <token id="1" string="Educating" lemma="educate" stem="educat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="elementary-school-age" lemma="elementary-school-age" stem="elementary-school-ag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="healthy" lemma="healthy" stem="healthi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="diets" lemma="diet" stem="diet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="reduce" lemma="reduce" stem="reduc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBG Educating) (NP (JJ elementary-school-age) (NNS children)) (PP (IN about) (NP (JJ healthy) (NNS diets))))) (VP (MD would) (VP (VB help) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN diabetes) (NNS cases)))))))) (, ,) (NP (NNP DeFronzo)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="diabetes cases" type="NP">
          <tokens>
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="DeFronzo" type="NP">
          <tokens>
            <token id="16" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="3" string="reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="the number of diabetes cases" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="elementary-school-age children" type="NP">
          <tokens>
            <token id="2" string="elementary-school-age" />
            <token id="3" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="would help reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="help" />
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="7" string="healthy diets" type="NP">
          <tokens>
            <token id="5" string="healthy" />
            <token id="6" string="diets" />
          </tokens>
        </chunking>
        <chunking id="8" string="help reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="8" string="help" />
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="9" string="the number" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="number" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="Educating elementary-school-age children about healthy diets" type="VP">
          <tokens>
            <token id="1" string="Educating" />
            <token id="2" string="elementary-school-age" />
            <token id="3" string="children" />
            <token id="4" string="about" />
            <token id="5" string="healthy" />
            <token id="6" string="diets" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="8">help</governor>
          <dependent id="1">Educating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">children</governor>
          <dependent id="2">elementary-school-age</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Educating</governor>
          <dependent id="3">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">diets</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">diets</governor>
          <dependent id="5">healthy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Educating</governor>
          <dependent id="6">diets</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">help</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="8">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">help</governor>
          <dependent id="9">reduce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">number</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">reduce</governor>
          <dependent id="11">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cases</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">cases</governor>
          <dependent id="13">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">number</governor>
          <dependent id="14">cases</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">DeFronzo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="DeFronzo" />
          </tokens>
        </entity>
        <entity id="2" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``If you have a 65-year-old mother who weighs 220 pounds and you tell her to go out and jog five miles Monday, Wednesday and Friday, she is going to laugh at you.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="65-year-old" lemma="65-year-old" stem="65-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="7" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="weighs" lemma="weigh" stem="weigh" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="220" lemma="220" stem="220" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="jog" lemma="jog" stem="jog" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="laugh" lemma="laugh" stem="laugh" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (S (NP (PRP you)) (VP (VBP have) (NP (NP (DT a) (JJ 65-year-old) (NN mother)) (SBAR (WHNP (WP who)) (S (VP (VBZ weighs) (NP (CD 220) (NNS pounds)))))))) (CC and) (S (NP (PRP you)) (VP (VBP tell) (S (NP (PRP her)) (VP (TO to) (VP (VP (VB go) (PRT (RP out))) (CC and) (VP (VB jog) (NP (CD five) (NNS miles))) (NP (NNP Monday) (, ,) (NNP Wednesday) (CC and) (NNP Friday))))))))) (, ,) (NP (PRP she)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (NN laugh) (PP (IN at) (NP (PRP you)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="If you have a 65-year-old mother who weighs 220 pounds and you tell her to go out and jog five miles Monday , Wednesday and Friday" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="have" />
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
            <token id="12" string="and" />
            <token id="13" string="you" />
            <token id="14" string="tell" />
            <token id="15" string="her" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell her to go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="14" string="tell" />
            <token id="15" string="her" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="who weighs 220 pounds" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="a 65-year-old mother who weighs 220 pounds" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="five miles" type="NP">
          <tokens>
            <token id="21" string="five" />
            <token id="22" string="miles" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="29" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to laugh at you" type="VP">
          <tokens>
            <token id="31" string="going" />
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="8" string="220 pounds" type="NP">
          <tokens>
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="9" string="to laugh at you" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="15" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="12" string="Monday , Wednesday and Friday" type="NP">
          <tokens>
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="13" string="have a 65-year-old mother who weighs 220 pounds" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="14" string="to go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="15" string="go out" type="VP">
          <tokens>
            <token id="17" string="go" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="16" string="is going to laugh at you" type="VP">
          <tokens>
            <token id="30" string="is" />
            <token id="31" string="going" />
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="17" string="jog five miles" type="VP">
          <tokens>
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
          </tokens>
        </chunking>
        <chunking id="18" string="weighs 220 pounds" type="VP">
          <tokens>
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="19" string="laugh at you" type="VP">
          <tokens>
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="20" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="21" string="a 65-year-old mother" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">have</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">going</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">mother</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">mother</governor>
          <dependent id="6">65-year-old</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="7">mother</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">weighs</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">mother</governor>
          <dependent id="9">weighs</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">pounds</governor>
          <dependent id="10">220</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">weighs</governor>
          <dependent id="11">pounds</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">tell</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="14">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">tell</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">go</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">tell</governor>
          <dependent id="17">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">go</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">go</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">go</governor>
          <dependent id="20">jog</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">miles</governor>
          <dependent id="21">five</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">jog</governor>
          <dependent id="22">miles</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">go</governor>
          <dependent id="23">Monday</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Monday</governor>
          <dependent id="25">Wednesday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Monday</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Monday</governor>
          <dependent id="27">Friday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">going</governor>
          <dependent id="29">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">going</governor>
          <dependent id="30">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">laugh</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">going</governor>
          <dependent id="33">laugh</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">you</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">laugh</governor>
          <dependent id="35">you</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday , Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="65-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="65-year-old" />
          </tokens>
        </entity>
        <entity id="4" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="five" />
          </tokens>
        </entity>
        <entity id="5" string="220" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="220" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Aly El-Shiekh envisions astronauts on a three-year trip to Mars ``knitting&amp;apost;&amp;apost; themselves a space station using ceramic fibers that can be braided into panels, beams, boxes and practically any other shape.</content>
      <tokens>
        <token id="1" string="Aly" lemma="aly" stem="aly" pos="RB" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="envisions" lemma="envision" stem="envis" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="astronauts" lemma="astronaut" stem="astronaut" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="three-year" lemma="three-year" stem="three-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Mars" lemma="Mars" stem="mar" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="knitting" lemma="knit" stem="knit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="braided" lemma="braid" stem="braid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="panels" lemma="panel" stem="panel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="beams" lemma="beam" stem="beam" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="boxes" lemma="box" stem="box" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="practically" lemma="practically" stem="practic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="shape" lemma="shape" stem="shape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Aly)) (NP (NNP El-Shiekh)) (VP (VBZ envisions) (NP (NNS astronauts)) (PP (IN on) (S (NP (NP (DT a) (JJ three-year) (NN trip)) (PP (TO to) (NP (NNP Mars)))) (VP (`` ``) (VBG knitting) ('' '') (NP (NP (ADVP (PRP themselves)) (DT a) (NN space) (NN station)) (VP (VBG using) (NP (NP (JJ ceramic) (NNS fibers)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN braided) (PP (IN into) (NP (NP (NNS panels)) (, ,) (NP (NNS beams)) (, ,) (NP (NNS boxes)) (CC and) (NP (RB practically) (DT any) (JJ other) (NN shape)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ceramic fibers" type="NP">
          <tokens>
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="2" string="boxes" type="NP">
          <tokens>
            <token id="30" string="boxes" />
          </tokens>
        </chunking>
        <chunking id="3" string="El-Shiekh" type="NP">
          <tokens>
            <token id="2" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` knitting '' themselves a space station using ceramic fibers that can be braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="11" string="``" />
            <token id="12" string="knitting" />
            <token id="13" string="''" />
            <token id="14" string="themselves" />
            <token id="15" string="a" />
            <token id="16" string="space" />
            <token id="17" string="station" />
            <token id="18" string="using" />
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="5" string="astronauts" type="NP">
          <tokens>
            <token id="4" string="astronauts" />
          </tokens>
        </chunking>
        <chunking id="6" string="a three-year trip" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="trip" />
          </tokens>
        </chunking>
        <chunking id="7" string="can be braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="8" string="panels" type="NP">
          <tokens>
            <token id="26" string="panels" />
          </tokens>
        </chunking>
        <chunking id="9" string="themselves a space station using ceramic fibers that can be braided into panels , beams , boxes and practically any other shape" type="NP">
          <tokens>
            <token id="14" string="themselves" />
            <token id="15" string="a" />
            <token id="16" string="space" />
            <token id="17" string="station" />
            <token id="18" string="using" />
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="10" string="using ceramic fibers that can be braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="18" string="using" />
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="11" string="be braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="12" string="practically any other shape" type="NP">
          <tokens>
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mars" type="NP">
          <tokens>
            <token id="10" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="14" string="that can be braided into panels , beams , boxes and practically any other shape" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="15" string="panels , beams , boxes and practically any other shape" type="NP">
          <tokens>
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="16" string="beams" type="NP">
          <tokens>
            <token id="28" string="beams" />
          </tokens>
        </chunking>
        <chunking id="17" string="themselves a space station" type="NP">
          <tokens>
            <token id="14" string="themselves" />
            <token id="15" string="a" />
            <token id="16" string="space" />
            <token id="17" string="station" />
          </tokens>
        </chunking>
        <chunking id="18" string="envisions astronauts on a three-year trip to Mars `` knitting '' themselves a space station using ceramic fibers that can be braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="3" string="envisions" />
            <token id="4" string="astronauts" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="trip" />
            <token id="9" string="to" />
            <token id="10" string="Mars" />
            <token id="11" string="``" />
            <token id="12" string="knitting" />
            <token id="13" string="''" />
            <token id="14" string="themselves" />
            <token id="15" string="a" />
            <token id="16" string="space" />
            <token id="17" string="station" />
            <token id="18" string="using" />
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="19" string="a three-year trip to Mars" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="trip" />
            <token id="9" string="to" />
            <token id="10" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="20" string="ceramic fibers that can be braided into panels , beams , boxes and practically any other shape" type="NP">
          <tokens>
            <token id="19" string="ceramic" />
            <token id="20" string="fibers" />
            <token id="21" string="that" />
            <token id="22" string="can" />
            <token id="23" string="be" />
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
        <chunking id="21" string="braided into panels , beams , boxes and practically any other shape" type="VP">
          <tokens>
            <token id="24" string="braided" />
            <token id="25" string="into" />
            <token id="26" string="panels" />
            <token id="27" string="," />
            <token id="28" string="beams" />
            <token id="29" string="," />
            <token id="30" string="boxes" />
            <token id="31" string="and" />
            <token id="32" string="practically" />
            <token id="33" string="any" />
            <token id="34" string="other" />
            <token id="35" string="shape" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">envisions</governor>
          <dependent id="1">Aly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">envisions</governor>
          <dependent id="2">El-Shiekh</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">envisions</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">envisions</governor>
          <dependent id="4">astronauts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">knitting</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trip</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">trip</governor>
          <dependent id="7">three-year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">knitting</governor>
          <dependent id="8">trip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Mars</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">trip</governor>
          <dependent id="10">Mars</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">envisions</governor>
          <dependent id="12">knitting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">station</governor>
          <dependent id="14">themselves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">station</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">station</governor>
          <dependent id="16">space</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">knitting</governor>
          <dependent id="17">station</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">station</governor>
          <dependent id="18">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">fibers</governor>
          <dependent id="19">ceramic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">using</governor>
          <dependent id="20">fibers</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">braided</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">braided</governor>
          <dependent id="22">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">braided</governor>
          <dependent id="23">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">fibers</governor>
          <dependent id="24">braided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">panels</governor>
          <dependent id="25">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">braided</governor>
          <dependent id="26">panels</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">panels</governor>
          <dependent id="28">beams</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">panels</governor>
          <dependent id="30">boxes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">panels</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">shape</governor>
          <dependent id="32">practically</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">shape</governor>
          <dependent id="33">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">shape</governor>
          <dependent id="34">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">panels</governor>
          <dependent id="35">shape</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three-year" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="three-year" />
          </tokens>
        </entity>
        <entity id="2" string="Mars" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Mars" />
          </tokens>
        </entity>
        <entity id="3" string="Aly El-Shiekh" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Aly" />
            <token id="2" string="El-Shiekh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``We believe if they can take the ceramic fibers they need and the machinery we&amp;apost;re developing they would be able to literally make the space stations they will need as they go,&amp;apost;&amp;apost; said El-Shiekh, a mechanical engineer at working in North Carolina State University&amp;apost;s textiles school.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="machinery" lemma="machinery" stem="machineri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="developing" lemma="develop" stem="develop" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="literally" lemma="literally" stem="liter" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="stations" lemma="station" stem="station" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="need" lemma="need" stem="need" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="go" lemma="go" stem="go" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="mechanical" lemma="mechanical" stem="mechan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="engineer" lemma="engineer" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="47" string="Carolina" lemma="Carolina" stem="carolina" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="48" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="49" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="50" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="textiles" lemma="textile" stem="textil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (PRP We)) (VP (VBP believe) (SBAR (IN if) (S (NP (PRP they)) (VP (MD can) (VP (VB take) (NP (NP (DT the) (JJ ceramic) (NNS fibers)) (SBAR (S (NP (PRP they)) (VP (VBP need))))))))))) (CC and) (S (NP (NP (DT the) (NN machinery)) (SBAR (S (NP (PRP we)) (VP (VBP 're) (VP (VBG developing) (NP (PRP they))))))) (VP (MD would) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB literally)) (VB make) (NP (NP (DT the) (NN space) (NNS stations)) (SBAR (S (NP (PRP they)) (VP (MD will) (VP (VB need) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP go))))))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP El-Shiekh)) (, ,) (NP (NP (DT a) (JJ mechanical) (NN engineer)) (PP (IN at) (S (VP (VBG working) (PP (IN in) (NP (NP (NNP North) (NNP Carolina) (NNP State) (NNP University) (POS 's)) (NNS textiles) (NN school)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="if they can take the ceramic fibers they need" type="SBAR">
          <tokens>
            <token id="4" string="if" />
            <token id="5" string="they" />
            <token id="6" string="can" />
            <token id="7" string="take" />
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="2" string="need" type="VP">
          <tokens>
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="3" string="will need as they go" type="VP">
          <tokens>
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="4" string="go" type="VP">
          <tokens>
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="5" string="would be able to literally make the space stations they will need as they go" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="be" />
            <token id="22" string="able" />
            <token id="23" string="to" />
            <token id="24" string="literally" />
            <token id="25" string="make" />
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="6" string="a mechanical engineer at working in North Carolina State University 's textiles school" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="mechanical" />
            <token id="42" string="engineer" />
            <token id="43" string="at" />
            <token id="44" string="working" />
            <token id="45" string="in" />
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
            <token id="50" string="'s" />
            <token id="51" string="textiles" />
            <token id="52" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="literally make the space stations they will need as they go" type="VP">
          <tokens>
            <token id="24" string="literally" />
            <token id="25" string="make" />
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="9" string="developing they" type="VP">
          <tokens>
            <token id="18" string="developing" />
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="North Carolina State University 's textiles school" type="NP">
          <tokens>
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
            <token id="50" string="'s" />
            <token id="51" string="textiles" />
            <token id="52" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="as they go" type="SBAR">
          <tokens>
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="12" string="the machinery" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="13" string="take the ceramic fibers they need" type="VP">
          <tokens>
            <token id="7" string="take" />
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="14" string="working in North Carolina State University 's textiles school" type="VP">
          <tokens>
            <token id="44" string="working" />
            <token id="45" string="in" />
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
            <token id="50" string="'s" />
            <token id="51" string="textiles" />
            <token id="52" string="school" />
          </tokens>
        </chunking>
        <chunking id="15" string="North Carolina State University 's" type="NP">
          <tokens>
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
            <token id="50" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="the space stations" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
          </tokens>
        </chunking>
        <chunking id="17" string="able to literally make the space stations they will need as they go" type="ADJP">
          <tokens>
            <token id="22" string="able" />
            <token id="23" string="to" />
            <token id="24" string="literally" />
            <token id="25" string="make" />
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="18" string="El-Shiekh" type="NP">
          <tokens>
            <token id="38" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="19" string="need as they go" type="VP">
          <tokens>
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="20" string="can take the ceramic fibers they need" type="VP">
          <tokens>
            <token id="6" string="can" />
            <token id="7" string="take" />
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="21" string="the ceramic fibers they need" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="22" string="we 're developing they" type="SBAR">
          <tokens>
            <token id="16" string="we" />
            <token id="17" string="'re" />
            <token id="18" string="developing" />
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="23" string="to literally make the space stations they will need as they go" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="literally" />
            <token id="25" string="make" />
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="24" string="we" type="NP">
          <tokens>
            <token id="16" string="we" />
          </tokens>
        </chunking>
        <chunking id="25" string="the space stations they will need as they go" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="26" string="they need" type="SBAR">
          <tokens>
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="27" string="they will need as they go" type="SBAR">
          <tokens>
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="28" string="a mechanical engineer" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="mechanical" />
            <token id="42" string="engineer" />
          </tokens>
        </chunking>
        <chunking id="29" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="30" string="El-Shiekh , a mechanical engineer at working in North Carolina State University 's textiles school" type="NP">
          <tokens>
            <token id="38" string="El-Shiekh" />
            <token id="39" string="," />
            <token id="40" string="a" />
            <token id="41" string="mechanical" />
            <token id="42" string="engineer" />
            <token id="43" string="at" />
            <token id="44" string="working" />
            <token id="45" string="in" />
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
            <token id="50" string="'s" />
            <token id="51" string="textiles" />
            <token id="52" string="school" />
          </tokens>
        </chunking>
        <chunking id="31" string="be able to literally make the space stations they will need as they go" type="VP">
          <tokens>
            <token id="21" string="be" />
            <token id="22" string="able" />
            <token id="23" string="to" />
            <token id="24" string="literally" />
            <token id="25" string="make" />
            <token id="26" string="the" />
            <token id="27" string="space" />
            <token id="28" string="stations" />
            <token id="29" string="they" />
            <token id="30" string="will" />
            <token id="31" string="need" />
            <token id="32" string="as" />
            <token id="33" string="they" />
            <token id="34" string="go" />
          </tokens>
        </chunking>
        <chunking id="32" string="believe if they can take the ceramic fibers they need" type="VP">
          <tokens>
            <token id="3" string="believe" />
            <token id="4" string="if" />
            <token id="5" string="they" />
            <token id="6" string="can" />
            <token id="7" string="take" />
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
            <token id="11" string="they" />
            <token id="12" string="need" />
          </tokens>
        </chunking>
        <chunking id="33" string="the ceramic fibers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="ceramic" />
            <token id="10" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="34" string="the machinery we 're developing they" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="machinery" />
            <token id="16" string="we" />
            <token id="17" string="'re" />
            <token id="18" string="developing" />
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="35" string="'re developing they" type="VP">
          <tokens>
            <token id="17" string="'re" />
            <token id="18" string="developing" />
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="36" string="said" type="VP">
          <tokens>
            <token id="37" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">believe</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="37">said</governor>
          <dependent id="3">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">take</governor>
          <dependent id="4">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">take</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">take</governor>
          <dependent id="6">can</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">believe</governor>
          <dependent id="7">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">fibers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">fibers</governor>
          <dependent id="9">ceramic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">take</governor>
          <dependent id="10">fibers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">need</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">fibers</governor>
          <dependent id="12">need</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">believe</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">machinery</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">able</governor>
          <dependent id="15">machinery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">developing</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">developing</governor>
          <dependent id="17">'re</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">machinery</governor>
          <dependent id="18">developing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">developing</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">able</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">able</governor>
          <dependent id="21">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">believe</governor>
          <dependent id="22">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">make</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">make</governor>
          <dependent id="24">literally</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">able</governor>
          <dependent id="25">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">stations</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">stations</governor>
          <dependent id="27">space</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">make</governor>
          <dependent id="28">stations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">need</governor>
          <dependent id="29">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">need</governor>
          <dependent id="30">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">stations</governor>
          <dependent id="31">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">go</governor>
          <dependent id="32">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">go</governor>
          <dependent id="33">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">need</governor>
          <dependent id="34">go</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">said</governor>
          <dependent id="38">El-Shiekh</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">engineer</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">engineer</governor>
          <dependent id="41">mechanical</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="38">El-Shiekh</governor>
          <dependent id="42">engineer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="44">working</governor>
          <dependent id="43">at</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">engineer</governor>
          <dependent id="44">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">school</governor>
          <dependent id="45">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">University</governor>
          <dependent id="46">North</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">University</governor>
          <dependent id="47">Carolina</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">University</governor>
          <dependent id="48">State</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="52">school</governor>
          <dependent id="49">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">University</governor>
          <dependent id="50">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">school</governor>
          <dependent id="51">textiles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">working</governor>
          <dependent id="52">school</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="North Carolina State University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="46" string="North" />
            <token id="47" string="Carolina" />
            <token id="48" string="State" />
            <token id="49" string="University" />
          </tokens>
        </entity>
        <entity id="2" string="El-Shiekh" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="El-Shiekh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>El-Shiekh and his students are developing machinery to braid long strands of ceramic fibers.</content>
      <tokens>
        <token id="1" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="developing" lemma="develop" stem="develop" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="machinery" lemma="machinery" stem="machineri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="braid" lemma="braid" stem="braid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="strands" lemma="strand" stem="strand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP El-Shiekh)) (CC and) (NP (PRP$ his) (NNS students))) (VP (VBP are) (VP (VBG developing) (NP (NN machinery)) (S (VP (TO to) (VP (VB braid) (NP (NP (JJ long) (NNS strands)) (PP (IN of) (NP (JJ ceramic) (NNS fibers))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his students" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="students" />
          </tokens>
        </chunking>
        <chunking id="2" string="ceramic fibers" type="NP">
          <tokens>
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="3" string="are developing machinery to braid long strands of ceramic fibers" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="developing" />
            <token id="7" string="machinery" />
            <token id="8" string="to" />
            <token id="9" string="braid" />
            <token id="10" string="long" />
            <token id="11" string="strands" />
            <token id="12" string="of" />
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="4" string="long strands" type="NP">
          <tokens>
            <token id="10" string="long" />
            <token id="11" string="strands" />
          </tokens>
        </chunking>
        <chunking id="5" string="El-Shiekh" type="NP">
          <tokens>
            <token id="1" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="6" string="developing machinery to braid long strands of ceramic fibers" type="VP">
          <tokens>
            <token id="6" string="developing" />
            <token id="7" string="machinery" />
            <token id="8" string="to" />
            <token id="9" string="braid" />
            <token id="10" string="long" />
            <token id="11" string="strands" />
            <token id="12" string="of" />
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="7" string="long strands of ceramic fibers" type="NP">
          <tokens>
            <token id="10" string="long" />
            <token id="11" string="strands" />
            <token id="12" string="of" />
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="8" string="machinery" type="NP">
          <tokens>
            <token id="7" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="9" string="braid long strands of ceramic fibers" type="VP">
          <tokens>
            <token id="9" string="braid" />
            <token id="10" string="long" />
            <token id="11" string="strands" />
            <token id="12" string="of" />
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="10" string="to braid long strands of ceramic fibers" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="braid" />
            <token id="10" string="long" />
            <token id="11" string="strands" />
            <token id="12" string="of" />
            <token id="13" string="ceramic" />
            <token id="14" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="11" string="El-Shiekh and his students" type="NP">
          <tokens>
            <token id="1" string="El-Shiekh" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="students" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">developing</governor>
          <dependent id="1">El-Shiekh</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">El-Shiekh</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">students</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">El-Shiekh</governor>
          <dependent id="4">students</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">developing</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">developing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">developing</governor>
          <dependent id="7">machinery</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">braid</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">developing</governor>
          <dependent id="9">braid</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">strands</governor>
          <dependent id="10">long</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">braid</governor>
          <dependent id="11">strands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">fibers</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">fibers</governor>
          <dependent id="13">ceramic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">strands</governor>
          <dependent id="14">fibers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="El-Shiekh" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="El-Shiekh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Such fibers, bonded with epoxy, also will form heat shields and many of the parts in the vessel that carries people to Mars.</content>
      <tokens>
        <token id="1" string="Such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="bonded" lemma="bond" stem="bond" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="epoxy" lemma="epoxy" stem="epoxi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="form" lemma="form" stem="form" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="shields" lemma="shield" stem="shield" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="vessel" lemma="vessel" stem="vessel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="carries" lemma="carry" stem="carri" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Mars" lemma="Mars" stem="mar" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Such) (NNS fibers)) (, ,) (VP (VBN bonded) (PP (IN with) (NP (NN epoxy)))) (, ,)) (ADVP (RB also)) (VP (MD will) (VP (VB form) (NP (NP (NN heat) (NNS shields)) (CC and) (NP (NP (JJ many)) (PP (IN of) (NP (DT the) (NNS parts))))) (PP (IN in) (NP (NP (DT the) (NN vessel)) (SBAR (WHNP (WDT that)) (S (VP (VBZ carries) (NP (NNS people)) (PP (TO to) (NP (NNP Mars)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="heat shields and many of the parts" type="NP">
          <tokens>
            <token id="11" string="heat" />
            <token id="12" string="shields" />
            <token id="13" string="and" />
            <token id="14" string="many" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="parts" />
          </tokens>
        </chunking>
        <chunking id="2" string="heat shields" type="NP">
          <tokens>
            <token id="11" string="heat" />
            <token id="12" string="shields" />
          </tokens>
        </chunking>
        <chunking id="3" string="many of the parts" type="NP">
          <tokens>
            <token id="14" string="many" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="parts" />
          </tokens>
        </chunking>
        <chunking id="4" string="epoxy" type="NP">
          <tokens>
            <token id="6" string="epoxy" />
          </tokens>
        </chunking>
        <chunking id="5" string="will form heat shields and many of the parts in the vessel that carries people to Mars" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="form" />
            <token id="11" string="heat" />
            <token id="12" string="shields" />
            <token id="13" string="and" />
            <token id="14" string="many" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="parts" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="vessel" />
            <token id="21" string="that" />
            <token id="22" string="carries" />
            <token id="23" string="people" />
            <token id="24" string="to" />
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="6" string="bonded with epoxy" type="VP">
          <tokens>
            <token id="4" string="bonded" />
            <token id="5" string="with" />
            <token id="6" string="epoxy" />
          </tokens>
        </chunking>
        <chunking id="7" string="Such fibers" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="23" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="many" type="NP">
          <tokens>
            <token id="14" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="Such fibers , bonded with epoxy ," type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="fibers" />
            <token id="3" string="," />
            <token id="4" string="bonded" />
            <token id="5" string="with" />
            <token id="6" string="epoxy" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="carries people to Mars" type="VP">
          <tokens>
            <token id="22" string="carries" />
            <token id="23" string="people" />
            <token id="24" string="to" />
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mars" type="NP">
          <tokens>
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="13" string="that carries people to Mars" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="carries" />
            <token id="23" string="people" />
            <token id="24" string="to" />
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="14" string="the parts" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="parts" />
          </tokens>
        </chunking>
        <chunking id="15" string="the vessel" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="16" string="the vessel that carries people to Mars" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="vessel" />
            <token id="21" string="that" />
            <token id="22" string="carries" />
            <token id="23" string="people" />
            <token id="24" string="to" />
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
        <chunking id="17" string="form heat shields and many of the parts in the vessel that carries people to Mars" type="VP">
          <tokens>
            <token id="10" string="form" />
            <token id="11" string="heat" />
            <token id="12" string="shields" />
            <token id="13" string="and" />
            <token id="14" string="many" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="parts" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="vessel" />
            <token id="21" string="that" />
            <token id="22" string="carries" />
            <token id="23" string="people" />
            <token id="24" string="to" />
            <token id="25" string="Mars" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">fibers</governor>
          <dependent id="1">Such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">form</governor>
          <dependent id="2">fibers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">fibers</governor>
          <dependent id="4">bonded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">epoxy</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">bonded</governor>
          <dependent id="6">epoxy</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">form</governor>
          <dependent id="8">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">form</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">form</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">shields</governor>
          <dependent id="11">heat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">form</governor>
          <dependent id="12">shields</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">shields</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">shields</governor>
          <dependent id="14">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">parts</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">parts</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">many</governor>
          <dependent id="17">parts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">vessel</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">vessel</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">form</governor>
          <dependent id="20">vessel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">carries</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">vessel</governor>
          <dependent id="22">carries</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">carries</governor>
          <dependent id="23">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Mars</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">carries</governor>
          <dependent id="25">Mars</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mars" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Mars" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>The parts will withstand speeds of 50,000 mph and temperatures of at least 4,000 degrees.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="withstand" lemma="withstand" stem="withstand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="speeds" lemma="speed" stem="speed" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="mph" lemma="mph" stem="mph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="temperatures" lemma="temperature" stem="temperatur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="4,000" lemma="4,000" stem="4,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="degrees" lemma="degree" stem="degre" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS parts)) (VP (MD will) (VP (VB withstand) (NP (NP (NP (NNS speeds)) (PP (IN of) (NP (CD 50,000) (NN mph)))) (CC and) (NP (NP (NNS temperatures)) (PP (IN of) (NP (QP (IN at) (JJS least) (CD 4,000)) (NNS degrees))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="speeds of 50,000 mph" type="NP">
          <tokens>
            <token id="5" string="speeds" />
            <token id="6" string="of" />
            <token id="7" string="50,000" />
            <token id="8" string="mph" />
          </tokens>
        </chunking>
        <chunking id="2" string="at least 4,000 degrees" type="NP">
          <tokens>
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="4,000" />
            <token id="15" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="3" string="temperatures" type="NP">
          <tokens>
            <token id="10" string="temperatures" />
          </tokens>
        </chunking>
        <chunking id="4" string="50,000 mph" type="NP">
          <tokens>
            <token id="7" string="50,000" />
            <token id="8" string="mph" />
          </tokens>
        </chunking>
        <chunking id="5" string="The parts" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="parts" />
          </tokens>
        </chunking>
        <chunking id="6" string="will withstand speeds of 50,000 mph and temperatures of at least 4,000 degrees" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="withstand" />
            <token id="5" string="speeds" />
            <token id="6" string="of" />
            <token id="7" string="50,000" />
            <token id="8" string="mph" />
            <token id="9" string="and" />
            <token id="10" string="temperatures" />
            <token id="11" string="of" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="4,000" />
            <token id="15" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="7" string="speeds of 50,000 mph and temperatures of at least 4,000 degrees" type="NP">
          <tokens>
            <token id="5" string="speeds" />
            <token id="6" string="of" />
            <token id="7" string="50,000" />
            <token id="8" string="mph" />
            <token id="9" string="and" />
            <token id="10" string="temperatures" />
            <token id="11" string="of" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="4,000" />
            <token id="15" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="8" string="speeds" type="NP">
          <tokens>
            <token id="5" string="speeds" />
          </tokens>
        </chunking>
        <chunking id="9" string="temperatures of at least 4,000 degrees" type="NP">
          <tokens>
            <token id="10" string="temperatures" />
            <token id="11" string="of" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="4,000" />
            <token id="15" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="10" string="withstand speeds of 50,000 mph and temperatures of at least 4,000 degrees" type="VP">
          <tokens>
            <token id="4" string="withstand" />
            <token id="5" string="speeds" />
            <token id="6" string="of" />
            <token id="7" string="50,000" />
            <token id="8" string="mph" />
            <token id="9" string="and" />
            <token id="10" string="temperatures" />
            <token id="11" string="of" />
            <token id="12" string="at" />
            <token id="13" string="least" />
            <token id="14" string="4,000" />
            <token id="15" string="degrees" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">parts</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">withstand</governor>
          <dependent id="2">parts</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">withstand</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">withstand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">withstand</governor>
          <dependent id="5">speeds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">mph</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">mph</governor>
          <dependent id="7">50,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">speeds</governor>
          <dependent id="8">mph</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">speeds</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">speeds</governor>
          <dependent id="10">temperatures</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">degrees</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">least</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="14">4,000</governor>
          <dependent id="13">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">degrees</governor>
          <dependent id="14">4,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">temperatures</governor>
          <dependent id="15">degrees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="4,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="4,000" />
          </tokens>
        </entity>
        <entity id="2" string="50,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="50,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>While much of his work relates to the Mars Mission Research Center here, El-Shiekh sees a big future for composite materials like ceramic fibers.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="relates" lemma="relate" stem="relat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Mars" lemma="Mars" stem="mar" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Mission" lemma="Mission" stem="mission" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Research" lemma="Research" stem="research" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="sees" lemma="see" stem="see" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="composite" lemma="composite" stem="composit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="materials" lemma="material" stem="materi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (NP (JJ much)) (PP (IN of) (NP (PRP$ his) (NN work)))) (VP (VBZ relates) (PP (TO to) (NP (DT the) (NNP Mars) (NNP Mission) (NNP Research) (NNP Center))) (ADVP (RB here))))) (, ,) (NP (NNP El-Shiekh)) (VP (VBZ sees) (NP (NP (DT a) (JJ big) (NN future)) (PP (IN for) (NP (NP (JJ composite) (NNS materials)) (PP (IN like) (NP (JJ ceramic) (NNS fibers))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ceramic fibers" type="NP">
          <tokens>
            <token id="24" string="ceramic" />
            <token id="25" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="2" string="a big future for composite materials like ceramic fibers" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="big" />
            <token id="19" string="future" />
            <token id="20" string="for" />
            <token id="21" string="composite" />
            <token id="22" string="materials" />
            <token id="23" string="like" />
            <token id="24" string="ceramic" />
            <token id="25" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="3" string="El-Shiekh" type="NP">
          <tokens>
            <token id="15" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="4" string="much of his work" type="NP">
          <tokens>
            <token id="2" string="much" />
            <token id="3" string="of" />
            <token id="4" string="his" />
            <token id="5" string="work" />
          </tokens>
        </chunking>
        <chunking id="5" string="a big future" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="big" />
            <token id="19" string="future" />
          </tokens>
        </chunking>
        <chunking id="6" string="relates to the Mars Mission Research Center here" type="VP">
          <tokens>
            <token id="6" string="relates" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Mars" />
            <token id="10" string="Mission" />
            <token id="11" string="Research" />
            <token id="12" string="Center" />
            <token id="13" string="here" />
          </tokens>
        </chunking>
        <chunking id="7" string="While much of his work relates to the Mars Mission Research Center here" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="much" />
            <token id="3" string="of" />
            <token id="4" string="his" />
            <token id="5" string="work" />
            <token id="6" string="relates" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Mars" />
            <token id="10" string="Mission" />
            <token id="11" string="Research" />
            <token id="12" string="Center" />
            <token id="13" string="here" />
          </tokens>
        </chunking>
        <chunking id="8" string="sees a big future for composite materials like ceramic fibers" type="VP">
          <tokens>
            <token id="16" string="sees" />
            <token id="17" string="a" />
            <token id="18" string="big" />
            <token id="19" string="future" />
            <token id="20" string="for" />
            <token id="21" string="composite" />
            <token id="22" string="materials" />
            <token id="23" string="like" />
            <token id="24" string="ceramic" />
            <token id="25" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Mars Mission Research Center" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Mars" />
            <token id="10" string="Mission" />
            <token id="11" string="Research" />
            <token id="12" string="Center" />
          </tokens>
        </chunking>
        <chunking id="10" string="composite materials like ceramic fibers" type="NP">
          <tokens>
            <token id="21" string="composite" />
            <token id="22" string="materials" />
            <token id="23" string="like" />
            <token id="24" string="ceramic" />
            <token id="25" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="11" string="his work" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="work" />
          </tokens>
        </chunking>
        <chunking id="12" string="composite materials" type="NP">
          <tokens>
            <token id="21" string="composite" />
            <token id="22" string="materials" />
          </tokens>
        </chunking>
        <chunking id="13" string="much" type="NP">
          <tokens>
            <token id="2" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">relates</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">relates</governor>
          <dependent id="2">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">work</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">work</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">much</governor>
          <dependent id="5">work</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">sees</governor>
          <dependent id="6">relates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Center</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Center</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Center</governor>
          <dependent id="9">Mars</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Center</governor>
          <dependent id="10">Mission</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Center</governor>
          <dependent id="11">Research</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">relates</governor>
          <dependent id="12">Center</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">relates</governor>
          <dependent id="13">here</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">sees</governor>
          <dependent id="15">El-Shiekh</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">sees</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">future</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">future</governor>
          <dependent id="18">big</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">sees</governor>
          <dependent id="19">future</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">materials</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">materials</governor>
          <dependent id="21">composite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">future</governor>
          <dependent id="22">materials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">fibers</governor>
          <dependent id="23">like</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">fibers</governor>
          <dependent id="24">ceramic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">materials</governor>
          <dependent id="25">fibers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="El-Shiekh" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="El-Shiekh" />
          </tokens>
        </entity>
        <entity id="2" string="future" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="future" />
          </tokens>
        </entity>
        <entity id="3" string="Mars Mission Research Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Mars" />
            <token id="10" string="Mission" />
            <token id="11" string="Research" />
            <token id="12" string="Center" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``The day may very well come when you are driving around with car engine parts of ceramic fiber,&amp;apost;&amp;apost; he said, adding that the vibration-damping properties of the materials also would make them good for torsion bars in cars.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="driving" lemma="drive" stem="drive" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="around" lemma="around" stem="around" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="engine" lemma="engine" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="fiber" lemma="fiber" stem="fiber" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="vibration-damping" lemma="vibration-damping" stem="vibration-damp" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="properties" lemma="property" stem="properti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="materials" lemma="material" stem="materi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="torsion" lemma="torsion" stem="torsion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="bars" lemma="bar" stem="bar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="cars" lemma="car" stem="car" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN day)) (VP (MD may) (VP (ADVP (RB very) (RB well)) (VBN come) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP are) (VP (VBG driving) (PRT (RP around)) (PP (IN with) (NP (NP (NN car) (NN engine) (NNS parts)) (PP (IN of) (NP (JJ ceramic) (NN fiber)))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (NP (DT the) (JJ vibration-damping) (NNS properties)) (PP (IN of) (NP (DT the) (NNS materials)))) (ADVP (RB also)) (VP (MD would) (VP (VB make) (S (NP (PRP them)) (ADJP (JJ good) (PP (IN for) (NP (NP (NN torsion) (NNS bars)) (PP (IN in) (NP (NNS cars)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are driving around with car engine parts of ceramic fiber" type="VP">
          <tokens>
            <token id="10" string="are" />
            <token id="11" string="driving" />
            <token id="12" string="around" />
            <token id="13" string="with" />
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="2" string="would make them good for torsion bars in cars" type="VP">
          <tokens>
            <token id="34" string="would" />
            <token id="35" string="make" />
            <token id="36" string="them" />
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="3" string="when you are driving around with car engine parts of ceramic fiber" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="are" />
            <token id="11" string="driving" />
            <token id="12" string="around" />
            <token id="13" string="with" />
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="4" string="them" type="NP">
          <tokens>
            <token id="36" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="The day" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="day" />
          </tokens>
        </chunking>
        <chunking id="6" string="the materials" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="materials" />
          </tokens>
        </chunking>
        <chunking id="7" string="cars" type="NP">
          <tokens>
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the vibration-damping properties of the materials also would make them good for torsion bars in cars" type="SBAR">
          <tokens>
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="vibration-damping" />
            <token id="29" string="properties" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="materials" />
            <token id="33" string="also" />
            <token id="34" string="would" />
            <token id="35" string="make" />
            <token id="36" string="them" />
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="9" string="good for torsion bars in cars" type="ADJP">
          <tokens>
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="torsion bars" type="NP">
          <tokens>
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
          </tokens>
        </chunking>
        <chunking id="12" string="may very well come when you are driving around with car engine parts of ceramic fiber" type="VP">
          <tokens>
            <token id="4" string="may" />
            <token id="5" string="very" />
            <token id="6" string="well" />
            <token id="7" string="come" />
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="are" />
            <token id="11" string="driving" />
            <token id="12" string="around" />
            <token id="13" string="with" />
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="13" string="car engine parts" type="NP">
          <tokens>
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
          </tokens>
        </chunking>
        <chunking id="14" string="ceramic fiber" type="NP">
          <tokens>
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="15" string="said , adding that the vibration-damping properties of the materials also would make them good for torsion bars in cars" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="," />
            <token id="25" string="adding" />
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="vibration-damping" />
            <token id="29" string="properties" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="materials" />
            <token id="33" string="also" />
            <token id="34" string="would" />
            <token id="35" string="make" />
            <token id="36" string="them" />
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="16" string="very well come when you are driving around with car engine parts of ceramic fiber" type="VP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="well" />
            <token id="7" string="come" />
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="are" />
            <token id="11" string="driving" />
            <token id="12" string="around" />
            <token id="13" string="with" />
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="17" string="car engine parts of ceramic fiber" type="NP">
          <tokens>
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="18" string="adding that the vibration-damping properties of the materials also would make them good for torsion bars in cars" type="VP">
          <tokens>
            <token id="25" string="adding" />
            <token id="26" string="that" />
            <token id="27" string="the" />
            <token id="28" string="vibration-damping" />
            <token id="29" string="properties" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="materials" />
            <token id="33" string="also" />
            <token id="34" string="would" />
            <token id="35" string="make" />
            <token id="36" string="them" />
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="driving around with car engine parts of ceramic fiber" type="VP">
          <tokens>
            <token id="11" string="driving" />
            <token id="12" string="around" />
            <token id="13" string="with" />
            <token id="14" string="car" />
            <token id="15" string="engine" />
            <token id="16" string="parts" />
            <token id="17" string="of" />
            <token id="18" string="ceramic" />
            <token id="19" string="fiber" />
          </tokens>
        </chunking>
        <chunking id="21" string="make them good for torsion bars in cars" type="VP">
          <tokens>
            <token id="35" string="make" />
            <token id="36" string="them" />
            <token id="37" string="good" />
            <token id="38" string="for" />
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="22" string="torsion bars in cars" type="NP">
          <tokens>
            <token id="39" string="torsion" />
            <token id="40" string="bars" />
            <token id="41" string="in" />
            <token id="42" string="cars" />
          </tokens>
        </chunking>
        <chunking id="23" string="the vibration-damping properties" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="vibration-damping" />
            <token id="29" string="properties" />
          </tokens>
        </chunking>
        <chunking id="24" string="you" type="NP">
          <tokens>
            <token id="9" string="you" />
          </tokens>
        </chunking>
        <chunking id="25" string="the vibration-damping properties of the materials" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="vibration-damping" />
            <token id="29" string="properties" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="materials" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">day</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">come</governor>
          <dependent id="3">day</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">come</governor>
          <dependent id="4">may</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">well</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">come</governor>
          <dependent id="6">well</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="7">come</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">driving</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">driving</governor>
          <dependent id="9">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">driving</governor>
          <dependent id="10">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">come</governor>
          <dependent id="11">driving</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">driving</governor>
          <dependent id="12">around</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">parts</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">parts</governor>
          <dependent id="14">car</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">parts</governor>
          <dependent id="15">engine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">driving</governor>
          <dependent id="16">parts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">fiber</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">fiber</governor>
          <dependent id="18">ceramic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">parts</governor>
          <dependent id="19">fiber</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">said</governor>
          <dependent id="25">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">make</governor>
          <dependent id="26">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">properties</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">properties</governor>
          <dependent id="28">vibration-damping</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">make</governor>
          <dependent id="29">properties</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">materials</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">materials</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">properties</governor>
          <dependent id="32">materials</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">make</governor>
          <dependent id="33">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">make</governor>
          <dependent id="34">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">adding</governor>
          <dependent id="35">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">good</governor>
          <dependent id="36">them</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="35">make</governor>
          <dependent id="37">good</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">bars</governor>
          <dependent id="38">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">bars</governor>
          <dependent id="39">torsion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">good</governor>
          <dependent id="40">bars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">cars</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">bars</governor>
          <dependent id="42">cars</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="The day may" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="day" />
            <token id="4" string="may" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``We also are working on the idea of putting this braided fabric in concrete as reinforcing material instead of metal rods,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="putting" lemma="put" stem="put" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="braided" lemma="braided" stem="braid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="fabric" lemma="fabric" stem="fabric" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="concrete" lemma="concrete" stem="concret" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="reinforcing" lemma="reinforce" stem="reinforc" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="material" lemma="material" stem="materi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="metal" lemma="metal" stem="metal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="rods" lemma="rod" stem="rod" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (ADVP (RB also)) (VP (VBP are) (VP (VBG working) (PP (IN on) (NP (NP (DT the) (NN idea)) (PP (IN of) (S (VP (VBG putting) (NP (NP (DT this) (JJ braided) (NN fabric)) (PP (IN in) (NP (NN concrete)))) (PP (IN as) (S (VP (VBG reinforcing) (NP (NP (NN material)) (PP (RB instead) (IN of) (NP (NN metal) (NNS rods))))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this braided fabric in concrete" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
            <token id="14" string="in" />
            <token id="15" string="concrete" />
          </tokens>
        </chunking>
        <chunking id="2" string="concrete" type="NP">
          <tokens>
            <token id="15" string="concrete" />
          </tokens>
        </chunking>
        <chunking id="3" string="working on the idea of putting this braided fabric in concrete as reinforcing material instead of metal rods" type="VP">
          <tokens>
            <token id="5" string="working" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="putting" />
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
            <token id="14" string="in" />
            <token id="15" string="concrete" />
            <token id="16" string="as" />
            <token id="17" string="reinforcing" />
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="4" string="metal rods" type="NP">
          <tokens>
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="this braided fabric" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
          </tokens>
        </chunking>
        <chunking id="7" string="reinforcing material instead of metal rods" type="VP">
          <tokens>
            <token id="17" string="reinforcing" />
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="8" string="material" type="NP">
          <tokens>
            <token id="18" string="material" />
          </tokens>
        </chunking>
        <chunking id="9" string="are working on the idea of putting this braided fabric in concrete as reinforcing material instead of metal rods" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="working" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="putting" />
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
            <token id="14" string="in" />
            <token id="15" string="concrete" />
            <token id="16" string="as" />
            <token id="17" string="reinforcing" />
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="10" string="the idea of putting this braided fabric in concrete as reinforcing material instead of metal rods" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="putting" />
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
            <token id="14" string="in" />
            <token id="15" string="concrete" />
            <token id="16" string="as" />
            <token id="17" string="reinforcing" />
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="11" string="material instead of metal rods" type="NP">
          <tokens>
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="12" string="putting this braided fabric in concrete as reinforcing material instead of metal rods" type="VP">
          <tokens>
            <token id="10" string="putting" />
            <token id="11" string="this" />
            <token id="12" string="braided" />
            <token id="13" string="fabric" />
            <token id="14" string="in" />
            <token id="15" string="concrete" />
            <token id="16" string="as" />
            <token id="17" string="reinforcing" />
            <token id="18" string="material" />
            <token id="19" string="instead" />
            <token id="20" string="of" />
            <token id="21" string="metal" />
            <token id="22" string="rods" />
          </tokens>
        </chunking>
        <chunking id="13" string="the idea" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="idea" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">working</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">working</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">working</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="5">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">idea</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">idea</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">working</governor>
          <dependent id="8">idea</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">putting</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">idea</governor>
          <dependent id="10">putting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">fabric</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">fabric</governor>
          <dependent id="12">braided</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">putting</governor>
          <dependent id="13">fabric</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">concrete</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">fabric</governor>
          <dependent id="15">concrete</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">reinforcing</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">putting</governor>
          <dependent id="17">reinforcing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">reinforcing</governor>
          <dependent id="18">material</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">rods</governor>
          <dependent id="19">instead</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="19">instead</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">rods</governor>
          <dependent id="21">metal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">material</governor>
          <dependent id="22">rods</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``It is stronger than steel, does not rust and would not wear away _ the road would not deteriorate.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="stronger" lemma="stronger" stem="stronger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="steel" lemma="steel" stem="steel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="rust" lemma="rust" stem="rust" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="wear" lemma="wear" stem="wear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="_" lemma="_" stem="_" pos="RB" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="deteriorate" lemma="deteriorate" stem="deterior" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VP (VBZ is) (ADJP (JJR stronger)) (PP (IN than) (NP (NN steel)))) (, ,) (VP (VBZ does) (NP (RB not) (NN rust))) (CC and) (VP (MD would) (RB not) (VP (VB wear) (S (ADVP (RB away)) (ADVP (RB _)) (NP (DT the) (NN road)) (VP (MD would) (RB not) (VP (VB deteriorate))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="steel" type="NP">
          <tokens>
            <token id="6" string="steel" />
          </tokens>
        </chunking>
        <chunking id="2" string="stronger" type="ADJP">
          <tokens>
            <token id="4" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="3" string="wear away _ the road would not deteriorate" type="VP">
          <tokens>
            <token id="14" string="wear" />
            <token id="15" string="away" />
            <token id="16" string="_" />
            <token id="17" string="the" />
            <token id="18" string="road" />
            <token id="19" string="would" />
            <token id="20" string="not" />
            <token id="21" string="deteriorate" />
          </tokens>
        </chunking>
        <chunking id="4" string="would not deteriorate" type="VP">
          <tokens>
            <token id="19" string="would" />
            <token id="20" string="not" />
            <token id="21" string="deteriorate" />
          </tokens>
        </chunking>
        <chunking id="5" string="is stronger than steel , does not rust and would not wear away _ the road would not deteriorate" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="stronger" />
            <token id="5" string="than" />
            <token id="6" string="steel" />
            <token id="7" string="," />
            <token id="8" string="does" />
            <token id="9" string="not" />
            <token id="10" string="rust" />
            <token id="11" string="and" />
            <token id="12" string="would" />
            <token id="13" string="not" />
            <token id="14" string="wear" />
            <token id="15" string="away" />
            <token id="16" string="_" />
            <token id="17" string="the" />
            <token id="18" string="road" />
            <token id="19" string="would" />
            <token id="20" string="not" />
            <token id="21" string="deteriorate" />
          </tokens>
        </chunking>
        <chunking id="6" string="is stronger than steel" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="stronger" />
            <token id="5" string="than" />
            <token id="6" string="steel" />
          </tokens>
        </chunking>
        <chunking id="7" string="would not wear away _ the road would not deteriorate" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="not" />
            <token id="14" string="wear" />
            <token id="15" string="away" />
            <token id="16" string="_" />
            <token id="17" string="the" />
            <token id="18" string="road" />
            <token id="19" string="would" />
            <token id="20" string="not" />
            <token id="21" string="deteriorate" />
          </tokens>
        </chunking>
        <chunking id="8" string="deteriorate" type="VP">
          <tokens>
            <token id="21" string="deteriorate" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="does not rust" type="VP">
          <tokens>
            <token id="8" string="does" />
            <token id="9" string="not" />
            <token id="10" string="rust" />
          </tokens>
        </chunking>
        <chunking id="11" string="the road" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="road" />
          </tokens>
        </chunking>
        <chunking id="12" string="not rust" type="NP">
          <tokens>
            <token id="9" string="not" />
            <token id="10" string="rust" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">stronger</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">stronger</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">stronger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">steel</governor>
          <dependent id="5">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">stronger</governor>
          <dependent id="6">steel</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">stronger</governor>
          <dependent id="8">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">rust</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">does</governor>
          <dependent id="10">rust</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">stronger</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">wear</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">wear</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">stronger</governor>
          <dependent id="14">wear</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">deteriorate</governor>
          <dependent id="15">away</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">deteriorate</governor>
          <dependent id="16">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">road</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">deteriorate</governor>
          <dependent id="18">road</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">deteriorate</governor>
          <dependent id="19">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">deteriorate</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">wear</governor>
          <dependent id="21">deteriorate</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The fibers, including Kevlar now used to make bulletproof vests, also could be used to make some body parts, and El-Shiekh is working with Duke University researchers on ceramic ``stents,&amp;apost;&amp;apost; collapsible braces for arteries.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="fibers" lemma="fiber" stem="fiber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Kevlar" lemma="Kevlar" stem="kevlar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="bulletproof" lemma="bulletproof" stem="bulletproof" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="vests" lemma="vest" stem="vest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Duke" lemma="Duke" stem="duke" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="30" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="ceramic" lemma="ceramic" stem="ceram" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="stents" lemma="stent" stem="stent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="collapsible" lemma="collapsible" stem="collaps" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="braces" lemma="brace" stem="brace" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="arteries" lemma="artery" stem="arteri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NNS fibers)) (, ,) (PP (VBG including) (NP (NP (NNP Kevlar)) (VP (ADVP (RB now)) (VBN used) (S (VP (TO to) (VP (VB make) (NP (JJ bulletproof) (NNS vests)))))))) (, ,)) (ADVP (RB also)) (VP (MD could) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB make) (NP (DT some) (NN body) (NNS parts))))))))) (, ,) (CC and) (S (NP (NNP El-Shiekh)) (VP (VBZ is) (VP (VBG working) (PP (IN with) (NP (NNP Duke) (NNP University) (NNS researchers))) (PP (IN on) (NP (NP (JJ ceramic) (`` ``) (NNS stents)) (, ,) ('' '') (NP (NP (JJ collapsible) (NNS braces)) (PP (IN for) (NP (NNS arteries))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The fibers , including Kevlar now used to make bulletproof vests ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fibers" />
            <token id="3" string="," />
            <token id="4" string="including" />
            <token id="5" string="Kevlar" />
            <token id="6" string="now" />
            <token id="7" string="used" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="working with Duke University researchers on ceramic `` stents , '' collapsible braces for arteries" type="VP">
          <tokens>
            <token id="26" string="working" />
            <token id="27" string="with" />
            <token id="28" string="Duke" />
            <token id="29" string="University" />
            <token id="30" string="researchers" />
            <token id="31" string="on" />
            <token id="32" string="ceramic" />
            <token id="33" string="``" />
            <token id="34" string="stents" />
            <token id="35" string="," />
            <token id="36" string="''" />
            <token id="37" string="collapsible" />
            <token id="38" string="braces" />
            <token id="39" string="for" />
            <token id="40" string="arteries" />
          </tokens>
        </chunking>
        <chunking id="3" string="Kevlar" type="NP">
          <tokens>
            <token id="5" string="Kevlar" />
          </tokens>
        </chunking>
        <chunking id="4" string="Duke University researchers" type="NP">
          <tokens>
            <token id="28" string="Duke" />
            <token id="29" string="University" />
            <token id="30" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="5" string="El-Shiekh" type="NP">
          <tokens>
            <token id="24" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="6" string="used to make some body parts" type="VP">
          <tokens>
            <token id="16" string="used" />
            <token id="17" string="to" />
            <token id="18" string="make" />
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="7" string="arteries" type="NP">
          <tokens>
            <token id="40" string="arteries" />
          </tokens>
        </chunking>
        <chunking id="8" string="to make bulletproof vests" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
          </tokens>
        </chunking>
        <chunking id="9" string="make bulletproof vests" type="VP">
          <tokens>
            <token id="9" string="make" />
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
          </tokens>
        </chunking>
        <chunking id="10" string="ceramic `` stents" type="NP">
          <tokens>
            <token id="32" string="ceramic" />
            <token id="33" string="``" />
            <token id="34" string="stents" />
          </tokens>
        </chunking>
        <chunking id="11" string="be used to make some body parts" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="used" />
            <token id="17" string="to" />
            <token id="18" string="make" />
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="12" string="Kevlar now used to make bulletproof vests" type="NP">
          <tokens>
            <token id="5" string="Kevlar" />
            <token id="6" string="now" />
            <token id="7" string="used" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
          </tokens>
        </chunking>
        <chunking id="13" string="now used to make bulletproof vests" type="VP">
          <tokens>
            <token id="6" string="now" />
            <token id="7" string="used" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
          </tokens>
        </chunking>
        <chunking id="14" string="could be used to make some body parts" type="VP">
          <tokens>
            <token id="14" string="could" />
            <token id="15" string="be" />
            <token id="16" string="used" />
            <token id="17" string="to" />
            <token id="18" string="make" />
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="15" string="is working with Duke University researchers on ceramic `` stents , '' collapsible braces for arteries" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="working" />
            <token id="27" string="with" />
            <token id="28" string="Duke" />
            <token id="29" string="University" />
            <token id="30" string="researchers" />
            <token id="31" string="on" />
            <token id="32" string="ceramic" />
            <token id="33" string="``" />
            <token id="34" string="stents" />
            <token id="35" string="," />
            <token id="36" string="''" />
            <token id="37" string="collapsible" />
            <token id="38" string="braces" />
            <token id="39" string="for" />
            <token id="40" string="arteries" />
          </tokens>
        </chunking>
        <chunking id="16" string="collapsible braces for arteries" type="NP">
          <tokens>
            <token id="37" string="collapsible" />
            <token id="38" string="braces" />
            <token id="39" string="for" />
            <token id="40" string="arteries" />
          </tokens>
        </chunking>
        <chunking id="17" string="some body parts" type="NP">
          <tokens>
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="18" string="collapsible braces" type="NP">
          <tokens>
            <token id="37" string="collapsible" />
            <token id="38" string="braces" />
          </tokens>
        </chunking>
        <chunking id="19" string="to make some body parts" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="make" />
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="20" string="ceramic `` stents , '' collapsible braces for arteries" type="NP">
          <tokens>
            <token id="32" string="ceramic" />
            <token id="33" string="``" />
            <token id="34" string="stents" />
            <token id="35" string="," />
            <token id="36" string="''" />
            <token id="37" string="collapsible" />
            <token id="38" string="braces" />
            <token id="39" string="for" />
            <token id="40" string="arteries" />
          </tokens>
        </chunking>
        <chunking id="21" string="The fibers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fibers" />
          </tokens>
        </chunking>
        <chunking id="22" string="make some body parts" type="VP">
          <tokens>
            <token id="18" string="make" />
            <token id="19" string="some" />
            <token id="20" string="body" />
            <token id="21" string="parts" />
          </tokens>
        </chunking>
        <chunking id="23" string="bulletproof vests" type="NP">
          <tokens>
            <token id="10" string="bulletproof" />
            <token id="11" string="vests" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">fibers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">used</governor>
          <dependent id="2">fibers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Kevlar</governor>
          <dependent id="4">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">fibers</governor>
          <dependent id="5">Kevlar</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">used</governor>
          <dependent id="6">now</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">Kevlar</governor>
          <dependent id="7">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">make</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">used</governor>
          <dependent id="9">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">vests</governor>
          <dependent id="10">bulletproof</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">make</governor>
          <dependent id="11">vests</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">used</governor>
          <dependent id="13">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">used</governor>
          <dependent id="14">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">used</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">make</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">used</governor>
          <dependent id="18">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">parts</governor>
          <dependent id="19">some</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">parts</governor>
          <dependent id="20">body</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">make</governor>
          <dependent id="21">parts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">used</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">working</governor>
          <dependent id="24">El-Shiekh</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">working</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">used</governor>
          <dependent id="26">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">researchers</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">researchers</governor>
          <dependent id="28">Duke</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">researchers</governor>
          <dependent id="29">University</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">working</governor>
          <dependent id="30">researchers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">stents</governor>
          <dependent id="31">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">stents</governor>
          <dependent id="32">ceramic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">working</governor>
          <dependent id="34">stents</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">braces</governor>
          <dependent id="37">collapsible</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">stents</governor>
          <dependent id="38">braces</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">arteries</governor>
          <dependent id="39">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">braces</governor>
          <dependent id="40">arteries</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Duke University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Duke" />
            <token id="29" string="University" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>``The possibilities are limitless.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="possibilities" lemma="possibility" stem="possibl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="limitless" lemma="limitless" stem="limitless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (NNS possibilities)) (VP (VBP are) (ADJP (JJ limitless))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="limitless" type="ADJP">
          <tokens>
            <token id="5" string="limitless" />
          </tokens>
        </chunking>
        <chunking id="2" string="The possibilities" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="possibilities" />
          </tokens>
        </chunking>
        <chunking id="3" string="are limitless" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="limitless" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">possibilities</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">limitless</governor>
          <dependent id="3">possibilities</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">limitless</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">limitless</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>said El-Shiekh, who can produce shapes ranging from hollow cubes to panels that have openings for wiring and conduits already braided into them.</content>
      <tokens>
        <token id="1" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="El-Shiekh" lemma="El-Shiekh" stem="el-shiekh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="produce" lemma="produce" stem="produc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="shapes" lemma="shape" stem="shape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="ranging" lemma="range" stem="rang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hollow" lemma="hollow" stem="hollow" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="cubes" lemma="cube" stem="cube" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="panels" lemma="panel" stem="panel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="openings" lemma="opening" stem="open" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="wiring" lemma="wiring" stem="wire" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="conduits" lemma="conduit" stem="conduit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="braided" lemma="braid" stem="braid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (VP (VBD said)) (NP (NP (NNP El-Shiekh)) (, ,) (SBAR (WHNP (WP who)) (S (VP (MD can) (VP (VB produce) (NP (NNS shapes))))))) (S (S (VP (VBG ranging) (PP (IN from) (NP (JJ hollow) (NNS cubes))) (PP (TO to) (NP (NP (NNS panels)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (NNS openings)) (PP (IN for) (NP (NN wiring))))))))))) (CC and) (S (NP (NNS conduits)) (ADVP (RB already)) (VP (VBD braided) (PP (IN into) (NP (PRP them)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="conduits" type="NP">
          <tokens>
            <token id="20" string="conduits" />
          </tokens>
        </chunking>
        <chunking id="2" string="El-Shiekh , who can produce shapes" type="NP">
          <tokens>
            <token id="2" string="El-Shiekh" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="can" />
            <token id="6" string="produce" />
            <token id="7" string="shapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="El-Shiekh" type="NP">
          <tokens>
            <token id="2" string="El-Shiekh" />
          </tokens>
        </chunking>
        <chunking id="4" string="ranging from hollow cubes to panels that have openings for wiring" type="VP">
          <tokens>
            <token id="8" string="ranging" />
            <token id="9" string="from" />
            <token id="10" string="hollow" />
            <token id="11" string="cubes" />
            <token id="12" string="to" />
            <token id="13" string="panels" />
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="openings" />
            <token id="17" string="for" />
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
        <chunking id="5" string="panels" type="NP">
          <tokens>
            <token id="13" string="panels" />
          </tokens>
        </chunking>
        <chunking id="6" string="that have openings for wiring" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="openings" />
            <token id="17" string="for" />
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
        <chunking id="7" string="can produce shapes" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="produce" />
            <token id="7" string="shapes" />
          </tokens>
        </chunking>
        <chunking id="8" string="openings for wiring" type="NP">
          <tokens>
            <token id="16" string="openings" />
            <token id="17" string="for" />
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
        <chunking id="9" string="who can produce shapes" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="can" />
            <token id="6" string="produce" />
            <token id="7" string="shapes" />
          </tokens>
        </chunking>
        <chunking id="10" string="wiring" type="NP">
          <tokens>
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
        <chunking id="11" string="them" type="NP">
          <tokens>
            <token id="24" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="panels that have openings for wiring" type="NP">
          <tokens>
            <token id="13" string="panels" />
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="openings" />
            <token id="17" string="for" />
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
        <chunking id="13" string="braided into them" type="VP">
          <tokens>
            <token id="22" string="braided" />
            <token id="23" string="into" />
            <token id="24" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="openings" type="NP">
          <tokens>
            <token id="16" string="openings" />
          </tokens>
        </chunking>
        <chunking id="15" string="hollow cubes" type="NP">
          <tokens>
            <token id="10" string="hollow" />
            <token id="11" string="cubes" />
          </tokens>
        </chunking>
        <chunking id="16" string="shapes" type="NP">
          <tokens>
            <token id="7" string="shapes" />
          </tokens>
        </chunking>
        <chunking id="17" string="produce shapes" type="VP">
          <tokens>
            <token id="6" string="produce" />
            <token id="7" string="shapes" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="1" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="have openings for wiring" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="openings" />
            <token id="17" string="for" />
            <token id="18" string="wiring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="1">said</governor>
          <dependent id="2">El-Shiekh</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">produce</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">produce</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">El-Shiekh</governor>
          <dependent id="6">produce</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">produce</governor>
          <dependent id="7">shapes</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">said</governor>
          <dependent id="8">ranging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">cubes</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">cubes</governor>
          <dependent id="10">hollow</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">ranging</governor>
          <dependent id="11">cubes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">panels</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">ranging</governor>
          <dependent id="13">panels</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">panels</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">have</governor>
          <dependent id="16">openings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">wiring</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">openings</governor>
          <dependent id="18">wiring</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">ranging</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">braided</governor>
          <dependent id="20">conduits</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">braided</governor>
          <dependent id="21">already</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">ranging</governor>
          <dependent id="22">braided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">them</governor>
          <dependent id="23">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">braided</governor>
          <dependent id="24">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="El-Shiekh" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="El-Shiekh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>``The big problem is cost and that&amp;apost;s why we&amp;apost;re working on this automated machinery.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="automated" lemma="automate" stem="autom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="machinery" lemma="machinery" stem="machineri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ big) (NN problem)) (VP (VBZ is) (NP (NN cost)))) (CC and) (S (NP (DT that)) (VP (VBZ 's) (SBAR (WHADVP (WRB why)) (S (NP (PRP we)) (VP (VBP 're) (VP (VBG working) (PP (IN on) (NP (DT this) (VBN automated) (NN machinery))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="8" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="cost" type="NP">
          <tokens>
            <token id="6" string="cost" />
          </tokens>
        </chunking>
        <chunking id="3" string="working on this automated machinery" type="VP">
          <tokens>
            <token id="13" string="working" />
            <token id="14" string="on" />
            <token id="15" string="this" />
            <token id="16" string="automated" />
            <token id="17" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="4" string="this automated machinery" type="NP">
          <tokens>
            <token id="15" string="this" />
            <token id="16" string="automated" />
            <token id="17" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s why we 're working on this automated machinery" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="why" />
            <token id="11" string="we" />
            <token id="12" string="'re" />
            <token id="13" string="working" />
            <token id="14" string="on" />
            <token id="15" string="this" />
            <token id="16" string="automated" />
            <token id="17" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="6" string="why" type="WHADVP">
          <tokens>
            <token id="10" string="why" />
          </tokens>
        </chunking>
        <chunking id="7" string="why we 're working on this automated machinery" type="SBAR">
          <tokens>
            <token id="10" string="why" />
            <token id="11" string="we" />
            <token id="12" string="'re" />
            <token id="13" string="working" />
            <token id="14" string="on" />
            <token id="15" string="this" />
            <token id="16" string="automated" />
            <token id="17" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="8" string="The big problem" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="big" />
            <token id="4" string="problem" />
          </tokens>
        </chunking>
        <chunking id="9" string="'re working on this automated machinery" type="VP">
          <tokens>
            <token id="12" string="'re" />
            <token id="13" string="working" />
            <token id="14" string="on" />
            <token id="15" string="this" />
            <token id="16" string="automated" />
            <token id="17" string="machinery" />
          </tokens>
        </chunking>
        <chunking id="10" string="we" type="NP">
          <tokens>
            <token id="11" string="we" />
          </tokens>
        </chunking>
        <chunking id="11" string="is cost" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="cost" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">problem</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">problem</governor>
          <dependent id="3">big</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">cost</governor>
          <dependent id="4">problem</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">cost</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">cost</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">cost</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">'s</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">cost</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">working</governor>
          <dependent id="10">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">working</governor>
          <dependent id="11">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">working</governor>
          <dependent id="12">'re</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">'s</governor>
          <dependent id="13">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">machinery</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">machinery</governor>
          <dependent id="15">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">machinery</governor>
          <dependent id="16">automated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">working</governor>
          <dependent id="17">machinery</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>It&amp;apost;s 8 p.m. and a dozen people wait in the lobby of Boston City Hospital&amp;apost;s emergency room.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="4" string="p.m." lemma="p.m." stem="p.m." pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="dozen" lemma="dozen" stem="dozen" pos="NN" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="wait" lemma="wait" stem="wait" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lobby" lemma="lobby" stem="lobbi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (S (NP (NP (CD 8) (NN p.m.)) (CC and) (NP (QP (DT a) (NN dozen)) (NNS people))) (VP (VB wait) (PP (IN in) (NP (NP (DT the) (NN lobby)) (PP (IN of) (NP (NP (NNP Boston) (NNP City) (NNP Hospital) (POS 's)) (NN emergency) (NN room)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s 8 p.m. and a dozen people wait in the lobby of Boston City Hospital 's emergency room" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="8" />
            <token id="4" string="p.m." />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="dozen" />
            <token id="8" string="people" />
            <token id="9" string="wait" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="lobby" />
            <token id="13" string="of" />
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
            <token id="17" string="'s" />
            <token id="18" string="emergency" />
            <token id="19" string="room" />
          </tokens>
        </chunking>
        <chunking id="2" string="Boston City Hospital 's" type="NP">
          <tokens>
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="8 p.m." type="NP">
          <tokens>
            <token id="3" string="8" />
            <token id="4" string="p.m." />
          </tokens>
        </chunking>
        <chunking id="4" string="the lobby" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="lobby" />
          </tokens>
        </chunking>
        <chunking id="5" string="wait in the lobby of Boston City Hospital 's emergency room" type="VP">
          <tokens>
            <token id="9" string="wait" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="lobby" />
            <token id="13" string="of" />
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
            <token id="17" string="'s" />
            <token id="18" string="emergency" />
            <token id="19" string="room" />
          </tokens>
        </chunking>
        <chunking id="6" string="a dozen people" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="dozen" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="8 p.m. and a dozen people" type="NP">
          <tokens>
            <token id="3" string="8" />
            <token id="4" string="p.m." />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="dozen" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="the lobby of Boston City Hospital 's emergency room" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="lobby" />
            <token id="13" string="of" />
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
            <token id="17" string="'s" />
            <token id="18" string="emergency" />
            <token id="19" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="Boston City Hospital 's emergency room" type="NP">
          <tokens>
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
            <token id="17" string="'s" />
            <token id="18" string="emergency" />
            <token id="19" string="room" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">p.m.</governor>
          <dependent id="3">8</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">wait</governor>
          <dependent id="4">p.m.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">p.m.</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">dozen</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">people</governor>
          <dependent id="7">dozen</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">p.m.</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">'s</governor>
          <dependent id="9">wait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">lobby</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">lobby</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">wait</governor>
          <dependent id="12">lobby</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">room</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Hospital</governor>
          <dependent id="14">Boston</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Hospital</governor>
          <dependent id="15">City</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">room</governor>
          <dependent id="16">Hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Hospital</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">room</governor>
          <dependent id="18">emergency</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">lobby</governor>
          <dependent id="19">room</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="dozen" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="dozen" />
          </tokens>
        </entity>
        <entity id="2" string="Boston City Hospital" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Boston" />
            <token id="15" string="City" />
            <token id="16" string="Hospital" />
          </tokens>
        </entity>
        <entity id="3" string="8 p.m." type="TIME" score="0.0">
          <tokens>
            <token id="3" string="8" />
            <token id="4" string="p.m." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>Behind the swinging doors, Dr. Peter Moyer is called to a car accident victim who has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians.</content>
      <tokens>
        <token id="1" string="Behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="swinging" lemma="swing" stem="swing" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="doors" lemma="door" stem="door" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Moyer" lemma="Moyer" stem="moyer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="accident" lemma="accident" stem="accid" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="slight" lemma="slight" stem="slight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="slips" lemma="slip" stem="slip" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="deeply" lemma="deeply" stem="deepli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="unconsciousness" lemma="unconsciousness" stem="unconsci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="barely" lemma="barely" stem="bare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="roused" lemma="rouse" stem="rous" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="34" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Behind) (NP (DT the) (VBG swinging) (NNS doors))) (, ,) (NP (NNP Dr.) (NNP Peter) (NNP Moyer)) (VP (VBZ is) (VP (VBN called) (PP (TO to) (NP (NP (DT a) (NN car) (NN accident) (NN victim)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ has) (NP (RB only) (JJ slight) (NNS injuries))) (CC but) (VP (VBZ slips) (ADVP (RB so) (RB deeply) (PP (IN into) (NP (NP (NN unconsciousness)) (SBAR (S (NP (PRP he)) (VP (MD can) (ADVP (RB barely)) (VP (VB be) (VP (VBN roused) (PP (IN by) (NP (CD two) (NNS physicians))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="called to a car accident victim who has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians" type="VP">
          <tokens>
            <token id="10" string="called" />
            <token id="11" string="to" />
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="accident" />
            <token id="15" string="victim" />
            <token id="16" string="who" />
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
            <token id="21" string="but" />
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="2" string="unconsciousness he can barely be roused by two physicians" type="NP">
          <tokens>
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="3" string="two physicians" type="NP">
          <tokens>
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="4" string="the swinging doors" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="swinging" />
            <token id="4" string="doors" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dr. Peter Moyer" type="NP">
          <tokens>
            <token id="6" string="Dr." />
            <token id="7" string="Peter" />
            <token id="8" string="Moyer" />
          </tokens>
        </chunking>
        <chunking id="6" string="who has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
            <token id="21" string="but" />
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="7" string="a car accident victim who has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="accident" />
            <token id="15" string="victim" />
            <token id="16" string="who" />
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
            <token id="21" string="but" />
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="8" string="only slight injuries" type="NP">
          <tokens>
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="9" string="can barely be roused by two physicians" type="VP">
          <tokens>
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="10" string="a car accident victim" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="accident" />
            <token id="15" string="victim" />
          </tokens>
        </chunking>
        <chunking id="11" string="he can barely be roused by two physicians" type="SBAR">
          <tokens>
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="12" string="unconsciousness" type="NP">
          <tokens>
            <token id="26" string="unconsciousness" />
          </tokens>
        </chunking>
        <chunking id="13" string="roused by two physicians" type="VP">
          <tokens>
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="14" string="slips so deeply into unconsciousness he can barely be roused by two physicians" type="VP">
          <tokens>
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="15" string="is called to a car accident victim who has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="called" />
            <token id="11" string="to" />
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="accident" />
            <token id="15" string="victim" />
            <token id="16" string="who" />
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
            <token id="21" string="but" />
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="16" string="has only slight injuries" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="17" string="has only slight injuries but slips so deeply into unconsciousness he can barely be roused by two physicians" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="only" />
            <token id="19" string="slight" />
            <token id="20" string="injuries" />
            <token id="21" string="but" />
            <token id="22" string="slips" />
            <token id="23" string="so" />
            <token id="24" string="deeply" />
            <token id="25" string="into" />
            <token id="26" string="unconsciousness" />
            <token id="27" string="he" />
            <token id="28" string="can" />
            <token id="29" string="barely" />
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="be roused by two physicians" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="roused" />
            <token id="32" string="by" />
            <token id="33" string="two" />
            <token id="34" string="physicians" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">doors</governor>
          <dependent id="1">Behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">doors</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">doors</governor>
          <dependent id="3">swinging</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">called</governor>
          <dependent id="4">doors</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Moyer</governor>
          <dependent id="6">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Moyer</governor>
          <dependent id="7">Peter</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">called</governor>
          <dependent id="8">Moyer</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">called</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">victim</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">victim</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">victim</governor>
          <dependent id="13">car</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">victim</governor>
          <dependent id="14">accident</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">called</governor>
          <dependent id="15">victim</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">has</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">victim</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">injuries</governor>
          <dependent id="18">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">injuries</governor>
          <dependent id="19">slight</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">has</governor>
          <dependent id="20">injuries</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">has</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">has</governor>
          <dependent id="22">slips</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">deeply</governor>
          <dependent id="23">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">slips</governor>
          <dependent id="24">deeply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">unconsciousness</governor>
          <dependent id="25">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">deeply</governor>
          <dependent id="26">unconsciousness</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">roused</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">roused</governor>
          <dependent id="28">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">roused</governor>
          <dependent id="29">barely</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">roused</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">unconsciousness</governor>
          <dependent id="31">roused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">physicians</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="34">physicians</governor>
          <dependent id="33">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">roused</governor>
          <dependent id="34">physicians</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peter Moyer" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Peter" />
            <token id="8" string="Moyer" />
          </tokens>
        </entity>
        <entity id="2" string="car accident" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="car" />
            <token id="14" string="accident" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="33" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>``Have you taken any drugs?&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="7" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (VP (VBP Have))) (ADVP (PRP you)) (VP (VBN taken) (NP (DT any) (NNS drugs)))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="taken any drugs" type="VP">
          <tokens>
            <token id="4" string="taken" />
            <token id="5" string="any" />
            <token id="6" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="Have" type="VP">
          <tokens>
            <token id="2" string="Have" />
          </tokens>
        </chunking>
        <chunking id="3" string="any drugs" type="NP">
          <tokens>
            <token id="5" string="any" />
            <token id="6" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="4">taken</governor>
          <dependent id="2">Have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">taken</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">taken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">drugs</governor>
          <dependent id="5">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">taken</governor>
          <dependent id="6">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>doctors ask.</content>
      <tokens>
        <token id="1" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="ask" lemma="ask" stem="ask" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS doctors)) (VP (VBP ask)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="doctors" type="NP">
          <tokens>
            <token id="1" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="2" string="ask" type="VP">
          <tokens>
            <token id="2" string="ask" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">ask</governor>
          <dependent id="1">doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">ask</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``Cocaine, heroin, marijuana?&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Cocaine" lemma="cocaine" stem="cocain" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="heroin" lemma="heroin" stem="heroin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="marijuana" lemma="marijuana" stem="marijuana" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (`` ``) (NN Cocaine)) (, ,) (NP (NN heroin)) (, ,) (NP (NN marijuana))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Cocaine" type="NP">
          <tokens>
            <token id="1" string="``" />
            <token id="2" string="Cocaine" />
          </tokens>
        </chunking>
        <chunking id="2" string="heroin" type="NP">
          <tokens>
            <token id="4" string="heroin" />
          </tokens>
        </chunking>
        <chunking id="3" string="marijuana" type="NP">
          <tokens>
            <token id="6" string="marijuana" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` Cocaine , heroin , marijuana" type="NP">
          <tokens>
            <token id="1" string="``" />
            <token id="2" string="Cocaine" />
            <token id="3" string="," />
            <token id="4" string="heroin" />
            <token id="5" string="," />
            <token id="6" string="marijuana" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Cocaine</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Cocaine</governor>
          <dependent id="4">heroin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Cocaine</governor>
          <dependent id="6">marijuana</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>It&amp;apost;s a question that has become more and more commonplace in emergency rooms already burdened by increased patient loads.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="commonplace" lemma="commonplace" stem="commonplac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="rooms" lemma="room" stem="room" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="burdened" lemma="burden" stem="burden" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="increased" lemma="increase" stem="increas" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="loads" lemma="load" stem="load" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (NP (NP (DT a) (NN question)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN become) (ADJP (ADVP (RBR more) (CC and) (RBR more)) (JJ commonplace)) (PP (IN in) (NP (NP (NN emergency) (NNS rooms)) (VP (ADVP (RB already)) (VBN burdened) (PP (IN by) (NP (VBN increased) (NN patient) (NNS loads)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that has become more and more commonplace in emergency rooms already burdened by increased patient loads" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="has" />
            <token id="7" string="become" />
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
            <token id="12" string="in" />
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="2" string="emergency rooms already burdened by increased patient loads" type="NP">
          <tokens>
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="3" string="more and more commonplace" type="ADJP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
          </tokens>
        </chunking>
        <chunking id="4" string="increased patient loads" type="NP">
          <tokens>
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="5" string="emergency rooms" type="NP">
          <tokens>
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="6" string="a question" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="question" />
          </tokens>
        </chunking>
        <chunking id="7" string="has become more and more commonplace in emergency rooms already burdened by increased patient loads" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="become" />
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
            <token id="12" string="in" />
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="8" string="become more and more commonplace in emergency rooms already burdened by increased patient loads" type="VP">
          <tokens>
            <token id="7" string="become" />
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
            <token id="12" string="in" />
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="9" string="already burdened by increased patient loads" type="VP">
          <tokens>
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="10" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="11" string="a question that has become more and more commonplace in emergency rooms already burdened by increased patient loads" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="question" />
            <token id="5" string="that" />
            <token id="6" string="has" />
            <token id="7" string="become" />
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
            <token id="12" string="in" />
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s a question that has become more and more commonplace in emergency rooms already burdened by increased patient loads" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="question" />
            <token id="5" string="that" />
            <token id="6" string="has" />
            <token id="7" string="become" />
            <token id="8" string="more" />
            <token id="9" string="and" />
            <token id="10" string="more" />
            <token id="11" string="commonplace" />
            <token id="12" string="in" />
            <token id="13" string="emergency" />
            <token id="14" string="rooms" />
            <token id="15" string="already" />
            <token id="16" string="burdened" />
            <token id="17" string="by" />
            <token id="18" string="increased" />
            <token id="19" string="patient" />
            <token id="20" string="loads" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">question</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">question</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">question</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">question</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">become</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">become</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">question</governor>
          <dependent id="7">become</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">commonplace</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">more</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">more</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">become</governor>
          <dependent id="11">commonplace</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">rooms</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">rooms</governor>
          <dependent id="13">emergency</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">become</governor>
          <dependent id="14">rooms</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">burdened</governor>
          <dependent id="15">already</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">rooms</governor>
          <dependent id="16">burdened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">loads</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">loads</governor>
          <dependent id="18">increased</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">loads</governor>
          <dependent id="19">patient</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">burdened</governor>
          <dependent id="20">loads</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>``There is an emergency in the emergency room right now in not only New York and Boston but around the country and for a variety of reasons,&amp;apost;&amp;apost; said Ken Raske, president of the Greater New York Hospital Association.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="variety" lemma="variety" stem="varieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Ken" lemma="Ken" stem="ken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="Raske" lemma="Raske" stem="rask" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Greater" lemma="Greater" stem="greater" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="39" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="40" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="41" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="42" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (EX There)) (VP (VBZ is) (NP (NP (DT an) (NN emergency)) (PP (IN in) (NP (NP (DT the) (NN emergency) (NN room)) (PP (PP (ADVP (RB right) (RB now)) (IN in) (NP (NP (RB not) (JJ only) (NNP New) (NNP York)) (CC and) (NP (NNP Boston)))) (CC but) (PP (IN around) (NP (DT the) (NN country))) (CC and) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS reasons))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Ken) (NNP Raske)) (, ,) (NP (NP (NN president)) (PP (IN of) (NP (DT the) (NNP Greater) (NNP New) (NNP York) (NNP Hospital) (NNP Association))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="not only New York and Boston" type="NP">
          <tokens>
            <token id="13" string="not" />
            <token id="14" string="only" />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="and" />
            <token id="18" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="2" string="not only New York" type="NP">
          <tokens>
            <token id="13" string="not" />
            <token id="14" string="only" />
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </chunking>
        <chunking id="3" string="president" type="NP">
          <tokens>
            <token id="35" string="president" />
          </tokens>
        </chunking>
        <chunking id="4" string="is an emergency in the emergency room right now in not only New York and Boston but around the country and for a variety of reasons" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="an" />
            <token id="5" string="emergency" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="emergency" />
            <token id="9" string="room" />
            <token id="10" string="right" />
            <token id="11" string="now" />
            <token id="12" string="in" />
            <token id="13" string="not" />
            <token id="14" string="only" />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="and" />
            <token id="18" string="Boston" />
            <token id="19" string="but" />
            <token id="20" string="around" />
            <token id="21" string="the" />
            <token id="22" string="country" />
            <token id="23" string="and" />
            <token id="24" string="for" />
            <token id="25" string="a" />
            <token id="26" string="variety" />
            <token id="27" string="of" />
            <token id="28" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="5" string="reasons" type="NP">
          <tokens>
            <token id="28" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="6" string="an emergency" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="emergency" />
          </tokens>
        </chunking>
        <chunking id="7" string="president of the Greater New York Hospital Association" type="NP">
          <tokens>
            <token id="35" string="president" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="Greater" />
            <token id="39" string="New" />
            <token id="40" string="York" />
            <token id="41" string="Hospital" />
            <token id="42" string="Association" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ken Raske" type="NP">
          <tokens>
            <token id="32" string="Ken" />
            <token id="33" string="Raske" />
          </tokens>
        </chunking>
        <chunking id="9" string="the emergency room" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="emergency" />
            <token id="9" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="the emergency room right now in not only New York and Boston but around the country and for a variety of reasons" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="emergency" />
            <token id="9" string="room" />
            <token id="10" string="right" />
            <token id="11" string="now" />
            <token id="12" string="in" />
            <token id="13" string="not" />
            <token id="14" string="only" />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="and" />
            <token id="18" string="Boston" />
            <token id="19" string="but" />
            <token id="20" string="around" />
            <token id="21" string="the" />
            <token id="22" string="country" />
            <token id="23" string="and" />
            <token id="24" string="for" />
            <token id="25" string="a" />
            <token id="26" string="variety" />
            <token id="27" string="of" />
            <token id="28" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="11" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="12" string="a variety of reasons" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="variety" />
            <token id="27" string="of" />
            <token id="28" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="13" string="the country" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="country" />
          </tokens>
        </chunking>
        <chunking id="14" string="a variety" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="variety" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="31" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Greater New York Hospital Association" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="Greater" />
            <token id="39" string="New" />
            <token id="40" string="York" />
            <token id="41" string="Hospital" />
            <token id="42" string="Association" />
          </tokens>
        </chunking>
        <chunking id="17" string="Boston" type="NP">
          <tokens>
            <token id="18" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="18" string="Ken Raske , president of the Greater New York Hospital Association" type="NP">
          <tokens>
            <token id="32" string="Ken" />
            <token id="33" string="Raske" />
            <token id="34" string="," />
            <token id="35" string="president" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="Greater" />
            <token id="39" string="New" />
            <token id="40" string="York" />
            <token id="41" string="Hospital" />
            <token id="42" string="Association" />
          </tokens>
        </chunking>
        <chunking id="19" string="an emergency in the emergency room right now in not only New York and Boston but around the country and for a variety of reasons" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="emergency" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="emergency" />
            <token id="9" string="room" />
            <token id="10" string="right" />
            <token id="11" string="now" />
            <token id="12" string="in" />
            <token id="13" string="not" />
            <token id="14" string="only" />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="and" />
            <token id="18" string="Boston" />
            <token id="19" string="but" />
            <token id="20" string="around" />
            <token id="21" string="the" />
            <token id="22" string="country" />
            <token id="23" string="and" />
            <token id="24" string="for" />
            <token id="25" string="a" />
            <token id="26" string="variety" />
            <token id="27" string="of" />
            <token id="28" string="reasons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">emergency</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">emergency</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">room</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">room</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">room</governor>
          <dependent id="8">emergency</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">emergency</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">room</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">now</governor>
          <dependent id="10">right</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">York</governor>
          <dependent id="11">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">York</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">York</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">York</governor>
          <dependent id="14">only</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">York</governor>
          <dependent id="15">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">room</governor>
          <dependent id="16">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">room</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">York</governor>
          <dependent id="18">Boston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">room</governor>
          <dependent id="19">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">country</governor>
          <dependent id="20">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">country</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">room</governor>
          <dependent id="22">country</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">room</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">variety</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">variety</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">room</governor>
          <dependent id="26">variety</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">reasons</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">variety</governor>
          <dependent id="28">reasons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Raske</governor>
          <dependent id="32">Ken</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="33">Raske</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="33">Raske</governor>
          <dependent id="35">president</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">Association</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">Association</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Association</governor>
          <dependent id="38">Greater</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Association</governor>
          <dependent id="39">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Association</governor>
          <dependent id="40">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Association</governor>
          <dependent id="41">Hospital</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">president</governor>
          <dependent id="42">Association</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right now" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="right" />
            <token id="11" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </entity>
        <entity id="3" string="Ken Raske" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Ken" />
            <token id="33" string="Raske" />
          </tokens>
        </entity>
        <entity id="4" string="Greater New York Hospital Association" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="38" string="Greater" />
            <token id="39" string="New" />
            <token id="40" string="York" />
            <token id="41" string="Hospital" />
            <token id="42" string="Association" />
          </tokens>
        </entity>
        <entity id="5" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Drugs, and their side effects of AIDS, violence and psychiatric disorders, play a role in the problems plaguing big-city emergency rooms, Raske said.</content>
      <tokens>
        <token id="1" string="Drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="side" lemma="side" stem="side" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="effects" lemma="effect" stem="effect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="AIDS" lemma="AIDS" stem="aids" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="psychiatric" lemma="psychiatric" stem="psychiatr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="disorders" lemma="disorder" stem="disord" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="plaguing" lemma="plague" stem="plagu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="big-city" lemma="big-city" stem="big-citi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="rooms" lemma="room" stem="room" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Raske" lemma="Raske" stem="rask" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNS Drugs)) (, ,) (CC and) (NP (NP (PRP$ their) (JJ side) (NNS effects)) (PP (IN of) (NP (NP (NNP AIDS)) (, ,) (NP (NN violence)) (CC and) (NP (JJ psychiatric) (NNS disorders))))) (, ,)) (VP (VBP play) (NP (NP (DT a) (NN role)) (PP (IN in) (NP (NP (DT the) (NNS problems)) (VP (VBG plaguing) (NP (JJ big-city) (NN emergency) (NNS rooms)))))))) (, ,) (NP (NNP Raske)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Drugs" type="NP">
          <tokens>
            <token id="1" string="Drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="a role in the problems plaguing big-city emergency rooms" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="role" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="problems" />
            <token id="21" string="plaguing" />
            <token id="22" string="big-city" />
            <token id="23" string="emergency" />
            <token id="24" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="3" string="the problems plaguing big-city emergency rooms" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="problems" />
            <token id="21" string="plaguing" />
            <token id="22" string="big-city" />
            <token id="23" string="emergency" />
            <token id="24" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="4" string="AIDS" type="NP">
          <tokens>
            <token id="8" string="AIDS" />
          </tokens>
        </chunking>
        <chunking id="5" string="big-city emergency rooms" type="NP">
          <tokens>
            <token id="22" string="big-city" />
            <token id="23" string="emergency" />
            <token id="24" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="6" string="a role" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="role" />
          </tokens>
        </chunking>
        <chunking id="7" string="their side effects of AIDS , violence and psychiatric disorders" type="NP">
          <tokens>
            <token id="4" string="their" />
            <token id="5" string="side" />
            <token id="6" string="effects" />
            <token id="7" string="of" />
            <token id="8" string="AIDS" />
            <token id="9" string="," />
            <token id="10" string="violence" />
            <token id="11" string="and" />
            <token id="12" string="psychiatric" />
            <token id="13" string="disorders" />
          </tokens>
        </chunking>
        <chunking id="8" string="Raske" type="NP">
          <tokens>
            <token id="26" string="Raske" />
          </tokens>
        </chunking>
        <chunking id="9" string="plaguing big-city emergency rooms" type="VP">
          <tokens>
            <token id="21" string="plaguing" />
            <token id="22" string="big-city" />
            <token id="23" string="emergency" />
            <token id="24" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="10" string="their side effects" type="NP">
          <tokens>
            <token id="4" string="their" />
            <token id="5" string="side" />
            <token id="6" string="effects" />
          </tokens>
        </chunking>
        <chunking id="11" string="the problems" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="problems" />
          </tokens>
        </chunking>
        <chunking id="12" string="play a role in the problems plaguing big-city emergency rooms" type="VP">
          <tokens>
            <token id="15" string="play" />
            <token id="16" string="a" />
            <token id="17" string="role" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="problems" />
            <token id="21" string="plaguing" />
            <token id="22" string="big-city" />
            <token id="23" string="emergency" />
            <token id="24" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="13" string="psychiatric disorders" type="NP">
          <tokens>
            <token id="12" string="psychiatric" />
            <token id="13" string="disorders" />
          </tokens>
        </chunking>
        <chunking id="14" string="AIDS , violence and psychiatric disorders" type="NP">
          <tokens>
            <token id="8" string="AIDS" />
            <token id="9" string="," />
            <token id="10" string="violence" />
            <token id="11" string="and" />
            <token id="12" string="psychiatric" />
            <token id="13" string="disorders" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="27" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="Drugs , and their side effects of AIDS , violence and psychiatric disorders ," type="NP">
          <tokens>
            <token id="1" string="Drugs" />
            <token id="2" string="," />
            <token id="3" string="and" />
            <token id="4" string="their" />
            <token id="5" string="side" />
            <token id="6" string="effects" />
            <token id="7" string="of" />
            <token id="8" string="AIDS" />
            <token id="9" string="," />
            <token id="10" string="violence" />
            <token id="11" string="and" />
            <token id="12" string="psychiatric" />
            <token id="13" string="disorders" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="violence" type="NP">
          <tokens>
            <token id="10" string="violence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">play</governor>
          <dependent id="1">Drugs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Drugs</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">effects</governor>
          <dependent id="4">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">effects</governor>
          <dependent id="5">side</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Drugs</governor>
          <dependent id="6">effects</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">AIDS</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">effects</governor>
          <dependent id="8">AIDS</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">AIDS</governor>
          <dependent id="10">violence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">AIDS</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">disorders</governor>
          <dependent id="12">psychiatric</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">AIDS</governor>
          <dependent id="13">disorders</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="15">play</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">role</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">play</governor>
          <dependent id="17">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">problems</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">problems</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">role</governor>
          <dependent id="20">problems</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">problems</governor>
          <dependent id="21">plaguing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">rooms</governor>
          <dependent id="22">big-city</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">rooms</governor>
          <dependent id="23">emergency</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">plaguing</governor>
          <dependent id="24">rooms</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">Raske</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="AIDS" />
          </tokens>
        </entity>
        <entity id="2" string="Raske" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Raske" />
          </tokens>
        </entity>
        <entity id="3" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>From 1986 to 1987, according to the National Institute on Drug Abuse, cocaine-related cases in emergency rooms increased 122 percent in the District of Columbia; 86 percent in both Boston and Atlanta; 80 percent in Detroit; 73 percent in Chicago; 53 percent in Minneapolis; 50 percent in Texas, and 39 percent in New York City.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Drug" lemma="Drug" stem="drug" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Abuse" lemma="abuse" stem="abuse" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="cocaine-related" lemma="cocaine-related" stem="cocaine-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="rooms" lemma="room" stem="room" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="increased" lemma="increase" stem="increas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="122" lemma="122" stem="122" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="22" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Columbia" lemma="Columbia" stem="columbia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="86" lemma="86" stem="86" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="30" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Atlanta" lemma="Atlanta" stem="atlanta" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="36" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="80" lemma="80" stem="80" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="38" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Detroit" lemma="Detroit" stem="detroit" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="41" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="73" lemma="73" stem="73" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="43" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Chicago" lemma="Chicago" stem="chicago" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="46" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="53" lemma="53" stem="53" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="48" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="49" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="Minneapolis" lemma="Minneapolis" stem="minneapoli" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="51" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="53" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="54" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="56" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="39" lemma="39" stem="39" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="59" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="60" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="62" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="63" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="64" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (CD 1986) (TO to) (CD 1987))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (NAC (NNP National) (NNP Institute) (PP (IN on) (NP (NNP Drug)))) (NN Abuse)))) (, ,) (NP (NP (JJ cocaine-related) (NNS cases)) (PP (IN in) (NP (NN emergency) (NNS rooms)))) (VP (VBD increased) (NP (NP (NP (NP (CD 122) (NN percent)) (PP (IN in) (NP (NP (DT the) (NNP District)) (PP (IN of) (NP (NNP Columbia)))))) (: ;) (NP (NP (CD 86) (NN percent)) (PP (IN in) (NP (CC both) (NP (NNP Boston)) (CC and) (NP (NNP Atlanta))))) (: ;) (NP (NP (CD 80) (NN percent)) (PP (IN in) (NP (NNP Detroit)))) (: ;) (NP (NP (CD 73) (NN percent)) (PP (IN in) (NP (NNP Chicago)))) (: ;) (NP (NP (CD 53) (NN percent)) (PP (IN in) (NP (NNP Minneapolis)))) (: ;) (NP (NP (CD 50) (NN percent)) (PP (IN in) (NP (NNP Texas))))) (, ,) (CC and) (NP (NP (CD 39) (NN percent)) (PP (IN in) (NP (NNP New) (NNP York) (NNP City)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Chicago" type="NP">
          <tokens>
            <token id="45" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="2" string="86 percent in both Boston and Atlanta" type="NP">
          <tokens>
            <token id="29" string="86" />
            <token id="30" string="percent" />
            <token id="31" string="in" />
            <token id="32" string="both" />
            <token id="33" string="Boston" />
            <token id="34" string="and" />
            <token id="35" string="Atlanta" />
          </tokens>
        </chunking>
        <chunking id="3" string="122 percent in the District of Columbia" type="NP">
          <tokens>
            <token id="21" string="122" />
            <token id="22" string="percent" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
          </tokens>
        </chunking>
        <chunking id="4" string="80 percent in Detroit" type="NP">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="in" />
            <token id="40" string="Detroit" />
          </tokens>
        </chunking>
        <chunking id="5" string="cocaine-related cases" type="NP">
          <tokens>
            <token id="15" string="cocaine-related" />
            <token id="16" string="cases" />
          </tokens>
        </chunking>
        <chunking id="6" string="Columbia" type="NP">
          <tokens>
            <token id="27" string="Columbia" />
          </tokens>
        </chunking>
        <chunking id="7" string="Texas" type="NP">
          <tokens>
            <token id="55" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="8" string="cocaine-related cases in emergency rooms" type="NP">
          <tokens>
            <token id="15" string="cocaine-related" />
            <token id="16" string="cases" />
            <token id="17" string="in" />
            <token id="18" string="emergency" />
            <token id="19" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="9" string="122 percent in the District of Columbia ; 86 percent in both Boston and Atlanta ; 80 percent in Detroit ; 73 percent in Chicago ; 53 percent in Minneapolis ; 50 percent in Texas , and 39 percent in New York City" type="NP">
          <tokens>
            <token id="21" string="122" />
            <token id="22" string="percent" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
            <token id="28" string=";" />
            <token id="29" string="86" />
            <token id="30" string="percent" />
            <token id="31" string="in" />
            <token id="32" string="both" />
            <token id="33" string="Boston" />
            <token id="34" string="and" />
            <token id="35" string="Atlanta" />
            <token id="36" string=";" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="in" />
            <token id="40" string="Detroit" />
            <token id="41" string=";" />
            <token id="42" string="73" />
            <token id="43" string="percent" />
            <token id="44" string="in" />
            <token id="45" string="Chicago" />
            <token id="46" string=";" />
            <token id="47" string="53" />
            <token id="48" string="percent" />
            <token id="49" string="in" />
            <token id="50" string="Minneapolis" />
            <token id="51" string=";" />
            <token id="52" string="50" />
            <token id="53" string="percent" />
            <token id="54" string="in" />
            <token id="55" string="Texas" />
            <token id="56" string="," />
            <token id="57" string="and" />
            <token id="58" string="39" />
            <token id="59" string="percent" />
            <token id="60" string="in" />
            <token id="61" string="New" />
            <token id="62" string="York" />
            <token id="63" string="City" />
          </tokens>
        </chunking>
        <chunking id="10" string="the National Institute on Drug Abuse" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="National" />
            <token id="10" string="Institute" />
            <token id="11" string="on" />
            <token id="12" string="Drug" />
            <token id="13" string="Abuse" />
          </tokens>
        </chunking>
        <chunking id="11" string="122 percent" type="NP">
          <tokens>
            <token id="21" string="122" />
            <token id="22" string="percent" />
          </tokens>
        </chunking>
        <chunking id="12" string="the District" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="District" />
          </tokens>
        </chunking>
        <chunking id="13" string="73 percent in Chicago" type="NP">
          <tokens>
            <token id="42" string="73" />
            <token id="43" string="percent" />
            <token id="44" string="in" />
            <token id="45" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="14" string="Detroit" type="NP">
          <tokens>
            <token id="40" string="Detroit" />
          </tokens>
        </chunking>
        <chunking id="15" string="emergency rooms" type="NP">
          <tokens>
            <token id="18" string="emergency" />
            <token id="19" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="16" string="both Boston and Atlanta" type="NP">
          <tokens>
            <token id="32" string="both" />
            <token id="33" string="Boston" />
            <token id="34" string="and" />
            <token id="35" string="Atlanta" />
          </tokens>
        </chunking>
        <chunking id="17" string="53 percent" type="NP">
          <tokens>
            <token id="47" string="53" />
            <token id="48" string="percent" />
          </tokens>
        </chunking>
        <chunking id="18" string="39 percent" type="NP">
          <tokens>
            <token id="58" string="39" />
            <token id="59" string="percent" />
          </tokens>
        </chunking>
        <chunking id="19" string="53 percent in Minneapolis" type="NP">
          <tokens>
            <token id="47" string="53" />
            <token id="48" string="percent" />
            <token id="49" string="in" />
            <token id="50" string="Minneapolis" />
          </tokens>
        </chunking>
        <chunking id="20" string="50 percent" type="NP">
          <tokens>
            <token id="52" string="50" />
            <token id="53" string="percent" />
          </tokens>
        </chunking>
        <chunking id="21" string="86 percent" type="NP">
          <tokens>
            <token id="29" string="86" />
            <token id="30" string="percent" />
          </tokens>
        </chunking>
        <chunking id="22" string="50 percent in Texas" type="NP">
          <tokens>
            <token id="52" string="50" />
            <token id="53" string="percent" />
            <token id="54" string="in" />
            <token id="55" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="23" string="80 percent" type="NP">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
          </tokens>
        </chunking>
        <chunking id="24" string="the District of Columbia" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
          </tokens>
        </chunking>
        <chunking id="25" string="Atlanta" type="NP">
          <tokens>
            <token id="35" string="Atlanta" />
          </tokens>
        </chunking>
        <chunking id="26" string="Minneapolis" type="NP">
          <tokens>
            <token id="50" string="Minneapolis" />
          </tokens>
        </chunking>
        <chunking id="27" string="73 percent" type="NP">
          <tokens>
            <token id="42" string="73" />
            <token id="43" string="percent" />
          </tokens>
        </chunking>
        <chunking id="28" string="New York City" type="NP">
          <tokens>
            <token id="61" string="New" />
            <token id="62" string="York" />
            <token id="63" string="City" />
          </tokens>
        </chunking>
        <chunking id="29" string="1986 to 1987" type="NP">
          <tokens>
            <token id="2" string="1986" />
            <token id="3" string="to" />
            <token id="4" string="1987" />
          </tokens>
        </chunking>
        <chunking id="30" string="increased 122 percent in the District of Columbia ; 86 percent in both Boston and Atlanta ; 80 percent in Detroit ; 73 percent in Chicago ; 53 percent in Minneapolis ; 50 percent in Texas , and 39 percent in New York City" type="VP">
          <tokens>
            <token id="20" string="increased" />
            <token id="21" string="122" />
            <token id="22" string="percent" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
            <token id="28" string=";" />
            <token id="29" string="86" />
            <token id="30" string="percent" />
            <token id="31" string="in" />
            <token id="32" string="both" />
            <token id="33" string="Boston" />
            <token id="34" string="and" />
            <token id="35" string="Atlanta" />
            <token id="36" string=";" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="in" />
            <token id="40" string="Detroit" />
            <token id="41" string=";" />
            <token id="42" string="73" />
            <token id="43" string="percent" />
            <token id="44" string="in" />
            <token id="45" string="Chicago" />
            <token id="46" string=";" />
            <token id="47" string="53" />
            <token id="48" string="percent" />
            <token id="49" string="in" />
            <token id="50" string="Minneapolis" />
            <token id="51" string=";" />
            <token id="52" string="50" />
            <token id="53" string="percent" />
            <token id="54" string="in" />
            <token id="55" string="Texas" />
            <token id="56" string="," />
            <token id="57" string="and" />
            <token id="58" string="39" />
            <token id="59" string="percent" />
            <token id="60" string="in" />
            <token id="61" string="New" />
            <token id="62" string="York" />
            <token id="63" string="City" />
          </tokens>
        </chunking>
        <chunking id="31" string="39 percent in New York City" type="NP">
          <tokens>
            <token id="58" string="39" />
            <token id="59" string="percent" />
            <token id="60" string="in" />
            <token id="61" string="New" />
            <token id="62" string="York" />
            <token id="63" string="City" />
          </tokens>
        </chunking>
        <chunking id="32" string="122 percent in the District of Columbia ; 86 percent in both Boston and Atlanta ; 80 percent in Detroit ; 73 percent in Chicago ; 53 percent in Minneapolis ; 50 percent in Texas" type="NP">
          <tokens>
            <token id="21" string="122" />
            <token id="22" string="percent" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
            <token id="28" string=";" />
            <token id="29" string="86" />
            <token id="30" string="percent" />
            <token id="31" string="in" />
            <token id="32" string="both" />
            <token id="33" string="Boston" />
            <token id="34" string="and" />
            <token id="35" string="Atlanta" />
            <token id="36" string=";" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="in" />
            <token id="40" string="Detroit" />
            <token id="41" string=";" />
            <token id="42" string="73" />
            <token id="43" string="percent" />
            <token id="44" string="in" />
            <token id="45" string="Chicago" />
            <token id="46" string=";" />
            <token id="47" string="53" />
            <token id="48" string="percent" />
            <token id="49" string="in" />
            <token id="50" string="Minneapolis" />
            <token id="51" string=";" />
            <token id="52" string="50" />
            <token id="53" string="percent" />
            <token id="54" string="in" />
            <token id="55" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="33" string="Boston" type="NP">
          <tokens>
            <token id="33" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="34" string="Drug" type="NP">
          <tokens>
            <token id="12" string="Drug" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">1987</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">1987</governor>
          <dependent id="2">1986</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">1987</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">increased</governor>
          <dependent id="4">1987</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Abuse</governor>
          <dependent id="6">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="6">according</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Abuse</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Abuse</governor>
          <dependent id="9">National</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">National</governor>
          <dependent id="10">Institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Drug</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">National</governor>
          <dependent id="12">Drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">increased</governor>
          <dependent id="13">Abuse</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">cases</governor>
          <dependent id="15">cocaine-related</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">increased</governor>
          <dependent id="16">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">rooms</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">rooms</governor>
          <dependent id="18">emergency</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">cases</governor>
          <dependent id="19">rooms</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">increased</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">percent</governor>
          <dependent id="21">122</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">increased</governor>
          <dependent id="22">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">District</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">District</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">percent</governor>
          <dependent id="25">District</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Columbia</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">District</governor>
          <dependent id="27">Columbia</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">percent</governor>
          <dependent id="29">86</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">percent</governor>
          <dependent id="30">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Boston</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="33">Boston</governor>
          <dependent id="32">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">percent</governor>
          <dependent id="33">Boston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">Boston</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">Boston</governor>
          <dependent id="35">Atlanta</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="38">percent</governor>
          <dependent id="37">80</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">percent</governor>
          <dependent id="38">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">Detroit</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">percent</governor>
          <dependent id="40">Detroit</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="43">percent</governor>
          <dependent id="42">73</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">percent</governor>
          <dependent id="43">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">Chicago</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">percent</governor>
          <dependent id="45">Chicago</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="48">percent</governor>
          <dependent id="47">53</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">percent</governor>
          <dependent id="48">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">Minneapolis</governor>
          <dependent id="49">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">percent</governor>
          <dependent id="50">Minneapolis</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="53">percent</governor>
          <dependent id="52">50</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">percent</governor>
          <dependent id="53">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">Texas</governor>
          <dependent id="54">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="53">percent</governor>
          <dependent id="55">Texas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">percent</governor>
          <dependent id="57">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="59">percent</governor>
          <dependent id="58">39</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">percent</governor>
          <dependent id="59">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">City</governor>
          <dependent id="60">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="63">City</governor>
          <dependent id="61">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="63">City</governor>
          <dependent id="62">York</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="59">percent</governor>
          <dependent id="63">City</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="District of Columbia" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="District" />
            <token id="26" string="of" />
            <token id="27" string="Columbia" />
          </tokens>
        </entity>
        <entity id="2" string="Detroit" type="LOCATION" score="0.0">
          <tokens>
            <token id="40" string="Detroit" />
          </tokens>
        </entity>
        <entity id="3" string="Chicago" type="LOCATION" score="0.0">
          <tokens>
            <token id="45" string="Chicago" />
          </tokens>
        </entity>
        <entity id="4" string="53 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="47" string="53" />
            <token id="48" string="percent" />
          </tokens>
        </entity>
        <entity id="5" string="39 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="58" string="39" />
            <token id="59" string="percent" />
          </tokens>
        </entity>
        <entity id="6" string="50 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="52" string="50" />
            <token id="53" string="percent" />
          </tokens>
        </entity>
        <entity id="7" string="86 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="29" string="86" />
            <token id="30" string="percent" />
          </tokens>
        </entity>
        <entity id="8" string="80 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
          </tokens>
        </entity>
        <entity id="9" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1987" />
          </tokens>
        </entity>
        <entity id="10" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1986" />
          </tokens>
        </entity>
        <entity id="11" string="Atlanta" type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="Atlanta" />
          </tokens>
        </entity>
        <entity id="12" string="Minneapolis" type="LOCATION" score="0.0">
          <tokens>
            <token id="50" string="Minneapolis" />
          </tokens>
        </entity>
        <entity id="13" string="73 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="42" string="73" />
            <token id="43" string="percent" />
          </tokens>
        </entity>
        <entity id="14" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="55" string="Texas" />
          </tokens>
        </entity>
        <entity id="15" string="New York City" type="LOCATION" score="0.0">
          <tokens>
            <token id="61" string="New" />
            <token id="62" string="York" />
            <token id="63" string="City" />
          </tokens>
        </entity>
        <entity id="16" string="122 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="21" string="122" />
            <token id="22" string="percent" />
          </tokens>
        </entity>
        <entity id="17" string="National Institute on Drug Abuse" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="National" />
            <token id="10" string="Institute" />
            <token id="11" string="on" />
            <token id="12" string="Drug" />
            <token id="13" string="Abuse" />
          </tokens>
        </entity>
        <entity id="18" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="33" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Efforts to stem the rising tide of drug abuse comes at a time when emergency rooms already face increased patient loads, partly because of the reduced role of the traditional family doctor and partly because there are more people who can&amp;apost;t afford a private doctor.</content>
      <tokens>
        <token id="1" string="Efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="stem" lemma="stem" stem="stem" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="rising" lemma="rise" stem="rise" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="tide" lemma="tide" stem="tide" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="rooms" lemma="room" stem="room" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="face" lemma="face" stem="face" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="increased" lemma="increase" stem="increas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="loads" lemma="load" stem="load" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="partly" lemma="partly" stem="partli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reduced" lemma="reduce" stem="reduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="partly" lemma="partly" stem="partli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="afford" lemma="afford" stem="afford" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Efforts) (S (VP (TO to) (VP (VB stem) (NP (NP (DT the) (VBG rising) (NN tide)) (PP (IN of) (NP (NN drug) (NN abuse)))))))) (VP (VBZ comes) (PP (IN at) (NP (DT a) (NN time))) (SBAR (SBAR (WHADVP (WRB when)) (S (NP (NN emergency) (NNS rooms)) (ADVP (RB already)) (VP (VBP face) (NP (VBN increased) (NN patient) (NNS loads)) (, ,) (PP (ADVP (RB partly)) (IN because) (IN of) (NP (NP (DT the) (VBN reduced) (NN role)) (PP (IN of) (NP (DT the) (JJ traditional) (NN family) (NN doctor)))))))) (CC and) (SBAR (RB partly) (IN because) (S (NP (EX there)) (VP (VBP are) (NP (NP (JJR more) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (MD ca) (RB n't) (VP (VB afford) (NP (DT a) (JJ private) (NN doctor)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when emergency rooms already face increased patient loads , partly because of the reduced role of the traditional family doctor and partly because there are more people who ca n't afford a private doctor" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="emergency" />
            <token id="16" string="rooms" />
            <token id="17" string="already" />
            <token id="18" string="face" />
            <token id="19" string="increased" />
            <token id="20" string="patient" />
            <token id="21" string="loads" />
            <token id="22" string="," />
            <token id="23" string="partly" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
            <token id="34" string="and" />
            <token id="35" string="partly" />
            <token id="36" string="because" />
            <token id="37" string="there" />
            <token id="38" string="are" />
            <token id="39" string="more" />
            <token id="40" string="people" />
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="2" string="stem the rising tide of drug abuse" type="VP">
          <tokens>
            <token id="3" string="stem" />
            <token id="4" string="the" />
            <token id="5" string="rising" />
            <token id="6" string="tide" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="3" string="when emergency rooms already face increased patient loads , partly because of the reduced role of the traditional family doctor" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="emergency" />
            <token id="16" string="rooms" />
            <token id="17" string="already" />
            <token id="18" string="face" />
            <token id="19" string="increased" />
            <token id="20" string="patient" />
            <token id="21" string="loads" />
            <token id="22" string="," />
            <token id="23" string="partly" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="4" string="there" type="NP">
          <tokens>
            <token id="37" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="more people who ca n't afford a private doctor" type="NP">
          <tokens>
            <token id="39" string="more" />
            <token id="40" string="people" />
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="6" string="who ca n't afford a private doctor" type="SBAR">
          <tokens>
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="7" string="the reduced role of the traditional family doctor" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="8" string="increased patient loads" type="NP">
          <tokens>
            <token id="19" string="increased" />
            <token id="20" string="patient" />
            <token id="21" string="loads" />
          </tokens>
        </chunking>
        <chunking id="9" string="partly because there are more people who ca n't afford a private doctor" type="SBAR">
          <tokens>
            <token id="35" string="partly" />
            <token id="36" string="because" />
            <token id="37" string="there" />
            <token id="38" string="are" />
            <token id="39" string="more" />
            <token id="40" string="people" />
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="10" string="afford a private doctor" type="VP">
          <tokens>
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="11" string="a private doctor" type="NP">
          <tokens>
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="12" string="the rising tide" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="rising" />
            <token id="6" string="tide" />
          </tokens>
        </chunking>
        <chunking id="13" string="comes at a time when emergency rooms already face increased patient loads , partly because of the reduced role of the traditional family doctor and partly because there are more people who ca n't afford a private doctor" type="VP">
          <tokens>
            <token id="10" string="comes" />
            <token id="11" string="at" />
            <token id="12" string="a" />
            <token id="13" string="time" />
            <token id="14" string="when" />
            <token id="15" string="emergency" />
            <token id="16" string="rooms" />
            <token id="17" string="already" />
            <token id="18" string="face" />
            <token id="19" string="increased" />
            <token id="20" string="patient" />
            <token id="21" string="loads" />
            <token id="22" string="," />
            <token id="23" string="partly" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
            <token id="34" string="and" />
            <token id="35" string="partly" />
            <token id="36" string="because" />
            <token id="37" string="there" />
            <token id="38" string="are" />
            <token id="39" string="more" />
            <token id="40" string="people" />
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="14" string="emergency rooms" type="NP">
          <tokens>
            <token id="15" string="emergency" />
            <token id="16" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="15" string="are more people who ca n't afford a private doctor" type="VP">
          <tokens>
            <token id="38" string="are" />
            <token id="39" string="more" />
            <token id="40" string="people" />
            <token id="41" string="who" />
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="16" string="more people" type="NP">
          <tokens>
            <token id="39" string="more" />
            <token id="40" string="people" />
          </tokens>
        </chunking>
        <chunking id="17" string="Efforts to stem the rising tide of drug abuse" type="NP">
          <tokens>
            <token id="1" string="Efforts" />
            <token id="2" string="to" />
            <token id="3" string="stem" />
            <token id="4" string="the" />
            <token id="5" string="rising" />
            <token id="6" string="tide" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="18" string="ca n't afford a private doctor" type="VP">
          <tokens>
            <token id="42" string="ca" />
            <token id="43" string="n't" />
            <token id="44" string="afford" />
            <token id="45" string="a" />
            <token id="46" string="private" />
            <token id="47" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="face increased patient loads , partly because of the reduced role of the traditional family doctor" type="VP">
          <tokens>
            <token id="18" string="face" />
            <token id="19" string="increased" />
            <token id="20" string="patient" />
            <token id="21" string="loads" />
            <token id="22" string="," />
            <token id="23" string="partly" />
            <token id="24" string="because" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="21" string="drug abuse" type="NP">
          <tokens>
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="22" string="to stem the rising tide of drug abuse" type="VP">
          <tokens>
            <token id="2" string="to" />
            <token id="3" string="stem" />
            <token id="4" string="the" />
            <token id="5" string="rising" />
            <token id="6" string="tide" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="23" string="the rising tide of drug abuse" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="rising" />
            <token id="6" string="tide" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="24" string="a time" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="25" string="the reduced role" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="reduced" />
            <token id="28" string="role" />
          </tokens>
        </chunking>
        <chunking id="26" string="the traditional family doctor" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="traditional" />
            <token id="32" string="family" />
            <token id="33" string="doctor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">comes</governor>
          <dependent id="1">Efforts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="3">stem</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Efforts</governor>
          <dependent id="3">stem</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">tide</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">tide</governor>
          <dependent id="5">rising</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">stem</governor>
          <dependent id="6">tide</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">abuse</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">abuse</governor>
          <dependent id="8">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">tide</governor>
          <dependent id="9">abuse</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">time</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">time</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">comes</governor>
          <dependent id="13">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">face</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">rooms</governor>
          <dependent id="15">emergency</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">face</governor>
          <dependent id="16">rooms</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">face</governor>
          <dependent id="17">already</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">comes</governor>
          <dependent id="18">face</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">loads</governor>
          <dependent id="19">increased</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">loads</governor>
          <dependent id="20">patient</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">face</governor>
          <dependent id="21">loads</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">role</governor>
          <dependent id="23">partly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">role</governor>
          <dependent id="24">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="24">because</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">role</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">role</governor>
          <dependent id="27">reduced</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">face</governor>
          <dependent id="28">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">doctor</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">doctor</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">doctor</governor>
          <dependent id="31">traditional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">doctor</governor>
          <dependent id="32">family</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">role</governor>
          <dependent id="33">doctor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">face</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">are</governor>
          <dependent id="35">partly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">are</governor>
          <dependent id="36">because</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="38">are</governor>
          <dependent id="37">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">face</governor>
          <dependent id="38">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">people</governor>
          <dependent id="39">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">are</governor>
          <dependent id="40">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">afford</governor>
          <dependent id="41">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="44">afford</governor>
          <dependent id="42">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="44">afford</governor>
          <dependent id="43">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="40">people</governor>
          <dependent id="44">afford</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">doctor</governor>
          <dependent id="45">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">doctor</governor>
          <dependent id="46">private</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="44">afford</governor>
          <dependent id="47">doctor</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>``It&amp;apost;s really providing a major backlog in the emergency department system,&amp;apost;&amp;apost; said Diane Howard, director of the American Hospital Association&amp;apost;s division of ambulatory care and health promotion.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="providing" lemma="provide" stem="provid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="backlog" lemma="backlog" stem="backlog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Diane" lemma="Diane" stem="dian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="division" lemma="division" stem="divis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="ambulatory" lemma="ambulatory" stem="ambulatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="promotion" lemma="promotion" stem="promot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADVP (RB really)) (VP (VBG providing) (NP (NP (DT a) (JJ major) (NN backlog)) (PP (IN in) (NP (DT the) (NN emergency) (NN department) (NN system))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Diane) (NNP Howard)) (, ,) (NP (NP (NN director)) (PP (IN of) (NP (NP (NP (DT the) (NNP American) (NNP Hospital) (NNP Association) (POS 's)) (NN division)) (PP (IN of) (NP (JJ ambulatory) (NN care) (CC and) (NN health) (NN promotion))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="director" type="NP">
          <tokens>
            <token id="20" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="Diane Howard" type="NP">
          <tokens>
            <token id="17" string="Diane" />
            <token id="18" string="Howard" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="the American Hospital Association 's division" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
            <token id="26" string="'s" />
            <token id="27" string="division" />
          </tokens>
        </chunking>
        <chunking id="5" string="director of the American Hospital Association 's division of ambulatory care and health promotion" type="NP">
          <tokens>
            <token id="20" string="director" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
            <token id="26" string="'s" />
            <token id="27" string="division" />
            <token id="28" string="of" />
            <token id="29" string="ambulatory" />
            <token id="30" string="care" />
            <token id="31" string="and" />
            <token id="32" string="health" />
            <token id="33" string="promotion" />
          </tokens>
        </chunking>
        <chunking id="6" string="the American Hospital Association 's division of ambulatory care and health promotion" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
            <token id="26" string="'s" />
            <token id="27" string="division" />
            <token id="28" string="of" />
            <token id="29" string="ambulatory" />
            <token id="30" string="care" />
            <token id="31" string="and" />
            <token id="32" string="health" />
            <token id="33" string="promotion" />
          </tokens>
        </chunking>
        <chunking id="7" string="the emergency department system" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="emergency" />
            <token id="12" string="department" />
            <token id="13" string="system" />
          </tokens>
        </chunking>
        <chunking id="8" string="providing a major backlog in the emergency department system" type="VP">
          <tokens>
            <token id="5" string="providing" />
            <token id="6" string="a" />
            <token id="7" string="major" />
            <token id="8" string="backlog" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="emergency" />
            <token id="12" string="department" />
            <token id="13" string="system" />
          </tokens>
        </chunking>
        <chunking id="9" string="a major backlog" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="major" />
            <token id="8" string="backlog" />
          </tokens>
        </chunking>
        <chunking id="10" string="the American Hospital Association 's" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s really providing a major backlog in the emergency department system" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="really" />
            <token id="5" string="providing" />
            <token id="6" string="a" />
            <token id="7" string="major" />
            <token id="8" string="backlog" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="emergency" />
            <token id="12" string="department" />
            <token id="13" string="system" />
          </tokens>
        </chunking>
        <chunking id="12" string="a major backlog in the emergency department system" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="major" />
            <token id="8" string="backlog" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="emergency" />
            <token id="12" string="department" />
            <token id="13" string="system" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="Diane Howard , director of the American Hospital Association 's division of ambulatory care and health promotion" type="NP">
          <tokens>
            <token id="17" string="Diane" />
            <token id="18" string="Howard" />
            <token id="19" string="," />
            <token id="20" string="director" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
            <token id="26" string="'s" />
            <token id="27" string="division" />
            <token id="28" string="of" />
            <token id="29" string="ambulatory" />
            <token id="30" string="care" />
            <token id="31" string="and" />
            <token id="32" string="health" />
            <token id="33" string="promotion" />
          </tokens>
        </chunking>
        <chunking id="15" string="ambulatory care and health promotion" type="NP">
          <tokens>
            <token id="29" string="ambulatory" />
            <token id="30" string="care" />
            <token id="31" string="and" />
            <token id="32" string="health" />
            <token id="33" string="promotion" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">providing</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">providing</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">providing</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">providing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">backlog</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">backlog</governor>
          <dependent id="7">major</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">providing</governor>
          <dependent id="8">backlog</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">system</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">system</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">system</governor>
          <dependent id="11">emergency</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">system</governor>
          <dependent id="12">department</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">backlog</governor>
          <dependent id="13">system</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Howard</governor>
          <dependent id="17">Diane</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="18">Howard</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Howard</governor>
          <dependent id="20">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">division</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Association</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Association</governor>
          <dependent id="23">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Association</governor>
          <dependent id="24">Hospital</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">division</governor>
          <dependent id="25">Association</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Association</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">director</governor>
          <dependent id="27">division</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">care</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">care</governor>
          <dependent id="29">ambulatory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">division</governor>
          <dependent id="30">care</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">care</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">promotion</governor>
          <dependent id="32">health</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">care</governor>
          <dependent id="33">promotion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Hospital Association" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="American" />
            <token id="24" string="Hospital" />
            <token id="25" string="Association" />
          </tokens>
        </entity>
        <entity id="2" string="Diane Howard" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Diane" />
            <token id="18" string="Howard" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>``The bottom line is that emergency care is being squeezed,&amp;apost;&amp;apost; Raske said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bottom" lemma="bottom" stem="bottom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="squeezed" lemma="squeeze" stem="squeez" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Raske" lemma="Raske" stem="rask" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ bottom) (NN line)) (VP (VBZ is) (SBAR (IN that) (S (NP (NN emergency) (NN care)) (VP (VBZ is) (VP (VBG being) (VP (VBN squeezed)))))))) (, ,) ('' '') (NP (NNP Raske)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="being squeezed" type="VP">
          <tokens>
            <token id="10" string="being" />
            <token id="11" string="squeezed" />
          </tokens>
        </chunking>
        <chunking id="2" string="emergency care" type="NP">
          <tokens>
            <token id="7" string="emergency" />
            <token id="8" string="care" />
          </tokens>
        </chunking>
        <chunking id="3" string="that emergency care is being squeezed" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="emergency" />
            <token id="8" string="care" />
            <token id="9" string="is" />
            <token id="10" string="being" />
            <token id="11" string="squeezed" />
          </tokens>
        </chunking>
        <chunking id="4" string="is being squeezed" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="being" />
            <token id="11" string="squeezed" />
          </tokens>
        </chunking>
        <chunking id="5" string="squeezed" type="VP">
          <tokens>
            <token id="11" string="squeezed" />
          </tokens>
        </chunking>
        <chunking id="6" string="Raske" type="NP">
          <tokens>
            <token id="14" string="Raske" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="The bottom line" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="bottom" />
            <token id="4" string="line" />
          </tokens>
        </chunking>
        <chunking id="9" string="is that emergency care is being squeezed" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="that" />
            <token id="7" string="emergency" />
            <token id="8" string="care" />
            <token id="9" string="is" />
            <token id="10" string="being" />
            <token id="11" string="squeezed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">line</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">line</governor>
          <dependent id="3">bottom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">is</governor>
          <dependent id="4">line</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">squeezed</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">care</governor>
          <dependent id="7">emergency</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">squeezed</governor>
          <dependent id="8">care</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">squeezed</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">squeezed</governor>
          <dependent id="10">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">is</governor>
          <dependent id="11">squeezed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Raske</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Raske" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Raske" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>``The real loser here is the patient.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="loser" lemma="loser" stem="loser" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (JJ real) (NN loser)) (ADVP (RB here)) (VP (VBZ is) (NP (DT the) (NN patient))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the patient" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="patient" />
          </tokens>
        </chunking>
        <chunking id="2" string="is the patient" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="the" />
            <token id="8" string="patient" />
          </tokens>
        </chunking>
        <chunking id="3" string="The real loser" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="real" />
            <token id="4" string="loser" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">loser</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">loser</governor>
          <dependent id="3">real</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">patient</governor>
          <dependent id="4">loser</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">patient</governor>
          <dependent id="5">here</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">patient</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">patient</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">patient</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="7-8" string="Joanne Pierluissi" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="her" id_sentence="2" />
        <mention ids_tokens="20" string="herself" id_sentence="2" />
        <mention ids_tokens="23" string="she" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" id_sentence="5" />
      <mentions>
        <mention ids_tokens="19" string="diabetes" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="1-2" string="San Antonio" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1-3" string="San Antonio's" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="7-8-9" string="Dr. Ralph DeFronzo" id_sentence="8" />
      <mentions>
        <mention ids_tokens="16" string="DeFronzo" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="Epidemiologist Dr. Michael Stern" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1" string="Stern" id_sentence="10" />
        <mention ids_tokens="10" string="him" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="20" type="PRONOMINAL">
      <referenced ids_tokens="3" string="you" id_sentence="13" />
      <mentions>
        <mention ids_tokens="29" string="they" id_sentence="15" />
        <mention ids_tokens="36" string="them" id_sentence="20" />
        <mention ids_tokens="2" string="We" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="4" string="astronauts" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="15" />
        <mention ids_tokens="16" string="we" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="26" string="panels" id_sentence="14" />
      <mentions>
        <mention ids_tokens="13-18" string="panels that have openings for wiring" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="28" string="beams" id_sentence="14" />
      <mentions>
        <mention ids_tokens="5" string="they" id_sentence="15" />
        <mention ids_tokens="11" string="they" id_sentence="15" />
        <mention ids_tokens="19" string="they" id_sentence="15" />
        <mention ids_tokens="33" string="they" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="38" string="El-Shiekh" id_sentence="15" />
      <mentions>
        <mention ids_tokens="3" string="his" id_sentence="16" />
        <mention ids_tokens="2-7" string="El-Shiekh , who can produce shapes" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="the ceramic fibers they need" id_sentence="15" />
      <mentions>
        <mention ids_tokens="13-14" string="ceramic fibers" id_sentence="16" />
        <mention ids_tokens="24-25" string="ceramic fibers" id_sentence="19" />
        <mention ids_tokens="1-2" string="The fibers" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="many of the parts" id_sentence="17" />
      <mentions>
        <mention ids_tokens="4" string="his" id_sentence="19" />
        <mention ids_tokens="22" string="he" id_sentence="20" />
        <mention ids_tokens="25" string="he" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25" string="composite materials like ceramic fibers" id_sentence="19" />
      <mentions>
        <mention ids_tokens="31-32" string="the materials" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="the idea of putting this braided fabric in concrete as reinforcing material instead of metal rods" id_sentence="21" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="28-29-30" string="Duke University researchers" id_sentence="23" />
      <mentions>
        <mention ids_tokens="24" string="them" id_sentence="25" />
        <mention ids_tokens="11" string="we" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="The big problem" id_sentence="26" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="1-2" string="`` Cocaine" id_sentence="31" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="32" />
        <mention ids_tokens="3-20" string="a question that has become more and more commonplace in emergency rooms already burdened by increased patient loads" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="32-33" string="Ken Raske" id_sentence="33" />
      <mentions>
        <mention ids_tokens="26" string="Raske" id_sentence="34" />
        <mention ids_tokens="14" string="Raske" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="22-23-24" string="big-city emergency rooms" id_sentence="34" />
      <mentions>
        <mention ids_tokens="18-19" string="emergency rooms" id_sentence="35" />
        <mention ids_tokens="15-16" string="emergency rooms" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13" string="the National Institute on Drug Abuse" id_sentence="35" />
      <mentions>
        <mention ids_tokens="8-9" string="drug abuse" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9" string="the rising tide of drug abuse" id_sentence="36" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="37" />
      </mentions>
    </coreference>
  </coreferences>
</document>
