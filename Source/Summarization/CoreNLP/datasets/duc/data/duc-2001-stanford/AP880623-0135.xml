<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP880623-0135">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Lawmakers clashed Thursday over the question of counting illegal aliens in the 1990 Census, debating whether following the letter of the Constitution results in a system that is unfair to citizens.</content>
      <tokens>
        <token id="1" string="Lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="clashed" lemma="clash" stem="clash" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="debating" lemma="debate" stem="debat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="results" lemma="result" stem="result" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Lawmakers)) (VP (VBD clashed) (NP-TMP (NNP Thursday)) (PP (IN over) (NP (NP (DT the) (NN question)) (PP (IN of) (S (VP (VBG counting) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (NP (DT the) (CD 1990) (NNP Census)) (, ,) (VP (VBG debating) (SBAR (IN whether) (S (S (VP (VBG following) (NP (NP (DT the) (NN letter)) (PP (IN of) (NP (DT the) (NNP Constitution)))))) (VP (VBZ results) (PP (IN in) (NP (NP (DT a) (NN system)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ unfair) (PP (TO to) (NP (NNS citizens))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lawmakers" type="NP">
          <tokens>
            <token id="1" string="Lawmakers" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="unfair to citizens" type="ADJP">
          <tokens>
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1990 Census , debating whether following the letter of the Constitution results in a system that is unfair to citizens" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="1990" />
            <token id="14" string="Census" />
            <token id="15" string="," />
            <token id="16" string="debating" />
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="5" string="that is unfair to citizens" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="6" string="the question" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="question" />
          </tokens>
        </chunking>
        <chunking id="7" string="whether following the letter of the Constitution results in a system that is unfair to citizens" type="SBAR">
          <tokens>
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Constitution" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="a system that is unfair to citizens" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="debating whether following the letter of the Constitution results in a system that is unfair to citizens" type="VP">
          <tokens>
            <token id="16" string="debating" />
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="11" string="is unfair to citizens" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="12" string="following the letter of the Constitution" type="VP">
          <tokens>
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="13" string="the question of counting illegal aliens in the 1990 Census , debating whether following the letter of the Constitution results in a system that is unfair to citizens" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="question" />
            <token id="7" string="of" />
            <token id="8" string="counting" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="1990" />
            <token id="14" string="Census" />
            <token id="15" string="," />
            <token id="16" string="debating" />
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="14" string="the 1990 Census" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="1990" />
            <token id="14" string="Census" />
          </tokens>
        </chunking>
        <chunking id="15" string="the letter of the Constitution" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="16" string="the letter" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="letter" />
          </tokens>
        </chunking>
        <chunking id="17" string="a system" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="system" />
          </tokens>
        </chunking>
        <chunking id="18" string="counting illegal aliens in the 1990 Census , debating whether following the letter of the Constitution results in a system that is unfair to citizens" type="VP">
          <tokens>
            <token id="8" string="counting" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="1990" />
            <token id="14" string="Census" />
            <token id="15" string="," />
            <token id="16" string="debating" />
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="19" string="clashed Thursday over the question of counting illegal aliens in the 1990 Census , debating whether following the letter of the Constitution results in a system that is unfair to citizens" type="VP">
          <tokens>
            <token id="2" string="clashed" />
            <token id="3" string="Thursday" />
            <token id="4" string="over" />
            <token id="5" string="the" />
            <token id="6" string="question" />
            <token id="7" string="of" />
            <token id="8" string="counting" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="1990" />
            <token id="14" string="Census" />
            <token id="15" string="," />
            <token id="16" string="debating" />
            <token id="17" string="whether" />
            <token id="18" string="following" />
            <token id="19" string="the" />
            <token id="20" string="letter" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Constitution" />
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="20" string="results in a system that is unfair to citizens" type="VP">
          <tokens>
            <token id="24" string="results" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="unfair" />
            <token id="31" string="to" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="21" string="citizens" type="NP">
          <tokens>
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">clashed</governor>
          <dependent id="1">Lawmakers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">clashed</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">clashed</governor>
          <dependent id="3">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">question</governor>
          <dependent id="4">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">question</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">clashed</governor>
          <dependent id="6">question</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">counting</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">question</governor>
          <dependent id="8">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">aliens</governor>
          <dependent id="9">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">counting</governor>
          <dependent id="10">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Census</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Census</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">Census</governor>
          <dependent id="13">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">counting</governor>
          <dependent id="14">Census</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">Census</governor>
          <dependent id="16">debating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">results</governor>
          <dependent id="17">whether</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="24">results</governor>
          <dependent id="18">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">letter</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">following</governor>
          <dependent id="20">letter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Constitution</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Constitution</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">letter</governor>
          <dependent id="23">Constitution</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">debating</governor>
          <dependent id="24">results</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">system</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">system</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">results</governor>
          <dependent id="27">system</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">unfair</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">unfair</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">system</governor>
          <dependent id="30">unfair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">citizens</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">unfair</governor>
          <dependent id="32">citizens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Thursday" />
          </tokens>
        </entity>
        <entity id="2" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The forum was a Census subcommittee hearing on bills which would require the Census Bureau to figure out whether people are in the country legally and, if not, to delete them from the counts used in reapportioning seats in the House of Representatives.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="forum" lemma="forum" stem="forum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="subcommittee" lemma="subcommittee" stem="subcommitte" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="bills" lemma="bill" stem="bill" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="require" lemma="require" stem="requir" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="15" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="figure" lemma="figure" stem="figur" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="24" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="legally" lemma="legally" stem="legal" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="32" string="delete" lemma="delete" stem="delet" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="33" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="36" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="37" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="39" string="reapportioning" lemma="reapportion" stem="reapport" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="40" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="42" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="43" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="44" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="45" string="Representatives" lemma="Representatives" stem="repres" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN forum)) (VP (VBD was) (NP (NP (DT a) (NNP Census) (NN subcommittee) (NN hearing)) (PP (IN on) (NP (NP (NNS bills)) (SBAR (WHNP (WDT which)) (S (VP (MD would) (VP (VB require) (S (NP (DT the) (NNP Census) (NNP Bureau)) (VP (VP (TO to) (VP (VB figure) (PRT (RP out)) (SBAR (IN whether) (S (NP (NNS people)) (VP (VBP are) (PP (IN in) (NP (DT the) (NN country))) (ADVP (RB legally))))))) (CC and) (, ,) (VP (ADVP (IN if) (RB not)) (, ,) (TO to) (VP (VB delete) (NP (PRP them)) (PP (IN from) (NP (NP (DT the) (NNS counts)) (VP (VBN used) (PP (IN in) (S (VP (VBG reapportioning) (NP (NNS seats)) (PP (IN in) (NP (NP (DT the) (NNP House)) (PP (IN of) (NP (NNPS Representatives))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Census subcommittee hearing" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Census" />
            <token id="6" string="subcommittee" />
            <token id="7" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="2" string="The forum" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="forum" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Census Bureau" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="4" string="the counts" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="counts" />
          </tokens>
        </chunking>
        <chunking id="5" string="to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="6" string="people" type="NP">
          <tokens>
            <token id="20" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="which would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="SBAR">
          <tokens>
            <token id="10" string="which" />
            <token id="11" string="would" />
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="9" string="figure out whether people are in the country legally" type="VP">
          <tokens>
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
          </tokens>
        </chunking>
        <chunking id="10" string="a Census subcommittee hearing on bills which would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Census" />
            <token id="6" string="subcommittee" />
            <token id="7" string="hearing" />
            <token id="8" string="on" />
            <token id="9" string="bills" />
            <token id="10" string="which" />
            <token id="11" string="would" />
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="11" string="to figure out whether people are in the country legally" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
          </tokens>
        </chunking>
        <chunking id="12" string="was a Census subcommittee hearing on bills which would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="Census" />
            <token id="6" string="subcommittee" />
            <token id="7" string="hearing" />
            <token id="8" string="on" />
            <token id="9" string="bills" />
            <token id="10" string="which" />
            <token id="11" string="would" />
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="13" string="the House" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="House" />
          </tokens>
        </chunking>
        <chunking id="14" string="Representatives" type="NP">
          <tokens>
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="15" string="are in the country legally" type="VP">
          <tokens>
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
          </tokens>
        </chunking>
        <chunking id="16" string="the counts used in reapportioning seats in the House of Representatives" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="17" string="if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="18" string="seats" type="NP">
          <tokens>
            <token id="40" string="seats" />
          </tokens>
        </chunking>
        <chunking id="19" string="whether people are in the country legally" type="SBAR">
          <tokens>
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
          </tokens>
        </chunking>
        <chunking id="20" string="require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="21" string="bills which would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="NP">
          <tokens>
            <token id="9" string="bills" />
            <token id="10" string="which" />
            <token id="11" string="would" />
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="22" string="reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="23" string="the country" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="country" />
          </tokens>
        </chunking>
        <chunking id="24" string="delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="25" string="would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="require" />
            <token id="13" string="the" />
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
            <token id="16" string="to" />
            <token id="17" string="figure" />
            <token id="18" string="out" />
            <token id="19" string="whether" />
            <token id="20" string="people" />
            <token id="21" string="are" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="legally" />
            <token id="26" string="and" />
            <token id="27" string="," />
            <token id="28" string="if" />
            <token id="29" string="not" />
            <token id="30" string="," />
            <token id="31" string="to" />
            <token id="32" string="delete" />
            <token id="33" string="them" />
            <token id="34" string="from" />
            <token id="35" string="the" />
            <token id="36" string="counts" />
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="26" string="the House of Representatives" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="27" string="used in reapportioning seats in the House of Representatives" type="VP">
          <tokens>
            <token id="37" string="used" />
            <token id="38" string="in" />
            <token id="39" string="reapportioning" />
            <token id="40" string="seats" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="28" string="bills" type="NP">
          <tokens>
            <token id="9" string="bills" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">forum</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">hearing</governor>
          <dependent id="2">forum</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">hearing</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">hearing</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">hearing</governor>
          <dependent id="5">Census</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">hearing</governor>
          <dependent id="6">subcommittee</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">hearing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">bills</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">hearing</governor>
          <dependent id="9">bills</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">require</governor>
          <dependent id="10">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">require</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">bills</governor>
          <dependent id="12">require</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Bureau</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Bureau</governor>
          <dependent id="14">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">figure</governor>
          <dependent id="15">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">figure</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">require</governor>
          <dependent id="17">figure</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">figure</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">country</governor>
          <dependent id="19">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">country</governor>
          <dependent id="20">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">country</governor>
          <dependent id="21">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">country</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">country</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">figure</governor>
          <dependent id="24">country</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">country</governor>
          <dependent id="25">legally</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">figure</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">not</governor>
          <dependent id="28">if</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="32">delete</governor>
          <dependent id="29">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">delete</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">figure</governor>
          <dependent id="32">delete</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">delete</governor>
          <dependent id="33">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">counts</governor>
          <dependent id="34">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">counts</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">delete</governor>
          <dependent id="36">counts</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="36">counts</governor>
          <dependent id="37">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">reapportioning</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="37">used</governor>
          <dependent id="39">reapportioning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">reapportioning</governor>
          <dependent id="40">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">House</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">House</governor>
          <dependent id="42">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">reapportioning</governor>
          <dependent id="43">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">Representatives</governor>
          <dependent id="44">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">House</governor>
          <dependent id="45">Representatives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House of Representatives" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="43" string="House" />
            <token id="44" string="of" />
            <token id="45" string="Representatives" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Census" />
            <token id="15" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>``This is a fairness issue,&amp;apost;&amp;apost; said Rep. Thomas J. Ridge, R-Pa., who contended that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="fairness" lemma="fairness" stem="fair" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="J." lemma="J." stem="j." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Ridge" lemma="Ridge" stem="ridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="R-Pa." lemma="R-Pa." stem="r-pa." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="contended" lemma="contend" stem="contend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="benefit" lemma="benefit" stem="benefit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="unfairly" lemma="unfairly" stem="unfairli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="totals" lemma="total" stem="total" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="give" lemma="give" stem="give" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="extra" lemma="extra" stem="extra" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="40" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (NN fairness) (NN issue)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Rep.) (NNP Thomas) (NNP J.) (NNP Ridge)) (, ,) (NP (NP (NNP R-Pa.)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD contended) (SBAR (IN that) (S (NP (NP (NNS states)) (PP (IN with) (NP (NP (JJ large) (NNS numbers)) (PP (IN of) (NP (JJ illegal) (NNS aliens)))))) (VP (VBP benefit) (ADVP (RB unfairly)) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ their) (JJ large) (NN population) (NNS totals)) (VP (VBP give) (NP (RB then)) (NP (NP (JJ extra) (NNS seats)) (PP (IN in) (NP (DT the) (NNP House))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="R-Pa. , who contended that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House" type="NP">
          <tokens>
            <token id="15" string="R-Pa." />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="contended" />
            <token id="19" string="that" />
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="3" string="then" type="NP">
          <tokens>
            <token id="35" string="then" />
          </tokens>
        </chunking>
        <chunking id="4" string="states with large numbers of illegal aliens" type="NP">
          <tokens>
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="5" string="benefit unfairly when their large population totals give then extra seats in the House" type="VP">
          <tokens>
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="6" string="extra seats in the House" type="NP">
          <tokens>
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="7" string="who contended that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="contended" />
            <token id="19" string="that" />
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="8" string="extra seats" type="NP">
          <tokens>
            <token id="36" string="extra" />
            <token id="37" string="seats" />
          </tokens>
        </chunking>
        <chunking id="9" string="a fairness issue" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="fairness" />
            <token id="6" string="issue" />
          </tokens>
        </chunking>
        <chunking id="10" string="Rep. Thomas J. Ridge , R-Pa. , who contended that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House" type="NP">
          <tokens>
            <token id="10" string="Rep." />
            <token id="11" string="Thomas" />
            <token id="12" string="J." />
            <token id="13" string="Ridge" />
            <token id="14" string="," />
            <token id="15" string="R-Pa." />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="contended" />
            <token id="19" string="that" />
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="11" string="when their large population totals give then extra seats in the House" type="SBAR">
          <tokens>
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="12" string="contended that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House" type="VP">
          <tokens>
            <token id="18" string="contended" />
            <token id="19" string="that" />
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="13" string="that states with large numbers of illegal aliens benefit unfairly when their large population totals give then extra seats in the House" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="states" />
            <token id="21" string="with" />
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="benefit" />
            <token id="28" string="unfairly" />
            <token id="29" string="when" />
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="14" string="is a fairness issue" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="fairness" />
            <token id="6" string="issue" />
          </tokens>
        </chunking>
        <chunking id="15" string="their large population totals" type="NP">
          <tokens>
            <token id="30" string="their" />
            <token id="31" string="large" />
            <token id="32" string="population" />
            <token id="33" string="totals" />
          </tokens>
        </chunking>
        <chunking id="16" string="large numbers" type="NP">
          <tokens>
            <token id="22" string="large" />
            <token id="23" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="17" string="give then extra seats in the House" type="VP">
          <tokens>
            <token id="34" string="give" />
            <token id="35" string="then" />
            <token id="36" string="extra" />
            <token id="37" string="seats" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="18" string="the House" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="House" />
          </tokens>
        </chunking>
        <chunking id="19" string="states" type="NP">
          <tokens>
            <token id="20" string="states" />
          </tokens>
        </chunking>
        <chunking id="20" string="when" type="WHADVP">
          <tokens>
            <token id="29" string="when" />
          </tokens>
        </chunking>
        <chunking id="21" string="Rep. Thomas J. Ridge" type="NP">
          <tokens>
            <token id="10" string="Rep." />
            <token id="11" string="Thomas" />
            <token id="12" string="J." />
            <token id="13" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="22" string="large numbers of illegal aliens" type="NP">
          <tokens>
            <token id="22" string="large" />
            <token id="23" string="numbers" />
            <token id="24" string="of" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="23" string="R-Pa." type="NP">
          <tokens>
            <token id="15" string="R-Pa." />
          </tokens>
        </chunking>
        <chunking id="24" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="25" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">issue</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">issue</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">issue</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">issue</governor>
          <dependent id="5">fairness</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="6">issue</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ridge</governor>
          <dependent id="10">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ridge</governor>
          <dependent id="11">Thomas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ridge</governor>
          <dependent id="12">J.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="13">Ridge</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Ridge</governor>
          <dependent id="15">R-Pa.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">contended</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">R-Pa.</governor>
          <dependent id="18">contended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">benefit</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">benefit</governor>
          <dependent id="20">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">numbers</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">numbers</governor>
          <dependent id="22">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">states</governor>
          <dependent id="23">numbers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">aliens</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">aliens</governor>
          <dependent id="25">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">numbers</governor>
          <dependent id="26">aliens</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">contended</governor>
          <dependent id="27">benefit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">benefit</governor>
          <dependent id="28">unfairly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">give</governor>
          <dependent id="29">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">totals</governor>
          <dependent id="30">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">totals</governor>
          <dependent id="31">large</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">totals</governor>
          <dependent id="32">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">give</governor>
          <dependent id="33">totals</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">benefit</governor>
          <dependent id="34">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="34">give</governor>
          <dependent id="35">then</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">seats</governor>
          <dependent id="36">extra</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">give</governor>
          <dependent id="37">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">House</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">House</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">seats</governor>
          <dependent id="40">House</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="40" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="R-Pa." type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="R-Pa." />
          </tokens>
        </entity>
        <entity id="3" string="Thomas J. Ridge" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Thomas" />
            <token id="12" string="J." />
            <token id="13" string="Ridge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Because there is a 435-seat limit, when one state gains a House member another must lose one.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="435-seat" lemma="435-seat" stem="435-seat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="gains" lemma="gain" stem="gain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="member" lemma="member" stem="member" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (JJ 435-seat) (NN limit)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (CD one) (NN state)) (VP (VBZ gains) (NP (DT a) (NNP House) (NN member))))))))) (NP (DT another)) (VP (MD must) (VP (VB lose) (NP (CD one)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a 435-seat limit" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="435-seat" />
            <token id="6" string="limit" />
          </tokens>
        </chunking>
        <chunking id="2" string="a 435-seat limit , when one state gains a House member" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="435-seat" />
            <token id="6" string="limit" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="one" />
            <token id="10" string="state" />
            <token id="11" string="gains" />
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="3" string="a House member" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="18" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="another" type="NP">
          <tokens>
            <token id="15" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="gains a House member" type="VP">
          <tokens>
            <token id="11" string="gains" />
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="7" string="must lose one" type="VP">
          <tokens>
            <token id="16" string="must" />
            <token id="17" string="lose" />
            <token id="18" string="one" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="lose one" type="VP">
          <tokens>
            <token id="17" string="lose" />
            <token id="18" string="one" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a 435-seat limit , when one state gains a House member" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="435-seat" />
            <token id="6" string="limit" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="one" />
            <token id="10" string="state" />
            <token id="11" string="gains" />
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="12" string="Because there is a 435-seat limit , when one state gains a House member" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="there" />
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="435-seat" />
            <token id="6" string="limit" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="one" />
            <token id="10" string="state" />
            <token id="11" string="gains" />
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="13" string="when one state gains a House member" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="one" />
            <token id="10" string="state" />
            <token id="11" string="gains" />
            <token id="12" string="a" />
            <token id="13" string="House" />
            <token id="14" string="member" />
          </tokens>
        </chunking>
        <chunking id="14" string="one state" type="NP">
          <tokens>
            <token id="9" string="one" />
            <token id="10" string="state" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">is</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">lose</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">limit</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">limit</governor>
          <dependent id="5">435-seat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="6">limit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">gains</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">state</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">gains</governor>
          <dependent id="10">state</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">limit</governor>
          <dependent id="11">gains</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">member</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">member</governor>
          <dependent id="13">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">gains</governor>
          <dependent id="14">member</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">lose</governor>
          <dependent id="15">another</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">lose</governor>
          <dependent id="16">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">lose</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">lose</governor>
          <dependent id="18">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Ridge cited the 1980 census, which estimated the number of illegal aliens at 2 million.</content>
      <tokens>
        <token id="1" string="Ridge" lemma="Ridge" stem="ridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="cited" lemma="cite" stem="cite" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="estimated" lemma="estimate" stem="estim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ridge)) (VP (VBD cited) (NP (NP (DT the) (CD 1980) (NN census)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD estimated) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ illegal) (NNS aliens)))) (PP (IN at) (NP (QP (CD 2) (CD million))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 1980 census" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="1980" />
            <token id="5" string="census" />
          </tokens>
        </chunking>
        <chunking id="3" string="estimated the number of illegal aliens at 2 million" type="VP">
          <tokens>
            <token id="8" string="estimated" />
            <token id="9" string="the" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="2 million" type="NP">
          <tokens>
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="the number of illegal aliens" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 1980 census , which estimated the number of illegal aliens at 2 million" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="1980" />
            <token id="5" string="census" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="estimated" />
            <token id="9" string="the" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </chunking>
        <chunking id="7" string="cited the 1980 census , which estimated the number of illegal aliens at 2 million" type="VP">
          <tokens>
            <token id="2" string="cited" />
            <token id="3" string="the" />
            <token id="4" string="1980" />
            <token id="5" string="census" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="estimated" />
            <token id="9" string="the" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </chunking>
        <chunking id="8" string="the number" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="number" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ridge" type="NP">
          <tokens>
            <token id="1" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="10" string="which estimated the number of illegal aliens at 2 million" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="estimated" />
            <token id="9" string="the" />
            <token id="10" string="number" />
            <token id="11" string="of" />
            <token id="12" string="illegal" />
            <token id="13" string="aliens" />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">cited</governor>
          <dependent id="1">Ridge</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">cited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">census</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">census</governor>
          <dependent id="4">1980</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">cited</governor>
          <dependent id="5">census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">estimated</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">census</governor>
          <dependent id="8">estimated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">number</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">estimated</governor>
          <dependent id="10">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">aliens</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">aliens</governor>
          <dependent id="12">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">number</governor>
          <dependent id="13">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">million</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">million</governor>
          <dependent id="15">2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">estimated</governor>
          <dependent id="16">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2 million" type="MONEY" score="0.0">
          <tokens>
            <token id="15" string="2" />
            <token id="16" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1980" />
          </tokens>
        </entity>
        <entity id="3" string="Ridge" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ridge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The result, he said, was that Georgia and Indiana lost House seats to New York and California.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Indiana" lemma="Indiana" stem="indiana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN result)) (PRN (, ,) (S (NP (PRP he)) (VP (VBD said))) (, ,)) (VP (VBD was) (SBAR (IN that) (S (NP (NNP Georgia) (CC and) (NNP Indiana)) (VP (VBD lost) (NP (NNP House) (NNS seats)) (PP (TO to) (NP (NNP New) (NNP York) (CC and) (NNP California))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="House seats" type="NP">
          <tokens>
            <token id="13" string="House" />
            <token id="14" string="seats" />
          </tokens>
        </chunking>
        <chunking id="2" string="New York and California" type="NP">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="and" />
            <token id="19" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="Georgia and Indiana" type="NP">
          <tokens>
            <token id="9" string="Georgia" />
            <token id="10" string="and" />
            <token id="11" string="Indiana" />
          </tokens>
        </chunking>
        <chunking id="4" string="was that Georgia and Indiana lost House seats to New York and California" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="that" />
            <token id="9" string="Georgia" />
            <token id="10" string="and" />
            <token id="11" string="Indiana" />
            <token id="12" string="lost" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="and" />
            <token id="19" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="lost House seats to New York and California" type="VP">
          <tokens>
            <token id="12" string="lost" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="and" />
            <token id="19" string="California" />
          </tokens>
        </chunking>
        <chunking id="6" string="The result" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="result" />
          </tokens>
        </chunking>
        <chunking id="7" string="that Georgia and Indiana lost House seats to New York and California" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="Georgia" />
            <token id="10" string="and" />
            <token id="11" string="Indiana" />
            <token id="12" string="lost" />
            <token id="13" string="House" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="and" />
            <token id="19" string="California" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">result</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">was</governor>
          <dependent id="2">result</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">was</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">lost</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">lost</governor>
          <dependent id="9">Georgia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Georgia</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Georgia</governor>
          <dependent id="11">Indiana</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">was</governor>
          <dependent id="12">lost</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">seats</governor>
          <dependent id="13">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">lost</governor>
          <dependent id="14">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">York</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">York</governor>
          <dependent id="16">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">lost</governor>
          <dependent id="17">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">York</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">York</governor>
          <dependent id="19">California</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="Indiana" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Indiana" />
          </tokens>
        </entity>
        <entity id="5" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Georgia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Subcommittee Chairman Mervyn M. Dymally, D-Calif., however, said he is unsure whether the bills backed by Ridge and others are constitutional.</content>
      <tokens>
        <token id="1" string="Subcommittee" lemma="Subcommittee" stem="subcommitte" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Chairman" lemma="Chairman" stem="chairman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Mervyn" lemma="Mervyn" stem="mervyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Dymally" lemma="Dymally" stem="dymal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="D-Calif." lemma="D-Calif." stem="d-calif." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="unsure" lemma="unsure" stem="unsur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="bills" lemma="bill" stem="bill" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="backed" lemma="back" stem="back" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Ridge" lemma="Ridge" stem="ridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="constitutional" lemma="constitutional" stem="constitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Subcommittee) (NNP Chairman) (NNP Mervyn) (NNP M.) (NNP Dymally)) (, ,) (NP (NP (NNP D-Calif.)) (, ,) (ADVP (RB however))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ is) (ADJP (JJ unsure)) (SBAR (IN whether) (S (S (NP (DT the) (NNS bills)) (VP (VBN backed) (PP (IN by) (NP (NNP Ridge))))) (CC and) (S (NP (NNS others)) (VP (VBP are) (ADJP (JJ constitutional)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are constitutional" type="VP">
          <tokens>
            <token id="23" string="are" />
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="2" string="D-Calif. , however" type="NP">
          <tokens>
            <token id="7" string="D-Calif." />
            <token id="8" string="," />
            <token id="9" string="however" />
          </tokens>
        </chunking>
        <chunking id="3" string="said he is unsure whether the bills backed by Ridge and others are constitutional" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="he" />
            <token id="13" string="is" />
            <token id="14" string="unsure" />
            <token id="15" string="whether" />
            <token id="16" string="the" />
            <token id="17" string="bills" />
            <token id="18" string="backed" />
            <token id="19" string="by" />
            <token id="20" string="Ridge" />
            <token id="21" string="and" />
            <token id="22" string="others" />
            <token id="23" string="are" />
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="4" string="unsure" type="ADJP">
          <tokens>
            <token id="14" string="unsure" />
          </tokens>
        </chunking>
        <chunking id="5" string="constitutional" type="ADJP">
          <tokens>
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="6" string="D-Calif." type="NP">
          <tokens>
            <token id="7" string="D-Calif." />
          </tokens>
        </chunking>
        <chunking id="7" string="he is unsure whether the bills backed by Ridge and others are constitutional" type="SBAR">
          <tokens>
            <token id="12" string="he" />
            <token id="13" string="is" />
            <token id="14" string="unsure" />
            <token id="15" string="whether" />
            <token id="16" string="the" />
            <token id="17" string="bills" />
            <token id="18" string="backed" />
            <token id="19" string="by" />
            <token id="20" string="Ridge" />
            <token id="21" string="and" />
            <token id="22" string="others" />
            <token id="23" string="are" />
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="8" string="is unsure whether the bills backed by Ridge and others are constitutional" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="unsure" />
            <token id="15" string="whether" />
            <token id="16" string="the" />
            <token id="17" string="bills" />
            <token id="18" string="backed" />
            <token id="19" string="by" />
            <token id="20" string="Ridge" />
            <token id="21" string="and" />
            <token id="22" string="others" />
            <token id="23" string="are" />
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="9" string="Subcommittee Chairman Mervyn M. Dymally , D-Calif. , however ," type="NP">
          <tokens>
            <token id="1" string="Subcommittee" />
            <token id="2" string="Chairman" />
            <token id="3" string="Mervyn" />
            <token id="4" string="M." />
            <token id="5" string="Dymally" />
            <token id="6" string="," />
            <token id="7" string="D-Calif." />
            <token id="8" string="," />
            <token id="9" string="however" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="backed by Ridge" type="VP">
          <tokens>
            <token id="18" string="backed" />
            <token id="19" string="by" />
            <token id="20" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="whether the bills backed by Ridge and others are constitutional" type="SBAR">
          <tokens>
            <token id="15" string="whether" />
            <token id="16" string="the" />
            <token id="17" string="bills" />
            <token id="18" string="backed" />
            <token id="19" string="by" />
            <token id="20" string="Ridge" />
            <token id="21" string="and" />
            <token id="22" string="others" />
            <token id="23" string="are" />
            <token id="24" string="constitutional" />
          </tokens>
        </chunking>
        <chunking id="13" string="Subcommittee Chairman Mervyn M. Dymally" type="NP">
          <tokens>
            <token id="1" string="Subcommittee" />
            <token id="2" string="Chairman" />
            <token id="3" string="Mervyn" />
            <token id="4" string="M." />
            <token id="5" string="Dymally" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ridge" type="NP">
          <tokens>
            <token id="20" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="15" string="the bills" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="bills" />
          </tokens>
        </chunking>
        <chunking id="16" string="others" type="NP">
          <tokens>
            <token id="22" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Dymally</governor>
          <dependent id="1">Subcommittee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Dymally</governor>
          <dependent id="2">Chairman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Dymally</governor>
          <dependent id="3">Mervyn</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Dymally</governor>
          <dependent id="4">M.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="5">Dymally</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Dymally</governor>
          <dependent id="7">D-Calif.</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">D-Calif.</governor>
          <dependent id="9">however</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">unsure</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">unsure</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="14">unsure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">backed</governor>
          <dependent id="15">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">bills</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">backed</governor>
          <dependent id="17">bills</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">unsure</governor>
          <dependent id="18">backed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Ridge</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">backed</governor>
          <dependent id="20">Ridge</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">backed</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">constitutional</governor>
          <dependent id="22">others</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">constitutional</governor>
          <dependent id="23">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">backed</governor>
          <dependent id="24">constitutional</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mervyn M. Dymally" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Mervyn" />
            <token id="4" string="M." />
            <token id="5" string="Dymally" />
          </tokens>
        </entity>
        <entity id="2" string="D-Calif." type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="D-Calif." />
          </tokens>
        </entity>
        <entity id="3" string="Ridge" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ridge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The U.S. Constitution requires the Census Bureau to cound all the ``persons&amp;apost;&amp;apost; in the country every 10 years for purposes of reapportionment.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="requires" lemma="require" stem="requir" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cound" lemma="cound" stem="cound" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="19" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="20" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="purposes" lemma="purpose" stem="purpos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP U.S.) (NNP Constitution)) (VP (VBZ requires) (S (NP (DT the) (NNP Census) (NNP Bureau)) (VP (TO to) (VP (VB cound) (NP (PDT all) (NP (NP (DT the) (`` ``) (NNS persons) ('' '')) (PP (IN in) (NP (DT the) (NN country))))) (NP-TMP (DT every) (CD 10) (NNS years)) (PP (IN for) (NP (NP (NNS purposes)) (PP (IN of) (NP (NN reapportionment))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cound all the `` persons '' in the country every 10 years for purposes of reapportionment" type="VP">
          <tokens>
            <token id="9" string="cound" />
            <token id="10" string="all" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="country" />
            <token id="18" string="every" />
            <token id="19" string="10" />
            <token id="20" string="years" />
            <token id="21" string="for" />
            <token id="22" string="purposes" />
            <token id="23" string="of" />
            <token id="24" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="2" string="The U.S. Constitution" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="U.S." />
            <token id="3" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="3" string="the `` persons '' in the country" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="4" string="the country" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Census Bureau" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Census" />
            <token id="7" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="requires the Census Bureau to cound all the `` persons '' in the country every 10 years for purposes of reapportionment" type="VP">
          <tokens>
            <token id="4" string="requires" />
            <token id="5" string="the" />
            <token id="6" string="Census" />
            <token id="7" string="Bureau" />
            <token id="8" string="to" />
            <token id="9" string="cound" />
            <token id="10" string="all" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="country" />
            <token id="18" string="every" />
            <token id="19" string="10" />
            <token id="20" string="years" />
            <token id="21" string="for" />
            <token id="22" string="purposes" />
            <token id="23" string="of" />
            <token id="24" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="7" string="all the `` persons '' in the country" type="NP">
          <tokens>
            <token id="10" string="all" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="8" string="purposes" type="NP">
          <tokens>
            <token id="22" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="9" string="reapportionment" type="NP">
          <tokens>
            <token id="24" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="10" string="purposes of reapportionment" type="NP">
          <tokens>
            <token id="22" string="purposes" />
            <token id="23" string="of" />
            <token id="24" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="11" string="to cound all the `` persons '' in the country every 10 years for purposes of reapportionment" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="cound" />
            <token id="10" string="all" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="country" />
            <token id="18" string="every" />
            <token id="19" string="10" />
            <token id="20" string="years" />
            <token id="21" string="for" />
            <token id="22" string="purposes" />
            <token id="23" string="of" />
            <token id="24" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="12" string="the `` persons ''" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="persons" />
            <token id="14" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Constitution</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Constitution</governor>
          <dependent id="2">U.S.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">requires</governor>
          <dependent id="3">Constitution</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">requires</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Bureau</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Bureau</governor>
          <dependent id="6">Census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">requires</governor>
          <dependent id="7">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">cound</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">requires</governor>
          <dependent id="9">cound</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">persons</governor>
          <dependent id="10">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">persons</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">cound</governor>
          <dependent id="13">persons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">country</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">country</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">persons</governor>
          <dependent id="17">country</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">years</governor>
          <dependent id="18">every</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">years</governor>
          <dependent id="19">10</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">cound</governor>
          <dependent id="20">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">purposes</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">cound</governor>
          <dependent id="22">purposes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">reapportionment</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">purposes</governor>
          <dependent id="24">reapportionment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="every 10 years" type="SET" score="0.0">
          <tokens>
            <token id="18" string="every" />
            <token id="19" string="10" />
            <token id="20" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Census" />
            <token id="7" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>It doesn&amp;apost;t specify citizens.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="specify" lemma="specify" stem="specifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ does) (RB n't) (VP (VB specify) (NP (NNS citizens)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="2" string="specify citizens" type="VP">
          <tokens>
            <token id="4" string="specify" />
            <token id="5" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="3" string="does n't specify citizens" type="VP">
          <tokens>
            <token id="2" string="does" />
            <token id="3" string="n't" />
            <token id="4" string="specify" />
            <token id="5" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="4" string="citizens" type="NP">
          <tokens>
            <token id="5" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">specify</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">specify</governor>
          <dependent id="2">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">specify</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">specify</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">specify</governor>
          <dependent id="5">citizens</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``I am disturbed by the implication that undocumented residents of the United States are not `persons,&amp;apost;&amp;apost;&amp;apost; Dymally said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="disturbed" lemma="disturb" stem="disturb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="implication" lemma="implication" stem="implic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="undocumented" lemma="undocument" stem="undocu" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="14" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="15" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Dymally" lemma="Dymally" stem="dymal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP am) (VP (VBN disturbed) (PP (IN by) (NP (NP (DT the) (NN implication)) (SBAR (WHNP (WDT that)) (S (VP (VBD undocumented) (SBAR (S (NP (NP (NNS residents)) (PP (IN of) (NP (DT the) (NNP United) (NNPS States)))) (VP (VBP are) (RB not) (NP (`` `) (NP (NNS persons)) (, ,) ('' ''))))))))))))) ('' ') (NP (NNP Dymally)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="residents of the United States" type="NP">
          <tokens>
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dymally" type="NP">
          <tokens>
            <token id="22" string="Dymally" />
          </tokens>
        </chunking>
        <chunking id="3" string="am disturbed by the implication that undocumented residents of the United States are not ` persons , ''" type="VP">
          <tokens>
            <token id="3" string="am" />
            <token id="4" string="disturbed" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="implication" />
            <token id="8" string="that" />
            <token id="9" string="undocumented" />
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="4" string="` persons , ''" type="NP">
          <tokens>
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="5" string="disturbed by the implication that undocumented residents of the United States are not ` persons , ''" type="VP">
          <tokens>
            <token id="4" string="disturbed" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="implication" />
            <token id="8" string="that" />
            <token id="9" string="undocumented" />
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="residents of the United States are not ` persons , ''" type="SBAR">
          <tokens>
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="8" string="are not ` persons , ''" type="VP">
          <tokens>
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="9" string="the implication that undocumented residents of the United States are not ` persons , ''" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="implication" />
            <token id="8" string="that" />
            <token id="9" string="undocumented" />
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="10" string="the United States" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
          </tokens>
        </chunking>
        <chunking id="11" string="the implication" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="implication" />
          </tokens>
        </chunking>
        <chunking id="12" string="persons" type="NP">
          <tokens>
            <token id="18" string="persons" />
          </tokens>
        </chunking>
        <chunking id="13" string="residents" type="NP">
          <tokens>
            <token id="10" string="residents" />
          </tokens>
        </chunking>
        <chunking id="14" string="undocumented residents of the United States are not ` persons , ''" type="VP">
          <tokens>
            <token id="9" string="undocumented" />
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="that undocumented residents of the United States are not ` persons , ''" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="undocumented" />
            <token id="10" string="residents" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="United" />
            <token id="14" string="States" />
            <token id="15" string="are" />
            <token id="16" string="not" />
            <token id="17" string="`" />
            <token id="18" string="persons" />
            <token id="19" string="," />
            <token id="20" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">disturbed</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">disturbed</governor>
          <dependent id="3">am</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="4">disturbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">implication</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">implication</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">disturbed</governor>
          <dependent id="7">implication</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">undocumented</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">implication</governor>
          <dependent id="9">undocumented</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">persons</governor>
          <dependent id="10">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">States</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">States</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">States</governor>
          <dependent id="13">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">residents</governor>
          <dependent id="14">States</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">persons</governor>
          <dependent id="15">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">persons</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">undocumented</governor>
          <dependent id="18">persons</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">Dymally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dymally" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Dymally" />
          </tokens>
        </entity>
        <entity id="2" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="United" />
            <token id="14" string="States" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Noting that at times in the past blacks and Indians have been excluded from participation in government, he commented: ``I do not want to return to a time when some human beings are considered less than equal in the eyes of the law.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Noting" lemma="note" stem="note" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Indians" lemma="Indians" stem="indian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="excluded" lemma="exclude" stem="exclud" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="participation" lemma="participation" stem="particip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="commented" lemma="comment" stem="comment" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="return" lemma="return" stem="return" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="beings" lemma="being" stem="be" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="equal" lemma="equal" stem="equal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="eyes" lemma="eye" stem="ey" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBG Noting) (NP (DT that)) (PP (IN at) (NP (NP (NNS times)) (PP (IN in) (NP (NP (DT the) (JJ past) (NNS blacks)) (CC and) (NP (NNPS Indians)))))))) (VP (VBP have) (VP (VBN been) (VP (VBN excluded) (PP (IN from) (NP (NP (NN participation)) (PP (IN in) (NP (NN government))))))))) (, ,) (NP (PRP he)) (VP (VBD commented) (: :) (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB not) (VP (VB want) (S (VP (TO to) (VP (VB return) (PP (TO to) (NP (DT a) (NN time))) (SBAR (WHADVP (WRB when)) (S (NP (DT some) (JJ human) (NNS beings)) (VP (VBP are) (VP (VBN considered) (ADJP (ADVP (JJR less) (IN than)) (JJ equal)) (PP (IN in) (NP (NP (DT the) (NNS eyes)) (PP (IN of) (NP (DT the) (NN law)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the past blacks and Indians" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="past" />
            <token id="8" string="blacks" />
            <token id="9" string="and" />
            <token id="10" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="2" string="to return to a time when some human beings are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="return" />
            <token id="29" string="to" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="the eyes of the law" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="excluded from participation in government" type="VP">
          <tokens>
            <token id="13" string="excluded" />
            <token id="14" string="from" />
            <token id="15" string="participation" />
            <token id="16" string="in" />
            <token id="17" string="government" />
          </tokens>
        </chunking>
        <chunking id="5" string="do not want to return to a time when some human beings are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="want" />
            <token id="27" string="to" />
            <token id="28" string="return" />
            <token id="29" string="to" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="6" string="the eyes" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="eyes" />
          </tokens>
        </chunking>
        <chunking id="7" string="participation in government" type="NP">
          <tokens>
            <token id="15" string="participation" />
            <token id="16" string="in" />
            <token id="17" string="government" />
          </tokens>
        </chunking>
        <chunking id="8" string="considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="9" string="return to a time when some human beings are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="28" string="return" />
            <token id="29" string="to" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="10" string="when some human beings are considered less than equal in the eyes of the law" type="SBAR">
          <tokens>
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="times in the past blacks and Indians" type="NP">
          <tokens>
            <token id="4" string="times" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="past" />
            <token id="8" string="blacks" />
            <token id="9" string="and" />
            <token id="10" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="13" string="commented : `` I do not want to return to a time when some human beings are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="20" string="commented" />
            <token id="21" string=":" />
            <token id="22" string="``" />
            <token id="23" string="I" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="want" />
            <token id="27" string="to" />
            <token id="28" string="return" />
            <token id="29" string="to" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="14" string="participation" type="NP">
          <tokens>
            <token id="15" string="participation" />
          </tokens>
        </chunking>
        <chunking id="15" string="the past blacks" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="past" />
            <token id="8" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="16" string="want to return to a time when some human beings are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="26" string="want" />
            <token id="27" string="to" />
            <token id="28" string="return" />
            <token id="29" string="to" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="17" string="been excluded from participation in government" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="excluded" />
            <token id="14" string="from" />
            <token id="15" string="participation" />
            <token id="16" string="in" />
            <token id="17" string="government" />
          </tokens>
        </chunking>
        <chunking id="18" string="Noting that at times in the past blacks and Indians" type="VP">
          <tokens>
            <token id="1" string="Noting" />
            <token id="2" string="that" />
            <token id="3" string="at" />
            <token id="4" string="times" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="past" />
            <token id="8" string="blacks" />
            <token id="9" string="and" />
            <token id="10" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="19" string="I" type="NP">
          <tokens>
            <token id="23" string="I" />
          </tokens>
        </chunking>
        <chunking id="20" string="when" type="WHADVP">
          <tokens>
            <token id="32" string="when" />
          </tokens>
        </chunking>
        <chunking id="21" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="22" string="times" type="NP">
          <tokens>
            <token id="4" string="times" />
          </tokens>
        </chunking>
        <chunking id="23" string="some human beings" type="NP">
          <tokens>
            <token id="33" string="some" />
            <token id="34" string="human" />
            <token id="35" string="beings" />
          </tokens>
        </chunking>
        <chunking id="24" string="government" type="NP">
          <tokens>
            <token id="17" string="government" />
          </tokens>
        </chunking>
        <chunking id="25" string="are considered less than equal in the eyes of the law" type="VP">
          <tokens>
            <token id="36" string="are" />
            <token id="37" string="considered" />
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
            <token id="41" string="in" />
            <token id="42" string="the" />
            <token id="43" string="eyes" />
            <token id="44" string="of" />
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="26" string="a time" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="time" />
          </tokens>
        </chunking>
        <chunking id="27" string="Indians" type="NP">
          <tokens>
            <token id="10" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="28" string="the law" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="law" />
          </tokens>
        </chunking>
        <chunking id="29" string="have been excluded from participation in government" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="excluded" />
            <token id="14" string="from" />
            <token id="15" string="participation" />
            <token id="16" string="in" />
            <token id="17" string="government" />
          </tokens>
        </chunking>
        <chunking id="30" string="less than equal" type="ADJP">
          <tokens>
            <token id="38" string="less" />
            <token id="39" string="than" />
            <token id="40" string="equal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubjpass">
          <governor id="13">excluded</governor>
          <dependent id="1">Noting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Noting</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">times</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Noting</governor>
          <dependent id="4">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">blacks</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">blacks</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">blacks</governor>
          <dependent id="7">past</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">times</governor>
          <dependent id="8">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">blacks</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">blacks</governor>
          <dependent id="10">Indians</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">excluded</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">excluded</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">commented</governor>
          <dependent id="13">excluded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">participation</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">excluded</governor>
          <dependent id="15">participation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">government</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">participation</governor>
          <dependent id="17">government</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">commented</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">commented</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">want</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">want</governor>
          <dependent id="24">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">want</governor>
          <dependent id="25">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">commented</governor>
          <dependent id="26">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">return</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">want</governor>
          <dependent id="28">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">time</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">time</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">return</governor>
          <dependent id="31">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">considered</governor>
          <dependent id="32">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">beings</governor>
          <dependent id="33">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">beings</governor>
          <dependent id="34">human</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="37">considered</governor>
          <dependent id="35">beings</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="37">considered</governor>
          <dependent id="36">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">return</governor>
          <dependent id="37">considered</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">equal</governor>
          <dependent id="38">less</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">less</governor>
          <dependent id="39">than</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">considered</governor>
          <dependent id="40">equal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">eyes</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">eyes</governor>
          <dependent id="42">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">considered</governor>
          <dependent id="43">eyes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">law</governor>
          <dependent id="44">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">law</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">eyes</governor>
          <dependent id="46">law</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="past" />
          </tokens>
        </entity>
        <entity id="2" string="Indians" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Indians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``Every census since the Constitution was adopted has counted all residents of the states, including both legal and illegal aliens,&amp;apost;&amp;apost; added Rep. Don Edwards, D-Calif.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="adopted" lemma="adopt" stem="adopt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="Edwards" lemma="Edwards" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="D-Calif" lemma="D-Calif" stem="d-calif" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (DT Every) (NN census)) (SBAR (IN since) (S (NP (DT the) (NNP Constitution)) (VP (VBD was) (VP (VBN adopted)))))) (VP (VBZ has) (VP (VBN counted) (NP (NP (DT all) (NNS residents)) (PP (IN of) (NP (DT the) (NNS states))) (, ,) (PP (VBG including) (NP (ADJP (DT both) (JJ legal) (CC and) (JJ illegal)) (NNS aliens))))))) (, ,) ('' '') (VP (VBD added)) (NP (NP (NNP Rep.) (NNP Don) (NNP Edwards)) (, ,) (NP (NNP D-Calif))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has counted all residents of the states , including both legal and illegal aliens" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="counted" />
            <token id="11" string="all" />
            <token id="12" string="residents" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="states" />
            <token id="16" string="," />
            <token id="17" string="including" />
            <token id="18" string="both" />
            <token id="19" string="legal" />
            <token id="20" string="and" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="both legal and illegal" type="ADJP">
          <tokens>
            <token id="18" string="both" />
            <token id="19" string="legal" />
            <token id="20" string="and" />
            <token id="21" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="3" string="Every census since the Constitution was adopted" type="NP">
          <tokens>
            <token id="2" string="Every" />
            <token id="3" string="census" />
            <token id="4" string="since" />
            <token id="5" string="the" />
            <token id="6" string="Constitution" />
            <token id="7" string="was" />
            <token id="8" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="counted all residents of the states , including both legal and illegal aliens" type="VP">
          <tokens>
            <token id="10" string="counted" />
            <token id="11" string="all" />
            <token id="12" string="residents" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="states" />
            <token id="16" string="," />
            <token id="17" string="including" />
            <token id="18" string="both" />
            <token id="19" string="legal" />
            <token id="20" string="and" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="6" string="Every census" type="NP">
          <tokens>
            <token id="2" string="Every" />
            <token id="3" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="D-Calif" type="NP">
          <tokens>
            <token id="30" string="D-Calif" />
          </tokens>
        </chunking>
        <chunking id="8" string="was adopted" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="9" string="Rep. Don Edwards" type="NP">
          <tokens>
            <token id="26" string="Rep." />
            <token id="27" string="Don" />
            <token id="28" string="Edwards" />
          </tokens>
        </chunking>
        <chunking id="10" string="the states" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="states" />
          </tokens>
        </chunking>
        <chunking id="11" string="both legal and illegal aliens" type="NP">
          <tokens>
            <token id="18" string="both" />
            <token id="19" string="legal" />
            <token id="20" string="and" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="12" string="since the Constitution was adopted" type="SBAR">
          <tokens>
            <token id="4" string="since" />
            <token id="5" string="the" />
            <token id="6" string="Constitution" />
            <token id="7" string="was" />
            <token id="8" string="adopted" />
          </tokens>
        </chunking>
        <chunking id="13" string="all residents of the states , including both legal and illegal aliens" type="NP">
          <tokens>
            <token id="11" string="all" />
            <token id="12" string="residents" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="states" />
            <token id="16" string="," />
            <token id="17" string="including" />
            <token id="18" string="both" />
            <token id="19" string="legal" />
            <token id="20" string="and" />
            <token id="21" string="illegal" />
            <token id="22" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="14" string="all residents" type="NP">
          <tokens>
            <token id="11" string="all" />
            <token id="12" string="residents" />
          </tokens>
        </chunking>
        <chunking id="15" string="added" type="VP">
          <tokens>
            <token id="25" string="added" />
          </tokens>
        </chunking>
        <chunking id="16" string="Rep. Don Edwards , D-Calif" type="NP">
          <tokens>
            <token id="26" string="Rep." />
            <token id="27" string="Don" />
            <token id="28" string="Edwards" />
            <token id="29" string="," />
            <token id="30" string="D-Calif" />
          </tokens>
        </chunking>
        <chunking id="17" string="adopted" type="VP">
          <tokens>
            <token id="8" string="adopted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">census</governor>
          <dependent id="2">Every</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">counted</governor>
          <dependent id="3">census</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">adopted</governor>
          <dependent id="4">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Constitution</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">adopted</governor>
          <dependent id="6">Constitution</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">adopted</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">census</governor>
          <dependent id="8">adopted</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">counted</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">added</governor>
          <dependent id="10">counted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">residents</governor>
          <dependent id="11">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">counted</governor>
          <dependent id="12">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">states</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">states</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">residents</governor>
          <dependent id="15">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">aliens</governor>
          <dependent id="17">including</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="19">legal</governor>
          <dependent id="18">both</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">aliens</governor>
          <dependent id="19">legal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">legal</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">legal</governor>
          <dependent id="21">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">residents</governor>
          <dependent id="22">aliens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">added</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Edwards</governor>
          <dependent id="26">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Edwards</governor>
          <dependent id="27">Don</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">added</governor>
          <dependent id="28">Edwards</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Edwards</governor>
          <dependent id="30">D-Calif</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Don Edwards" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Don" />
            <token id="28" string="Edwards" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``It was never the intent of the framers to include only citizens for apportionment purposes.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="intent" lemma="intent" stem="intent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="framers" lemma="framer" stem="framer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="include" lemma="include" stem="includ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="apportionment" lemma="apportionment" stem="apportion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="purposes" lemma="purpose" stem="purpos" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBD was) (ADVP (RB never)) (NP (NP (DT the) (NN intent)) (PP (IN of) (NP (DT the) (NNS framers))) (S (VP (TO to) (VP (VB include) (NP (NP (RB only) (NNS citizens)) (PP (IN for) (NP (NN apportionment) (NNS purposes))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the intent of the framers to include only citizens for apportionment purposes" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="intent" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="framers" />
            <token id="10" string="to" />
            <token id="11" string="include" />
            <token id="12" string="only" />
            <token id="13" string="citizens" />
            <token id="14" string="for" />
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="2" string="the framers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="framers" />
          </tokens>
        </chunking>
        <chunking id="3" string="only citizens" type="NP">
          <tokens>
            <token id="12" string="only" />
            <token id="13" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="4" string="the intent" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="intent" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="only citizens for apportionment purposes" type="NP">
          <tokens>
            <token id="12" string="only" />
            <token id="13" string="citizens" />
            <token id="14" string="for" />
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="7" string="apportionment purposes" type="NP">
          <tokens>
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="8" string="was never the intent of the framers to include only citizens for apportionment purposes" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="never" />
            <token id="5" string="the" />
            <token id="6" string="intent" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="framers" />
            <token id="10" string="to" />
            <token id="11" string="include" />
            <token id="12" string="only" />
            <token id="13" string="citizens" />
            <token id="14" string="for" />
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="9" string="to include only citizens for apportionment purposes" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="include" />
            <token id="12" string="only" />
            <token id="13" string="citizens" />
            <token id="14" string="for" />
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
        <chunking id="10" string="include only citizens for apportionment purposes" type="VP">
          <tokens>
            <token id="11" string="include" />
            <token id="12" string="only" />
            <token id="13" string="citizens" />
            <token id="14" string="for" />
            <token id="15" string="apportionment" />
            <token id="16" string="purposes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">intent</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">intent</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">intent</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">intent</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">intent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">framers</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">framers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">intent</governor>
          <dependent id="9">framers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">include</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">intent</governor>
          <dependent id="11">include</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">citizens</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">include</governor>
          <dependent id="13">citizens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">purposes</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">purposes</governor>
          <dependent id="15">apportionment</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">citizens</governor>
          <dependent id="16">purposes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>And Rep. Albert G. Bustamente, D-Texas, termed the worry over counting aliens ``hysterical,&amp;apost;&amp;apost; pointing out that the movement of Americans into western and southern states has had a much larger effect on representation than the presence of aliens.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="G." lemma="G." stem="g." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Bustamente" lemma="Bustamente" stem="bustament" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="D-Texas" lemma="D-Texas" stem="d-texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="termed" lemma="term" stem="term" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="worry" lemma="worry" stem="worri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hysterical" lemma="hysterical" stem="hyster" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pointing" lemma="point" stem="point" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="movement" lemma="movement" stem="movement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="western" lemma="western" stem="western" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="southern" lemma="southern" stem="southern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="larger" lemma="larger" stem="larger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="representation" lemma="representation" stem="represent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="presence" lemma="presence" stem="presenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (NNP Rep.) (NNP Albert) (NNP G.) (NNP Bustamente)) (, ,) (NP (NNP D-Texas)) (, ,)) (VP (VBN termed) (NP (DT the) (NN worry)) (PP (IN over) (S (VP (VP (VBG counting) (S (NP (NNS aliens)) (`` ``) (ADJP (JJ hysterical)))) (, ,) ('' '') (VP (VBG pointing) (PRT (RP out)) (SBAR (IN that) (S (NP (NP (DT the) (NN movement)) (PP (IN of) (NP (NP (NNPS Americans)) (PP (IN into) (NP (JJ western) (CC and) (JJ southern) (NNS states)))))) (VP (VBZ has) (VP (VBN had) (NP (NP (DT a) (ADJP (RB much) (JJR larger)) (NN effect)) (PP (IN on) (NP (NN representation))))))))) (PP (IN than) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (NNS aliens))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the movement of Americans into western and southern states has had a much larger effect on representation" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="movement" />
            <token id="24" string="of" />
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
            <token id="31" string="has" />
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="2" string="aliens" type="NP">
          <tokens>
            <token id="14" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="Americans" type="NP">
          <tokens>
            <token id="25" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="much larger" type="ADJP">
          <tokens>
            <token id="34" string="much" />
            <token id="35" string="larger" />
          </tokens>
        </chunking>
        <chunking id="5" string="termed the worry over counting aliens `` hysterical , '' pointing out that the movement of Americans into western and southern states has had a much larger effect on representation than the presence of aliens" type="VP">
          <tokens>
            <token id="9" string="termed" />
            <token id="10" string="the" />
            <token id="11" string="worry" />
            <token id="12" string="over" />
            <token id="13" string="counting" />
            <token id="14" string="aliens" />
            <token id="15" string="``" />
            <token id="16" string="hysterical" />
            <token id="17" string="," />
            <token id="18" string="''" />
            <token id="19" string="pointing" />
            <token id="20" string="out" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="movement" />
            <token id="24" string="of" />
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
            <token id="31" string="has" />
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
            <token id="39" string="than" />
            <token id="40" string="the" />
            <token id="41" string="presence" />
            <token id="42" string="of" />
            <token id="43" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="6" string="the presence of aliens" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="presence" />
            <token id="42" string="of" />
            <token id="43" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="7" string="Rep. Albert G. Bustamente" type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Albert" />
            <token id="4" string="G." />
            <token id="5" string="Bustamente" />
          </tokens>
        </chunking>
        <chunking id="8" string="representation" type="NP">
          <tokens>
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="9" string="counting aliens `` hysterical , '' pointing out that the movement of Americans into western and southern states has had a much larger effect on representation than the presence of aliens" type="VP">
          <tokens>
            <token id="13" string="counting" />
            <token id="14" string="aliens" />
            <token id="15" string="``" />
            <token id="16" string="hysterical" />
            <token id="17" string="," />
            <token id="18" string="''" />
            <token id="19" string="pointing" />
            <token id="20" string="out" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="movement" />
            <token id="24" string="of" />
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
            <token id="31" string="has" />
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
            <token id="39" string="than" />
            <token id="40" string="the" />
            <token id="41" string="presence" />
            <token id="42" string="of" />
            <token id="43" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="10" string="D-Texas" type="NP">
          <tokens>
            <token id="7" string="D-Texas" />
          </tokens>
        </chunking>
        <chunking id="11" string="a much larger effect on representation" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="12" string="pointing out that the movement of Americans into western and southern states has had a much larger effect on representation" type="VP">
          <tokens>
            <token id="19" string="pointing" />
            <token id="20" string="out" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="movement" />
            <token id="24" string="of" />
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
            <token id="31" string="has" />
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="13" string="counting aliens `` hysterical" type="VP">
          <tokens>
            <token id="13" string="counting" />
            <token id="14" string="aliens" />
            <token id="15" string="``" />
            <token id="16" string="hysterical" />
          </tokens>
        </chunking>
        <chunking id="14" string="Rep. Albert G. Bustamente , D-Texas ," type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Albert" />
            <token id="4" string="G." />
            <token id="5" string="Bustamente" />
            <token id="6" string="," />
            <token id="7" string="D-Texas" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="had a much larger effect on representation" type="VP">
          <tokens>
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="16" string="a much larger effect" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
          </tokens>
        </chunking>
        <chunking id="17" string="the movement of Americans into western and southern states" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="movement" />
            <token id="24" string="of" />
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
          </tokens>
        </chunking>
        <chunking id="18" string="has had a much larger effect on representation" type="VP">
          <tokens>
            <token id="31" string="has" />
            <token id="32" string="had" />
            <token id="33" string="a" />
            <token id="34" string="much" />
            <token id="35" string="larger" />
            <token id="36" string="effect" />
            <token id="37" string="on" />
            <token id="38" string="representation" />
          </tokens>
        </chunking>
        <chunking id="19" string="Americans into western and southern states" type="NP">
          <tokens>
            <token id="25" string="Americans" />
            <token id="26" string="into" />
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
          </tokens>
        </chunking>
        <chunking id="20" string="hysterical" type="ADJP">
          <tokens>
            <token id="16" string="hysterical" />
          </tokens>
        </chunking>
        <chunking id="21" string="the movement" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="movement" />
          </tokens>
        </chunking>
        <chunking id="22" string="the worry" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="worry" />
          </tokens>
        </chunking>
        <chunking id="23" string="western and southern states" type="NP">
          <tokens>
            <token id="27" string="western" />
            <token id="28" string="and" />
            <token id="29" string="southern" />
            <token id="30" string="states" />
          </tokens>
        </chunking>
        <chunking id="24" string="the presence" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="presence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">termed</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Bustamente</governor>
          <dependent id="2">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Bustamente</governor>
          <dependent id="3">Albert</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Bustamente</governor>
          <dependent id="4">G.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">termed</governor>
          <dependent id="5">Bustamente</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Bustamente</governor>
          <dependent id="7">D-Texas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">termed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">worry</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">termed</governor>
          <dependent id="11">worry</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">counting</governor>
          <dependent id="12">over</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">termed</governor>
          <dependent id="13">counting</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">hysterical</governor>
          <dependent id="14">aliens</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">counting</governor>
          <dependent id="16">hysterical</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">counting</governor>
          <dependent id="19">pointing</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="19">pointing</governor>
          <dependent id="20">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">had</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">movement</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">had</governor>
          <dependent id="23">movement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Americans</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">movement</governor>
          <dependent id="25">Americans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">states</governor>
          <dependent id="26">into</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">states</governor>
          <dependent id="27">western</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">western</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">western</governor>
          <dependent id="29">southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Americans</governor>
          <dependent id="30">states</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">had</governor>
          <dependent id="31">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">pointing</governor>
          <dependent id="32">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">effect</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">larger</governor>
          <dependent id="34">much</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">effect</governor>
          <dependent id="35">larger</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">had</governor>
          <dependent id="36">effect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">representation</governor>
          <dependent id="37">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">effect</governor>
          <dependent id="38">representation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">presence</governor>
          <dependent id="39">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">presence</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">counting</governor>
          <dependent id="41">presence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">aliens</governor>
          <dependent id="42">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">presence</governor>
          <dependent id="43">aliens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="Albert G. Bustamente" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Albert" />
            <token id="4" string="G." />
            <token id="5" string="Bustamente" />
          </tokens>
        </entity>
        <entity id="3" string="D-Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="D-Texas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>The Census Bureau also opposes the bills, contending that the effort to determine who is an illegal alien could delay and complicate the count and that people would be unlikely to tell the truth anyway.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="opposes" lemma="oppose" stem="oppos" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="bills" lemma="bill" stem="bill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="contending" lemma="contend" stem="contend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="alien" lemma="alien" stem="alien" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="delay" lemma="delay" stem="delai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="complicate" lemma="complicate" stem="complic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="unlikely" lemma="unlikely" stem="unlik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="anyway" lemma="anyway" stem="anywai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Census) (NNP Bureau)) (ADVP (RB also)) (VP (VBZ opposes) (NP (DT the) (NNS bills)) (, ,) (S (VP (VBG contending) (SBAR (SBAR (IN that) (S (NP (DT the) (NN effort) (S (VP (TO to) (VP (VB determine) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (NP (DT an) (JJ illegal) (NN alien))))))))) (VP (MD could) (VP (VB delay) (CC and) (VB complicate) (NP (DT the) (NN count)))))) (CC and) (SBAR (IN that) (S (NP (NNS people)) (VP (MD would) (VP (VB be) (ADJP (JJ unlikely) (S (VP (TO to) (VP (VB tell) (NP (DT the) (NN truth)) (ADVP (RB anyway)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could delay and complicate the count" type="VP">
          <tokens>
            <token id="20" string="could" />
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Census Bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="3" string="an illegal alien" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="4" string="to tell the truth anyway" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="5" string="would be unlikely to tell the truth anyway" type="VP">
          <tokens>
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="6" string="that the effort to determine who is an illegal alien could delay and complicate the count" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="effort" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
            <token id="20" string="could" />
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
          </tokens>
        </chunking>
        <chunking id="7" string="be unlikely to tell the truth anyway" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="8" string="contending that the effort to determine who is an illegal alien could delay and complicate the count and that people would be unlikely to tell the truth anyway" type="VP">
          <tokens>
            <token id="9" string="contending" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="effort" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
            <token id="20" string="could" />
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
            <token id="26" string="and" />
            <token id="27" string="that" />
            <token id="28" string="people" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="9" string="that the effort to determine who is an illegal alien could delay and complicate the count and that people would be unlikely to tell the truth anyway" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="effort" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
            <token id="20" string="could" />
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
            <token id="26" string="and" />
            <token id="27" string="that" />
            <token id="28" string="people" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="10" string="that people would be unlikely to tell the truth anyway" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="people" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="11" string="the count" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="count" />
          </tokens>
        </chunking>
        <chunking id="12" string="people" type="NP">
          <tokens>
            <token id="28" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="is an illegal alien" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="14" string="determine who is an illegal alien" type="VP">
          <tokens>
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="15" string="to determine who is an illegal alien" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="16" string="unlikely to tell the truth anyway" type="ADJP">
          <tokens>
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="17" string="tell the truth anyway" type="VP">
          <tokens>
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="18" string="the effort to determine who is an illegal alien" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="effort" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="19" string="delay and complicate the count" type="VP">
          <tokens>
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
          </tokens>
        </chunking>
        <chunking id="20" string="opposes the bills , contending that the effort to determine who is an illegal alien could delay and complicate the count and that people would be unlikely to tell the truth anyway" type="VP">
          <tokens>
            <token id="5" string="opposes" />
            <token id="6" string="the" />
            <token id="7" string="bills" />
            <token id="8" string="," />
            <token id="9" string="contending" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="effort" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
            <token id="20" string="could" />
            <token id="21" string="delay" />
            <token id="22" string="and" />
            <token id="23" string="complicate" />
            <token id="24" string="the" />
            <token id="25" string="count" />
            <token id="26" string="and" />
            <token id="27" string="that" />
            <token id="28" string="people" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="unlikely" />
            <token id="32" string="to" />
            <token id="33" string="tell" />
            <token id="34" string="the" />
            <token id="35" string="truth" />
            <token id="36" string="anyway" />
          </tokens>
        </chunking>
        <chunking id="21" string="who is an illegal alien" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="is" />
            <token id="17" string="an" />
            <token id="18" string="illegal" />
            <token id="19" string="alien" />
          </tokens>
        </chunking>
        <chunking id="22" string="the truth" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="truth" />
          </tokens>
        </chunking>
        <chunking id="23" string="the bills" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="bills" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">opposes</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">opposes</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">opposes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">bills</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">opposes</governor>
          <dependent id="7">bills</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">opposes</governor>
          <dependent id="9">contending</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">delay</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">effort</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">delay</governor>
          <dependent id="12">effort</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">determine</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">effort</governor>
          <dependent id="14">determine</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">alien</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">alien</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">alien</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">alien</governor>
          <dependent id="18">illegal</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">determine</governor>
          <dependent id="19">alien</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">delay</governor>
          <dependent id="20">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">contending</governor>
          <dependent id="21">delay</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">delay</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">delay</governor>
          <dependent id="23">complicate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">count</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">delay</governor>
          <dependent id="25">count</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">delay</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">unlikely</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">unlikely</governor>
          <dependent id="28">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">unlikely</governor>
          <dependent id="29">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">unlikely</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">delay</governor>
          <dependent id="31">unlikely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">tell</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">unlikely</governor>
          <dependent id="33">tell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">truth</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">tell</governor>
          <dependent id="35">truth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">tell</governor>
          <dependent id="36">anyway</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>But Reps. Tom Petri, R-Wis.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Reps." lemma="Reps." stem="reps." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Tom" lemma="Tom" stem="tom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Petri" lemma="Petri" stem="petri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="R-Wis" lemma="R-Wis" stem="r-wi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC But) (NP (NP (NNP Reps.) (NNP Tom) (NNP Petri)) (, ,) (NP (NNP R-Wis)) (. .))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Reps. Tom Petri" type="NP">
          <tokens>
            <token id="2" string="Reps." />
            <token id="3" string="Tom" />
            <token id="4" string="Petri" />
          </tokens>
        </chunking>
        <chunking id="2" string="R-Wis" type="NP">
          <tokens>
            <token id="6" string="R-Wis" />
          </tokens>
        </chunking>
        <chunking id="3" string="Reps. Tom Petri , R-Wis ." type="NP">
          <tokens>
            <token id="2" string="Reps." />
            <token id="3" string="Tom" />
            <token id="4" string="Petri" />
            <token id="5" string="," />
            <token id="6" string="R-Wis" />
            <token id="7" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">Petri</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Petri</governor>
          <dependent id="2">Reps.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Petri</governor>
          <dependent id="3">Tom</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">Petri</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Petri</governor>
          <dependent id="6">R-Wis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tom Petri" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Tom" />
            <token id="4" string="Petri" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>and William F. Goodling, R-Pa., asserted that counting illegal aliens violates citizens&amp;apost; basic right to equal representation by giving greater voice in Congress to states where the aliens live.</content>
      <tokens>
        <token id="1" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="F." lemma="F." stem="f." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Goodling" lemma="Goodling" stem="goodl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="R-Pa." lemma="R-Pa." stem="r-pa." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="asserted" lemma="assert" stem="assert" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="violates" lemma="violate" stem="violat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="basic" lemma="basic" stem="basic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="equal" lemma="equal" stem="equal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="representation" lemma="representation" stem="represent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="greater" lemma="greater" stem="greater" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="live" lemma="live" stem="live" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC and) (NP (NP (NNP William) (NNP F.) (NNP Goodling)) (, ,) (NP (NNP R-Pa.)) (, ,)) (VP (VBD asserted) (SBAR (IN that) (S (NP (VBG counting) (JJ illegal) (NNS aliens)) (VP (VBZ violates) (NP (NP (NP (NNS citizens) (POS ')) (JJ basic) (NN right)) (PP (TO to) (NP (JJ equal) (NN representation)))) (PP (IN by) (S (VP (VBG giving) (NP (JJR greater) (NN voice)) (PP (IN in) (NP (NNP Congress))) (PP (TO to) (NP (NP (NNS states)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NNS aliens)) (VP (VBP live))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the aliens" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="states where the aliens live" type="NP">
          <tokens>
            <token id="28" string="states" />
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="3" string="William F. Goodling , R-Pa. ," type="NP">
          <tokens>
            <token id="2" string="William" />
            <token id="3" string="F." />
            <token id="4" string="Goodling" />
            <token id="5" string="," />
            <token id="6" string="R-Pa." />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="greater voice" type="NP">
          <tokens>
            <token id="23" string="greater" />
            <token id="24" string="voice" />
          </tokens>
        </chunking>
        <chunking id="5" string="William F. Goodling" type="NP">
          <tokens>
            <token id="2" string="William" />
            <token id="3" string="F." />
            <token id="4" string="Goodling" />
          </tokens>
        </chunking>
        <chunking id="6" string="violates citizens ' basic right to equal representation by giving greater voice in Congress to states where the aliens live" type="VP">
          <tokens>
            <token id="13" string="violates" />
            <token id="14" string="citizens" />
            <token id="15" string="'" />
            <token id="16" string="basic" />
            <token id="17" string="right" />
            <token id="18" string="to" />
            <token id="19" string="equal" />
            <token id="20" string="representation" />
            <token id="21" string="by" />
            <token id="22" string="giving" />
            <token id="23" string="greater" />
            <token id="24" string="voice" />
            <token id="25" string="in" />
            <token id="26" string="Congress" />
            <token id="27" string="to" />
            <token id="28" string="states" />
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="7" string="states" type="NP">
          <tokens>
            <token id="28" string="states" />
          </tokens>
        </chunking>
        <chunking id="8" string="giving greater voice in Congress to states where the aliens live" type="VP">
          <tokens>
            <token id="22" string="giving" />
            <token id="23" string="greater" />
            <token id="24" string="voice" />
            <token id="25" string="in" />
            <token id="26" string="Congress" />
            <token id="27" string="to" />
            <token id="28" string="states" />
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="9" string="Congress" type="NP">
          <tokens>
            <token id="26" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="10" string="citizens '" type="NP">
          <tokens>
            <token id="14" string="citizens" />
            <token id="15" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="asserted that counting illegal aliens violates citizens ' basic right to equal representation by giving greater voice in Congress to states where the aliens live" type="VP">
          <tokens>
            <token id="8" string="asserted" />
            <token id="9" string="that" />
            <token id="10" string="counting" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="violates" />
            <token id="14" string="citizens" />
            <token id="15" string="'" />
            <token id="16" string="basic" />
            <token id="17" string="right" />
            <token id="18" string="to" />
            <token id="19" string="equal" />
            <token id="20" string="representation" />
            <token id="21" string="by" />
            <token id="22" string="giving" />
            <token id="23" string="greater" />
            <token id="24" string="voice" />
            <token id="25" string="in" />
            <token id="26" string="Congress" />
            <token id="27" string="to" />
            <token id="28" string="states" />
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="12" string="counting illegal aliens" type="NP">
          <tokens>
            <token id="10" string="counting" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="13" string="where the aliens live" type="SBAR">
          <tokens>
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="14" string="that counting illegal aliens violates citizens ' basic right to equal representation by giving greater voice in Congress to states where the aliens live" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="counting" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="violates" />
            <token id="14" string="citizens" />
            <token id="15" string="'" />
            <token id="16" string="basic" />
            <token id="17" string="right" />
            <token id="18" string="to" />
            <token id="19" string="equal" />
            <token id="20" string="representation" />
            <token id="21" string="by" />
            <token id="22" string="giving" />
            <token id="23" string="greater" />
            <token id="24" string="voice" />
            <token id="25" string="in" />
            <token id="26" string="Congress" />
            <token id="27" string="to" />
            <token id="28" string="states" />
            <token id="29" string="where" />
            <token id="30" string="the" />
            <token id="31" string="aliens" />
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="15" string="citizens ' basic right" type="NP">
          <tokens>
            <token id="14" string="citizens" />
            <token id="15" string="'" />
            <token id="16" string="basic" />
            <token id="17" string="right" />
          </tokens>
        </chunking>
        <chunking id="16" string="equal representation" type="NP">
          <tokens>
            <token id="19" string="equal" />
            <token id="20" string="representation" />
          </tokens>
        </chunking>
        <chunking id="17" string="R-Pa." type="NP">
          <tokens>
            <token id="6" string="R-Pa." />
          </tokens>
        </chunking>
        <chunking id="18" string="live" type="VP">
          <tokens>
            <token id="32" string="live" />
          </tokens>
        </chunking>
        <chunking id="19" string="where" type="WHADVP">
          <tokens>
            <token id="29" string="where" />
          </tokens>
        </chunking>
        <chunking id="20" string="citizens ' basic right to equal representation" type="NP">
          <tokens>
            <token id="14" string="citizens" />
            <token id="15" string="'" />
            <token id="16" string="basic" />
            <token id="17" string="right" />
            <token id="18" string="to" />
            <token id="19" string="equal" />
            <token id="20" string="representation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">asserted</governor>
          <dependent id="1">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Goodling</governor>
          <dependent id="2">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Goodling</governor>
          <dependent id="3">F.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">asserted</governor>
          <dependent id="4">Goodling</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Goodling</governor>
          <dependent id="6">R-Pa.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">asserted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">violates</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">aliens</governor>
          <dependent id="10">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">aliens</governor>
          <dependent id="11">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">violates</governor>
          <dependent id="12">aliens</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">asserted</governor>
          <dependent id="13">violates</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">right</governor>
          <dependent id="14">citizens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">citizens</governor>
          <dependent id="15">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">right</governor>
          <dependent id="16">basic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">violates</governor>
          <dependent id="17">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">representation</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">representation</governor>
          <dependent id="19">equal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">right</governor>
          <dependent id="20">representation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">giving</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">violates</governor>
          <dependent id="22">giving</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">voice</governor>
          <dependent id="23">greater</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">giving</governor>
          <dependent id="24">voice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Congress</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">giving</governor>
          <dependent id="26">Congress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">states</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">giving</governor>
          <dependent id="28">states</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">live</governor>
          <dependent id="29">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">aliens</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">live</governor>
          <dependent id="31">aliens</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">states</governor>
          <dependent id="32">live</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="R-Pa." type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="R-Pa." />
          </tokens>
        </entity>
        <entity id="2" string="William F. Goodling" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="William" />
            <token id="3" string="F." />
            <token id="4" string="Goodling" />
          </tokens>
        </entity>
        <entity id="3" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="17" string="right" />
          </tokens>
        </entity>
        <entity id="4" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>And Rep. Tim Valentine, D-N.C.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Tim" lemma="Tim" stem="tim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Valentine" lemma="Valentine" stem="valentin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="D-N.C" lemma="D-N.C" stem="d-n.c" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC And) (NP (NP (NNP Rep.) (NNP Tim) (NNP Valentine)) (, ,) (NP (NNP D-N.C)) (. .))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rep. Tim Valentine" type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Tim" />
            <token id="4" string="Valentine" />
          </tokens>
        </chunking>
        <chunking id="2" string="Rep. Tim Valentine , D-N.C ." type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Tim" />
            <token id="4" string="Valentine" />
            <token id="5" string="," />
            <token id="6" string="D-N.C" />
            <token id="7" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="D-N.C" type="NP">
          <tokens>
            <token id="6" string="D-N.C" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">Valentine</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Valentine</governor>
          <dependent id="2">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Valentine</governor>
          <dependent id="3">Tim</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">Valentine</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Valentine</governor>
          <dependent id="6">D-N.C</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tim Valentine" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Tim" />
            <token id="4" string="Valentine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>, contended that counting aliens ``in effect, is granting representation in Congress to individuals who have entered this country by breaking the laws of the United States.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="contended" lemma="contend" stem="contend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="granting" lemma="grant" stem="grant" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="representation" lemma="representation" stem="represent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="individuals" lemma="individual" stem="individu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="entered" lemma="enter" stem="enter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="breaking" lemma="break" stem="break" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (, ,) (S (VP (VBD contended) (SBAR (IN that) (SINV (S (VP (VBG counting) (NP (NNS aliens)) (`` ``) (PP (IN in) (NP (NN effect))))) (, ,) (VP (VBZ is) (VP (VBG granting) (NP (NP (NN representation)) (PP (IN in) (NP (NNP Congress)))) (PP (TO to) (NP (NP (NNS individuals)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN entered))))))))) (NP (NP (DT this) (NN country)) (PP (IN by) (S (VP (VBG breaking) (NP (NP (DT the) (NNS laws)) (PP (IN of) (NP (DT the) (NNP United) (NNPS States)))))))) (. .) ('' '')))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="representation in Congress" type="NP">
          <tokens>
            <token id="12" string="representation" />
            <token id="13" string="in" />
            <token id="14" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="2" string="the laws of the United States" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="laws" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
          </tokens>
        </chunking>
        <chunking id="3" string="the laws" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="laws" />
          </tokens>
        </chunking>
        <chunking id="4" string="aliens" type="NP">
          <tokens>
            <token id="5" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="5" string="granting representation in Congress to individuals who have entered" type="VP">
          <tokens>
            <token id="11" string="granting" />
            <token id="12" string="representation" />
            <token id="13" string="in" />
            <token id="14" string="Congress" />
            <token id="15" string="to" />
            <token id="16" string="individuals" />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
          </tokens>
        </chunking>
        <chunking id="6" string="contended that counting aliens `` in effect , is granting representation in Congress to individuals who have entered this country by breaking the laws of the United States . ''" type="VP">
          <tokens>
            <token id="2" string="contended" />
            <token id="3" string="that" />
            <token id="4" string="counting" />
            <token id="5" string="aliens" />
            <token id="6" string="``" />
            <token id="7" string="in" />
            <token id="8" string="effect" />
            <token id="9" string="," />
            <token id="10" string="is" />
            <token id="11" string="granting" />
            <token id="12" string="representation" />
            <token id="13" string="in" />
            <token id="14" string="Congress" />
            <token id="15" string="to" />
            <token id="16" string="individuals" />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
            <token id="20" string="this" />
            <token id="21" string="country" />
            <token id="22" string="by" />
            <token id="23" string="breaking" />
            <token id="24" string="the" />
            <token id="25" string="laws" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
            <token id="30" string="." />
            <token id="31" string="''" />
          </tokens>
        </chunking>
        <chunking id="7" string="entered" type="VP">
          <tokens>
            <token id="19" string="entered" />
          </tokens>
        </chunking>
        <chunking id="8" string="who have entered" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
          </tokens>
        </chunking>
        <chunking id="9" string="representation" type="NP">
          <tokens>
            <token id="12" string="representation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="14" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="individuals" type="NP">
          <tokens>
            <token id="16" string="individuals" />
          </tokens>
        </chunking>
        <chunking id="12" string="the United States" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
          </tokens>
        </chunking>
        <chunking id="13" string="have entered" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="entered" />
          </tokens>
        </chunking>
        <chunking id="14" string="this country by breaking the laws of the United States" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="country" />
            <token id="22" string="by" />
            <token id="23" string="breaking" />
            <token id="24" string="the" />
            <token id="25" string="laws" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
          </tokens>
        </chunking>
        <chunking id="15" string="this country" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="16" string="that counting aliens `` in effect , is granting representation in Congress to individuals who have entered this country by breaking the laws of the United States . ''" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="counting" />
            <token id="5" string="aliens" />
            <token id="6" string="``" />
            <token id="7" string="in" />
            <token id="8" string="effect" />
            <token id="9" string="," />
            <token id="10" string="is" />
            <token id="11" string="granting" />
            <token id="12" string="representation" />
            <token id="13" string="in" />
            <token id="14" string="Congress" />
            <token id="15" string="to" />
            <token id="16" string="individuals" />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
            <token id="20" string="this" />
            <token id="21" string="country" />
            <token id="22" string="by" />
            <token id="23" string="breaking" />
            <token id="24" string="the" />
            <token id="25" string="laws" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
            <token id="30" string="." />
            <token id="31" string="''" />
          </tokens>
        </chunking>
        <chunking id="17" string="effect" type="NP">
          <tokens>
            <token id="8" string="effect" />
          </tokens>
        </chunking>
        <chunking id="18" string="counting aliens `` in effect" type="VP">
          <tokens>
            <token id="4" string="counting" />
            <token id="5" string="aliens" />
            <token id="6" string="``" />
            <token id="7" string="in" />
            <token id="8" string="effect" />
          </tokens>
        </chunking>
        <chunking id="19" string="breaking the laws of the United States" type="VP">
          <tokens>
            <token id="23" string="breaking" />
            <token id="24" string="the" />
            <token id="25" string="laws" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="United" />
            <token id="29" string="States" />
          </tokens>
        </chunking>
        <chunking id="20" string="individuals who have entered" type="NP">
          <tokens>
            <token id="16" string="individuals" />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
          </tokens>
        </chunking>
        <chunking id="21" string="is granting representation in Congress to individuals who have entered" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="granting" />
            <token id="12" string="representation" />
            <token id="13" string="in" />
            <token id="14" string="Congress" />
            <token id="15" string="to" />
            <token id="16" string="individuals" />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="entered" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">contended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">granting</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">granting</governor>
          <dependent id="4">counting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">counting</governor>
          <dependent id="5">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">effect</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">counting</governor>
          <dependent id="8">effect</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">granting</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">contended</governor>
          <dependent id="11">granting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">granting</governor>
          <dependent id="12">representation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Congress</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">representation</governor>
          <dependent id="14">Congress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">individuals</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">granting</governor>
          <dependent id="16">individuals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">entered</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">entered</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">individuals</governor>
          <dependent id="19">entered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">country</governor>
          <dependent id="20">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">granting</governor>
          <dependent id="21">country</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">breaking</governor>
          <dependent id="22">by</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">country</governor>
          <dependent id="23">breaking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">laws</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">breaking</governor>
          <dependent id="25">laws</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">States</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">States</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">States</governor>
          <dependent id="28">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">laws</governor>
          <dependent id="29">States</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="United" />
            <token id="29" string="States" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The U.S. Constitution" id_sentence="8" />
      <mentions>
        <mention ids_tokens="22-23" string="the Constitution" id_sentence="1" />
        <mention ids_tokens="1" string="It" id_sentence="9" />
        <mention ids_tokens="5-6" string="the Constitution" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="16-17" string="the bills" id_sentence="7" />
      <mentions>
        <mention ids_tokens="9-45" string="bills which would require the Census Bureau to figure out whether people are in the country legally and , if not , to delete them from the counts used in reapportioning seats in the House of Representatives" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="20" string="people" id_sentence="2" />
      <mentions>
        <mention ids_tokens="30" string="their" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="42-43-44-45" string="the House of Representatives" id_sentence="2" />
      <mentions>
        <mention ids_tokens="39-40" string="the House" id_sentence="3" />
        <mention ids_tokens="13" string="House" id_sentence="4" />
        <mention ids_tokens="13" string="House" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="11-12-13" string="Thomas J. Ridge" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="Ridge" id_sentence="5" />
        <mention ids_tokens="4" string="he" id_sentence="6" />
        <mention ids_tokens="20" string="Ridge" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="36-37-38-39-40" string="extra seats in the House" id_sentence="3" />
      <mentions>
        <mention ids_tokens="13-14" string="House seats" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="3-4-5" string="Mervyn M. Dymally" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="10" />
        <mention ids_tokens="22" string="Dymally" id_sentence="10" />
        <mention ids_tokens="19" string="he" id_sentence="11" />
        <mention ids_tokens="23" string="I" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17" string="the `` persons '' in the country" id_sentence="8" />
      <mentions>
        <mention ids_tokens="10-14" string="residents of the United States" id_sentence="10" />
        <mention ids_tokens="17-20" string="` persons ,''" id_sentence="10" />
        <mention ids_tokens="18" string="persons" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14-15-16-17-18-19-20" string="the implication that undocumented residents of the United States are not ` persons , ''" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="12-13-14" string="the United States" id_sentence="10" />
      <mentions>
        <mention ids_tokens="14-15" string="the states" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="14" string="aliens" id_sentence="14" />
      <mentions>
        <mention ids_tokens="18-22" string="both legal and illegal aliens" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16" string="only citizens for apportionment purposes" id_sentence="13" />
      <mentions>
        <mention ids_tokens="14-15" string="citizens'" id_sentence="17" />
      </mentions>
    </coreference>
  </coreferences>
</document>
