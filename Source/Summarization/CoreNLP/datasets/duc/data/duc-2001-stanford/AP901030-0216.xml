<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP901030-0216">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Britain and France were linked beneath the English Channel on Tuesday when workers used a two-inch probe to connect two halves of a 31-mile undersea rail tunnel, officials reported.</content>
      <tokens>
        <token id="1" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="linked" lemma="link" stem="link" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="beneath" lemma="beneath" stem="beneath" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="two-inch" lemma="two-inch" stem="two-inch" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="connect" lemma="connect" stem="connect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="21" string="halves" lemma="half" stem="halv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="31-mile" lemma="31-mile" stem="31-mile" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="undersea" lemma="undersea" stem="undersea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="rail" lemma="rail" stem="rail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Britain) (CC and) (NNP France)) (VP (VBD were) (VP (VBN linked) (PP (IN beneath) (NP (NP (DT the) (NNP English) (NNP Channel)) (PP (IN on) (NP (NNP Tuesday))))) (SBAR (WHADVP (WRB when)) (S (NP (NNS workers)) (VP (VBD used) (NP (DT a) (JJ two-inch) (NN probe)) (S (VP (TO to) (VP (VB connect) (NP (NP (CD two) (NNS halves)) (PP (IN of) (NP (DT a) (JJ 31-mile) (NN undersea) (NN rail) (NN tunnel))))))))))))) (, ,) (NP (NNS officials)) (VP (VBD reported)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="linked beneath the English Channel on Tuesday when workers used a two-inch probe to connect two halves of a 31-mile undersea rail tunnel" type="VP">
          <tokens>
            <token id="5" string="linked" />
            <token id="6" string="beneath" />
            <token id="7" string="the" />
            <token id="8" string="English" />
            <token id="9" string="Channel" />
            <token id="10" string="on" />
            <token id="11" string="Tuesday" />
            <token id="12" string="when" />
            <token id="13" string="workers" />
            <token id="14" string="used" />
            <token id="15" string="a" />
            <token id="16" string="two-inch" />
            <token id="17" string="probe" />
            <token id="18" string="to" />
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="two halves" type="NP">
          <tokens>
            <token id="20" string="two" />
            <token id="21" string="halves" />
          </tokens>
        </chunking>
        <chunking id="3" string="used a two-inch probe to connect two halves of a 31-mile undersea rail tunnel" type="VP">
          <tokens>
            <token id="14" string="used" />
            <token id="15" string="a" />
            <token id="16" string="two-inch" />
            <token id="17" string="probe" />
            <token id="18" string="to" />
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain and France" type="NP">
          <tokens>
            <token id="1" string="Britain" />
            <token id="2" string="and" />
            <token id="3" string="France" />
          </tokens>
        </chunking>
        <chunking id="5" string="a two-inch probe" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="two-inch" />
            <token id="17" string="probe" />
          </tokens>
        </chunking>
        <chunking id="6" string="the English Channel on Tuesday" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="English" />
            <token id="9" string="Channel" />
            <token id="10" string="on" />
            <token id="11" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="two halves of a 31-mile undersea rail tunnel" type="NP">
          <tokens>
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="9" string="were linked beneath the English Channel on Tuesday when workers used a two-inch probe to connect two halves of a 31-mile undersea rail tunnel" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="linked" />
            <token id="6" string="beneath" />
            <token id="7" string="the" />
            <token id="8" string="English" />
            <token id="9" string="Channel" />
            <token id="10" string="on" />
            <token id="11" string="Tuesday" />
            <token id="12" string="when" />
            <token id="13" string="workers" />
            <token id="14" string="used" />
            <token id="15" string="a" />
            <token id="16" string="two-inch" />
            <token id="17" string="probe" />
            <token id="18" string="to" />
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="the English Channel" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="English" />
            <token id="9" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="11" string="a 31-mile undersea rail tunnel" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="12" string="officials" type="NP">
          <tokens>
            <token id="29" string="officials" />
          </tokens>
        </chunking>
        <chunking id="13" string="connect two halves of a 31-mile undersea rail tunnel" type="VP">
          <tokens>
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="14" string="reported" type="VP">
          <tokens>
            <token id="30" string="reported" />
          </tokens>
        </chunking>
        <chunking id="15" string="to connect two halves of a 31-mile undersea rail tunnel" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="16" string="Tuesday" type="NP">
          <tokens>
            <token id="11" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="17" string="workers" type="NP">
          <tokens>
            <token id="13" string="workers" />
          </tokens>
        </chunking>
        <chunking id="18" string="when workers used a two-inch probe to connect two halves of a 31-mile undersea rail tunnel" type="SBAR">
          <tokens>
            <token id="12" string="when" />
            <token id="13" string="workers" />
            <token id="14" string="used" />
            <token id="15" string="a" />
            <token id="16" string="two-inch" />
            <token id="17" string="probe" />
            <token id="18" string="to" />
            <token id="19" string="connect" />
            <token id="20" string="two" />
            <token id="21" string="halves" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="31-mile" />
            <token id="25" string="undersea" />
            <token id="26" string="rail" />
            <token id="27" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">linked</governor>
          <dependent id="1">Britain</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Britain</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Britain</governor>
          <dependent id="3">France</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">linked</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">reported</governor>
          <dependent id="5">linked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Channel</governor>
          <dependent id="6">beneath</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Channel</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Channel</governor>
          <dependent id="8">English</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">linked</governor>
          <dependent id="9">Channel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Tuesday</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Channel</governor>
          <dependent id="11">Tuesday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">used</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">used</governor>
          <dependent id="13">workers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">linked</governor>
          <dependent id="14">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">probe</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">probe</governor>
          <dependent id="16">two-inch</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">used</governor>
          <dependent id="17">probe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">connect</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">used</governor>
          <dependent id="19">connect</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">halves</governor>
          <dependent id="20">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">connect</governor>
          <dependent id="21">halves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">tunnel</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">tunnel</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">tunnel</governor>
          <dependent id="24">31-mile</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">tunnel</governor>
          <dependent id="25">undersea</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">tunnel</governor>
          <dependent id="26">rail</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">halves</governor>
          <dependent id="27">tunnel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">reported</governor>
          <dependent id="29">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">reported</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="English Channel" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="English" />
            <token id="9" string="Channel" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Britain" />
          </tokens>
        </entity>
        <entity id="4" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="5" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Management sources at TransManche Link, the construction consortium building the ``Chunnel&amp;apost;&amp;apost; - the Channel Tunnel - confirmed the historic linkup occurred about 8:25 p.m. when British workers sent the probe through to French colleagues.</content>
      <tokens>
        <token id="1" string="Management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="TransManche" lemma="TransManche" stem="transmanch" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Link" lemma="Link" stem="link" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="consortium" lemma="consortium" stem="consortium" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="building" lemma="build" stem="build" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Chunnel" lemma="Chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="confirmed" lemma="confirm" stem="confirm" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="26" string="8:25" lemma="8:25" stem="8:25" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="27" string="p.m." lemma="p.m." stem="p.m." pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="28" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="30" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="sent" lemma="send" stem="sent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="37" string="colleagues" lemma="colleague" stem="colleagu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Management) (NNS sources)) (PP (IN at) (NP (NP (NNP TransManche) (NNP Link)) (, ,) (NP (NP (DT the) (NN construction) (NN consortium)) (VP (VBG building) (NP (NP (DT the) (`` ``) (NNP Chunnel) ('' '')) (: -) (NP (DT the) (NNP Channel) (NN Tunnel)) (: -))))))) (VP (VBD confirmed) (SBAR (S (NP (DT the) (JJ historic) (NN linkup)) (VP (VBD occurred) (PP (IN about) (NP (CD 8:25) (RB p.m.))) (SBAR (WHADVP (WRB when)) (S (NP (JJ British) (NNS workers)) (VP (VBD sent) (NP (DT the) (NN probe)) (PP (IN through) (PP (TO to) (NP (JJ French) (NNS colleagues))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="British workers" type="NP">
          <tokens>
            <token id="29" string="British" />
            <token id="30" string="workers" />
          </tokens>
        </chunking>
        <chunking id="2" string="8:25 p.m." type="NP">
          <tokens>
            <token id="26" string="8:25" />
            <token id="27" string="p.m." />
          </tokens>
        </chunking>
        <chunking id="3" string="TransManche Link , the construction consortium building the `` Chunnel '' - the Channel Tunnel -" type="NP">
          <tokens>
            <token id="4" string="TransManche" />
            <token id="5" string="Link" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="construction" />
            <token id="9" string="consortium" />
            <token id="10" string="building" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
            <token id="15" string="-" />
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
            <token id="19" string="-" />
          </tokens>
        </chunking>
        <chunking id="4" string="the `` Chunnel '' - the Channel Tunnel -" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
            <token id="15" string="-" />
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
            <token id="19" string="-" />
          </tokens>
        </chunking>
        <chunking id="5" string="the historic linkup" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="historic" />
            <token id="23" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="6" string="building the `` Chunnel '' - the Channel Tunnel -" type="VP">
          <tokens>
            <token id="10" string="building" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
            <token id="15" string="-" />
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
            <token id="19" string="-" />
          </tokens>
        </chunking>
        <chunking id="7" string="the probe" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="probe" />
          </tokens>
        </chunking>
        <chunking id="8" string="French colleagues" type="NP">
          <tokens>
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="9" string="sent the probe through to French colleagues" type="VP">
          <tokens>
            <token id="31" string="sent" />
            <token id="32" string="the" />
            <token id="33" string="probe" />
            <token id="34" string="through" />
            <token id="35" string="to" />
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="28" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="occurred about 8:25 p.m. when British workers sent the probe through to French colleagues" type="VP">
          <tokens>
            <token id="24" string="occurred" />
            <token id="25" string="about" />
            <token id="26" string="8:25" />
            <token id="27" string="p.m." />
            <token id="28" string="when" />
            <token id="29" string="British" />
            <token id="30" string="workers" />
            <token id="31" string="sent" />
            <token id="32" string="the" />
            <token id="33" string="probe" />
            <token id="34" string="through" />
            <token id="35" string="to" />
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="12" string="confirmed the historic linkup occurred about 8:25 p.m. when British workers sent the probe through to French colleagues" type="VP">
          <tokens>
            <token id="20" string="confirmed" />
            <token id="21" string="the" />
            <token id="22" string="historic" />
            <token id="23" string="linkup" />
            <token id="24" string="occurred" />
            <token id="25" string="about" />
            <token id="26" string="8:25" />
            <token id="27" string="p.m." />
            <token id="28" string="when" />
            <token id="29" string="British" />
            <token id="30" string="workers" />
            <token id="31" string="sent" />
            <token id="32" string="the" />
            <token id="33" string="probe" />
            <token id="34" string="through" />
            <token id="35" string="to" />
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Channel Tunnel" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
          </tokens>
        </chunking>
        <chunking id="14" string="Management sources" type="NP">
          <tokens>
            <token id="1" string="Management" />
            <token id="2" string="sources" />
          </tokens>
        </chunking>
        <chunking id="15" string="the `` Chunnel ''" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
          </tokens>
        </chunking>
        <chunking id="16" string="the construction consortium" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="construction" />
            <token id="9" string="consortium" />
          </tokens>
        </chunking>
        <chunking id="17" string="when British workers sent the probe through to French colleagues" type="SBAR">
          <tokens>
            <token id="28" string="when" />
            <token id="29" string="British" />
            <token id="30" string="workers" />
            <token id="31" string="sent" />
            <token id="32" string="the" />
            <token id="33" string="probe" />
            <token id="34" string="through" />
            <token id="35" string="to" />
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="18" string="the construction consortium building the `` Chunnel '' - the Channel Tunnel -" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="construction" />
            <token id="9" string="consortium" />
            <token id="10" string="building" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
            <token id="15" string="-" />
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
            <token id="19" string="-" />
          </tokens>
        </chunking>
        <chunking id="19" string="TransManche Link" type="NP">
          <tokens>
            <token id="4" string="TransManche" />
            <token id="5" string="Link" />
          </tokens>
        </chunking>
        <chunking id="20" string="the historic linkup occurred about 8:25 p.m. when British workers sent the probe through to French colleagues" type="SBAR">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="historic" />
            <token id="23" string="linkup" />
            <token id="24" string="occurred" />
            <token id="25" string="about" />
            <token id="26" string="8:25" />
            <token id="27" string="p.m." />
            <token id="28" string="when" />
            <token id="29" string="British" />
            <token id="30" string="workers" />
            <token id="31" string="sent" />
            <token id="32" string="the" />
            <token id="33" string="probe" />
            <token id="34" string="through" />
            <token id="35" string="to" />
            <token id="36" string="French" />
            <token id="37" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="21" string="Management sources at TransManche Link , the construction consortium building the `` Chunnel '' - the Channel Tunnel -" type="NP">
          <tokens>
            <token id="1" string="Management" />
            <token id="2" string="sources" />
            <token id="3" string="at" />
            <token id="4" string="TransManche" />
            <token id="5" string="Link" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="construction" />
            <token id="9" string="consortium" />
            <token id="10" string="building" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="Chunnel" />
            <token id="14" string="''" />
            <token id="15" string="-" />
            <token id="16" string="the" />
            <token id="17" string="Channel" />
            <token id="18" string="Tunnel" />
            <token id="19" string="-" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">sources</governor>
          <dependent id="1">Management</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">confirmed</governor>
          <dependent id="2">sources</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Link</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Link</governor>
          <dependent id="4">TransManche</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sources</governor>
          <dependent id="5">Link</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">consortium</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">consortium</governor>
          <dependent id="8">construction</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Link</governor>
          <dependent id="9">consortium</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">consortium</governor>
          <dependent id="10">building</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Chunnel</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">building</governor>
          <dependent id="13">Chunnel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Tunnel</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Tunnel</governor>
          <dependent id="17">Channel</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Chunnel</governor>
          <dependent id="18">Tunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">confirmed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">linkup</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">linkup</governor>
          <dependent id="22">historic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">occurred</governor>
          <dependent id="23">linkup</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">confirmed</governor>
          <dependent id="24">occurred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">8:25</governor>
          <dependent id="25">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">occurred</governor>
          <dependent id="26">8:25</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">8:25</governor>
          <dependent id="27">p.m.</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">sent</governor>
          <dependent id="28">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">workers</governor>
          <dependent id="29">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">sent</governor>
          <dependent id="30">workers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">occurred</governor>
          <dependent id="31">sent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">probe</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">sent</governor>
          <dependent id="33">probe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">colleagues</governor>
          <dependent id="34">through</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">colleagues</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">colleagues</governor>
          <dependent id="36">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">sent</governor>
          <dependent id="37">colleagues</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="36" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="about 8:25 p.m." type="TIME" score="0.0">
          <tokens>
            <token id="25" string="about" />
            <token id="26" string="8:25" />
            <token id="27" string="p.m." />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="29" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>``It is an example of what Europe is about,&amp;apost;&amp;apost; British Prime Minister Margaret Thatcher said in London.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="Prime" lemma="Prime" stem="prime" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Minister" lemma="Minister" stem="minist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="16" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Thatcher" lemma="Thatcher" stem="thatcher" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (NP (NP (DT an) (NN example)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (NNP Europe)) (VP (VBZ is) (RB about)))))))) (, ,) ('' '') (NP (JJ British) (NNP Prime) (NNP Minister) (NNP Margaret) (NNP Thatcher)) (VP (VBD said) (PP (IN in) (NP (NNP London)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an example" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="example" />
          </tokens>
        </chunking>
        <chunking id="2" string="what Europe is about" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="3" string="an example of what Europe is about" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="example" />
            <token id="6" string="of" />
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="4" string="British Prime Minister Margaret Thatcher" type="NP">
          <tokens>
            <token id="13" string="British" />
            <token id="14" string="Prime" />
            <token id="15" string="Minister" />
            <token id="16" string="Margaret" />
            <token id="17" string="Thatcher" />
          </tokens>
        </chunking>
        <chunking id="5" string="Europe" type="NP">
          <tokens>
            <token id="8" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="6" string="London" type="NP">
          <tokens>
            <token id="20" string="London" />
          </tokens>
        </chunking>
        <chunking id="7" string="said in London" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="in" />
            <token id="20" string="London" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="is an example of what Europe is about" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="an" />
            <token id="5" string="example" />
            <token id="6" string="of" />
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="10" string="is about" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">example</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">example</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">example</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="5">example</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">is</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">is</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="8">Europe</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">example</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">is</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Thatcher</governor>
          <dependent id="13">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Thatcher</governor>
          <dependent id="14">Prime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Thatcher</governor>
          <dependent id="15">Minister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Thatcher</governor>
          <dependent id="16">Margaret</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Thatcher</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">London</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="20">London</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Europe" />
          </tokens>
        </entity>
        <entity id="3" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="London" />
          </tokens>
        </entity>
        <entity id="4" string="Margaret Thatcher" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Margaret" />
            <token id="17" string="Thatcher" />
          </tokens>
        </entity>
        <entity id="5" string="Minister" type="TITLE" score="0.0">
          <tokens>
            <token id="15" string="Minister" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>``This is Europe in practice.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT This)) (VP (VBZ is) (NP (NP (NNP Europe)) (PP (IN in) (NP (NN practice))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="practice" type="NP">
          <tokens>
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="2" string="Europe" type="NP">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="3" string="is Europe in practice" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="Europe" />
            <token id="5" string="in" />
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe in practice" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="in" />
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="5" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">Europe</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">Europe</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">practice</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Europe</governor>
          <dependent id="6">practice</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The linkup fulfills a dream by Napoleon in 1802, who thought he could defeat the English by connecting Britain to Europe with a land passage.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="fulfills" lemma="fulfil" stem="fulfil" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="dream" lemma="dream" stem="dream" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Napoleon" lemma="Napoleon" stem="napoleon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="1802" lemma="1802" stem="1802" pos="NNP" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="defeat" lemma="defeat" stem="defeat" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="connecting" lemma="connect" stem="connect" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="land" lemma="land" stem="land" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN linkup)) (VP (VBZ fulfills) (NP (DT a) (NN dream)) (PP (IN by) (NP (NP (NNP Napoleon)) (PP (IN in) (NP (NNP 1802))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD thought) (SBAR (S (NP (PRP he)) (VP (MD could) (VP (VB defeat) (NP (DT the) (NNP English)) (PP (IN by) (S (VP (VBG connecting) (NP (NNP Britain)) (PP (TO to) (NP (NNP Europe))) (PP (IN with) (NP (DT a) (NN land) (NN passage)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could defeat the English by connecting Britain to Europe with a land passage" type="VP">
          <tokens>
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="2" string="Europe" type="NP">
          <tokens>
            <token id="22" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="3" string="The linkup" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="4" string="a land passage" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="5" string="fulfills a dream by Napoleon in 1802 , who thought he could defeat the English by connecting Britain to Europe with a land passage" type="VP">
          <tokens>
            <token id="3" string="fulfills" />
            <token id="4" string="a" />
            <token id="5" string="dream" />
            <token id="6" string="by" />
            <token id="7" string="Napoleon" />
            <token id="8" string="in" />
            <token id="9" string="1802" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="thought" />
            <token id="13" string="he" />
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="Napoleon" type="NP">
          <tokens>
            <token id="7" string="Napoleon" />
          </tokens>
        </chunking>
        <chunking id="8" string="a dream" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="dream" />
          </tokens>
        </chunking>
        <chunking id="9" string="Napoleon in 1802 , who thought he could defeat the English by connecting Britain to Europe with a land passage" type="NP">
          <tokens>
            <token id="7" string="Napoleon" />
            <token id="8" string="in" />
            <token id="9" string="1802" />
            <token id="10" string="," />
            <token id="11" string="who" />
            <token id="12" string="thought" />
            <token id="13" string="he" />
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="10" string="connecting Britain to Europe with a land passage" type="VP">
          <tokens>
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="11" string="thought he could defeat the English by connecting Britain to Europe with a land passage" type="VP">
          <tokens>
            <token id="12" string="thought" />
            <token id="13" string="he" />
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="12" string="who thought he could defeat the English by connecting Britain to Europe with a land passage" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="thought" />
            <token id="13" string="he" />
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="13" string="defeat the English by connecting Britain to Europe with a land passage" type="VP">
          <tokens>
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="he could defeat the English by connecting Britain to Europe with a land passage" type="SBAR">
          <tokens>
            <token id="13" string="he" />
            <token id="14" string="could" />
            <token id="15" string="defeat" />
            <token id="16" string="the" />
            <token id="17" string="English" />
            <token id="18" string="by" />
            <token id="19" string="connecting" />
            <token id="20" string="Britain" />
            <token id="21" string="to" />
            <token id="22" string="Europe" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="land" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="16" string="the English" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="English" />
          </tokens>
        </chunking>
        <chunking id="17" string="1802" type="NP">
          <tokens>
            <token id="9" string="1802" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">linkup</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">fulfills</governor>
          <dependent id="2">linkup</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fulfills</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">dream</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">fulfills</governor>
          <dependent id="5">dream</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Napoleon</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">fulfills</governor>
          <dependent id="7">Napoleon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1802</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Napoleon</governor>
          <dependent id="9">1802</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">thought</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Napoleon</governor>
          <dependent id="12">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">defeat</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">defeat</governor>
          <dependent id="14">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">thought</governor>
          <dependent id="15">defeat</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">English</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">defeat</governor>
          <dependent id="17">English</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">connecting</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">defeat</governor>
          <dependent id="19">connecting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">connecting</governor>
          <dependent id="20">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Europe</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">connecting</governor>
          <dependent id="22">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">passage</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">passage</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">passage</governor>
          <dependent id="25">land</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">connecting</governor>
          <dependent id="26">passage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Europe" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Britain" />
          </tokens>
        </entity>
        <entity id="3" string="Napoleon" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Napoleon" />
          </tokens>
        </entity>
        <entity id="4" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="English" />
          </tokens>
        </entity>
        <entity id="5" string="1802" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1802" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The Chunnel is scheduled for completion in June 1993.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Chunnel" lemma="Chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="completion" lemma="completion" stem="complet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="1993" lemma="1993" stem="1993" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Chunnel)) (VP (VBZ is) (VP (VBN scheduled) (PP (IN for) (NP (NP (NN completion)) (PP (IN in) (NP (NNP June) (CD 1993))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="scheduled for completion in June 1993" type="VP">
          <tokens>
            <token id="4" string="scheduled" />
            <token id="5" string="for" />
            <token id="6" string="completion" />
            <token id="7" string="in" />
            <token id="8" string="June" />
            <token id="9" string="1993" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Chunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Chunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="completion" type="NP">
          <tokens>
            <token id="6" string="completion" />
          </tokens>
        </chunking>
        <chunking id="4" string="June 1993" type="NP">
          <tokens>
            <token id="8" string="June" />
            <token id="9" string="1993" />
          </tokens>
        </chunking>
        <chunking id="5" string="is scheduled for completion in June 1993" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="scheduled" />
            <token id="5" string="for" />
            <token id="6" string="completion" />
            <token id="7" string="in" />
            <token id="8" string="June" />
            <token id="9" string="1993" />
          </tokens>
        </chunking>
        <chunking id="6" string="completion in June 1993" type="NP">
          <tokens>
            <token id="6" string="completion" />
            <token id="7" string="in" />
            <token id="8" string="June" />
            <token id="9" string="1993" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Chunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">scheduled</governor>
          <dependent id="2">Chunnel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">scheduled</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">scheduled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">completion</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">scheduled</governor>
          <dependent id="6">completion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">June</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">completion</governor>
          <dependent id="8">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">June</governor>
          <dependent id="9">1993</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="June 1993" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="June" />
            <token id="9" string="1993" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``This is a hugely historic moment because it means, in effect, that Britain is no longer an island,&amp;apost;&amp;apost; said a construction union official.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="hugely" lemma="hugely" stem="huge" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="means" lemma="mean" stem="mean" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="union" lemma="union" stem="union" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (ADJP (RB hugely) (JJ historic)) (NN moment)) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ means)))) (, ,) (PP (IN in) (NP (NN effect))) (, ,) (SBAR (IN that) (S (NP (NNP Britain)) (VP (VBZ is) (ADVP (RB no) (RBR longer)) (NP (DT an) (NN island))))))) (, ,) ('' '') (VP (VBD said) (NP (DT a) (NN construction) (NN union))) (NP (NN official)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="means" type="VP">
          <tokens>
            <token id="10" string="means" />
          </tokens>
        </chunking>
        <chunking id="2" string="official" type="NP">
          <tokens>
            <token id="28" string="official" />
          </tokens>
        </chunking>
        <chunking id="3" string="a hugely historic moment" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
            <token id="7" string="moment" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="Britain" type="NP">
          <tokens>
            <token id="16" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="hugely historic" type="ADJP">
          <tokens>
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
          </tokens>
        </chunking>
        <chunking id="7" string="is no longer an island" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="8" string="because it means" type="SBAR">
          <tokens>
            <token id="8" string="because" />
            <token id="9" string="it" />
            <token id="10" string="means" />
          </tokens>
        </chunking>
        <chunking id="9" string="an island" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="10" string="a construction union" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="construction" />
            <token id="27" string="union" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a hugely historic moment because it means , in effect , that Britain is no longer an island" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
            <token id="7" string="moment" />
            <token id="8" string="because" />
            <token id="9" string="it" />
            <token id="10" string="means" />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="effect" />
            <token id="14" string="," />
            <token id="15" string="that" />
            <token id="16" string="Britain" />
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="12" string="effect" type="NP">
          <tokens>
            <token id="13" string="effect" />
          </tokens>
        </chunking>
        <chunking id="13" string="said a construction union" type="VP">
          <tokens>
            <token id="24" string="said" />
            <token id="25" string="a" />
            <token id="26" string="construction" />
            <token id="27" string="union" />
          </tokens>
        </chunking>
        <chunking id="14" string="that Britain is no longer an island" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="Britain" />
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="15" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">moment</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">moment</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">moment</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">historic</governor>
          <dependent id="5">hugely</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">moment</governor>
          <dependent id="6">historic</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="7">moment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">means</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">means</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">moment</governor>
          <dependent id="10">means</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">effect</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">moment</governor>
          <dependent id="13">effect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">island</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">island</governor>
          <dependent id="16">Britain</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">island</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">longer</governor>
          <dependent id="18">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">island</governor>
          <dependent id="19">longer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">island</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">moment</governor>
          <dependent id="21">island</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">union</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">union</governor>
          <dependent id="26">construction</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">said</governor>
          <dependent id="27">union</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="28">official</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Eight workers suffered injuries, two seriously, about 90 minutes later when a tractor towing supplies rolled over on them in a service gallery, authorities in nearby Sangatte reported.</content>
      <tokens>
        <token id="1" string="Eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="tractor" lemma="tractor" stem="tractor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="towing" lemma="tow" stem="tow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="supplies" lemma="supplies" stem="suppli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="rolled" lemma="roll" stem="roll" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="gallery" lemma="gallery" stem="galleri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="nearby" lemma="nearby" stem="nearbi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (CD Eight) (NNS workers)) (VP (VBD suffered) (NP (NP (NP (NNS injuries)) (, ,) (ADVP (NP (CD two)) (RB seriously)) (, ,)) (PP (IN about) (ADVP (NP (CD 90) (NNS minutes)) (RB later)))) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT a) (NN tractor)) (VP (VBG towing) (NP (NNS supplies)))) (VP (VBD rolled) (PRT (RP over)) (PP (IN on) (NP (PRP them))) (PP (IN in) (NP (DT a) (NN service) (NN gallery)))))))) (, ,) (NP (NP (NNS authorities)) (PP (IN in) (NP (JJ nearby) (NNP Sangatte)))) (VP (VBD reported)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="injuries , two seriously , about 90 minutes later" type="NP">
          <tokens>
            <token id="4" string="injuries" />
            <token id="5" string="," />
            <token id="6" string="two" />
            <token id="7" string="seriously" />
            <token id="8" string="," />
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="later" />
          </tokens>
        </chunking>
        <chunking id="2" string="a tractor towing supplies" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tractor" />
            <token id="16" string="towing" />
            <token id="17" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="3" string="a tractor" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tractor" />
          </tokens>
        </chunking>
        <chunking id="4" string="injuries" type="NP">
          <tokens>
            <token id="4" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="5" string="when a tractor towing supplies rolled over on them in a service gallery" type="SBAR">
          <tokens>
            <token id="13" string="when" />
            <token id="14" string="a" />
            <token id="15" string="tractor" />
            <token id="16" string="towing" />
            <token id="17" string="supplies" />
            <token id="18" string="rolled" />
            <token id="19" string="over" />
            <token id="20" string="on" />
            <token id="21" string="them" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="service" />
            <token id="25" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="6" string="two" type="NP">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </chunking>
        <chunking id="7" string="injuries , two seriously ," type="NP">
          <tokens>
            <token id="4" string="injuries" />
            <token id="5" string="," />
            <token id="6" string="two" />
            <token id="7" string="seriously" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="a service gallery" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="service" />
            <token id="25" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="21" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="nearby Sangatte" type="NP">
          <tokens>
            <token id="29" string="nearby" />
            <token id="30" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="13" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="suffered injuries , two seriously , about 90 minutes later when a tractor towing supplies rolled over on them in a service gallery" type="VP">
          <tokens>
            <token id="3" string="suffered" />
            <token id="4" string="injuries" />
            <token id="5" string="," />
            <token id="6" string="two" />
            <token id="7" string="seriously" />
            <token id="8" string="," />
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="later" />
            <token id="13" string="when" />
            <token id="14" string="a" />
            <token id="15" string="tractor" />
            <token id="16" string="towing" />
            <token id="17" string="supplies" />
            <token id="18" string="rolled" />
            <token id="19" string="over" />
            <token id="20" string="on" />
            <token id="21" string="them" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="service" />
            <token id="25" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="13" string="authorities" type="NP">
          <tokens>
            <token id="27" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="14" string="towing supplies" type="VP">
          <tokens>
            <token id="16" string="towing" />
            <token id="17" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="15" string="Eight workers" type="NP">
          <tokens>
            <token id="1" string="Eight" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="16" string="rolled over on them in a service gallery" type="VP">
          <tokens>
            <token id="18" string="rolled" />
            <token id="19" string="over" />
            <token id="20" string="on" />
            <token id="21" string="them" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="service" />
            <token id="25" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="17" string="supplies" type="NP">
          <tokens>
            <token id="17" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="18" string="authorities in nearby Sangatte" type="NP">
          <tokens>
            <token id="27" string="authorities" />
            <token id="28" string="in" />
            <token id="29" string="nearby" />
            <token id="30" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="19" string="90 minutes" type="NP">
          <tokens>
            <token id="10" string="90" />
            <token id="11" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="20" string="reported" type="VP">
          <tokens>
            <token id="31" string="reported" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">workers</governor>
          <dependent id="1">Eight</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suffered</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">reported</governor>
          <dependent id="3">suffered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">suffered</governor>
          <dependent id="4">injuries</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">seriously</governor>
          <dependent id="6">two</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">injuries</governor>
          <dependent id="7">seriously</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">later</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">minutes</governor>
          <dependent id="10">90</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="12">later</governor>
          <dependent id="11">minutes</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">injuries</governor>
          <dependent id="12">later</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">rolled</governor>
          <dependent id="13">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">tractor</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">rolled</governor>
          <dependent id="15">tractor</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">tractor</governor>
          <dependent id="16">towing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">towing</governor>
          <dependent id="17">supplies</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">suffered</governor>
          <dependent id="18">rolled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">rolled</governor>
          <dependent id="19">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">them</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">rolled</governor>
          <dependent id="21">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">gallery</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">gallery</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">gallery</governor>
          <dependent id="24">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">rolled</governor>
          <dependent id="25">gallery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">reported</governor>
          <dependent id="27">authorities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Sangatte</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">Sangatte</governor>
          <dependent id="29">nearby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">authorities</governor>
          <dependent id="30">Sangatte</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">reported</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Eight" />
          </tokens>
        </entity>
        <entity id="2" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="about 90 minutes later" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The basic goal of the Channel Tunnel project is to enable passengers to travel between London and Paris in about three hours.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="basic" lemma="basic" stem="basic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="goal" lemma="goal" stem="goal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="enable" lemma="enable" stem="enabl" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="travel" lemma="travel" stem="travel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Paris" lemma="Paris" stem="pari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ basic) (NN goal)) (PP (IN of) (NP (DT the) (NNP Channel) (NN Tunnel) (NN project)))) (VP (VBZ is) (S (VP (TO to) (VP (VB enable) (S (NP (NNS passengers)) (VP (TO to) (VP (VB travel) (PP (IN between) (NP (NNP London) (CC and) (NNP Paris))) (PP (IN in) (PP (IN about) (NP (CD three) (NNS hours))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The basic goal" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="basic" />
            <token id="3" string="goal" />
          </tokens>
        </chunking>
        <chunking id="2" string="passengers" type="NP">
          <tokens>
            <token id="12" string="passengers" />
          </tokens>
        </chunking>
        <chunking id="3" string="to enable passengers to travel between London and Paris in about three hours" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="enable" />
            <token id="12" string="passengers" />
            <token id="13" string="to" />
            <token id="14" string="travel" />
            <token id="15" string="between" />
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
            <token id="19" string="in" />
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="4" string="enable passengers to travel between London and Paris in about three hours" type="VP">
          <tokens>
            <token id="11" string="enable" />
            <token id="12" string="passengers" />
            <token id="13" string="to" />
            <token id="14" string="travel" />
            <token id="15" string="between" />
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
            <token id="19" string="in" />
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="5" string="The basic goal of the Channel Tunnel project" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="basic" />
            <token id="3" string="goal" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="Channel" />
            <token id="7" string="Tunnel" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
        <chunking id="6" string="is to enable passengers to travel between London and Paris in about three hours" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="to" />
            <token id="11" string="enable" />
            <token id="12" string="passengers" />
            <token id="13" string="to" />
            <token id="14" string="travel" />
            <token id="15" string="between" />
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
            <token id="19" string="in" />
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="7" string="three hours" type="NP">
          <tokens>
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="8" string="travel between London and Paris in about three hours" type="VP">
          <tokens>
            <token id="14" string="travel" />
            <token id="15" string="between" />
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
            <token id="19" string="in" />
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Channel Tunnel project" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Channel" />
            <token id="7" string="Tunnel" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
        <chunking id="10" string="to travel between London and Paris in about three hours" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="travel" />
            <token id="15" string="between" />
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
            <token id="19" string="in" />
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="11" string="London and Paris" type="NP">
          <tokens>
            <token id="16" string="London" />
            <token id="17" string="and" />
            <token id="18" string="Paris" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">goal</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">goal</governor>
          <dependent id="2">basic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="3">goal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">project</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">project</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">project</governor>
          <dependent id="6">Channel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">project</governor>
          <dependent id="7">Tunnel</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">goal</governor>
          <dependent id="8">project</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">enable</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">is</governor>
          <dependent id="11">enable</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">enable</governor>
          <dependent id="12">passengers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">travel</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">enable</governor>
          <dependent id="14">travel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">London</governor>
          <dependent id="15">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">travel</governor>
          <dependent id="16">London</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">London</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">London</governor>
          <dependent id="18">Paris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">hours</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">hours</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">hours</governor>
          <dependent id="21">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">travel</governor>
          <dependent id="22">hours</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="about three hours" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="about" />
            <token id="21" string="three" />
            <token id="22" string="hours" />
          </tokens>
        </entity>
        <entity id="2" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="London" />
          </tokens>
        </entity>
        <entity id="3" string="Paris" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Paris" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>That time is comparable to flying, if transport to and from airports is included, and is half the time of a car-ferry journey.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="comparable" lemma="comparable" stem="compar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="flying" lemma="fly" stem="fly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="transport" lemma="transport" stem="transport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="airports" lemma="airport" stem="airport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="included" lemma="include" stem="includ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="half" lemma="half" stem="half" pos="PDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="car-ferry" lemma="car-ferry" stem="car-ferri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="journey" lemma="journey" stem="journei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN time)) (VP (VBZ is) (ADJP (JJ comparable) (PP (TO to) (S (VP (VBG flying))))) (, ,) (SBAR (IN if) (S (NP (NP (NN transport)) (PP (TO to) (CC and) (IN from) (NP (NNS airports)))) (VP (VP (VBZ is) (VP (VBN included))) (, ,) (CC and) (VP (VBZ is) (NP (NP (PDT half) (DT the) (NN time)) (PP (IN of) (NP (DT a) (JJ car-ferry) (NN journey))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="airports" type="NP">
          <tokens>
            <token id="13" string="airports" />
          </tokens>
        </chunking>
        <chunking id="2" string="half the time of a car-ferry journey" type="NP">
          <tokens>
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="3" string="is comparable to flying , if transport to and from airports is included , and is half the time of a car-ferry journey" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="comparable" />
            <token id="5" string="to" />
            <token id="6" string="flying" />
            <token id="7" string="," />
            <token id="8" string="if" />
            <token id="9" string="transport" />
            <token id="10" string="to" />
            <token id="11" string="and" />
            <token id="12" string="from" />
            <token id="13" string="airports" />
            <token id="14" string="is" />
            <token id="15" string="included" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="is" />
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="4" string="transport" type="NP">
          <tokens>
            <token id="9" string="transport" />
          </tokens>
        </chunking>
        <chunking id="5" string="is included , and is half the time of a car-ferry journey" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="included" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="is" />
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="6" string="is included" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="included" />
          </tokens>
        </chunking>
        <chunking id="7" string="a car-ferry journey" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="8" string="is half the time of a car-ferry journey" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="9" string="half the time" type="NP">
          <tokens>
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="That time" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="transport to and from airports" type="NP">
          <tokens>
            <token id="9" string="transport" />
            <token id="10" string="to" />
            <token id="11" string="and" />
            <token id="12" string="from" />
            <token id="13" string="airports" />
          </tokens>
        </chunking>
        <chunking id="12" string="flying" type="VP">
          <tokens>
            <token id="6" string="flying" />
          </tokens>
        </chunking>
        <chunking id="13" string="included" type="VP">
          <tokens>
            <token id="15" string="included" />
          </tokens>
        </chunking>
        <chunking id="14" string="if transport to and from airports is included , and is half the time of a car-ferry journey" type="SBAR">
          <tokens>
            <token id="8" string="if" />
            <token id="9" string="transport" />
            <token id="10" string="to" />
            <token id="11" string="and" />
            <token id="12" string="from" />
            <token id="13" string="airports" />
            <token id="14" string="is" />
            <token id="15" string="included" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="is" />
            <token id="19" string="half" />
            <token id="20" string="the" />
            <token id="21" string="time" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="car-ferry" />
            <token id="25" string="journey" />
          </tokens>
        </chunking>
        <chunking id="15" string="comparable to flying" type="ADJP">
          <tokens>
            <token id="4" string="comparable" />
            <token id="5" string="to" />
            <token id="6" string="flying" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">time</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">comparable</governor>
          <dependent id="2">time</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">comparable</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">comparable</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">flying</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">comparable</governor>
          <dependent id="6">flying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">included</governor>
          <dependent id="8">if</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">transport</governor>
          <dependent id="9">transport</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">included</governor>
          <dependent id="9">transport</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">airports</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">to</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">to</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">transport</governor>
          <dependent id="13">airports</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">transport</governor>
          <dependent id="13">airports</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">included</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">comparable</governor>
          <dependent id="15">included</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">included</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">time</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="21">time</governor>
          <dependent id="19">half</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">time</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">included</governor>
          <dependent id="21">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">journey</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">journey</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">journey</governor>
          <dependent id="24">car-ferry</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">time</governor>
          <dependent id="25">journey</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The conservative Daily Express newspaper noted in its Wednesday editions that Britons would theoretically be able to walk to France for the first time since the last Ice Age.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="3" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Express" lemma="Express" stem="express" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="editions" lemma="edition" stem="edit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Britons" lemma="Britons" stem="briton" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="theoretically" lemma="theoretically" stem="theoret" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Ice" lemma="Ice" stem="ice" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Age" lemma="Age" stem="age" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ conservative) (NNP Daily) (NNP Express) (NN newspaper)) (VP (VBD noted) (PP (IN in) (NP (PRP$ its) (NNP Wednesday) (NNS editions))) (SBAR (WHNP (WDT that)) (S (NP (NNPS Britons)) (VP (MD would) (ADVP (RB theoretically)) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (VB walk) (PP (TO to) (NP (NNP France))) (PP (IN for) (NP (NP (DT the) (JJ first) (NN time)) (PP (IN since) (NP (DT the) (JJ last) (NNP Ice) (NNP Age)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its Wednesday editions" type="NP">
          <tokens>
            <token id="8" string="its" />
            <token id="9" string="Wednesday" />
            <token id="10" string="editions" />
          </tokens>
        </chunking>
        <chunking id="2" string="noted in its Wednesday editions that Britons would theoretically be able to walk to France for the first time since the last Ice Age" type="VP">
          <tokens>
            <token id="6" string="noted" />
            <token id="7" string="in" />
            <token id="8" string="its" />
            <token id="9" string="Wednesday" />
            <token id="10" string="editions" />
            <token id="11" string="that" />
            <token id="12" string="Britons" />
            <token id="13" string="would" />
            <token id="14" string="theoretically" />
            <token id="15" string="be" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="3" string="walk to France for the first time since the last Ice Age" type="VP">
          <tokens>
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="4" string="that Britons would theoretically be able to walk to France for the first time since the last Ice Age" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="Britons" />
            <token id="13" string="would" />
            <token id="14" string="theoretically" />
            <token id="15" string="be" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="5" string="the first time" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="would theoretically be able to walk to France for the first time since the last Ice Age" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="theoretically" />
            <token id="15" string="be" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first time since the last Ice Age" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="8" string="able to walk to France for the first time since the last Ice Age" type="ADJP">
          <tokens>
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="9" string="Britons" type="NP">
          <tokens>
            <token id="12" string="Britons" />
          </tokens>
        </chunking>
        <chunking id="10" string="be able to walk to France for the first time since the last Ice Age" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="able" />
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="11" string="The conservative Daily Express newspaper" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="conservative" />
            <token id="3" string="Daily" />
            <token id="4" string="Express" />
            <token id="5" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="12" string="to walk to France for the first time since the last Ice Age" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="walk" />
            <token id="19" string="to" />
            <token id="20" string="France" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="since" />
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
        <chunking id="13" string="France" type="NP">
          <tokens>
            <token id="20" string="France" />
          </tokens>
        </chunking>
        <chunking id="14" string="the last Ice Age" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="last" />
            <token id="28" string="Ice" />
            <token id="29" string="Age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">newspaper</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">newspaper</governor>
          <dependent id="2">conservative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">newspaper</governor>
          <dependent id="3">Daily</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">newspaper</governor>
          <dependent id="4">Express</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">noted</governor>
          <dependent id="5">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">noted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">editions</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">editions</governor>
          <dependent id="8">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">editions</governor>
          <dependent id="9">Wednesday</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">noted</governor>
          <dependent id="10">editions</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">walk</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">able</governor>
          <dependent id="12">Britons</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">able</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">able</governor>
          <dependent id="14">theoretically</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">able</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">noted</governor>
          <dependent id="16">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">walk</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">able</governor>
          <dependent id="18">walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">France</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">walk</governor>
          <dependent id="20">France</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">time</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">time</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">time</governor>
          <dependent id="23">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">walk</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Age</governor>
          <dependent id="25">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Age</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">Age</governor>
          <dependent id="27">last</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Age</governor>
          <dependent id="28">Ice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">time</governor>
          <dependent id="29">Age</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="23" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="4" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Britons" />
          </tokens>
        </entity>
        <entity id="5" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="France" />
          </tokens>
        </entity>
        <entity id="6" string="Daily Express" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Daily" />
            <token id="4" string="Express" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The cost of the project has soared from an initial estimate of $9.4 billion to $16.7 billion, including an extra $1.97 billion for unforeseen cost overruns.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="soared" lemma="soar" stem="soar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="estimate" lemma="estimate" stem="estim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="9.4" lemma="9.4" stem="9.4" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="16.7" lemma="16.7" stem="16.7" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="19" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="extra" lemma="extra" stem="extra" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="1.97" lemma="1.97" stem="1.97" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="unforeseen" lemma="unforeseen" stem="unforeseen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="overruns" lemma="overrun" stem="overrun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN cost)) (PP (IN of) (NP (DT the) (NN project)))) (VP (VBZ has) (VP (VBN soared) (PP (IN from) (NP (NP (DT an) (JJ initial) (NN estimate)) (PP (IN of) (NP (QP ($ $) (CD 9.4) (CD billion) (TO to) ($ $) (CD 16.7) (CD billion)))) (, ,) (PP (VBG including) (NP (NP (DT an) (JJ extra) (QP ($ $) (CD 1.97) (CD billion))) (PP (IN for) (NP (JJ unforeseen) (NN cost) (NNS overruns))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="soared from an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion for unforeseen cost overruns" type="VP">
          <tokens>
            <token id="7" string="soared" />
            <token id="8" string="from" />
            <token id="9" string="an" />
            <token id="10" string="initial" />
            <token id="11" string="estimate" />
            <token id="12" string="of" />
            <token id="13" string="$" />
            <token id="14" string="9.4" />
            <token id="15" string="billion" />
            <token id="16" string="to" />
            <token id="17" string="$" />
            <token id="18" string="16.7" />
            <token id="19" string="billion" />
            <token id="20" string="," />
            <token id="21" string="including" />
            <token id="22" string="an" />
            <token id="23" string="extra" />
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
            <token id="27" string="for" />
            <token id="28" string="unforeseen" />
            <token id="29" string="cost" />
            <token id="30" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="2" string="an extra $ 1.97 billion" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="extra" />
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
          </tokens>
        </chunking>
        <chunking id="3" string="The cost of the project" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cost" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="project" />
          </tokens>
        </chunking>
        <chunking id="4" string="the project" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="project" />
          </tokens>
        </chunking>
        <chunking id="5" string="$ 9.4 billion to $ 16.7 billion" type="NP">
          <tokens>
            <token id="13" string="$" />
            <token id="14" string="9.4" />
            <token id="15" string="billion" />
            <token id="16" string="to" />
            <token id="17" string="$" />
            <token id="18" string="16.7" />
            <token id="19" string="billion" />
          </tokens>
        </chunking>
        <chunking id="6" string="an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion for unforeseen cost overruns" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="initial" />
            <token id="11" string="estimate" />
            <token id="12" string="of" />
            <token id="13" string="$" />
            <token id="14" string="9.4" />
            <token id="15" string="billion" />
            <token id="16" string="to" />
            <token id="17" string="$" />
            <token id="18" string="16.7" />
            <token id="19" string="billion" />
            <token id="20" string="," />
            <token id="21" string="including" />
            <token id="22" string="an" />
            <token id="23" string="extra" />
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
            <token id="27" string="for" />
            <token id="28" string="unforeseen" />
            <token id="29" string="cost" />
            <token id="30" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="7" string="an extra $ 1.97 billion for unforeseen cost overruns" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="extra" />
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
            <token id="27" string="for" />
            <token id="28" string="unforeseen" />
            <token id="29" string="cost" />
            <token id="30" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="8" string="an initial estimate" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="initial" />
            <token id="11" string="estimate" />
          </tokens>
        </chunking>
        <chunking id="9" string="The cost" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cost" />
          </tokens>
        </chunking>
        <chunking id="10" string="has soared from an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion for unforeseen cost overruns" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="soared" />
            <token id="8" string="from" />
            <token id="9" string="an" />
            <token id="10" string="initial" />
            <token id="11" string="estimate" />
            <token id="12" string="of" />
            <token id="13" string="$" />
            <token id="14" string="9.4" />
            <token id="15" string="billion" />
            <token id="16" string="to" />
            <token id="17" string="$" />
            <token id="18" string="16.7" />
            <token id="19" string="billion" />
            <token id="20" string="," />
            <token id="21" string="including" />
            <token id="22" string="an" />
            <token id="23" string="extra" />
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
            <token id="27" string="for" />
            <token id="28" string="unforeseen" />
            <token id="29" string="cost" />
            <token id="30" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="11" string="unforeseen cost overruns" type="NP">
          <tokens>
            <token id="28" string="unforeseen" />
            <token id="29" string="cost" />
            <token id="30" string="overruns" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cost</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">soared</governor>
          <dependent id="2">cost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">project</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">project</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">cost</governor>
          <dependent id="5">project</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">soared</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">soared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">estimate</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">estimate</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">estimate</governor>
          <dependent id="10">initial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">soared</governor>
          <dependent id="11">estimate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">$</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">$</governor>
          <dependent id="13">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">$</governor>
          <dependent id="14">9.4</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">$</governor>
          <dependent id="15">billion</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">$</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">estimate</governor>
          <dependent id="17">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">billion</governor>
          <dependent id="18">16.7</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">$</governor>
          <dependent id="19">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">$</governor>
          <dependent id="21">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">$</governor>
          <dependent id="22">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">$</governor>
          <dependent id="23">extra</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">estimate</governor>
          <dependent id="24">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">billion</governor>
          <dependent id="25">1.97</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">$</governor>
          <dependent id="26">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">overruns</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">overruns</governor>
          <dependent id="28">unforeseen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">overruns</governor>
          <dependent id="29">cost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">$</governor>
          <dependent id="30">overruns</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 9.4 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="13" string="$" />
            <token id="14" string="9.4" />
            <token id="15" string="billion" />
          </tokens>
        </entity>
        <entity id="2" string="$ 16.7 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="17" string="$" />
            <token id="18" string="16.7" />
            <token id="19" string="billion" />
          </tokens>
        </entity>
        <entity id="3" string="$ 1.97 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="24" string="$" />
            <token id="25" string="1.97" />
            <token id="26" string="billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>The threading of the probes through 100 yards of chalk under the English Channel marks a major turning point in three years of drilling on the world&amp;apost;s costliest tunnel.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="threading" lemma="threading" stem="thread" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="probes" lemma="probe" stem="probe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="yards" lemma="yard" stem="yard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="chalk" lemma="chalk" stem="chalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="14" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="15" string="marks" lemma="mark" stem="mark" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="turning" lemma="turning" stem="turn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="costliest" lemma="costliest" stem="costliest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="30" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN threading)) (PP (IN of) (NP (NP (DT the) (NNS probes)) (PP (IN through) (NP (NP (CD 100) (NNS yards)) (PP (IN of) (NP (NP (NN chalk)) (PP (IN under) (NP (DT the) (NNP English) (NNP Channel)))))))))) (VP (VBZ marks) (NP (DT a) (JJ major) (NN turning) (NN point)) (PP (IN in) (NP (NP (CD three) (NNS years)) (PP (IN of) (NP (NP (NN drilling)) (PP (IN on) (NP (NP (DT the) (NN world) (POS 's)) (JJS costliest) (NN tunnel)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the world 's costliest tunnel" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="world" />
            <token id="28" string="'s" />
            <token id="29" string="costliest" />
            <token id="30" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="The threading of the probes through 100 yards of chalk under the English Channel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="threading" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="probes" />
            <token id="6" string="through" />
            <token id="7" string="100" />
            <token id="8" string="yards" />
            <token id="9" string="of" />
            <token id="10" string="chalk" />
            <token id="11" string="under" />
            <token id="12" string="the" />
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="3" string="three years" type="NP">
          <tokens>
            <token id="21" string="three" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="three years of drilling on the world 's costliest tunnel" type="NP">
          <tokens>
            <token id="21" string="three" />
            <token id="22" string="years" />
            <token id="23" string="of" />
            <token id="24" string="drilling" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="world" />
            <token id="28" string="'s" />
            <token id="29" string="costliest" />
            <token id="30" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="100 yards" type="NP">
          <tokens>
            <token id="7" string="100" />
            <token id="8" string="yards" />
          </tokens>
        </chunking>
        <chunking id="6" string="a major turning point" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="major" />
            <token id="18" string="turning" />
            <token id="19" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="drilling" type="NP">
          <tokens>
            <token id="24" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="8" string="chalk under the English Channel" type="NP">
          <tokens>
            <token id="10" string="chalk" />
            <token id="11" string="under" />
            <token id="12" string="the" />
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="9" string="the probes through 100 yards of chalk under the English Channel" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="probes" />
            <token id="6" string="through" />
            <token id="7" string="100" />
            <token id="8" string="yards" />
            <token id="9" string="of" />
            <token id="10" string="chalk" />
            <token id="11" string="under" />
            <token id="12" string="the" />
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="10" string="marks a major turning point in three years of drilling on the world 's costliest tunnel" type="VP">
          <tokens>
            <token id="15" string="marks" />
            <token id="16" string="a" />
            <token id="17" string="major" />
            <token id="18" string="turning" />
            <token id="19" string="point" />
            <token id="20" string="in" />
            <token id="21" string="three" />
            <token id="22" string="years" />
            <token id="23" string="of" />
            <token id="24" string="drilling" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="world" />
            <token id="28" string="'s" />
            <token id="29" string="costliest" />
            <token id="30" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="11" string="the English Channel" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="12" string="drilling on the world 's costliest tunnel" type="NP">
          <tokens>
            <token id="24" string="drilling" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="world" />
            <token id="28" string="'s" />
            <token id="29" string="costliest" />
            <token id="30" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="13" string="100 yards of chalk under the English Channel" type="NP">
          <tokens>
            <token id="7" string="100" />
            <token id="8" string="yards" />
            <token id="9" string="of" />
            <token id="10" string="chalk" />
            <token id="11" string="under" />
            <token id="12" string="the" />
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="14" string="chalk" type="NP">
          <tokens>
            <token id="10" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="15" string="the probes" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="probes" />
          </tokens>
        </chunking>
        <chunking id="16" string="The threading" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="threading" />
          </tokens>
        </chunking>
        <chunking id="17" string="the world 's" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="world" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">threading</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">marks</governor>
          <dependent id="2">threading</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">probes</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">probes</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">threading</governor>
          <dependent id="5">probes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">yards</governor>
          <dependent id="6">through</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">yards</governor>
          <dependent id="7">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">probes</governor>
          <dependent id="8">yards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">chalk</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">yards</governor>
          <dependent id="10">chalk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Channel</governor>
          <dependent id="11">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Channel</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Channel</governor>
          <dependent id="13">English</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">chalk</governor>
          <dependent id="14">Channel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">marks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">point</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">point</governor>
          <dependent id="17">major</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">point</governor>
          <dependent id="18">turning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">marks</governor>
          <dependent id="19">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">years</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">years</governor>
          <dependent id="21">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">marks</governor>
          <dependent id="22">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">drilling</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">years</governor>
          <dependent id="24">drilling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">tunnel</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">world</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">tunnel</governor>
          <dependent id="27">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">world</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">tunnel</governor>
          <dependent id="29">costliest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">drilling</governor>
          <dependent id="30">tunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="three years" type="DURATION" score="0.0">
          <tokens>
            <token id="21" string="three" />
            <token id="22" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="English Channel" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="English" />
            <token id="14" string="Channel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>The meeting point was just over 13{ miles southeast of Shakespeare Cliff, the British terminus near the town of Dover, and 10 miles northwest of the French town of Sangatte, near Calais.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="southeast" lemma="southeast" stem="southeast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Shakespeare" lemma="Shakespeare" stem="shakespear" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Cliff" lemma="Cliff" stem="cliff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="17" string="terminus" lemma="terminus" stem="terminu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="town" lemma="town" stem="town" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Dover" lemma="Dover" stem="dover" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="northwest" lemma="northwest" stem="northwest" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="31" string="town" lemma="town" stem="town" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN meeting) (NN point)) (VP (VBD was) (ADVP (RB just)) (PP (IN over) (NP (NP (NP (CD 13)) (-LRB- -LCB-) (NP (NP (NNS miles) (NN southeast)) (PP (IN of) (NP (NP (NNP Shakespeare) (NNP Cliff)) (, ,) (UCP (NP (NP (DT the) (JJ British) (NN terminus)) (PP (IN near) (NP (NP (DT the) (NN town)) (PP (IN of) (NP (NNP Dover)))))) (, ,) (CC and) (ADVP (NP (CD 10) (NNS miles)) (RB northwest)) (PP (IN of) (NP (DT the) (JJ French) (NN town)))) (PP (IN of) (NP (NNP Sangatte)))))) (, ,)) (PP (IN near) (NP (NNP Calais)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="13" type="NP">
          <tokens>
            <token id="7" string="13" />
          </tokens>
        </chunking>
        <chunking id="2" string="Calais" type="NP">
          <tokens>
            <token id="36" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="3" string="The meeting point" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="meeting" />
            <token id="3" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="the town" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="town" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dover" type="NP">
          <tokens>
            <token id="22" string="Dover" />
          </tokens>
        </chunking>
        <chunking id="6" string="Shakespeare Cliff , the British terminus near the town of Dover , and 10 miles northwest of the French town of Sangatte" type="NP">
          <tokens>
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="10" />
            <token id="26" string="miles" />
            <token id="27" string="northwest" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
            <token id="32" string="of" />
            <token id="33" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sangatte" type="NP">
          <tokens>
            <token id="33" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="8" string="Shakespeare Cliff" type="NP">
          <tokens>
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
          </tokens>
        </chunking>
        <chunking id="9" string="the British terminus" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
          </tokens>
        </chunking>
        <chunking id="10" string="13 -LCB- miles southeast of Shakespeare Cliff , the British terminus near the town of Dover , and 10 miles northwest of the French town of Sangatte ," type="NP">
          <tokens>
            <token id="7" string="13" />
            <token id="8" string="{" />
            <token id="9" string="miles" />
            <token id="10" string="southeast" />
            <token id="11" string="of" />
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="10" />
            <token id="26" string="miles" />
            <token id="27" string="northwest" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
            <token id="32" string="of" />
            <token id="33" string="Sangatte" />
            <token id="34" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the town of Dover" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
          </tokens>
        </chunking>
        <chunking id="12" string="the French town" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
          </tokens>
        </chunking>
        <chunking id="13" string="the British terminus near the town of Dover" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
          </tokens>
        </chunking>
        <chunking id="14" string="10 miles" type="NP">
          <tokens>
            <token id="25" string="10" />
            <token id="26" string="miles" />
          </tokens>
        </chunking>
        <chunking id="15" string="was just over 13 -LCB- miles southeast of Shakespeare Cliff , the British terminus near the town of Dover , and 10 miles northwest of the French town of Sangatte , near Calais" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="just" />
            <token id="6" string="over" />
            <token id="7" string="13" />
            <token id="8" string="{" />
            <token id="9" string="miles" />
            <token id="10" string="southeast" />
            <token id="11" string="of" />
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="10" />
            <token id="26" string="miles" />
            <token id="27" string="northwest" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
            <token id="32" string="of" />
            <token id="33" string="Sangatte" />
            <token id="34" string="," />
            <token id="35" string="near" />
            <token id="36" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="16" string="miles southeast of Shakespeare Cliff , the British terminus near the town of Dover , and 10 miles northwest of the French town of Sangatte" type="NP">
          <tokens>
            <token id="9" string="miles" />
            <token id="10" string="southeast" />
            <token id="11" string="of" />
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="10" />
            <token id="26" string="miles" />
            <token id="27" string="northwest" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
            <token id="32" string="of" />
            <token id="33" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="17" string="miles southeast" type="NP">
          <tokens>
            <token id="9" string="miles" />
            <token id="10" string="southeast" />
          </tokens>
        </chunking>
        <chunking id="18" string="13 -LCB- miles southeast of Shakespeare Cliff , the British terminus near the town of Dover , and 10 miles northwest of the French town of Sangatte , near Calais" type="NP">
          <tokens>
            <token id="7" string="13" />
            <token id="8" string="{" />
            <token id="9" string="miles" />
            <token id="10" string="southeast" />
            <token id="11" string="of" />
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="terminus" />
            <token id="18" string="near" />
            <token id="19" string="the" />
            <token id="20" string="town" />
            <token id="21" string="of" />
            <token id="22" string="Dover" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="10" />
            <token id="26" string="miles" />
            <token id="27" string="northwest" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="French" />
            <token id="31" string="town" />
            <token id="32" string="of" />
            <token id="33" string="Sangatte" />
            <token id="34" string="," />
            <token id="35" string="near" />
            <token id="36" string="Calais" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">point</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">point</governor>
          <dependent id="2">meeting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">13</governor>
          <dependent id="3">point</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">13</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">13</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">13</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">13</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">southeast</governor>
          <dependent id="9">miles</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">13</governor>
          <dependent id="10">southeast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Cliff</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Cliff</governor>
          <dependent id="12">Shakespeare</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">southeast</governor>
          <dependent id="13">Cliff</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">terminus</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">terminus</governor>
          <dependent id="16">British</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Cliff</governor>
          <dependent id="17">terminus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">town</governor>
          <dependent id="18">near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">town</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">terminus</governor>
          <dependent id="20">town</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Dover</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">town</governor>
          <dependent id="22">Dover</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">terminus</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">miles</governor>
          <dependent id="25">10</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="27">northwest</governor>
          <dependent id="26">miles</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">terminus</governor>
          <dependent id="27">northwest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">town</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">town</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">town</governor>
          <dependent id="30">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">northwest</governor>
          <dependent id="31">town</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Sangatte</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Cliff</governor>
          <dependent id="33">Sangatte</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Calais</governor>
          <dependent id="35">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">13</governor>
          <dependent id="36">Calais</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="30" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="13" />
          </tokens>
        </entity>
        <entity id="3" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Calais" />
          </tokens>
        </entity>
        <entity id="4" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="16" string="British" />
          </tokens>
        </entity>
        <entity id="5" string="Dover" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Dover" />
          </tokens>
        </entity>
        <entity id="6" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="33" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="7" string="Shakespeare Cliff" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Shakespeare" />
            <token id="13" string="Cliff" />
          </tokens>
        </entity>
        <entity id="8" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>The tunnel starts a few miles inland on each side, accounting for its total length of 31 miles.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="starts" lemma="start" stem="start" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="inland" lemma="inland" stem="inland" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="accounting" lemma="account" stem="account" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="length" lemma="length" stem="length" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="31" lemma="31" stem="31" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN tunnel)) (VP (VBZ starts) (ADVP (NP (DT a) (JJ few) (NNS miles)) (RB inland)) (PP (IN on) (NP (DT each) (NN side))) (, ,) (PP (VBG accounting) (PP (IN for) (NP (NP (PRP$ its) (JJ total) (NN length)) (PP (IN of) (NP (CD 31) (NNS miles))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its total length of 31 miles" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
            <token id="17" string="of" />
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="31 miles" type="NP">
          <tokens>
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="a few miles" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="miles" />
          </tokens>
        </chunking>
        <chunking id="4" string="starts a few miles inland on each side , accounting for its total length of 31 miles" type="VP">
          <tokens>
            <token id="3" string="starts" />
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="miles" />
            <token id="7" string="inland" />
            <token id="8" string="on" />
            <token id="9" string="each" />
            <token id="10" string="side" />
            <token id="11" string="," />
            <token id="12" string="accounting" />
            <token id="13" string="for" />
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
            <token id="17" string="of" />
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="The tunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="6" string="its total length" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
          </tokens>
        </chunking>
        <chunking id="7" string="each side" type="NP">
          <tokens>
            <token id="9" string="each" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">starts</governor>
          <dependent id="2">tunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">starts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">miles</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">miles</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">inland</governor>
          <dependent id="6">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">starts</governor>
          <dependent id="7">inland</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">side</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">side</governor>
          <dependent id="9">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">starts</governor>
          <dependent id="10">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">length</governor>
          <dependent id="12">accounting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">length</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">length</governor>
          <dependent id="14">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">length</governor>
          <dependent id="15">total</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">starts</governor>
          <dependent id="16">length</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">miles</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">miles</governor>
          <dependent id="18">31</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">length</governor>
          <dependent id="19">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="31" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="31" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>Geological conditions account for the different progress on each side.</content>
      <tokens>
        <token id="1" string="Geological" lemma="geological" stem="geolog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="account" lemma="account" stem="account" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Geological) (NNS conditions)) (VP (VBP account) (PP (IN for) (NP (NP (DT the) (JJ different) (NN progress)) (PP (IN on) (NP (DT each) (NN side)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="account for the different progress on each side" type="VP">
          <tokens>
            <token id="3" string="account" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="different" />
            <token id="7" string="progress" />
            <token id="8" string="on" />
            <token id="9" string="each" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
        <chunking id="2" string="Geological conditions" type="NP">
          <tokens>
            <token id="1" string="Geological" />
            <token id="2" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="3" string="the different progress" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="different" />
            <token id="7" string="progress" />
          </tokens>
        </chunking>
        <chunking id="4" string="the different progress on each side" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="different" />
            <token id="7" string="progress" />
            <token id="8" string="on" />
            <token id="9" string="each" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
        <chunking id="5" string="each side" type="NP">
          <tokens>
            <token id="9" string="each" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">conditions</governor>
          <dependent id="1">Geological</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">account</governor>
          <dependent id="2">conditions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">account</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">progress</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">progress</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">progress</governor>
          <dependent id="6">different</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">account</governor>
          <dependent id="7">progress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">side</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">side</governor>
          <dependent id="9">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">progress</governor>
          <dependent id="10">side</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>French workers reaching the tiny hole telephoned their British counterparts and relayed the news to TransManche officials.</content>
      <tokens>
        <token id="1" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="reaching" lemma="reach" stem="reach" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="tiny" lemma="tiny" stem="tini" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="telephoned" lemma="telephone" stem="telephon" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="counterparts" lemma="counterpart" stem="counterpart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="relayed" lemma="relay" stem="relai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="TransManche" lemma="TransManche" stem="transmanch" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ French) (NNS workers)) (VP (VBG reaching) (NP (DT the) (JJ tiny) (NN hole)))) (VP (VP (VBD telephoned) (NP (PRP$ their) (JJ British) (NNS counterparts))) (CC and) (VP (VBD relayed) (NP (DT the) (NN news)) (PP (TO to) (NP (NNP TransManche) (NNS officials))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="French workers reaching the tiny hole" type="NP">
          <tokens>
            <token id="1" string="French" />
            <token id="2" string="workers" />
            <token id="3" string="reaching" />
            <token id="4" string="the" />
            <token id="5" string="tiny" />
            <token id="6" string="hole" />
          </tokens>
        </chunking>
        <chunking id="2" string="the news" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="news" />
          </tokens>
        </chunking>
        <chunking id="3" string="telephoned their British counterparts" type="VP">
          <tokens>
            <token id="7" string="telephoned" />
            <token id="8" string="their" />
            <token id="9" string="British" />
            <token id="10" string="counterparts" />
          </tokens>
        </chunking>
        <chunking id="4" string="telephoned their British counterparts and relayed the news to TransManche officials" type="VP">
          <tokens>
            <token id="7" string="telephoned" />
            <token id="8" string="their" />
            <token id="9" string="British" />
            <token id="10" string="counterparts" />
            <token id="11" string="and" />
            <token id="12" string="relayed" />
            <token id="13" string="the" />
            <token id="14" string="news" />
            <token id="15" string="to" />
            <token id="16" string="TransManche" />
            <token id="17" string="officials" />
          </tokens>
        </chunking>
        <chunking id="5" string="French workers" type="NP">
          <tokens>
            <token id="1" string="French" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="6" string="their British counterparts" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="British" />
            <token id="10" string="counterparts" />
          </tokens>
        </chunking>
        <chunking id="7" string="relayed the news to TransManche officials" type="VP">
          <tokens>
            <token id="12" string="relayed" />
            <token id="13" string="the" />
            <token id="14" string="news" />
            <token id="15" string="to" />
            <token id="16" string="TransManche" />
            <token id="17" string="officials" />
          </tokens>
        </chunking>
        <chunking id="8" string="reaching the tiny hole" type="VP">
          <tokens>
            <token id="3" string="reaching" />
            <token id="4" string="the" />
            <token id="5" string="tiny" />
            <token id="6" string="hole" />
          </tokens>
        </chunking>
        <chunking id="9" string="TransManche officials" type="NP">
          <tokens>
            <token id="16" string="TransManche" />
            <token id="17" string="officials" />
          </tokens>
        </chunking>
        <chunking id="10" string="the tiny hole" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="tiny" />
            <token id="6" string="hole" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">workers</governor>
          <dependent id="1">French</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">telephoned</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">workers</governor>
          <dependent id="3">reaching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">hole</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">hole</governor>
          <dependent id="5">tiny</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">reaching</governor>
          <dependent id="6">hole</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">telephoned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">counterparts</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">counterparts</governor>
          <dependent id="9">British</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">telephoned</governor>
          <dependent id="10">counterparts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">telephoned</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">telephoned</governor>
          <dependent id="12">relayed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">news</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">relayed</governor>
          <dependent id="14">news</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">officials</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">officials</governor>
          <dependent id="16">TransManche</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">relayed</governor>
          <dependent id="17">officials</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The first champagne corks popped minutes later.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="3" string="champagne" lemma="champagne" stem="champagn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="corks" lemma="cork" stem="cork" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="popped" lemma="pop" stem="pop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ first) (NN champagne) (NNS corks)) (VP (VBD popped) (NP (NNS minutes)) (ADVP (RB later))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="popped minutes later" type="VP">
          <tokens>
            <token id="5" string="popped" />
            <token id="6" string="minutes" />
            <token id="7" string="later" />
          </tokens>
        </chunking>
        <chunking id="2" string="minutes" type="NP">
          <tokens>
            <token id="6" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="3" string="The first champagne corks" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="champagne" />
            <token id="4" string="corks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">corks</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">corks</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">corks</governor>
          <dependent id="3">champagne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">popped</governor>
          <dependent id="4">corks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">popped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">popped</governor>
          <dependent id="6">minutes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">popped</governor>
          <dependent id="7">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="minutes later" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="minutes" />
            <token id="7" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``It&amp;apost;s an exciting moment.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="exciting" lemma="exciting" stem="excit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (NP (DT an) (JJ exciting) (NN moment))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an exciting moment" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="exciting" />
            <token id="6" string="moment" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s an exciting moment" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="an" />
            <token id="5" string="exciting" />
            <token id="6" string="moment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">moment</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">moment</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">moment</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">moment</governor>
          <dependent id="5">exciting</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">moment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>It&amp;apost;s the first time we have air passing between the two tunnels,&amp;apost;&amp;apost; said Gordon Crighton, tunnel engineering manager.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="passing" lemma="passing" stem="pass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="13" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Gordon" lemma="Gordon" stem="gordon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Crighton" lemma="Crighton" stem="crighton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="manager" lemma="manager" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP It)) (VP (VBZ 's) (NP (NP (DT the) (JJ first) (NN time)) (SBAR (S (NP (PRP we)) (VP (VBP have) (NP (NP (NN air) (NN passing)) (PP (IN between) (NP (DT the) (CD two) (NNS tunnels)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Gordon) (NNP Crighton)) (, ,) (NP (NN tunnel) (NN engineering) (NN manager))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have air passing between the two tunnels" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="air" />
            <token id="9" string="passing" />
            <token id="10" string="between" />
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="2" string="the first time we have air passing between the two tunnels" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
            <token id="6" string="we" />
            <token id="7" string="have" />
            <token id="8" string="air" />
            <token id="9" string="passing" />
            <token id="10" string="between" />
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="air passing" type="NP">
          <tokens>
            <token id="8" string="air" />
            <token id="9" string="passing" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s the first time we have air passing between the two tunnels" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
            <token id="6" string="we" />
            <token id="7" string="have" />
            <token id="8" string="air" />
            <token id="9" string="passing" />
            <token id="10" string="between" />
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="tunnel engineering manager" type="NP">
          <tokens>
            <token id="20" string="tunnel" />
            <token id="21" string="engineering" />
            <token id="22" string="manager" />
          </tokens>
        </chunking>
        <chunking id="8" string="air passing between the two tunnels" type="NP">
          <tokens>
            <token id="8" string="air" />
            <token id="9" string="passing" />
            <token id="10" string="between" />
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="9" string="the first time" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="we have air passing between the two tunnels" type="SBAR">
          <tokens>
            <token id="6" string="we" />
            <token id="7" string="have" />
            <token id="8" string="air" />
            <token id="9" string="passing" />
            <token id="10" string="between" />
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="11" string="Gordon Crighton" type="NP">
          <tokens>
            <token id="17" string="Gordon" />
            <token id="18" string="Crighton" />
          </tokens>
        </chunking>
        <chunking id="12" string="the two tunnels" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="two" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="13" string="Gordon Crighton , tunnel engineering manager" type="NP">
          <tokens>
            <token id="17" string="Gordon" />
            <token id="18" string="Crighton" />
            <token id="19" string="," />
            <token id="20" string="tunnel" />
            <token id="21" string="engineering" />
            <token id="22" string="manager" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">time</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">time</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">time</governor>
          <dependent id="4">first</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">time</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">passing</governor>
          <dependent id="8">air</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="9">passing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">tunnels</governor>
          <dependent id="10">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">tunnels</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">tunnels</governor>
          <dependent id="12">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">passing</governor>
          <dependent id="13">tunnels</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Crighton</governor>
          <dependent id="17">Gordon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="18">Crighton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">manager</governor>
          <dependent id="20">tunnel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">manager</governor>
          <dependent id="21">engineering</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Crighton</governor>
          <dependent id="22">manager</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Gordon Crighton" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Gordon" />
            <token id="18" string="Crighton" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``We see it as just another exercise, but I&amp;apost;m sure there will be a lot of parties going on,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="exercise" lemma="exercise" stem="exercis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="parties" lemma="party" stem="parti" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP We)) (VP (VBP see) (NP (PRP it)) (ADVP (RB as) (NP (RB just) (DT another) (NN exercise))))) (, ,) (CC but) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ sure) (SBAR (S (NP (EX there)) (VP (MD will) (VP (VB be) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NNS parties)) (VP (VBG going) (PP (IN on)))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lot of parties going on" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m sure there will be a lot of parties going on" type="VP">
          <tokens>
            <token id="12" string="'m" />
            <token id="13" string="sure" />
            <token id="14" string="there" />
            <token id="15" string="will" />
            <token id="16" string="be" />
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="4" string="will be a lot of parties going on" type="VP">
          <tokens>
            <token id="15" string="will" />
            <token id="16" string="be" />
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="see it as just another exercise" type="VP">
          <tokens>
            <token id="3" string="see" />
            <token id="4" string="it" />
            <token id="5" string="as" />
            <token id="6" string="just" />
            <token id="7" string="another" />
            <token id="8" string="exercise" />
          </tokens>
        </chunking>
        <chunking id="8" string="there will be a lot of parties going on" type="SBAR">
          <tokens>
            <token id="14" string="there" />
            <token id="15" string="will" />
            <token id="16" string="be" />
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="14" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="parties going on" type="NP">
          <tokens>
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="11" string="just another exercise" type="NP">
          <tokens>
            <token id="6" string="just" />
            <token id="7" string="another" />
            <token id="8" string="exercise" />
          </tokens>
        </chunking>
        <chunking id="12" string="going on" type="VP">
          <tokens>
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="13" string="a lot" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="lot" />
          </tokens>
        </chunking>
        <chunking id="14" string="be a lot of parties going on" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="sure there will be a lot of parties going on" type="ADJP">
          <tokens>
            <token id="13" string="sure" />
            <token id="14" string="there" />
            <token id="15" string="will" />
            <token id="16" string="be" />
            <token id="17" string="a" />
            <token id="18" string="lot" />
            <token id="19" string="of" />
            <token id="20" string="parties" />
            <token id="21" string="going" />
            <token id="22" string="on" />
          </tokens>
        </chunking>
        <chunking id="18" string="parties" type="NP">
          <tokens>
            <token id="20" string="parties" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">see</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="3">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">see</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">see</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">exercise</governor>
          <dependent id="6">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">exercise</governor>
          <dependent id="7">another</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">as</governor>
          <dependent id="8">exercise</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">see</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">sure</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">sure</governor>
          <dependent id="12">'m</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">see</governor>
          <dependent id="13">sure</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="18">lot</governor>
          <dependent id="14">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">lot</governor>
          <dependent id="15">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">lot</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">lot</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">sure</governor>
          <dependent id="18">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">parties</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">lot</governor>
          <dependent id="20">parties</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">parties</governor>
          <dependent id="21">going</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">going</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Preliminary tests indicated the two halves were 20 inches out of alignment.</content>
      <tokens>
        <token id="1" string="Preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="tests" lemma="test" stem="test" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="indicated" lemma="indicate" stem="indic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="halves" lemma="half" stem="halv" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="alignment" lemma="alignment" stem="align" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Preliminary) (NNS tests)) (VP (VBD indicated) (SBAR (S (NP (DT the) (CD two) (NNS halves)) (VP (VBD were) (ADVP (NP (CD 20) (NNS inches)) (IN out)) (PP (IN of) (NP (NN alignment))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were 20 inches out of alignment" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="2" string="Preliminary tests" type="NP">
          <tokens>
            <token id="1" string="Preliminary" />
            <token id="2" string="tests" />
          </tokens>
        </chunking>
        <chunking id="3" string="the two halves were 20 inches out of alignment" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="4" string="the two halves" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
          </tokens>
        </chunking>
        <chunking id="5" string="indicated the two halves were 20 inches out of alignment" type="VP">
          <tokens>
            <token id="3" string="indicated" />
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="6" string="alignment" type="NP">
          <tokens>
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="7" string="20 inches" type="NP">
          <tokens>
            <token id="8" string="20" />
            <token id="9" string="inches" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">tests</governor>
          <dependent id="1">Preliminary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">indicated</governor>
          <dependent id="2">tests</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">indicated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">halves</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">halves</governor>
          <dependent id="5">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">alignment</governor>
          <dependent id="6">halves</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">alignment</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">inches</governor>
          <dependent id="8">20</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">alignment</governor>
          <dependent id="9">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">inches</governor>
          <dependent id="10">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">alignment</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">indicated</governor>
          <dependent id="12">alignment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="two" />
          </tokens>
        </entity>
        <entity id="2" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>Another day will be needed to be certain, technicians said, but they called the line-up ``exceptional,&amp;apost;&amp;apost; considering the massive boring machines are drilling holes about three stories high.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="2" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="technicians" lemma="technician" stem="technician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="line-up" lemma="line-up" stem="line-up" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="exceptional" lemma="exceptional" stem="except" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="considering" lemma="consider" stem="consid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="massive" lemma="massive" stem="massiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="machines" lemma="machine" stem="machin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="drilling" lemma="drill" stem="drill" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="holes" lemma="hole" stem="hole" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="32" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT Another) (NN day)) (SBAR (S (VP (MD will) (VP (VB be) (VP (VBN needed) (S (VP (TO to) (VP (VB be) (ADJP (JJ certain))))))))))) (, ,) (NP (NNS technicians)) (VP (VBD said))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBD called) (S (NP (DT the) (JJ line-up)) (`` ``) (ADJP (JJ exceptional))) (, ,) ('' '') (S (VP (VBG considering) (SBAR (S (NP (DT the) (JJ massive) (JJ boring) (NNS machines)) (VP (VBP are) (VP (VBG drilling) (NP (NNS holes)) (PP (IN about) (ADJP (NP (CD three) (NNS stories)) (JJ high))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="three stories" type="NP">
          <tokens>
            <token id="31" string="three" />
            <token id="32" string="stories" />
          </tokens>
        </chunking>
        <chunking id="2" string="the line-up" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="line-up" />
          </tokens>
        </chunking>
        <chunking id="3" string="will be needed to be certain" type="SBAR">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="4" string="technicians" type="NP">
          <tokens>
            <token id="10" string="technicians" />
          </tokens>
        </chunking>
        <chunking id="5" string="exceptional" type="ADJP">
          <tokens>
            <token id="19" string="exceptional" />
          </tokens>
        </chunking>
        <chunking id="6" string="be certain" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="7" string="Another day will be needed to be certain" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="day" />
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="8" string="the massive boring machines" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="massive" />
            <token id="25" string="boring" />
            <token id="26" string="machines" />
          </tokens>
        </chunking>
        <chunking id="9" string="called the line-up `` exceptional , '' considering the massive boring machines are drilling holes about three stories high" type="VP">
          <tokens>
            <token id="15" string="called" />
            <token id="16" string="the" />
            <token id="17" string="line-up" />
            <token id="18" string="``" />
            <token id="19" string="exceptional" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="considering" />
            <token id="23" string="the" />
            <token id="24" string="massive" />
            <token id="25" string="boring" />
            <token id="26" string="machines" />
            <token id="27" string="are" />
            <token id="28" string="drilling" />
            <token id="29" string="holes" />
            <token id="30" string="about" />
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="Another day" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="day" />
          </tokens>
        </chunking>
        <chunking id="12" string="to be certain" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="13" string="three stories high" type="ADJP">
          <tokens>
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="14" string="be needed to be certain" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="15" string="needed to be certain" type="VP">
          <tokens>
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="16" string="considering the massive boring machines are drilling holes about three stories high" type="VP">
          <tokens>
            <token id="22" string="considering" />
            <token id="23" string="the" />
            <token id="24" string="massive" />
            <token id="25" string="boring" />
            <token id="26" string="machines" />
            <token id="27" string="are" />
            <token id="28" string="drilling" />
            <token id="29" string="holes" />
            <token id="30" string="about" />
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="the massive boring machines are drilling holes about three stories high" type="SBAR">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="massive" />
            <token id="25" string="boring" />
            <token id="26" string="machines" />
            <token id="27" string="are" />
            <token id="28" string="drilling" />
            <token id="29" string="holes" />
            <token id="30" string="about" />
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="19" string="certain" type="ADJP">
          <tokens>
            <token id="8" string="certain" />
          </tokens>
        </chunking>
        <chunking id="20" string="are drilling holes about three stories high" type="VP">
          <tokens>
            <token id="27" string="are" />
            <token id="28" string="drilling" />
            <token id="29" string="holes" />
            <token id="30" string="about" />
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="21" string="drilling holes about three stories high" type="VP">
          <tokens>
            <token id="28" string="drilling" />
            <token id="29" string="holes" />
            <token id="30" string="about" />
            <token id="31" string="three" />
            <token id="32" string="stories" />
            <token id="33" string="high" />
          </tokens>
        </chunking>
        <chunking id="22" string="holes" type="NP">
          <tokens>
            <token id="29" string="holes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">day</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="2">day</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">needed</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">needed</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">day</governor>
          <dependent id="5">needed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">certain</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">certain</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">needed</governor>
          <dependent id="8">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">technicians</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">said</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">called</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">said</governor>
          <dependent id="15">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">line-up</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">exceptional</governor>
          <dependent id="17">line-up</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">called</governor>
          <dependent id="19">exceptional</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">called</governor>
          <dependent id="22">considering</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">machines</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">machines</governor>
          <dependent id="24">massive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">machines</governor>
          <dependent id="25">boring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">drilling</governor>
          <dependent id="26">machines</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">drilling</governor>
          <dependent id="27">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">considering</governor>
          <dependent id="28">drilling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">drilling</governor>
          <dependent id="29">holes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">high</governor>
          <dependent id="30">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">stories</governor>
          <dependent id="31">three</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="33">high</governor>
          <dependent id="32">stories</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">drilling</governor>
          <dependent id="33">high</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Another day" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The workers will now bore out a one-yard hole to permit passage from one half to the other.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="bore" lemma="bear" stem="bore" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="one-yard" lemma="one-yard" stem="one-yard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="permit" lemma="permit" stem="permit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS workers)) (VP (MD will) (S (ADVP (RB now)) (VP (VBN bore) (PRT (RP out)) (NP (DT a) (JJ one-yard) (NN hole) (S (VP (TO to) (VP (VB permit) (NP (NN passage)) (PP (IN from) (NP (NP (CD one) (NN half)) (PP (TO to) (NP (DT the) (JJ other)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one half to the other" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="2" string="will now bore out a one-yard hole to permit passage from one half to the other" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="now" />
            <token id="5" string="bore" />
            <token id="6" string="out" />
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
            <token id="10" string="to" />
            <token id="11" string="permit" />
            <token id="12" string="passage" />
            <token id="13" string="from" />
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="3" string="one half" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="half" />
          </tokens>
        </chunking>
        <chunking id="4" string="bore out a one-yard hole to permit passage from one half to the other" type="VP">
          <tokens>
            <token id="5" string="bore" />
            <token id="6" string="out" />
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
            <token id="10" string="to" />
            <token id="11" string="permit" />
            <token id="12" string="passage" />
            <token id="13" string="from" />
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="5" string="a one-yard hole to permit passage from one half to the other" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
            <token id="10" string="to" />
            <token id="11" string="permit" />
            <token id="12" string="passage" />
            <token id="13" string="from" />
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="6" string="to permit passage from one half to the other" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="permit" />
            <token id="12" string="passage" />
            <token id="13" string="from" />
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="7" string="permit passage from one half to the other" type="VP">
          <tokens>
            <token id="11" string="permit" />
            <token id="12" string="passage" />
            <token id="13" string="from" />
            <token id="14" string="one" />
            <token id="15" string="half" />
            <token id="16" string="to" />
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
        <chunking id="8" string="passage" type="NP">
          <tokens>
            <token id="12" string="passage" />
          </tokens>
        </chunking>
        <chunking id="9" string="The workers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="10" string="the other" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="other" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">workers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">will</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">bore</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">will</governor>
          <dependent id="5">bore</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">bore</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">hole</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">hole</governor>
          <dependent id="8">one-yard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">bore</governor>
          <dependent id="9">hole</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">permit</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">hole</governor>
          <dependent id="11">permit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">permit</governor>
          <dependent id="12">passage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">half</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">half</governor>
          <dependent id="14">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">permit</governor>
          <dependent id="15">half</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">other</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">other</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">half</governor>
          <dependent id="18">other</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>They are expected to greet each other with handshakes in a few weeks.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="greet" lemma="greet" stem="greet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="handshakes" lemma="handshake" stem="handshak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VBN expected) (S (VP (TO to) (VP (VB greet) (NP (DT each) (JJ other)) (PP (IN with) (NP (NP (NNS handshakes)) (PP (IN in) (NP (DT a) (JJ few) (NNS weeks)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="handshakes in a few weeks" type="NP">
          <tokens>
            <token id="9" string="handshakes" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="each other" type="NP">
          <tokens>
            <token id="6" string="each" />
            <token id="7" string="other" />
          </tokens>
        </chunking>
        <chunking id="4" string="handshakes" type="NP">
          <tokens>
            <token id="9" string="handshakes" />
          </tokens>
        </chunking>
        <chunking id="5" string="are expected to greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="expected" />
            <token id="4" string="to" />
            <token id="5" string="greet" />
            <token id="6" string="each" />
            <token id="7" string="other" />
            <token id="8" string="with" />
            <token id="9" string="handshakes" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="6" string="greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="5" string="greet" />
            <token id="6" string="each" />
            <token id="7" string="other" />
            <token id="8" string="with" />
            <token id="9" string="handshakes" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="7" string="a few weeks" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="8" string="expected to greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="3" string="expected" />
            <token id="4" string="to" />
            <token id="5" string="greet" />
            <token id="6" string="each" />
            <token id="7" string="other" />
            <token id="8" string="with" />
            <token id="9" string="handshakes" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="9" string="to greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="greet" />
            <token id="6" string="each" />
            <token id="7" string="other" />
            <token id="8" string="with" />
            <token id="9" string="handshakes" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">expected</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">expected</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">greet</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">expected</governor>
          <dependent id="5">greet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">other</governor>
          <dependent id="6">each</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">greet</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">handshakes</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">greet</governor>
          <dependent id="9">handshakes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">weeks</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">weeks</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">weeks</governor>
          <dependent id="12">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">handshakes</governor>
          <dependent id="13">weeks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a few weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="few" />
            <token id="13" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Two Japanese-designed boring machines are drilling the tunnel.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="Japanese-designed" lemma="japanese-designed" stem="japanese-design" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="machines" lemma="machine" stem="machin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="drilling" lemma="drill" stem="drill" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD Two) (JJ Japanese-designed) (JJ boring) (NNS machines)) (VP (VBP are) (VP (VBG drilling) (NP (DT the) (NN tunnel)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are drilling the tunnel" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="drilling" />
            <token id="7" string="the" />
            <token id="8" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="drilling the tunnel" type="VP">
          <tokens>
            <token id="6" string="drilling" />
            <token id="7" string="the" />
            <token id="8" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="Two Japanese-designed boring machines" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="Japanese-designed" />
            <token id="3" string="boring" />
            <token id="4" string="machines" />
          </tokens>
        </chunking>
        <chunking id="4" string="the tunnel" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="4">machines</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">machines</governor>
          <dependent id="2">Japanese-designed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">machines</governor>
          <dependent id="3">boring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">drilling</governor>
          <dependent id="4">machines</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">drilling</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">drilling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">tunnel</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">drilling</governor>
          <dependent id="8">tunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Two" />
          </tokens>
        </entity>
        <entity id="2" string="Japanese-designed" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Japanese-designed" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>After it is finished, one will be dismantled and hauled out in pieces.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dismantled" lemma="dismantle" stem="dismantl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="hauled" lemma="haul" stem="haul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="pieces" lemma="piece" stem="piec" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN After) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN finished))))) (, ,) (NP (CD one)) (VP (MD will) (VP (VB be) (VP (VP (VBN dismantled)) (CC and) (VP (VBN hauled) (PRT (RP out)) (PP (IN in) (NP (NNS pieces))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pieces" type="NP">
          <tokens>
            <token id="14" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="2" string="be dismantled and hauled out in pieces" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="dismantled" />
            <token id="10" string="and" />
            <token id="11" string="hauled" />
            <token id="12" string="out" />
            <token id="13" string="in" />
            <token id="14" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="3" string="hauled out in pieces" type="VP">
          <tokens>
            <token id="11" string="hauled" />
            <token id="12" string="out" />
            <token id="13" string="in" />
            <token id="14" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="will be dismantled and hauled out in pieces" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="be" />
            <token id="9" string="dismantled" />
            <token id="10" string="and" />
            <token id="11" string="hauled" />
            <token id="12" string="out" />
            <token id="13" string="in" />
            <token id="14" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="6" string="is finished" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="finished" />
          </tokens>
        </chunking>
        <chunking id="7" string="dismantled and hauled out in pieces" type="VP">
          <tokens>
            <token id="9" string="dismantled" />
            <token id="10" string="and" />
            <token id="11" string="hauled" />
            <token id="12" string="out" />
            <token id="13" string="in" />
            <token id="14" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="8" string="dismantled" type="VP">
          <tokens>
            <token id="9" string="dismantled" />
          </tokens>
        </chunking>
        <chunking id="9" string="finished" type="VP">
          <tokens>
            <token id="4" string="finished" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="After it is finished" type="SBAR">
          <tokens>
            <token id="1" string="After" />
            <token id="2" string="it" />
            <token id="3" string="is" />
            <token id="4" string="finished" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">finished</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">finished</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">finished</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">dismantled</governor>
          <dependent id="4">finished</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">dismantled</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">dismantled</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">dismantled</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">dismantled</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">dismantled</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">dismantled</governor>
          <dependent id="11">hauled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">hauled</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">pieces</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">hauled</governor>
          <dependent id="14">pieces</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>The other will drill its own grave and be buried in cement because French officials said it will be too costly to extricate it.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="drill" lemma="drill" stem="drill" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="grave" lemma="grave" stem="grave" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="buried" lemma="bury" stem="buri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="cement" lemma="cement" stem="cement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="15" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="costly" lemma="costly" stem="costli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="extricate" lemma="extricate" stem="extric" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ other)) (VP (MD will) (VP (VP (VB drill) (NP (PRP$ its) (JJ own) (NN grave))) (CC and) (VP (VB be) (VP (VBN buried) (PP (IN in) (NP (NN cement))) (SBAR (IN because) (S (NP (JJ French) (NNS officials)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (MD will) (VP (VB be) (ADJP (RB too) (JJ costly) (S (VP (TO to) (VP (VB extricate) (NP (PRP it))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="it will be too costly to extricate it" type="SBAR">
          <tokens>
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="drill its own grave" type="VP">
          <tokens>
            <token id="4" string="drill" />
            <token id="5" string="its" />
            <token id="6" string="own" />
            <token id="7" string="grave" />
          </tokens>
        </chunking>
        <chunking id="3" string="be buried in cement because French officials said it will be too costly to extricate it" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="buried" />
            <token id="11" string="in" />
            <token id="12" string="cement" />
            <token id="13" string="because" />
            <token id="14" string="French" />
            <token id="15" string="officials" />
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="will be too costly to extricate it" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="buried in cement because French officials said it will be too costly to extricate it" type="VP">
          <tokens>
            <token id="10" string="buried" />
            <token id="11" string="in" />
            <token id="12" string="cement" />
            <token id="13" string="because" />
            <token id="14" string="French" />
            <token id="15" string="officials" />
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="because French officials said it will be too costly to extricate it" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="French" />
            <token id="15" string="officials" />
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="too costly to extricate it" type="ADJP">
          <tokens>
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="extricate it" type="VP">
          <tokens>
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="drill its own grave and be buried in cement because French officials said it will be too costly to extricate it" type="VP">
          <tokens>
            <token id="4" string="drill" />
            <token id="5" string="its" />
            <token id="6" string="own" />
            <token id="7" string="grave" />
            <token id="8" string="and" />
            <token id="9" string="be" />
            <token id="10" string="buried" />
            <token id="11" string="in" />
            <token id="12" string="cement" />
            <token id="13" string="because" />
            <token id="14" string="French" />
            <token id="15" string="officials" />
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="cement" type="NP">
          <tokens>
            <token id="12" string="cement" />
          </tokens>
        </chunking>
        <chunking id="12" string="said it will be too costly to extricate it" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="The other" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="other" />
          </tokens>
        </chunking>
        <chunking id="14" string="be too costly to extricate it" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="to extricate it" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="its own grave" type="NP">
          <tokens>
            <token id="5" string="its" />
            <token id="6" string="own" />
            <token id="7" string="grave" />
          </tokens>
        </chunking>
        <chunking id="17" string="French officials" type="NP">
          <tokens>
            <token id="14" string="French" />
            <token id="15" string="officials" />
          </tokens>
        </chunking>
        <chunking id="18" string="will drill its own grave and be buried in cement because French officials said it will be too costly to extricate it" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="drill" />
            <token id="5" string="its" />
            <token id="6" string="own" />
            <token id="7" string="grave" />
            <token id="8" string="and" />
            <token id="9" string="be" />
            <token id="10" string="buried" />
            <token id="11" string="in" />
            <token id="12" string="cement" />
            <token id="13" string="because" />
            <token id="14" string="French" />
            <token id="15" string="officials" />
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="too" />
            <token id="21" string="costly" />
            <token id="22" string="to" />
            <token id="23" string="extricate" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">other</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">drill</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">drill</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">drill</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">grave</governor>
          <dependent id="5">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">grave</governor>
          <dependent id="6">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">drill</governor>
          <dependent id="7">grave</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">drill</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">buried</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">drill</governor>
          <dependent id="10">buried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">cement</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">buried</governor>
          <dependent id="12">cement</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">said</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">officials</governor>
          <dependent id="14">French</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">officials</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">buried</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">costly</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">costly</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">costly</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">costly</governor>
          <dependent id="20">too</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="21">costly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">extricate</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">costly</governor>
          <dependent id="23">extricate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">extricate</governor>
          <dependent id="24">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="French" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>A work slowdown since last week by militant tunnelers demanding more pay on the French side appeared likely Monday to stall the linkup until the weekend or beyond.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="slowdown" lemma="slowdown" stem="slowdown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="militant" lemma="militant" stem="milit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="tunnelers" lemma="tunneler" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="demanding" lemma="demand" stem="demand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pay" lemma="pay" stem="pai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="stall" lemma="stall" stem="stall" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="weekend" lemma="weekend" stem="weekend" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN work) (NN slowdown)) (PP (IN since) (NP (NP (JJ last) (NN week)) (PP (IN by) (NP (NP (JJ militant) (NNS tunnelers)) (VP (VBG demanding) (NP (JJR more) (NN pay)) (PP (IN on) (NP (DT the) (JJ French) (NN side))))))))) (VP (VBD appeared) (ADJP (JJ likely)) (NP-TMP (NNP Monday)) (S (VP (TO to) (VP (VB stall) (NP (DT the) (NN linkup)) (PP (PP (IN until) (NP (DT the) (NN weekend))) (CC or) (PP (IN beyond))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="militant tunnelers" type="NP">
          <tokens>
            <token id="8" string="militant" />
            <token id="9" string="tunnelers" />
          </tokens>
        </chunking>
        <chunking id="2" string="likely" type="ADJP">
          <tokens>
            <token id="18" string="likely" />
          </tokens>
        </chunking>
        <chunking id="3" string="demanding more pay on the French side" type="VP">
          <tokens>
            <token id="10" string="demanding" />
            <token id="11" string="more" />
            <token id="12" string="pay" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="French" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
        <chunking id="4" string="more pay" type="NP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="pay" />
          </tokens>
        </chunking>
        <chunking id="5" string="the French side" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="French" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
        <chunking id="6" string="appeared likely Monday to stall the linkup until the weekend or beyond" type="VP">
          <tokens>
            <token id="17" string="appeared" />
            <token id="18" string="likely" />
            <token id="19" string="Monday" />
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="linkup" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="weekend" />
            <token id="27" string="or" />
            <token id="28" string="beyond" />
          </tokens>
        </chunking>
        <chunking id="7" string="the weekend" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="8" string="to stall the linkup until the weekend or beyond" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="linkup" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="weekend" />
            <token id="27" string="or" />
            <token id="28" string="beyond" />
          </tokens>
        </chunking>
        <chunking id="9" string="last week by militant tunnelers demanding more pay on the French side" type="NP">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="week" />
            <token id="7" string="by" />
            <token id="8" string="militant" />
            <token id="9" string="tunnelers" />
            <token id="10" string="demanding" />
            <token id="11" string="more" />
            <token id="12" string="pay" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="French" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
        <chunking id="10" string="A work slowdown" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="work" />
            <token id="3" string="slowdown" />
          </tokens>
        </chunking>
        <chunking id="11" string="last week" type="NP">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="week" />
          </tokens>
        </chunking>
        <chunking id="12" string="militant tunnelers demanding more pay on the French side" type="NP">
          <tokens>
            <token id="8" string="militant" />
            <token id="9" string="tunnelers" />
            <token id="10" string="demanding" />
            <token id="11" string="more" />
            <token id="12" string="pay" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="French" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
        <chunking id="13" string="the linkup" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="14" string="stall the linkup until the weekend or beyond" type="VP">
          <tokens>
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="linkup" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="weekend" />
            <token id="27" string="or" />
            <token id="28" string="beyond" />
          </tokens>
        </chunking>
        <chunking id="15" string="A work slowdown since last week by militant tunnelers demanding more pay on the French side" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="work" />
            <token id="3" string="slowdown" />
            <token id="4" string="since" />
            <token id="5" string="last" />
            <token id="6" string="week" />
            <token id="7" string="by" />
            <token id="8" string="militant" />
            <token id="9" string="tunnelers" />
            <token id="10" string="demanding" />
            <token id="11" string="more" />
            <token id="12" string="pay" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="French" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">slowdown</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">slowdown</governor>
          <dependent id="2">work</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">appeared</governor>
          <dependent id="3">slowdown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">week</governor>
          <dependent id="4">since</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">week</governor>
          <dependent id="5">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">slowdown</governor>
          <dependent id="6">week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">tunnelers</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">tunnelers</governor>
          <dependent id="8">militant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">week</governor>
          <dependent id="9">tunnelers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">tunnelers</governor>
          <dependent id="10">demanding</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">pay</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">demanding</governor>
          <dependent id="12">pay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">side</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">side</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">side</governor>
          <dependent id="15">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">demanding</governor>
          <dependent id="16">side</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">appeared</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">appeared</governor>
          <dependent id="18">likely</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">appeared</governor>
          <dependent id="19">Monday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">stall</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">appeared</governor>
          <dependent id="21">stall</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">linkup</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">stall</governor>
          <dependent id="23">linkup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">weekend</governor>
          <dependent id="24">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">weekend</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">stall</governor>
          <dependent id="26">weekend</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">weekend</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">weekend</governor>
          <dependent id="28">beyond</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="Monday" />
          </tokens>
        </entity>
        <entity id="4" string="the weekend" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="weekend" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>But TransManche officials said earlier Tuesday that the meeting in the middle would occur on schedule.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="TransManche" lemma="TransManche" stem="transmanch" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="middle" lemma="middle" stem="middl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="occur" lemma="occur" stem="occur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="schedule" lemma="schedule" stem="schedul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP TransManche) (NNS officials)) (VP (VBD said) (ADVP (RBR earlier)) (NP-TMP (NNP Tuesday)) (SBAR (IN that) (S (NP (NP (DT the) (NN meeting)) (PP (IN in) (NP (DT the) (NN middle)))) (VP (MD would) (VP (VB occur) (PP (IN on) (NP (NN schedule)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the meeting in the middle would occur on schedule" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="meeting" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="middle" />
            <token id="13" string="would" />
            <token id="14" string="occur" />
            <token id="15" string="on" />
            <token id="16" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="2" string="schedule" type="NP">
          <tokens>
            <token id="16" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="3" string="occur on schedule" type="VP">
          <tokens>
            <token id="14" string="occur" />
            <token id="15" string="on" />
            <token id="16" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="4" string="said earlier Tuesday that the meeting in the middle would occur on schedule" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="earlier" />
            <token id="6" string="Tuesday" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="meeting" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="middle" />
            <token id="13" string="would" />
            <token id="14" string="occur" />
            <token id="15" string="on" />
            <token id="16" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="5" string="the meeting" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="6" string="the middle" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="middle" />
          </tokens>
        </chunking>
        <chunking id="7" string="TransManche officials" type="NP">
          <tokens>
            <token id="2" string="TransManche" />
            <token id="3" string="officials" />
          </tokens>
        </chunking>
        <chunking id="8" string="would occur on schedule" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="occur" />
            <token id="15" string="on" />
            <token id="16" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="9" string="the meeting in the middle" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="meeting" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="middle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">officials</governor>
          <dependent id="2">TransManche</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">said</governor>
          <dependent id="5">earlier</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">said</governor>
          <dependent id="6">Tuesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">occur</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">meeting</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">occur</governor>
          <dependent id="9">meeting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">middle</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">middle</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">meeting</governor>
          <dependent id="12">middle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">occur</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="14">occur</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">schedule</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">occur</governor>
          <dependent id="16">schedule</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earlier Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="earlier" />
            <token id="6" string="Tuesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The Chunnel actually consists of three tunnels - two for railway trains and a smaller maintenance tunnel between them.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Chunnel" lemma="Chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="consists" lemma="consist" stem="consist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="railway" lemma="railway" stem="railwai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="maintenance" lemma="maintenance" stem="mainten" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Chunnel)) (ADVP (RB actually)) (VP (VBZ consists) (PP (IN of) (NP (CD three) (NNS tunnels))) (: -) (NP (NP (NP (CD two)) (PP (IN for) (NP (NN railway) (NNS trains)))) (CC and) (NP (NP (DT a) (JJR smaller) (NN maintenance) (NN tunnel)) (PP (IN between) (NP (PRP them)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="railway trains" type="NP">
          <tokens>
            <token id="11" string="railway" />
            <token id="12" string="trains" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Chunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Chunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="three tunnels" type="NP">
          <tokens>
            <token id="6" string="three" />
            <token id="7" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="4" string="a smaller maintenance tunnel between them" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="smaller" />
            <token id="16" string="maintenance" />
            <token id="17" string="tunnel" />
            <token id="18" string="between" />
            <token id="19" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="a smaller maintenance tunnel" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="smaller" />
            <token id="16" string="maintenance" />
            <token id="17" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="6" string="two for railway trains and a smaller maintenance tunnel between them" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="for" />
            <token id="11" string="railway" />
            <token id="12" string="trains" />
            <token id="13" string="and" />
            <token id="14" string="a" />
            <token id="15" string="smaller" />
            <token id="16" string="maintenance" />
            <token id="17" string="tunnel" />
            <token id="18" string="between" />
            <token id="19" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="consists of three tunnels - two for railway trains and a smaller maintenance tunnel between them" type="VP">
          <tokens>
            <token id="4" string="consists" />
            <token id="5" string="of" />
            <token id="6" string="three" />
            <token id="7" string="tunnels" />
            <token id="8" string="-" />
            <token id="9" string="two" />
            <token id="10" string="for" />
            <token id="11" string="railway" />
            <token id="12" string="trains" />
            <token id="13" string="and" />
            <token id="14" string="a" />
            <token id="15" string="smaller" />
            <token id="16" string="maintenance" />
            <token id="17" string="tunnel" />
            <token id="18" string="between" />
            <token id="19" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="two" type="NP">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </chunking>
        <chunking id="9" string="two for railway trains" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="for" />
            <token id="11" string="railway" />
            <token id="12" string="trains" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="19" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Chunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">consists</governor>
          <dependent id="2">Chunnel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">consists</governor>
          <dependent id="3">actually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">consists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">tunnels</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">tunnels</governor>
          <dependent id="6">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">consists</governor>
          <dependent id="7">tunnels</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">consists</governor>
          <dependent id="9">two</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">trains</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">trains</governor>
          <dependent id="11">railway</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">two</governor>
          <dependent id="12">trains</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">two</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tunnel</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">tunnel</governor>
          <dependent id="15">smaller</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">tunnel</governor>
          <dependent id="16">maintenance</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">two</governor>
          <dependent id="17">tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">them</governor>
          <dependent id="18">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">tunnel</governor>
          <dependent id="19">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Taking into account all the tunnels, 80 percent of the drilling has been completed by giant, Japanese-built boring machines working from Calais and Folkstone, England.</content>
      <tokens>
        <token id="1" string="Taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="account" lemma="account" stem="account" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="80" lemma="80" stem="80" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="9" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="completed" lemma="complete" stem="complet" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="giant" lemma="giant" stem="giant" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Japanese-built" lemma="japanese-built" stem="japanese-built" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="machines" lemma="machine" stem="machin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Folkstone" lemma="Folkstone" stem="folkston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Taking) (PP (IN into) (NP (NN account))) (NP (PDT all) (DT the) (NNS tunnels)))) (, ,) (NP (NP (CD 80) (NN percent)) (PP (IN of) (NP (DT the) (NN drilling)))) (VP (VBZ has) (VP (VBN been) (VP (VBN completed) (PP (IN by) (NP (NP (NN giant)) (, ,) (NP (NP (JJ Japanese-built) (JJ boring) (NNS machines)) (VP (VBG working) (PP (IN from) (NP (NP (NNP Calais)) (CC and) (NP (NNP Folkstone) (, ,) (NNP England))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="giant , Japanese-built boring machines working from Calais and Folkstone , England" type="NP">
          <tokens>
            <token id="17" string="giant" />
            <token id="18" string="," />
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="2" string="Calais" type="NP">
          <tokens>
            <token id="24" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taking into account all the tunnels" type="VP">
          <tokens>
            <token id="1" string="Taking" />
            <token id="2" string="into" />
            <token id="3" string="account" />
            <token id="4" string="all" />
            <token id="5" string="the" />
            <token id="6" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="4" string="Calais and Folkstone , England" type="NP">
          <tokens>
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="5" string="the drilling" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="6" string="working from Calais and Folkstone , England" type="VP">
          <tokens>
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="7" string="been completed by giant , Japanese-built boring machines working from Calais and Folkstone , England" type="VP">
          <tokens>
            <token id="14" string="been" />
            <token id="15" string="completed" />
            <token id="16" string="by" />
            <token id="17" string="giant" />
            <token id="18" string="," />
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="8" string="completed by giant , Japanese-built boring machines working from Calais and Folkstone , England" type="VP">
          <tokens>
            <token id="15" string="completed" />
            <token id="16" string="by" />
            <token id="17" string="giant" />
            <token id="18" string="," />
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="9" string="80 percent" type="NP">
          <tokens>
            <token id="8" string="80" />
            <token id="9" string="percent" />
          </tokens>
        </chunking>
        <chunking id="10" string="Japanese-built boring machines working from Calais and Folkstone , England" type="NP">
          <tokens>
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="11" string="Folkstone , England" type="NP">
          <tokens>
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="12" string="80 percent of the drilling" type="NP">
          <tokens>
            <token id="8" string="80" />
            <token id="9" string="percent" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="13" string="giant" type="NP">
          <tokens>
            <token id="17" string="giant" />
          </tokens>
        </chunking>
        <chunking id="14" string="all the tunnels" type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="the" />
            <token id="6" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="15" string="has been completed by giant , Japanese-built boring machines working from Calais and Folkstone , England" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="completed" />
            <token id="16" string="by" />
            <token id="17" string="giant" />
            <token id="18" string="," />
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
            <token id="22" string="working" />
            <token id="23" string="from" />
            <token id="24" string="Calais" />
            <token id="25" string="and" />
            <token id="26" string="Folkstone" />
            <token id="27" string="," />
            <token id="28" string="England" />
          </tokens>
        </chunking>
        <chunking id="16" string="Japanese-built boring machines" type="NP">
          <tokens>
            <token id="19" string="Japanese-built" />
            <token id="20" string="boring" />
            <token id="21" string="machines" />
          </tokens>
        </chunking>
        <chunking id="17" string="account" type="NP">
          <tokens>
            <token id="3" string="account" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="15">completed</governor>
          <dependent id="1">Taking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">account</governor>
          <dependent id="2">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Taking</governor>
          <dependent id="3">account</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="6">tunnels</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">tunnels</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Taking</governor>
          <dependent id="6">tunnels</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">percent</governor>
          <dependent id="8">80</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">completed</governor>
          <dependent id="9">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">drilling</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">drilling</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">percent</governor>
          <dependent id="12">drilling</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">completed</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">completed</governor>
          <dependent id="14">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">completed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">giant</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">completed</governor>
          <dependent id="17">giant</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">machines</governor>
          <dependent id="19">Japanese-built</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">machines</governor>
          <dependent id="20">boring</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">giant</governor>
          <dependent id="21">machines</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">machines</governor>
          <dependent id="22">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Calais</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">working</governor>
          <dependent id="24">Calais</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">Calais</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">England</governor>
          <dependent id="26">Folkstone</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">Calais</governor>
          <dependent id="28">England</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Calais" />
          </tokens>
        </entity>
        <entity id="2" string="Folkstone" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Folkstone" />
          </tokens>
        </entity>
        <entity id="3" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="England" />
          </tokens>
        </entity>
        <entity id="4" string="80 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="8" string="80" />
            <token id="9" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Tuesday&amp;apost;s linkup in the service tunnel is described by the French as a ``mouse ole&amp;apost;&amp;apost; - a bore only two inches in diameter.</content>
      <tokens>
        <token id="1" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="described" lemma="describe" stem="describ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="mouse" lemma="mouse" stem="mous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="ole" lemma="ole" stem="ol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="bore" lemma="bear" stem="bore" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="diameter" lemma="diameter" stem="diamet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Tuesday) (POS 's)) (NN linkup)) (PP (IN in) (NP (DT the) (NN service) (NN tunnel)))) (VP (VBZ is) (VP (VBN described) (PP (IN by) (NP (DT the) (JJ French))) (PP (IN as) (NP (NP (DT a) (`` ``) (NN mouse) (NN ole) ('' '')) (: -) (NP (NP (DT a) (VBN bore) (QP (RB only) (CD two)) (NNS inches)) (PP (IN in) (NP (NN diameter)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a `` mouse ole '' - a bore only two inches in diameter" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="``" />
            <token id="16" string="mouse" />
            <token id="17" string="ole" />
            <token id="18" string="''" />
            <token id="19" string="-" />
            <token id="20" string="a" />
            <token id="21" string="bore" />
            <token id="22" string="only" />
            <token id="23" string="two" />
            <token id="24" string="inches" />
            <token id="25" string="in" />
            <token id="26" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="2" string="the French" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="French" />
          </tokens>
        </chunking>
        <chunking id="3" string="a `` mouse ole ''" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="``" />
            <token id="16" string="mouse" />
            <token id="17" string="ole" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="4" string="Tuesday 's linkup in the service tunnel" type="NP">
          <tokens>
            <token id="1" string="Tuesday" />
            <token id="2" string="'s" />
            <token id="3" string="linkup" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="service" />
            <token id="7" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="Tuesday 's linkup" type="NP">
          <tokens>
            <token id="1" string="Tuesday" />
            <token id="2" string="'s" />
            <token id="3" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="6" string="diameter" type="NP">
          <tokens>
            <token id="26" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="7" string="described by the French as a `` mouse ole '' - a bore only two inches in diameter" type="VP">
          <tokens>
            <token id="9" string="described" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="French" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="``" />
            <token id="16" string="mouse" />
            <token id="17" string="ole" />
            <token id="18" string="''" />
            <token id="19" string="-" />
            <token id="20" string="a" />
            <token id="21" string="bore" />
            <token id="22" string="only" />
            <token id="23" string="two" />
            <token id="24" string="inches" />
            <token id="25" string="in" />
            <token id="26" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="8" string="Tuesday 's" type="NP">
          <tokens>
            <token id="1" string="Tuesday" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bore only two inches" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="bore" />
            <token id="22" string="only" />
            <token id="23" string="two" />
            <token id="24" string="inches" />
          </tokens>
        </chunking>
        <chunking id="10" string="the service tunnel" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="service" />
            <token id="7" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="11" string="is described by the French as a `` mouse ole '' - a bore only two inches in diameter" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="described" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="French" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="``" />
            <token id="16" string="mouse" />
            <token id="17" string="ole" />
            <token id="18" string="''" />
            <token id="19" string="-" />
            <token id="20" string="a" />
            <token id="21" string="bore" />
            <token id="22" string="only" />
            <token id="23" string="two" />
            <token id="24" string="inches" />
            <token id="25" string="in" />
            <token id="26" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="12" string="a bore only two inches in diameter" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="bore" />
            <token id="22" string="only" />
            <token id="23" string="two" />
            <token id="24" string="inches" />
            <token id="25" string="in" />
            <token id="26" string="diameter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">linkup</governor>
          <dependent id="1">Tuesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Tuesday</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">described</governor>
          <dependent id="3">linkup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">tunnel</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">tunnel</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">tunnel</governor>
          <dependent id="6">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">linkup</governor>
          <dependent id="7">tunnel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">described</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">described</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">French</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">French</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">described</governor>
          <dependent id="12">French</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">ole</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">ole</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">ole</governor>
          <dependent id="16">mouse</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">described</governor>
          <dependent id="17">ole</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">inches</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">inches</governor>
          <dependent id="21">bore</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">two</governor>
          <dependent id="22">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">inches</governor>
          <dependent id="23">two</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">ole</governor>
          <dependent id="24">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">diameter</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">inches</governor>
          <dependent id="26">diameter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Tuesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>President Francois Mitterrand and Mrs. Thatcher are expected to meet each other in the tunnel Jan. 26, after the digging for much of the tunnel is finished.</content>
      <tokens>
        <token id="1" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="2" string="Francois" lemma="Francois" stem="francoi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Mitterrand" lemma="Mitterrand" stem="mitterrand" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Thatcher" lemma="Thatcher" stem="thatcher" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="digging" lemma="digging" stem="dig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP President) (NNP Francois) (NNP Mitterrand) (CC and) (NNP Mrs.) (NNP Thatcher)) (VP (VBP are) (VP (VBN expected) (S (VP (TO to) (VP (VB meet) (NP (DT each) (JJ other)) (PP (IN in) (NP (DT the) (NN tunnel))) (NP-TMP (NNP Jan.) (CD 26))))) (, ,) (SBAR (IN after) (S (NP (NP (DT the) (NN digging)) (PP (IN for) (NP (NP (JJ much)) (PP (IN of) (NP (DT the) (NN tunnel)))))) (VP (VBZ is) (VP (VBN finished))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="President Francois Mitterrand and Mrs. Thatcher" type="NP">
          <tokens>
            <token id="1" string="President" />
            <token id="2" string="Francois" />
            <token id="3" string="Mitterrand" />
            <token id="4" string="and" />
            <token id="5" string="Mrs." />
            <token id="6" string="Thatcher" />
          </tokens>
        </chunking>
        <chunking id="2" string="each other" type="NP">
          <tokens>
            <token id="11" string="each" />
            <token id="12" string="other" />
          </tokens>
        </chunking>
        <chunking id="3" string="finished" type="VP">
          <tokens>
            <token id="28" string="finished" />
          </tokens>
        </chunking>
        <chunking id="4" string="meet each other in the tunnel Jan. 26" type="VP">
          <tokens>
            <token id="10" string="meet" />
            <token id="11" string="each" />
            <token id="12" string="other" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="tunnel" />
            <token id="16" string="Jan." />
            <token id="17" string="26" />
          </tokens>
        </chunking>
        <chunking id="5" string="are expected to meet each other in the tunnel Jan. 26 , after the digging for much of the tunnel is finished" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="expected" />
            <token id="9" string="to" />
            <token id="10" string="meet" />
            <token id="11" string="each" />
            <token id="12" string="other" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="tunnel" />
            <token id="16" string="Jan." />
            <token id="17" string="26" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="digging" />
            <token id="22" string="for" />
            <token id="23" string="much" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="tunnel" />
            <token id="27" string="is" />
            <token id="28" string="finished" />
          </tokens>
        </chunking>
        <chunking id="6" string="after the digging for much of the tunnel is finished" type="SBAR">
          <tokens>
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="digging" />
            <token id="22" string="for" />
            <token id="23" string="much" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="tunnel" />
            <token id="27" string="is" />
            <token id="28" string="finished" />
          </tokens>
        </chunking>
        <chunking id="7" string="to meet each other in the tunnel Jan. 26" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="meet" />
            <token id="11" string="each" />
            <token id="12" string="other" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="tunnel" />
            <token id="16" string="Jan." />
            <token id="17" string="26" />
          </tokens>
        </chunking>
        <chunking id="8" string="expected to meet each other in the tunnel Jan. 26 , after the digging for much of the tunnel is finished" type="VP">
          <tokens>
            <token id="8" string="expected" />
            <token id="9" string="to" />
            <token id="10" string="meet" />
            <token id="11" string="each" />
            <token id="12" string="other" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="tunnel" />
            <token id="16" string="Jan." />
            <token id="17" string="26" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="digging" />
            <token id="22" string="for" />
            <token id="23" string="much" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="tunnel" />
            <token id="27" string="is" />
            <token id="28" string="finished" />
          </tokens>
        </chunking>
        <chunking id="9" string="the digging for much of the tunnel" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="digging" />
            <token id="22" string="for" />
            <token id="23" string="much" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="is finished" type="VP">
          <tokens>
            <token id="27" string="is" />
            <token id="28" string="finished" />
          </tokens>
        </chunking>
        <chunking id="11" string="much of the tunnel" type="NP">
          <tokens>
            <token id="23" string="much" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="12" string="the digging" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="digging" />
          </tokens>
        </chunking>
        <chunking id="13" string="the tunnel" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="14" string="much" type="NP">
          <tokens>
            <token id="23" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Mitterrand</governor>
          <dependent id="1">President</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Mitterrand</governor>
          <dependent id="2">Francois</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">expected</governor>
          <dependent id="3">Mitterrand</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Mitterrand</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Thatcher</governor>
          <dependent id="5">Mrs.</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Mitterrand</governor>
          <dependent id="6">Thatcher</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">expected</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">meet</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">expected</governor>
          <dependent id="10">meet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">other</governor>
          <dependent id="11">each</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">meet</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">tunnel</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">tunnel</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">meet</governor>
          <dependent id="15">tunnel</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">meet</governor>
          <dependent id="16">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">Jan.</governor>
          <dependent id="17">26</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">finished</governor>
          <dependent id="19">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">digging</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">finished</governor>
          <dependent id="21">digging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">much</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">digging</governor>
          <dependent id="23">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">tunnel</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">tunnel</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">much</governor>
          <dependent id="26">tunnel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">finished</governor>
          <dependent id="27">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">expected</governor>
          <dependent id="28">finished</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francois Mitterrand" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Francois" />
            <token id="3" string="Mitterrand" />
          </tokens>
        </entity>
        <entity id="2" string="Thatcher" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thatcher" />
          </tokens>
        </entity>
        <entity id="3" string="Jan. 26" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Jan." />
            <token id="17" string="26" />
          </tokens>
        </entity>
        <entity id="4" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>The first coupling of the two rail tunnels is scheduled for mid-1991.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="3" string="coupling" lemma="coupling" stem="coupl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="rail" lemma="rail" stem="rail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="mid-1991" lemma="mid-1991" stem="mid-1991" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ first) (NN coupling)) (PP (IN of) (NP (DT the) (CD two) (NN rail) (NNS tunnels)))) (VP (VBZ is) (VP (VBN scheduled) (PP (IN for) (NP (NN mid-1991))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="mid-1991" type="NP">
          <tokens>
            <token id="12" string="mid-1991" />
          </tokens>
        </chunking>
        <chunking id="2" string="The first coupling" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="coupling" />
          </tokens>
        </chunking>
        <chunking id="3" string="the two rail tunnels" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="two" />
            <token id="7" string="rail" />
            <token id="8" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="4" string="The first coupling of the two rail tunnels" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="coupling" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="two" />
            <token id="7" string="rail" />
            <token id="8" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="5" string="is scheduled for mid-1991" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="scheduled" />
            <token id="11" string="for" />
            <token id="12" string="mid-1991" />
          </tokens>
        </chunking>
        <chunking id="6" string="scheduled for mid-1991" type="VP">
          <tokens>
            <token id="10" string="scheduled" />
            <token id="11" string="for" />
            <token id="12" string="mid-1991" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">coupling</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">coupling</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">scheduled</governor>
          <dependent id="3">coupling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">tunnels</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">tunnels</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">tunnels</governor>
          <dependent id="6">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">tunnels</governor>
          <dependent id="7">rail</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">coupling</governor>
          <dependent id="8">tunnels</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">scheduled</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">scheduled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">mid-1991</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">scheduled</governor>
          <dependent id="12">mid-1991</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Eurotunnel PLC, the world&amp;apost;s largest engineering project, announced Oct. 8 that it had reached an agreement with its banks on $3.5 billion in new credit.</content>
      <tokens>
        <token id="1" string="Eurotunnel" lemma="Eurotunnel" stem="eurotunnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="PLC" lemma="PLC" stem="plc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="agreement" lemma="agreement" stem="agreement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="banks" lemma="bank" stem="bank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="3.5" lemma="3.5" stem="3.5" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Eurotunnel) (NNP PLC)) (, ,) (NP (NP (DT the) (NN world) (POS 's)) (JJS largest) (NN engineering) (NN project)) (, ,)) (VP (VBD announced) (NP-TMP (NNP Oct.) (CD 8)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD had) (VP (VBN reached) (NP (NP (DT an) (NN agreement)) (PP (IN with) (NP (PRP$ its) (NNS banks)))) (PP (IN on) (NP (QP ($ $) (CD 3.5) (CD billion)))) (PP (IN in) (NP (JJ new) (NN credit)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the world 's largest engineering project" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="largest" />
            <token id="8" string="engineering" />
            <token id="9" string="project" />
          </tokens>
        </chunking>
        <chunking id="2" string="Eurotunnel PLC , the world 's largest engineering project ," type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="largest" />
            <token id="8" string="engineering" />
            <token id="9" string="project" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="an agreement with its banks" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="agreement" />
            <token id="20" string="with" />
            <token id="21" string="its" />
            <token id="22" string="banks" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="its banks" type="NP">
          <tokens>
            <token id="21" string="its" />
            <token id="22" string="banks" />
          </tokens>
        </chunking>
        <chunking id="6" string="reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="17" string="reached" />
            <token id="18" string="an" />
            <token id="19" string="agreement" />
            <token id="20" string="with" />
            <token id="21" string="its" />
            <token id="22" string="banks" />
            <token id="23" string="on" />
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
            <token id="27" string="in" />
            <token id="28" string="new" />
            <token id="29" string="credit" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 3.5 billion" type="NP">
          <tokens>
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
          </tokens>
        </chunking>
        <chunking id="8" string="announced Oct. 8 that it had reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="11" string="announced" />
            <token id="12" string="Oct." />
            <token id="13" string="8" />
            <token id="14" string="that" />
            <token id="15" string="it" />
            <token id="16" string="had" />
            <token id="17" string="reached" />
            <token id="18" string="an" />
            <token id="19" string="agreement" />
            <token id="20" string="with" />
            <token id="21" string="its" />
            <token id="22" string="banks" />
            <token id="23" string="on" />
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
            <token id="27" string="in" />
            <token id="28" string="new" />
            <token id="29" string="credit" />
          </tokens>
        </chunking>
        <chunking id="9" string="that it had reached an agreement with its banks on $ 3.5 billion in new credit" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="it" />
            <token id="16" string="had" />
            <token id="17" string="reached" />
            <token id="18" string="an" />
            <token id="19" string="agreement" />
            <token id="20" string="with" />
            <token id="21" string="its" />
            <token id="22" string="banks" />
            <token id="23" string="on" />
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
            <token id="27" string="in" />
            <token id="28" string="new" />
            <token id="29" string="credit" />
          </tokens>
        </chunking>
        <chunking id="10" string="Eurotunnel PLC" type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </chunking>
        <chunking id="11" string="an agreement" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="agreement" />
          </tokens>
        </chunking>
        <chunking id="12" string="the world 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="had reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="reached" />
            <token id="18" string="an" />
            <token id="19" string="agreement" />
            <token id="20" string="with" />
            <token id="21" string="its" />
            <token id="22" string="banks" />
            <token id="23" string="on" />
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
            <token id="27" string="in" />
            <token id="28" string="new" />
            <token id="29" string="credit" />
          </tokens>
        </chunking>
        <chunking id="14" string="new credit" type="NP">
          <tokens>
            <token id="28" string="new" />
            <token id="29" string="credit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">PLC</governor>
          <dependent id="1">Eurotunnel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">announced</governor>
          <dependent id="2">PLC</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">world</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">project</governor>
          <dependent id="5">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">world</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">project</governor>
          <dependent id="7">largest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">project</governor>
          <dependent id="8">engineering</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">PLC</governor>
          <dependent id="9">project</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">announced</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="11">announced</governor>
          <dependent id="12">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Oct.</governor>
          <dependent id="13">8</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">reached</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">reached</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">reached</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">announced</governor>
          <dependent id="17">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">agreement</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">reached</governor>
          <dependent id="19">agreement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">banks</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">banks</governor>
          <dependent id="21">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">agreement</governor>
          <dependent id="22">banks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">$</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">reached</governor>
          <dependent id="24">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">billion</governor>
          <dependent id="25">3.5</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">$</governor>
          <dependent id="26">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">credit</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">credit</governor>
          <dependent id="28">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">reached</governor>
          <dependent id="29">credit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oct. 8" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Oct." />
            <token id="13" string="8" />
          </tokens>
        </entity>
        <entity id="2" string="$ 3.5 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="24" string="$" />
            <token id="25" string="3.5" />
            <token id="26" string="billion" />
          </tokens>
        </entity>
        <entity id="3" string="Eurotunnel PLC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>More than 200 banks are involved in the financing.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="banks" lemma="bank" stem="bank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="financing" lemma="financing" stem="financ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 200)) (NNS banks)) (VP (VBP are) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN financing))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are involved in the financing" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="involved" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="financing" />
          </tokens>
        </chunking>
        <chunking id="2" string="the financing" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="financing" />
          </tokens>
        </chunking>
        <chunking id="3" string="involved in the financing" type="VP">
          <tokens>
            <token id="6" string="involved" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="financing" />
          </tokens>
        </chunking>
        <chunking id="4" string="More than 200 banks" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="200" />
            <token id="4" string="banks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">200</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">banks</governor>
          <dependent id="3">200</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">involved</governor>
          <dependent id="4">banks</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">involved</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">financing</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">financing</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">involved</governor>
          <dependent id="9">financing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="200" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="200" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>The Chunnel&amp;apost;s scheduled debut in mid-1993 would come six months after the 12-nation European Community formally drops remaining trade barriers, becoming a unified marketplace of 320 million consumers.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Chunnel" lemma="Chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="debut" lemma="debut" stem="debut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="mid-1993" lemma="mid-1993" stem="mid-1993" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="12-nation" lemma="12-nation" stem="12-nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="European" lemma="European" stem="european" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Community" lemma="Community" stem="commun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="formally" lemma="formally" stem="formal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="drops" lemma="drop" stem="drop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="trade" lemma="trade" stem="trade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="barriers" lemma="barrier" stem="barrier" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="becoming" lemma="become" stem="becom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="unified" lemma="unify" stem="unifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="marketplace" lemma="marketplace" stem="marketplac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="320" lemma="320" stem="320" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="30" string="consumers" lemma="consumer" stem="consum" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NNP Chunnel) (POS 's)) (VBN scheduled) (NN debut)) (PP (IN in) (NP (NN mid-1993)))) (VP (MD would) (VP (VB come) (NP (CD six) (NNS months)) (SBAR (IN after) (S (NP (DT the) (JJ 12-nation) (NNP European) (NNP Community)) (VP (ADVP (RB formally)) (VBZ drops) (S (VP (VBG remaining) (NP (NN trade) (NNS barriers)))) (, ,) (S (VP (VBG becoming) (NP (NP (DT a) (VBN unified) (NN marketplace)) (PP (IN of) (NP (QP (CD 320) (CD million)) (NNS consumers))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would come six months after the 12-nation European Community formally drops remaining trade barriers , becoming a unified marketplace of 320 million consumers" type="VP">
          <tokens>
            <token id="8" string="would" />
            <token id="9" string="come" />
            <token id="10" string="six" />
            <token id="11" string="months" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="12-nation" />
            <token id="15" string="European" />
            <token id="16" string="Community" />
            <token id="17" string="formally" />
            <token id="18" string="drops" />
            <token id="19" string="remaining" />
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
            <token id="22" string="," />
            <token id="23" string="becoming" />
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="2" string="formally drops remaining trade barriers , becoming a unified marketplace of 320 million consumers" type="VP">
          <tokens>
            <token id="17" string="formally" />
            <token id="18" string="drops" />
            <token id="19" string="remaining" />
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
            <token id="22" string="," />
            <token id="23" string="becoming" />
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="3" string="becoming a unified marketplace of 320 million consumers" type="VP">
          <tokens>
            <token id="23" string="becoming" />
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="4" string="a unified marketplace of 320 million consumers" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="5" string="mid-1993" type="NP">
          <tokens>
            <token id="7" string="mid-1993" />
          </tokens>
        </chunking>
        <chunking id="6" string="trade barriers" type="NP">
          <tokens>
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
          </tokens>
        </chunking>
        <chunking id="7" string="six months" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="months" />
          </tokens>
        </chunking>
        <chunking id="8" string="remaining trade barriers" type="VP">
          <tokens>
            <token id="19" string="remaining" />
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
          </tokens>
        </chunking>
        <chunking id="9" string="a unified marketplace" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Chunnel 's scheduled debut in mid-1993" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Chunnel" />
            <token id="3" string="'s" />
            <token id="4" string="scheduled" />
            <token id="5" string="debut" />
            <token id="6" string="in" />
            <token id="7" string="mid-1993" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Chunnel 's scheduled debut" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Chunnel" />
            <token id="3" string="'s" />
            <token id="4" string="scheduled" />
            <token id="5" string="debut" />
          </tokens>
        </chunking>
        <chunking id="12" string="320 million consumers" type="NP">
          <tokens>
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 12-nation European Community" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="12-nation" />
            <token id="15" string="European" />
            <token id="16" string="Community" />
          </tokens>
        </chunking>
        <chunking id="14" string="after the 12-nation European Community formally drops remaining trade barriers , becoming a unified marketplace of 320 million consumers" type="SBAR">
          <tokens>
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="12-nation" />
            <token id="15" string="European" />
            <token id="16" string="Community" />
            <token id="17" string="formally" />
            <token id="18" string="drops" />
            <token id="19" string="remaining" />
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
            <token id="22" string="," />
            <token id="23" string="becoming" />
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
        <chunking id="15" string="The Chunnel 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Chunnel" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="come six months after the 12-nation European Community formally drops remaining trade barriers , becoming a unified marketplace of 320 million consumers" type="VP">
          <tokens>
            <token id="9" string="come" />
            <token id="10" string="six" />
            <token id="11" string="months" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="12-nation" />
            <token id="15" string="European" />
            <token id="16" string="Community" />
            <token id="17" string="formally" />
            <token id="18" string="drops" />
            <token id="19" string="remaining" />
            <token id="20" string="trade" />
            <token id="21" string="barriers" />
            <token id="22" string="," />
            <token id="23" string="becoming" />
            <token id="24" string="a" />
            <token id="25" string="unified" />
            <token id="26" string="marketplace" />
            <token id="27" string="of" />
            <token id="28" string="320" />
            <token id="29" string="million" />
            <token id="30" string="consumers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Chunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">debut</governor>
          <dependent id="2">Chunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Chunnel</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">debut</governor>
          <dependent id="4">scheduled</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">come</governor>
          <dependent id="5">debut</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">mid-1993</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">debut</governor>
          <dependent id="7">mid-1993</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">come</governor>
          <dependent id="8">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">come</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">months</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">come</governor>
          <dependent id="11">months</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">drops</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Community</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">Community</governor>
          <dependent id="14">12-nation</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Community</governor>
          <dependent id="15">European</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">drops</governor>
          <dependent id="16">Community</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">drops</governor>
          <dependent id="17">formally</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">come</governor>
          <dependent id="18">drops</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">drops</governor>
          <dependent id="19">remaining</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">barriers</governor>
          <dependent id="20">trade</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">remaining</governor>
          <dependent id="21">barriers</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">drops</governor>
          <dependent id="23">becoming</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">marketplace</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">marketplace</governor>
          <dependent id="25">unified</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">becoming</governor>
          <dependent id="26">marketplace</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">consumers</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">million</governor>
          <dependent id="28">320</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">consumers</governor>
          <dependent id="29">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">marketplace</governor>
          <dependent id="30">consumers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six months" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="months" />
          </tokens>
        </entity>
        <entity id="2" string="320 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="320" />
            <token id="29" string="million" />
          </tokens>
        </entity>
        <entity id="3" string="European Community" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="European" />
            <token id="16" string="Community" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Officials estimate the tunnel may carry 28 million passengers in the first year of operation, although Eurotunnel doesn&amp;apost;t expect a profit until the end of the century.</content>
      <tokens>
        <token id="1" string="Officials" lemma="official" stem="official" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="estimate" lemma="estimate" stem="estim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="28" lemma="28" stem="28" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Eurotunnel" lemma="Eurotunnel" stem="eurotunnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="19" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="profit" lemma="profit" stem="profit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Officials)) (VP (VBP estimate) (SBAR (S (NP (DT the) (NN tunnel)) (VP (MD may) (VP (VB carry) (NP (QP (CD 28) (CD million)) (NNS passengers)) (PP (IN in) (NP (NP (DT the) (JJ first) (NN year)) (PP (IN of) (NP (NN operation))))) (, ,) (SBAR (IN although) (S (NP (NNP Eurotunnel)) (VP (VBZ does) (RB n't) (VP (VB expect) (NP (DT a) (NN profit)) (PP (IN until) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN century)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first year" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="28 million passengers" type="NP">
          <tokens>
            <token id="7" string="28" />
            <token id="8" string="million" />
            <token id="9" string="passengers" />
          </tokens>
        </chunking>
        <chunking id="4" string="the end of the century" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="5" string="Officials" type="NP">
          <tokens>
            <token id="1" string="Officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="does n't expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="7" string="expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="8" string="the century" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="9" string="estimate the tunnel may carry 28 million passengers in the first year of operation , although Eurotunnel does n't expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="2" string="estimate" />
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
            <token id="5" string="may" />
            <token id="6" string="carry" />
            <token id="7" string="28" />
            <token id="8" string="million" />
            <token id="9" string="passengers" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
            <token id="16" string="," />
            <token id="17" string="although" />
            <token id="18" string="Eurotunnel" />
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="10" string="may carry 28 million passengers in the first year of operation , although Eurotunnel does n't expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="5" string="may" />
            <token id="6" string="carry" />
            <token id="7" string="28" />
            <token id="8" string="million" />
            <token id="9" string="passengers" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
            <token id="16" string="," />
            <token id="17" string="although" />
            <token id="18" string="Eurotunnel" />
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="11" string="although Eurotunnel does n't expect a profit until the end of the century" type="SBAR">
          <tokens>
            <token id="17" string="although" />
            <token id="18" string="Eurotunnel" />
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="12" string="a profit" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="profit" />
          </tokens>
        </chunking>
        <chunking id="13" string="the first year of operation" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
          </tokens>
        </chunking>
        <chunking id="14" string="carry 28 million passengers in the first year of operation , although Eurotunnel does n't expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="6" string="carry" />
            <token id="7" string="28" />
            <token id="8" string="million" />
            <token id="9" string="passengers" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
            <token id="16" string="," />
            <token id="17" string="although" />
            <token id="18" string="Eurotunnel" />
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="15" string="Eurotunnel" type="NP">
          <tokens>
            <token id="18" string="Eurotunnel" />
          </tokens>
        </chunking>
        <chunking id="16" string="the tunnel may carry 28 million passengers in the first year of operation , although Eurotunnel does n't expect a profit until the end of the century" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
            <token id="5" string="may" />
            <token id="6" string="carry" />
            <token id="7" string="28" />
            <token id="8" string="million" />
            <token id="9" string="passengers" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
            <token id="16" string="," />
            <token id="17" string="although" />
            <token id="18" string="Eurotunnel" />
            <token id="19" string="does" />
            <token id="20" string="n't" />
            <token id="21" string="expect" />
            <token id="22" string="a" />
            <token id="23" string="profit" />
            <token id="24" string="until" />
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </chunking>
        <chunking id="17" string="operation" type="NP">
          <tokens>
            <token id="15" string="operation" />
          </tokens>
        </chunking>
        <chunking id="18" string="the tunnel" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">estimate</governor>
          <dependent id="1">Officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">estimate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">tunnel</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">carry</governor>
          <dependent id="4">tunnel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">carry</governor>
          <dependent id="5">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">estimate</governor>
          <dependent id="6">carry</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">million</governor>
          <dependent id="7">28</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">passengers</governor>
          <dependent id="8">million</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">carry</governor>
          <dependent id="9">passengers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">year</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">year</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">year</governor>
          <dependent id="12">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">carry</governor>
          <dependent id="13">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">operation</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">year</governor>
          <dependent id="15">operation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">expect</governor>
          <dependent id="17">although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">expect</governor>
          <dependent id="18">Eurotunnel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">expect</governor>
          <dependent id="19">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">expect</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">carry</governor>
          <dependent id="21">expect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">profit</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">expect</governor>
          <dependent id="23">profit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">end</governor>
          <dependent id="24">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">end</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">expect</governor>
          <dependent id="26">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">century</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">century</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">end</governor>
          <dependent id="29">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the first year of operation" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="year" />
            <token id="14" string="of" />
            <token id="15" string="operation" />
          </tokens>
        </entity>
        <entity id="2" string="the end of the century" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="end" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="century" />
          </tokens>
        </entity>
        <entity id="3" string="Eurotunnel" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Eurotunnel" />
          </tokens>
        </entity>
        <entity id="4" string="28 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="28" />
            <token id="8" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>A study released last Friday in Paris by transportation experts said the tunnel&amp;apost;s completion will aggravate traffic congestion in a wide area of continental Europe.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="released" lemma="release" stem="releas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Paris" lemma="Paris" stem="pari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="transportation" lemma="transportation" stem="transport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="completion" lemma="completion" stem="complet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="aggravate" lemma="aggravate" stem="aggrav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="congestion" lemma="congestion" stem="congest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="wide" lemma="wide" stem="wide" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="continental" lemma="continental" stem="continent" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN study)) (VP (VBD released) (NP-TMP (JJ last) (NNP Friday)) (PP (IN in) (NP (NNP Paris))) (PP (IN by) (NP (NN transportation) (NNS experts))))) (VP (VBD said) (SBAR (S (NP (NP (DT the) (NN tunnel) (POS 's)) (NN completion)) (VP (MD will) (VP (VB aggravate) (NP (NN traffic) (NN congestion)) (PP (IN in) (NP (NP (DT a) (JJ wide) (NN area)) (PP (IN of) (NP (JJ continental) (NNP Europe)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A study released last Friday in Paris by transportation experts" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="study" />
            <token id="3" string="released" />
            <token id="4" string="last" />
            <token id="5" string="Friday" />
            <token id="6" string="in" />
            <token id="7" string="Paris" />
            <token id="8" string="by" />
            <token id="9" string="transportation" />
            <token id="10" string="experts" />
          </tokens>
        </chunking>
        <chunking id="2" string="a wide area" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
          </tokens>
        </chunking>
        <chunking id="3" string="transportation experts" type="NP">
          <tokens>
            <token id="9" string="transportation" />
            <token id="10" string="experts" />
          </tokens>
        </chunking>
        <chunking id="4" string="the tunnel 's completion will aggravate traffic congestion in a wide area of continental Europe" type="SBAR">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="tunnel" />
            <token id="14" string="'s" />
            <token id="15" string="completion" />
            <token id="16" string="will" />
            <token id="17" string="aggravate" />
            <token id="18" string="traffic" />
            <token id="19" string="congestion" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
            <token id="24" string="of" />
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="5" string="continental Europe" type="NP">
          <tokens>
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="6" string="released last Friday in Paris by transportation experts" type="VP">
          <tokens>
            <token id="3" string="released" />
            <token id="4" string="last" />
            <token id="5" string="Friday" />
            <token id="6" string="in" />
            <token id="7" string="Paris" />
            <token id="8" string="by" />
            <token id="9" string="transportation" />
            <token id="10" string="experts" />
          </tokens>
        </chunking>
        <chunking id="7" string="the tunnel 's completion" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="tunnel" />
            <token id="14" string="'s" />
            <token id="15" string="completion" />
          </tokens>
        </chunking>
        <chunking id="8" string="will aggravate traffic congestion in a wide area of continental Europe" type="VP">
          <tokens>
            <token id="16" string="will" />
            <token id="17" string="aggravate" />
            <token id="18" string="traffic" />
            <token id="19" string="congestion" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
            <token id="24" string="of" />
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="9" string="A study" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="study" />
          </tokens>
        </chunking>
        <chunking id="10" string="the tunnel 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="tunnel" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="aggravate traffic congestion in a wide area of continental Europe" type="VP">
          <tokens>
            <token id="17" string="aggravate" />
            <token id="18" string="traffic" />
            <token id="19" string="congestion" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
            <token id="24" string="of" />
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="12" string="said the tunnel 's completion will aggravate traffic congestion in a wide area of continental Europe" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="the" />
            <token id="13" string="tunnel" />
            <token id="14" string="'s" />
            <token id="15" string="completion" />
            <token id="16" string="will" />
            <token id="17" string="aggravate" />
            <token id="18" string="traffic" />
            <token id="19" string="congestion" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
            <token id="24" string="of" />
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="13" string="traffic congestion" type="NP">
          <tokens>
            <token id="18" string="traffic" />
            <token id="19" string="congestion" />
          </tokens>
        </chunking>
        <chunking id="14" string="a wide area of continental Europe" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="wide" />
            <token id="23" string="area" />
            <token id="24" string="of" />
            <token id="25" string="continental" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="15" string="Paris" type="NP">
          <tokens>
            <token id="7" string="Paris" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">study</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="2">study</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">study</governor>
          <dependent id="3">released</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Friday</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">released</governor>
          <dependent id="5">Friday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Paris</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">released</governor>
          <dependent id="7">Paris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">experts</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">experts</governor>
          <dependent id="9">transportation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">released</governor>
          <dependent id="10">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">tunnel</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">completion</governor>
          <dependent id="13">tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">tunnel</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">aggravate</governor>
          <dependent id="15">completion</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">aggravate</governor>
          <dependent id="16">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="17">aggravate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">congestion</governor>
          <dependent id="18">traffic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">aggravate</governor>
          <dependent id="19">congestion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">area</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">area</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">area</governor>
          <dependent id="22">wide</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">aggravate</governor>
          <dependent id="23">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Europe</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">Europe</governor>
          <dependent id="25">continental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">area</governor>
          <dependent id="26">Europe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Europe" />
          </tokens>
        </entity>
        <entity id="2" string="last Friday" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="last" />
            <token id="5" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="Paris" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Paris" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>Some Britons have worries of a different sort, fearing an influx of ills from the continent ranging from terrorism to rabid animals.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Britons" lemma="Britons" stem="briton" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="worries" lemma="worry" stem="worri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fearing" lemma="fear" stem="fear" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="influx" lemma="influx" stem="influx" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ills" lemma="ill" stem="ill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="continent" lemma="continent" stem="contin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="ranging" lemma="range" stem="rang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="terrorism" lemma="terrorism" stem="terror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="rabid" lemma="rabid" stem="rabid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (NNPS Britons)) (VP (VBP have) (NP (NP (NNS worries)) (PP (IN of) (NP (DT a) (JJ different) (NN sort)))) (, ,) (S (VP (VBG fearing) (NP (NP (DT an) (NN influx)) (PP (IN of) (NP (NNS ills)))) (PP (IN from) (NP (NP (DT the) (NN continent)) (VP (VBG ranging) (PP (IN from) (NP (NN terrorism))) (PP (TO to) (NP (JJ rabid) (NNS animals))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the continent ranging from terrorism to rabid animals" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="continent" />
            <token id="18" string="ranging" />
            <token id="19" string="from" />
            <token id="20" string="terrorism" />
            <token id="21" string="to" />
            <token id="22" string="rabid" />
            <token id="23" string="animals" />
          </tokens>
        </chunking>
        <chunking id="2" string="an influx" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="influx" />
          </tokens>
        </chunking>
        <chunking id="3" string="Some Britons" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="Britons" />
          </tokens>
        </chunking>
        <chunking id="4" string="the continent" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="continent" />
          </tokens>
        </chunking>
        <chunking id="5" string="rabid animals" type="NP">
          <tokens>
            <token id="22" string="rabid" />
            <token id="23" string="animals" />
          </tokens>
        </chunking>
        <chunking id="6" string="have worries of a different sort , fearing an influx of ills from the continent ranging from terrorism to rabid animals" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="worries" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="different" />
            <token id="8" string="sort" />
            <token id="9" string="," />
            <token id="10" string="fearing" />
            <token id="11" string="an" />
            <token id="12" string="influx" />
            <token id="13" string="of" />
            <token id="14" string="ills" />
            <token id="15" string="from" />
            <token id="16" string="the" />
            <token id="17" string="continent" />
            <token id="18" string="ranging" />
            <token id="19" string="from" />
            <token id="20" string="terrorism" />
            <token id="21" string="to" />
            <token id="22" string="rabid" />
            <token id="23" string="animals" />
          </tokens>
        </chunking>
        <chunking id="7" string="worries of a different sort" type="NP">
          <tokens>
            <token id="4" string="worries" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="different" />
            <token id="8" string="sort" />
          </tokens>
        </chunking>
        <chunking id="8" string="fearing an influx of ills from the continent ranging from terrorism to rabid animals" type="VP">
          <tokens>
            <token id="10" string="fearing" />
            <token id="11" string="an" />
            <token id="12" string="influx" />
            <token id="13" string="of" />
            <token id="14" string="ills" />
            <token id="15" string="from" />
            <token id="16" string="the" />
            <token id="17" string="continent" />
            <token id="18" string="ranging" />
            <token id="19" string="from" />
            <token id="20" string="terrorism" />
            <token id="21" string="to" />
            <token id="22" string="rabid" />
            <token id="23" string="animals" />
          </tokens>
        </chunking>
        <chunking id="9" string="an influx of ills" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="influx" />
            <token id="13" string="of" />
            <token id="14" string="ills" />
          </tokens>
        </chunking>
        <chunking id="10" string="worries" type="NP">
          <tokens>
            <token id="4" string="worries" />
          </tokens>
        </chunking>
        <chunking id="11" string="ranging from terrorism to rabid animals" type="VP">
          <tokens>
            <token id="18" string="ranging" />
            <token id="19" string="from" />
            <token id="20" string="terrorism" />
            <token id="21" string="to" />
            <token id="22" string="rabid" />
            <token id="23" string="animals" />
          </tokens>
        </chunking>
        <chunking id="12" string="terrorism" type="NP">
          <tokens>
            <token id="20" string="terrorism" />
          </tokens>
        </chunking>
        <chunking id="13" string="ills" type="NP">
          <tokens>
            <token id="14" string="ills" />
          </tokens>
        </chunking>
        <chunking id="14" string="a different sort" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="different" />
            <token id="8" string="sort" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Britons</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">Britons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="4">worries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">sort</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">sort</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">sort</governor>
          <dependent id="7">different</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">worries</governor>
          <dependent id="8">sort</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">have</governor>
          <dependent id="10">fearing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">influx</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">fearing</governor>
          <dependent id="12">influx</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">ills</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">influx</governor>
          <dependent id="14">ills</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">continent</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">continent</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">fearing</governor>
          <dependent id="17">continent</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">continent</governor>
          <dependent id="18">ranging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">terrorism</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">ranging</governor>
          <dependent id="20">terrorism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">animals</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">animals</governor>
          <dependent id="22">rabid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">ranging</governor>
          <dependent id="23">animals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Britons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>Since construction began in late 1987, there have been seven deaths on the British side and two on the French.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="French" lemma="French" stem="french" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Since) (S (NP (NN construction)) (VP (VBD began) (PP (IN in) (NP (JJ late) (CD 1987)))))) (, ,) (NP (EX there)) (VP (VBP have) (VP (VBN been) (NP (NP (CD seven) (NNS deaths)) (PP (IN on) (NP (NP (DT the) (JJ British) (NN side)) (CC and) (NP (CD two))))) (PP (IN on) (NP (DT the) (NNP French))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have been seven deaths on the British side and two on the French" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="seven" />
            <token id="12" string="deaths" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="side" />
            <token id="17" string="and" />
            <token id="18" string="two" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="French" />
          </tokens>
        </chunking>
        <chunking id="2" string="seven deaths on the British side and two" type="NP">
          <tokens>
            <token id="11" string="seven" />
            <token id="12" string="deaths" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="side" />
            <token id="17" string="and" />
            <token id="18" string="two" />
          </tokens>
        </chunking>
        <chunking id="3" string="Since construction began in late 1987" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="construction" />
            <token id="3" string="began" />
            <token id="4" string="in" />
            <token id="5" string="late" />
            <token id="6" string="1987" />
          </tokens>
        </chunking>
        <chunking id="4" string="two" type="NP">
          <tokens>
            <token id="18" string="two" />
          </tokens>
        </chunking>
        <chunking id="5" string="there" type="NP">
          <tokens>
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="began in late 1987" type="VP">
          <tokens>
            <token id="3" string="began" />
            <token id="4" string="in" />
            <token id="5" string="late" />
            <token id="6" string="1987" />
          </tokens>
        </chunking>
        <chunking id="7" string="the British side and two" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="side" />
            <token id="17" string="and" />
            <token id="18" string="two" />
          </tokens>
        </chunking>
        <chunking id="8" string="the French" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="French" />
          </tokens>
        </chunking>
        <chunking id="9" string="late 1987" type="NP">
          <tokens>
            <token id="5" string="late" />
            <token id="6" string="1987" />
          </tokens>
        </chunking>
        <chunking id="10" string="construction" type="NP">
          <tokens>
            <token id="2" string="construction" />
          </tokens>
        </chunking>
        <chunking id="11" string="the British side" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="side" />
          </tokens>
        </chunking>
        <chunking id="12" string="been seven deaths on the British side and two on the French" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="seven" />
            <token id="12" string="deaths" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="side" />
            <token id="17" string="and" />
            <token id="18" string="two" />
            <token id="19" string="on" />
            <token id="20" string="the" />
            <token id="21" string="French" />
          </tokens>
        </chunking>
        <chunking id="13" string="seven deaths" type="NP">
          <tokens>
            <token id="11" string="seven" />
            <token id="12" string="deaths" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">began</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">began</governor>
          <dependent id="2">construction</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">deaths</governor>
          <dependent id="3">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">1987</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">1987</governor>
          <dependent id="5">late</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">began</governor>
          <dependent id="6">1987</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="12">deaths</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">deaths</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">deaths</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">deaths</governor>
          <dependent id="11">seven</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">deaths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">side</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">side</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">side</governor>
          <dependent id="15">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">deaths</governor>
          <dependent id="16">side</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">side</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">side</governor>
          <dependent id="18">two</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">French</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">French</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">deaths</governor>
          <dependent id="21">French</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="late 1987" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="late" />
            <token id="6" string="1987" />
          </tokens>
        </entity>
        <entity id="4" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="seven" />
          </tokens>
        </entity>
        <entity id="5" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Five British firms were ordered last Wednesday to stand trial on charges related to the death of a construction worker last year.</content>
      <tokens>
        <token id="1" string="Five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="firms" lemma="firm" stem="firm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="ordered" lemma="order" stem="order" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="related" lemma="relate" stem="relat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="worker" lemma="worker" stem="worker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD Five) (JJ British) (NNS firms)) (VP (VBD were) (VP (VBN ordered) (NP-TMP (JJ last) (NNP Wednesday)) (S (VP (TO to) (VP (VB stand) (NP (NN trial)) (PP (IN on) (NP (NP (NNS charges)) (VP (VBN related) (PP (TO to) (NP (NP (DT the) (NN death)) (PP (IN of) (NP (DT a) (NN construction) (NN worker))))) (NP-TMP (JJ last) (NN year)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Five British firms" type="NP">
          <tokens>
            <token id="1" string="Five" />
            <token id="2" string="British" />
            <token id="3" string="firms" />
          </tokens>
        </chunking>
        <chunking id="2" string="related to the death of a construction worker last year" type="VP">
          <tokens>
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="were ordered last Wednesday to stand trial on charges related to the death of a construction worker last year" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="ordered" />
            <token id="6" string="last" />
            <token id="7" string="Wednesday" />
            <token id="8" string="to" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="on" />
            <token id="12" string="charges" />
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="ordered last Wednesday to stand trial on charges related to the death of a construction worker last year" type="VP">
          <tokens>
            <token id="5" string="ordered" />
            <token id="6" string="last" />
            <token id="7" string="Wednesday" />
            <token id="8" string="to" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="on" />
            <token id="12" string="charges" />
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="to stand trial on charges related to the death of a construction worker last year" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="on" />
            <token id="12" string="charges" />
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="charges" type="NP">
          <tokens>
            <token id="12" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="charges related to the death of a construction worker last year" type="NP">
          <tokens>
            <token id="12" string="charges" />
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="stand trial on charges related to the death of a construction worker last year" type="VP">
          <tokens>
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="on" />
            <token id="12" string="charges" />
            <token id="13" string="related" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="a construction worker" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
          </tokens>
        </chunking>
        <chunking id="10" string="the death" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="11" string="trial" type="NP">
          <tokens>
            <token id="10" string="trial" />
          </tokens>
        </chunking>
        <chunking id="12" string="the death of a construction worker" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="death" />
            <token id="17" string="of" />
            <token id="18" string="a" />
            <token id="19" string="construction" />
            <token id="20" string="worker" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="3">firms</governor>
          <dependent id="1">Five</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">firms</governor>
          <dependent id="2">British</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">ordered</governor>
          <dependent id="3">firms</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">ordered</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">ordered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Wednesday</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">ordered</governor>
          <dependent id="7">Wednesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">stand</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">ordered</governor>
          <dependent id="9">stand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">stand</governor>
          <dependent id="10">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">charges</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stand</governor>
          <dependent id="12">charges</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">charges</governor>
          <dependent id="13">related</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">death</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">death</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">related</governor>
          <dependent id="16">death</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">worker</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">worker</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">worker</governor>
          <dependent id="19">construction</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">death</governor>
          <dependent id="20">worker</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">year</governor>
          <dependent id="21">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">related</governor>
          <dependent id="22">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Five" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Five" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="last" />
            <token id="22" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="last Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="last" />
            <token id="7" string="Wednesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>The undersea bond between the two hereditary enemies was envisioned nearly 200 years ago by a French engineer called Albert Mathieu.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="undersea" lemma="undersea" stem="undersea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="bond" lemma="bond" stem="bond" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="hereditary" lemma="hereditary" stem="hereditari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="enemies" lemma="enemy" stem="enemi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="envisioned" lemma="envision" stem="envis" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="18" string="engineer" lemma="engineer" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Mathieu" lemma="Mathieu" stem="mathieu" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN undersea) (NN bond)) (PP (IN between) (NP (DT the) (CD two) (JJ hereditary) (NNS enemies)))) (VP (VBD was) (VP (VBN envisioned) (ADVP (NP (QP (RB nearly) (CD 200)) (NNS years)) (RB ago)) (PP (IN by) (NP (NP (DT a) (JJ French) (NN engineer)) (VP (VBN called) (NP (NNP Albert) (NNP Mathieu))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The undersea bond" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="undersea" />
            <token id="3" string="bond" />
          </tokens>
        </chunking>
        <chunking id="2" string="envisioned nearly 200 years ago by a French engineer called Albert Mathieu" type="VP">
          <tokens>
            <token id="10" string="envisioned" />
            <token id="11" string="nearly" />
            <token id="12" string="200" />
            <token id="13" string="years" />
            <token id="14" string="ago" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="French" />
            <token id="18" string="engineer" />
            <token id="19" string="called" />
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </chunking>
        <chunking id="3" string="nearly 200 years" type="NP">
          <tokens>
            <token id="11" string="nearly" />
            <token id="12" string="200" />
            <token id="13" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="a French engineer called Albert Mathieu" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="French" />
            <token id="18" string="engineer" />
            <token id="19" string="called" />
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </chunking>
        <chunking id="5" string="The undersea bond between the two hereditary enemies" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="undersea" />
            <token id="3" string="bond" />
            <token id="4" string="between" />
            <token id="5" string="the" />
            <token id="6" string="two" />
            <token id="7" string="hereditary" />
            <token id="8" string="enemies" />
          </tokens>
        </chunking>
        <chunking id="6" string="was envisioned nearly 200 years ago by a French engineer called Albert Mathieu" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="envisioned" />
            <token id="11" string="nearly" />
            <token id="12" string="200" />
            <token id="13" string="years" />
            <token id="14" string="ago" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="French" />
            <token id="18" string="engineer" />
            <token id="19" string="called" />
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </chunking>
        <chunking id="7" string="Albert Mathieu" type="NP">
          <tokens>
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </chunking>
        <chunking id="8" string="the two hereditary enemies" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="two" />
            <token id="7" string="hereditary" />
            <token id="8" string="enemies" />
          </tokens>
        </chunking>
        <chunking id="9" string="called Albert Mathieu" type="VP">
          <tokens>
            <token id="19" string="called" />
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </chunking>
        <chunking id="10" string="a French engineer" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="French" />
            <token id="18" string="engineer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">bond</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">bond</governor>
          <dependent id="2">undersea</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">envisioned</governor>
          <dependent id="3">bond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">enemies</governor>
          <dependent id="4">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">enemies</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">enemies</governor>
          <dependent id="6">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">enemies</governor>
          <dependent id="7">hereditary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">bond</governor>
          <dependent id="8">enemies</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">envisioned</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">envisioned</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">200</governor>
          <dependent id="11">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">years</governor>
          <dependent id="12">200</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="14">ago</governor>
          <dependent id="13">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">envisioned</governor>
          <dependent id="14">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">engineer</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">engineer</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">engineer</governor>
          <dependent id="17">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">envisioned</governor>
          <dependent id="18">engineer</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">engineer</governor>
          <dependent id="19">called</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Mathieu</governor>
          <dependent id="20">Albert</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">called</governor>
          <dependent id="21">Mathieu</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="17" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="nearly 200 years ago" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="nearly" />
            <token id="12" string="200" />
            <token id="13" string="years" />
            <token id="14" string="ago" />
          </tokens>
        </entity>
        <entity id="3" string="Albert Mathieu" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Albert" />
            <token id="21" string="Mathieu" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Napoleon wanted to build it, but Britain warned him off.</content>
      <tokens>
        <token id="1" string="Napoleon" lemma="Napoleon" stem="napoleon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="build" lemma="build" stem="build" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="warned" lemma="warn" stem="warn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Napoleon)) (VP (VBD wanted) (S (VP (TO to) (VP (VB build) (NP (PRP it))))))) (, ,) (CC but) (S (NP (NNP Britain)) (VP (VBD warned) (NP (PRP him)) (PRT (RP off)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="warned him off" type="VP">
          <tokens>
            <token id="9" string="warned" />
            <token id="10" string="him" />
            <token id="11" string="off" />
          </tokens>
        </chunking>
        <chunking id="2" string="build it" type="VP">
          <tokens>
            <token id="4" string="build" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="wanted to build it" type="VP">
          <tokens>
            <token id="2" string="wanted" />
            <token id="3" string="to" />
            <token id="4" string="build" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="8" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="Napoleon" type="NP">
          <tokens>
            <token id="1" string="Napoleon" />
          </tokens>
        </chunking>
        <chunking id="8" string="to build it" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="build" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">wanted</governor>
          <dependent id="1">Napoleon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">build</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">wanted</governor>
          <dependent id="4">build</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">build</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">wanted</governor>
          <dependent id="7">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">warned</governor>
          <dependent id="8">Britain</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">wanted</governor>
          <dependent id="9">warned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">warned</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">warned</governor>
          <dependent id="11">off</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Britain" />
          </tokens>
        </entity>
        <entity id="2" string="Napoleon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Napoleon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>Tunneling actually started in subsequent efforts in 1882 and 1974, but were abandoned.</content>
      <tokens>
        <token id="1" string="Tunneling" lemma="tunneling" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="subsequent" lemma="subsequent" stem="subsequ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1882" lemma="1882" stem="1882" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="abandoned" lemma="abandon" stem="abandon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Tunneling)) (ADVP (RB actually)) (VP (VP (VBD started) (PP (IN in) (NP (JJ subsequent) (NNS efforts))) (PP (IN in) (NP (CD 1882) (CC and) (CD 1974)))) (, ,) (CC but) (VP (VBD were) (VP (VBN abandoned)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were abandoned" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="abandoned" />
          </tokens>
        </chunking>
        <chunking id="2" string="started in subsequent efforts in 1882 and 1974 , but were abandoned" type="VP">
          <tokens>
            <token id="3" string="started" />
            <token id="4" string="in" />
            <token id="5" string="subsequent" />
            <token id="6" string="efforts" />
            <token id="7" string="in" />
            <token id="8" string="1882" />
            <token id="9" string="and" />
            <token id="10" string="1974" />
            <token id="11" string="," />
            <token id="12" string="but" />
            <token id="13" string="were" />
            <token id="14" string="abandoned" />
          </tokens>
        </chunking>
        <chunking id="3" string="subsequent efforts" type="NP">
          <tokens>
            <token id="5" string="subsequent" />
            <token id="6" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="4" string="1882 and 1974" type="NP">
          <tokens>
            <token id="8" string="1882" />
            <token id="9" string="and" />
            <token id="10" string="1974" />
          </tokens>
        </chunking>
        <chunking id="5" string="Tunneling" type="NP">
          <tokens>
            <token id="1" string="Tunneling" />
          </tokens>
        </chunking>
        <chunking id="6" string="abandoned" type="VP">
          <tokens>
            <token id="14" string="abandoned" />
          </tokens>
        </chunking>
        <chunking id="7" string="started in subsequent efforts in 1882 and 1974" type="VP">
          <tokens>
            <token id="3" string="started" />
            <token id="4" string="in" />
            <token id="5" string="subsequent" />
            <token id="6" string="efforts" />
            <token id="7" string="in" />
            <token id="8" string="1882" />
            <token id="9" string="and" />
            <token id="10" string="1974" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">started</governor>
          <dependent id="1">Tunneling</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">started</governor>
          <dependent id="2">actually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">started</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">efforts</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">efforts</governor>
          <dependent id="5">subsequent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">started</governor>
          <dependent id="6">efforts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1882</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">started</governor>
          <dependent id="8">1882</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">1882</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">1882</governor>
          <dependent id="10">1974</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">started</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">abandoned</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">started</governor>
          <dependent id="14">abandoned</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1974" />
          </tokens>
        </entity>
        <entity id="2" string="1882" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1882" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1" string="Britain" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20-21" string="an island" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="11-12" string="the French" id_sentence="33" />
      <mentions>
        <mention ids_tokens="3" string="France" id_sentence="1" />
        <mention ids_tokens="20" string="France" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="20" string="two" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="27" />
        <mention ids_tokens="5" string="it" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11" string="the English Channel on Tuesday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="16-17" string="the English" id_sentence="5" />
        <mention ids_tokens="12-14" string="the English Channel" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="11" string="Tuesday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-2" string="Tuesday's" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="15-16-17" string="a two-inch probe" id_sentence="1" />
      <mentions>
        <mention ids_tokens="32-33" string="the probe" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the two halves" id_sentence="22" />
      <mentions>
        <mention ids_tokens="20-27" string="two halves of a 31-mile undersea rail tunnel" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="4-5" string="TransManche Link" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="3" />
        <mention ids_tokens="4-10" string="an example of what Europe is about" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19" string="the `` Chunnel '' - the Channel Tunnel -" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The Chunnel" id_sentence="6" />
        <mention ids_tokens="1-2" string="The Chunnel" id_sentence="31" />
        <mention ids_tokens="1-3" string="The Chunnel's" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="21-22-23" string="the historic linkup" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The linkup" id_sentence="5" />
        <mention ids_tokens="22-23" string="the linkup" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="25-26" string="continental Europe" id_sentence="40" />
      <mentions>
        <mention ids_tokens="8" string="Europe" id_sentence="3" />
        <mention ids_tokens="22" string="Europe" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="15" string="Minister" id_sentence="3" />
      <mentions>
        <mention ids_tokens="13" string="he" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="4-5-6" string="Europe in practice" id_sentence="4" />
      <mentions>
        <mention ids_tokens="2" string="This" id_sentence="7" />
        <mention ids_tokens="4-7" string="a hugely historic moment" id_sentence="7" />
        <mention ids_tokens="9" string="it" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26" string="Napoleon in 1802 , who thought he could defeat the English by connecting Britain to Europe with a land passage" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="Napoleon" id_sentence="45" />
        <mention ids_tokens="10" string="him" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="10-11" string="90 minutes" id_sentence="8" />
      <mentions>
        <mention ids_tokens="6" string="minutes" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="29-30" string="nearby Sangatte" id_sentence="8" />
      <mentions>
        <mention ids_tokens="33" string="Sangatte" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="the Channel Tunnel project" id_sentence="9" />
      <mentions>
        <mention ids_tokens="4-5" string="the project" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="23" string="first" id_sentence="11" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="19" />
        <mention ids_tokens="4-6" string="an exciting moment" id_sentence="19" />
        <mention ids_tokens="1" string="It" id_sentence="20" />
        <mention ids_tokens="3-13" string="the first time we have air passing between the two tunnels" id_sentence="20" />
        <mention ids_tokens="4" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="11-12" string="the drilling" id_sentence="32" />
      <mentions>
        <mention ids_tokens="24-30" string="drilling on the world's costliest tunnel" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="26-27-28-29-30" string="the world 's costliest tunnel" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1-2" string="The tunnel" id_sentence="15" />
        <mention ids_tokens="14" string="its" id_sentence="15" />
        <mention ids_tokens="7-8" string="the tunnel" id_sentence="26" />
        <mention ids_tokens="14-15" string="the tunnel" id_sentence="34" />
        <mention ids_tokens="25-26" string="the tunnel" id_sentence="34" />
        <mention ids_tokens="3-4" string="the tunnel" id_sentence="39" />
        <mention ids_tokens="12-14" string="the tunnel's" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="French workers reaching the tiny hole" id_sentence="17" />
      <mentions>
        <mention ids_tokens="6" string="we" id_sentence="20" />
        <mention ids_tokens="2" string="We" id_sentence="21" />
        <mention ids_tokens="1-2" string="The workers" id_sentence="24" />
        <mention ids_tokens="1" string="They" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="16-17" string="TransManche officials" id_sentence="17" />
      <mentions>
        <mention ids_tokens="19" string="them" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="17-18" string="the other" id_sentence="24" />
      <mentions>
        <mention ids_tokens="5" string="its" id_sentence="28" />
        <mention ids_tokens="24" string="it" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="1-2" string="Eurotunnel PLC" id_sentence="36" />
      <mentions>
        <mention ids_tokens="18" string="Eurotunnel" id_sentence="39" />
      </mentions>
    </coreference>
  </coreferences>
</document>
