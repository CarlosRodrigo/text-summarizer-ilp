<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06246065">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Among the 29 million Americans who voted for Democrat George McGovern in 1972 was a 24-year-old black law student and one-time campus agitator named Clarence Thomas.; As Thomas later explained, being Republican was regarded as &amp;quot;a fate . . . worse than death among blacks.&amp;quot;</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Democrat" lemma="Democrat" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="McGovern" lemma="McGovern" stem="mcgovern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1972" lemma="1972" stem="1972" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="24-year-old" lemma="24-year-old" stem="24-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one-time" lemma="one-time" stem="one-tim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="campus" lemma="campus" stem="campu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="agitator" lemma="agitator" stem="agit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Thomas." lemma="Thomas." stem="thomas." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Republican" lemma="Republican" stem="republican" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="35" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="regarded" lemma="regard" stem="regard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="fate" lemma="fate" stem="fate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (NP (NP (DT the) (QP (CD 29) (CD million)) (NNPS Americans)) (SBAR (WHNP (WP who)) (S (VP (VBD voted) (SBAR (IN for) (S (NP (NP (NNP Democrat) (NNP George) (NNP McGovern)) (PP (IN in) (NP (CD 1972)))) (VP (VBD was) (NP (NP (DT a) (JJ 24-year-old) (JJ black) (NN law) (NN student) (CC and) (JJ one-time) (NN campus) (NN agitator)) (VP (VBN named) (NP (NP (NNP Clarence) (NNP Thomas.)) (SBAR (S (: ;) (PP (IN As) (NP (NNP Thomas))) (ADVP (RB later)) (VP (VBD explained))))))))))))))) (, ,) (S (VP (VBG being) (NP (NNP Republican)))) (VP (VBD was) (VP (VBN regarded) (PP (IN as) (NP (`` ``) (NP (DT a) (NN fate)) (: ...) (NP (JJR worse)))) (PP (IN than) (NP (NP (NN death)) (PP (IN among) (NP (NNS blacks))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="29" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="voted for Democrat George McGovern in 1972 was a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="VP">
          <tokens>
            <token id="7" string="voted" />
            <token id="8" string="for" />
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
            <token id="12" string="in" />
            <token id="13" string="1972" />
            <token id="14" string="was" />
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="3" string="worse" type="NP">
          <tokens>
            <token id="42" string="worse" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` a fate ... worse" type="NP">
          <tokens>
            <token id="38" string="&quot;" />
            <token id="39" string="a" />
            <token id="40" string="fate" />
            <token id="41" string=". . ." />
            <token id="42" string="worse" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 29 million Americans" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="29" />
            <token id="4" string="million" />
            <token id="5" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="6" string="; As Thomas later explained" type="SBAR">
          <tokens>
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="7" string="a fate" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="fate" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 29 million Americans who voted for Democrat George McGovern in 1972 was a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="29" />
            <token id="4" string="million" />
            <token id="5" string="Americans" />
            <token id="6" string="who" />
            <token id="7" string="voted" />
            <token id="8" string="for" />
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
            <token id="12" string="in" />
            <token id="13" string="1972" />
            <token id="14" string="was" />
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Thomas. ; As Thomas later explained" type="NP">
          <tokens>
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="10" string="Clarence Thomas." type="NP">
          <tokens>
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
          </tokens>
        </chunking>
        <chunking id="11" string="being Republican" type="VP">
          <tokens>
            <token id="33" string="being" />
            <token id="34" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="12" string="death among blacks" type="NP">
          <tokens>
            <token id="44" string="death" />
            <token id="45" string="among" />
            <token id="46" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="13" string="Democrat George McGovern in 1972" type="NP">
          <tokens>
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
            <token id="12" string="in" />
            <token id="13" string="1972" />
          </tokens>
        </chunking>
        <chunking id="14" string="regarded as `` a fate ... worse than death among blacks" type="VP">
          <tokens>
            <token id="36" string="regarded" />
            <token id="37" string="as" />
            <token id="38" string="&quot;" />
            <token id="39" string="a" />
            <token id="40" string="fate" />
            <token id="41" string=". . ." />
            <token id="42" string="worse" />
            <token id="43" string="than" />
            <token id="44" string="death" />
            <token id="45" string="among" />
            <token id="46" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="15" string="death" type="NP">
          <tokens>
            <token id="44" string="death" />
          </tokens>
        </chunking>
        <chunking id="16" string="for Democrat George McGovern in 1972 was a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="SBAR">
          <tokens>
            <token id="8" string="for" />
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
            <token id="12" string="in" />
            <token id="13" string="1972" />
            <token id="14" string="was" />
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="17" string="Republican" type="NP">
          <tokens>
            <token id="34" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="18" string="a 24-year-old black law student and one-time campus agitator" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
          </tokens>
        </chunking>
        <chunking id="19" string="blacks" type="NP">
          <tokens>
            <token id="46" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="20" string="who voted for Democrat George McGovern in 1972 was a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="voted" />
            <token id="8" string="for" />
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
            <token id="12" string="in" />
            <token id="13" string="1972" />
            <token id="14" string="was" />
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="21" string="explained" type="VP">
          <tokens>
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="22" string="Democrat George McGovern" type="NP">
          <tokens>
            <token id="9" string="Democrat" />
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
          </tokens>
        </chunking>
        <chunking id="23" string="was a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="24" string="1972" type="NP">
          <tokens>
            <token id="13" string="1972" />
          </tokens>
        </chunking>
        <chunking id="25" string="a 24-year-old black law student and one-time campus agitator named Clarence Thomas. ; As Thomas later explained" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="24-year-old" />
            <token id="17" string="black" />
            <token id="18" string="law" />
            <token id="19" string="student" />
            <token id="20" string="and" />
            <token id="21" string="one-time" />
            <token id="22" string="campus" />
            <token id="23" string="agitator" />
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
        <chunking id="26" string="was regarded as `` a fate ... worse than death among blacks" type="VP">
          <tokens>
            <token id="35" string="was" />
            <token id="36" string="regarded" />
            <token id="37" string="as" />
            <token id="38" string="&quot;" />
            <token id="39" string="a" />
            <token id="40" string="fate" />
            <token id="41" string=". . ." />
            <token id="42" string="worse" />
            <token id="43" string="than" />
            <token id="44" string="death" />
            <token id="45" string="among" />
            <token id="46" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="27" string="named Clarence Thomas. ; As Thomas later explained" type="VP">
          <tokens>
            <token id="24" string="named" />
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
            <token id="27" string=";" />
            <token id="28" string="As" />
            <token id="29" string="Thomas" />
            <token id="30" string="later" />
            <token id="31" string="explained" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">Americans</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Americans</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">29</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">Americans</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">regarded</governor>
          <dependent id="5">Americans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">voted</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Americans</governor>
          <dependent id="7">voted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">student</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">McGovern</governor>
          <dependent id="9">Democrat</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">McGovern</governor>
          <dependent id="10">George</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">student</governor>
          <dependent id="11">McGovern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1972</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">McGovern</governor>
          <dependent id="13">1972</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">student</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">student</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">student</governor>
          <dependent id="16">24-year-old</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">student</governor>
          <dependent id="17">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">student</governor>
          <dependent id="18">law</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">voted</governor>
          <dependent id="19">student</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">student</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">agitator</governor>
          <dependent id="21">one-time</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">agitator</governor>
          <dependent id="22">campus</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">student</governor>
          <dependent id="23">agitator</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">student</governor>
          <dependent id="24">named</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Thomas.</governor>
          <dependent id="25">Clarence</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">named</governor>
          <dependent id="26">Thomas.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Thomas</governor>
          <dependent id="28">As</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">explained</governor>
          <dependent id="29">Thomas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">explained</governor>
          <dependent id="30">later</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">Thomas.</governor>
          <dependent id="31">explained</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">Republican</governor>
          <dependent id="33">being</dependent>
        </dependency>
        <dependency type="csubjpass">
          <governor id="36">regarded</governor>
          <dependent id="34">Republican</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="36">regarded</governor>
          <dependent id="35">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="36">regarded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">fate</governor>
          <dependent id="37">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">fate</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">regarded</governor>
          <dependent id="40">fate</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="40">fate</governor>
          <dependent id="42">worse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">death</governor>
          <dependent id="43">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">regarded</governor>
          <dependent id="44">death</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">blacks</governor>
          <dependent id="45">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">death</governor>
          <dependent id="46">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="29 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="29" />
            <token id="4" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="24-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="24-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Democrat" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Democrat" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence Thomas." type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Clarence" />
            <token id="26" string="Thomas." />
          </tokens>
        </entity>
        <entity id="5" string="1972" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1972" />
          </tokens>
        </entity>
        <entity id="6" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Americans" />
          </tokens>
        </entity>
        <entity id="7" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Thomas" />
          </tokens>
        </entity>
        <entity id="8" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="34" string="Republican" />
          </tokens>
        </entity>
        <entity id="9" string="George McGovern" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="George" />
            <token id="11" string="McGovern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Yet in a matter of weeks, Thomas goes before the Senate Judiciary Committee as President Bush&amp;apost;s nominee to join the increasingly conservative Supreme Court.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Judiciary" lemma="Judiciary" stem="judiciari" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="17" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="join" lemma="join" stem="join" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="increasingly" lemma="increasingly" stem="increasingli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="25" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Yet) (PP (IN in) (NP (NP (DT a) (NN matter)) (PP (IN of) (NP (NNS weeks))))) (, ,) (NP (NNP Thomas)) (VP (VBZ goes) (PP (IN before) (NP (DT the) (NNP Senate) (NNP Judiciary) (NNP Committee))) (PP (IN as) (NP (NP (NNP President) (NNP Bush) (POS 's)) (NN nominee) (S (VP (TO to) (VP (VB join) (NP (DT the) (ADJP (RB increasingly) (JJ conservative)) (NP (NNP Supreme) (NNP Court))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Supreme Court" type="NP">
          <tokens>
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="2" string="weeks" type="NP">
          <tokens>
            <token id="6" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="increasingly conservative" type="ADJP">
          <tokens>
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="4" string="to join the increasingly conservative Supreme Court" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="join" />
            <token id="22" string="the" />
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="join the increasingly conservative Supreme Court" type="VP">
          <tokens>
            <token id="21" string="join" />
            <token id="22" string="the" />
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="Judiciary" />
            <token id="14" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="8" string="a matter of weeks" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="matter" />
            <token id="5" string="of" />
            <token id="6" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="9" string="President Bush 's nominee to join the increasingly conservative Supreme Court" type="NP">
          <tokens>
            <token id="16" string="President" />
            <token id="17" string="Bush" />
            <token id="18" string="'s" />
            <token id="19" string="nominee" />
            <token id="20" string="to" />
            <token id="21" string="join" />
            <token id="22" string="the" />
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="10" string="President Bush 's" type="NP">
          <tokens>
            <token id="16" string="President" />
            <token id="17" string="Bush" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="goes before the Senate Judiciary Committee as President Bush 's nominee to join the increasingly conservative Supreme Court" type="VP">
          <tokens>
            <token id="9" string="goes" />
            <token id="10" string="before" />
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="Judiciary" />
            <token id="14" string="Committee" />
            <token id="15" string="as" />
            <token id="16" string="President" />
            <token id="17" string="Bush" />
            <token id="18" string="'s" />
            <token id="19" string="nominee" />
            <token id="20" string="to" />
            <token id="21" string="join" />
            <token id="22" string="the" />
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
        <chunking id="12" string="a matter" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="matter" />
          </tokens>
        </chunking>
        <chunking id="13" string="the increasingly conservative Supreme Court" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="increasingly" />
            <token id="24" string="conservative" />
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">goes</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">matter</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">matter</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">goes</governor>
          <dependent id="4">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">weeks</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">matter</governor>
          <dependent id="6">weeks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">goes</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">goes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Committee</governor>
          <dependent id="10">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Committee</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Committee</governor>
          <dependent id="12">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Committee</governor>
          <dependent id="13">Judiciary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">goes</governor>
          <dependent id="14">Committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">nominee</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Bush</governor>
          <dependent id="16">President</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">nominee</governor>
          <dependent id="17">Bush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Bush</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">goes</governor>
          <dependent id="19">nominee</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">join</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">nominee</governor>
          <dependent id="21">join</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Court</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">conservative</governor>
          <dependent id="23">increasingly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">Court</governor>
          <dependent id="24">conservative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Court</governor>
          <dependent id="25">Supreme</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">join</governor>
          <dependent id="26">Court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Supreme" />
            <token id="26" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="weeks" />
          </tokens>
        </entity>
        <entity id="3" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="24" string="conservative" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Senate Judiciary Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Senate" />
            <token id="13" string="Judiciary" />
            <token id="14" string="Committee" />
          </tokens>
        </entity>
        <entity id="6" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Bush" />
          </tokens>
        </entity>
        <entity id="7" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="16" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Thomas&amp;apost; dramatic political and philosophical transformation reveals more about the man than does his Horatio Alger journey from rural Southern poverty to Supreme Court nomination.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="dramatic" lemma="dramatic" stem="dramat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="philosophical" lemma="philosophical" stem="philosoph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="transformation" lemma="transformation" stem="transform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="reveals" lemma="reveal" stem="reveal" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Horatio" lemma="Horatio" stem="horatio" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Alger" lemma="Alger" stem="alger" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="journey" lemma="journey" stem="journei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rural" lemma="rural" stem="rural" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="22" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="25" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas) (POS ')) (JJ dramatic) (ADJP (JJ political) (CC and) (JJ philosophical)) (NN transformation)) (VP (VBZ reveals) (ADVP (RBR more) (PP (IN about) (NP (DT the) (NN man)))) (SBAR (IN than) (S (VP (VBZ does) (NP (NP (PRP$ his) (NNP Horatio) (NNP Alger) (NN journey)) (PP (IN from) (NP (JJ rural) (NNP Southern) (NN poverty)))) (PP (TO to) (NP (NNP Supreme) (NNP Court) (NN nomination))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="political and philosophical" type="ADJP">
          <tokens>
            <token id="4" string="political" />
            <token id="5" string="and" />
            <token id="6" string="philosophical" />
          </tokens>
        </chunking>
        <chunking id="2" string="the man" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="man" />
          </tokens>
        </chunking>
        <chunking id="3" string="rural Southern poverty" type="NP">
          <tokens>
            <token id="20" string="rural" />
            <token id="21" string="Southern" />
            <token id="22" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="4" string="than does his Horatio Alger journey from rural Southern poverty to Supreme Court nomination" type="SBAR">
          <tokens>
            <token id="13" string="than" />
            <token id="14" string="does" />
            <token id="15" string="his" />
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
            <token id="18" string="journey" />
            <token id="19" string="from" />
            <token id="20" string="rural" />
            <token id="21" string="Southern" />
            <token id="22" string="poverty" />
            <token id="23" string="to" />
            <token id="24" string="Supreme" />
            <token id="25" string="Court" />
            <token id="26" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="5" string="his Horatio Alger journey" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
            <token id="18" string="journey" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas ' dramatic political and philosophical transformation" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="'" />
            <token id="3" string="dramatic" />
            <token id="4" string="political" />
            <token id="5" string="and" />
            <token id="6" string="philosophical" />
            <token id="7" string="transformation" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas '" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="does his Horatio Alger journey from rural Southern poverty to Supreme Court nomination" type="VP">
          <tokens>
            <token id="14" string="does" />
            <token id="15" string="his" />
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
            <token id="18" string="journey" />
            <token id="19" string="from" />
            <token id="20" string="rural" />
            <token id="21" string="Southern" />
            <token id="22" string="poverty" />
            <token id="23" string="to" />
            <token id="24" string="Supreme" />
            <token id="25" string="Court" />
            <token id="26" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="9" string="reveals more about the man than does his Horatio Alger journey from rural Southern poverty to Supreme Court nomination" type="VP">
          <tokens>
            <token id="8" string="reveals" />
            <token id="9" string="more" />
            <token id="10" string="about" />
            <token id="11" string="the" />
            <token id="12" string="man" />
            <token id="13" string="than" />
            <token id="14" string="does" />
            <token id="15" string="his" />
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
            <token id="18" string="journey" />
            <token id="19" string="from" />
            <token id="20" string="rural" />
            <token id="21" string="Southern" />
            <token id="22" string="poverty" />
            <token id="23" string="to" />
            <token id="24" string="Supreme" />
            <token id="25" string="Court" />
            <token id="26" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="10" string="his Horatio Alger journey from rural Southern poverty" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
            <token id="18" string="journey" />
            <token id="19" string="from" />
            <token id="20" string="rural" />
            <token id="21" string="Southern" />
            <token id="22" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="11" string="Supreme Court nomination" type="NP">
          <tokens>
            <token id="24" string="Supreme" />
            <token id="25" string="Court" />
            <token id="26" string="nomination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="7">transformation</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Thomas</governor>
          <dependent id="2">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">transformation</governor>
          <dependent id="3">dramatic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">transformation</governor>
          <dependent id="4">political</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">political</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">political</governor>
          <dependent id="6">philosophical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">reveals</governor>
          <dependent id="7">transformation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">reveals</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">reveals</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">man</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">man</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">more</governor>
          <dependent id="12">man</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">does</governor>
          <dependent id="13">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">reveals</governor>
          <dependent id="14">does</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">journey</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">journey</governor>
          <dependent id="16">Horatio</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">journey</governor>
          <dependent id="17">Alger</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">does</governor>
          <dependent id="18">journey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">poverty</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">poverty</governor>
          <dependent id="20">rural</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">poverty</governor>
          <dependent id="21">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">journey</governor>
          <dependent id="22">poverty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">nomination</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">nomination</governor>
          <dependent id="24">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">nomination</governor>
          <dependent id="25">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">does</governor>
          <dependent id="26">nomination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Supreme" />
            <token id="25" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Horatio Alger" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Horatio" />
            <token id="17" string="Alger" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Southern" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="Southern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>To friends, his is a story of courage, to foes, a story of opportunism.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="courage" lemma="courage" stem="courag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="foes" lemma="foe" stem="foe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="opportunism" lemma="opportunism" stem="opportun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (TO To) (NP (NNS friends))) (, ,) (NP (PRP$ his)) (VP (VBZ is) (NP (NP (DT a) (NN story)) (PP (IN of) (NP (NN courage)))) (, ,) (PP (TO to) (NP (NP (NNS foes)) (, ,) (NP (NP (DT a) (NN story)) (PP (IN of) (NP (NN opportunism))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his" type="NP">
          <tokens>
            <token id="4" string="his" />
          </tokens>
        </chunking>
        <chunking id="2" string="a story of courage" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="story" />
            <token id="8" string="of" />
            <token id="9" string="courage" />
          </tokens>
        </chunking>
        <chunking id="3" string="foes" type="NP">
          <tokens>
            <token id="12" string="foes" />
          </tokens>
        </chunking>
        <chunking id="4" string="a story" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="story" />
          </tokens>
        </chunking>
        <chunking id="5" string="courage" type="NP">
          <tokens>
            <token id="9" string="courage" />
          </tokens>
        </chunking>
        <chunking id="6" string="a story of opportunism" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="opportunism" />
          </tokens>
        </chunking>
        <chunking id="7" string="opportunism" type="NP">
          <tokens>
            <token id="17" string="opportunism" />
          </tokens>
        </chunking>
        <chunking id="8" string="friends" type="NP">
          <tokens>
            <token id="2" string="friends" />
          </tokens>
        </chunking>
        <chunking id="9" string="is a story of courage , to foes , a story of opportunism" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="a" />
            <token id="7" string="story" />
            <token id="8" string="of" />
            <token id="9" string="courage" />
            <token id="10" string="," />
            <token id="11" string="to" />
            <token id="12" string="foes" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="opportunism" />
          </tokens>
        </chunking>
        <chunking id="10" string="foes , a story of opportunism" type="NP">
          <tokens>
            <token id="12" string="foes" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="opportunism" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">friends</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">story</governor>
          <dependent id="2">friends</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">story</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">story</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">story</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">courage</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">story</governor>
          <dependent id="9">courage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">foes</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">story</governor>
          <dependent id="12">foes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">story</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">foes</governor>
          <dependent id="15">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">opportunism</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">story</governor>
          <dependent id="17">opportunism</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Racial anger, protest lyrics; The homespun homilies of his grandfather, the ruler-slapping discipline of the nuns who taught him at a Catholic school in segregated Savannah, Ga., the racial anger in the writings of Richard Wright and Malcolm X, the iconoclastic theories of such academicians as Thomas Sowell and William Barclay Allen, even the protest lyrics of singer-songwriter Nina Simone -- all are parts of the story.</content>
      <tokens>
        <token id="1" string="Racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="anger" lemma="anger" stem="anger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="protest" lemma="protest" stem="protest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="lyrics" lemma="lyric" stem="lyric" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="homespun" lemma="homespun" stem="homespun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="homilies" lemma="homily" stem="homili" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="ruler-slapping" lemma="ruler-slapping" stem="ruler-slap" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="nuns" lemma="nun" stem="nun" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="taught" lemma="teach" stem="taught" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Catholic" lemma="catholic" stem="cathol" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="26" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="segregated" lemma="segregate" stem="segreg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Ga." lemma="Ga." stem="ga." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="anger" lemma="anger" stem="anger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="writings" lemma="writings" stem="write" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string="Wright" lemma="Wright" stem="wright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Malcolm" lemma="Malcolm" stem="malcolm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="44" string="X" lemma="x" stem="x" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="iconoclastic" lemma="iconoclastic" stem="iconoclast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="theories" lemma="theory" stem="theori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="academicians" lemma="academician" stem="academician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="54" string="Sowell" lemma="Sowell" stem="sowel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="55" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="57" string="Barclay" lemma="Barclay" stem="barclai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="58" string="Allen" lemma="Allen" stem="allen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="59" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="protest" lemma="protest" stem="protest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="lyrics" lemma="lyric" stem="lyric" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="singer-songwriter" lemma="singer-songwriter" stem="singer-songwrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="Nina" lemma="Nina" stem="nina" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="67" string="Simone" lemma="Simone" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="68" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="70" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="72" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="74" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="75" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (JJ Racial) (NN anger)) (, ,) (NP (NN protest) (NNS lyrics)) (: ;) (NP (NP (DT The) (JJ homespun) (NNS homilies)) (PP (IN of) (NP (PRP$ his) (NN grandfather)))) (, ,) (NP (NP (NP (DT the) (JJ ruler-slapping) (NN discipline)) (PP (IN of) (NP (DT the) (NNS nuns))) (SBAR (WHNP (WP who)) (S (VP (VBD taught) (NP (PRP him)) (PP (IN at) (NP (NP (DT a) (JJ Catholic) (NN school)) (PP (IN in) (NP (VBN segregated) (NNP Savannah))))))))) (, ,) (NP (NNP Ga.)) (, ,) (NP (NP (DT the) (JJ racial) (NN anger)) (PP (IN in) (NP (NP (DT the) (NNS writings)) (PP (IN of) (NP (NP (NNP Richard) (NNP Wright)) (CC and) (NP (NNP Malcolm) (NN X))))))) (, ,) (NP (NP (DT the) (JJ iconoclastic) (NNS theories)) (PP (IN of) (NP (NP (JJ such) (NNS academicians)) (PP (IN as) (NP (NNP Thomas) (NNP Sowell)))))) (CC and) (NP (NP (NNP William) (NNP Barclay) (NNP Allen)) (, ,) (RB even) (NP (NP (NP (DT the) (NN protest) (NNS lyrics)) (PP (IN of) (NP (NN singer-songwriter) (NNP Nina) (NNP Simone)))) (PRN (: --) (S (NP (DT all)) (VP (VBP are) (NP (NP (NNS parts)) (PP (IN of) (NP (DT the) (NN story)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="69" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="the writings of Richard Wright and Malcolm X" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="writings" />
            <token id="39" string="of" />
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
            <token id="42" string="and" />
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
          </tokens>
        </chunking>
        <chunking id="3" string="the iconoclastic theories of such academicians as Thomas Sowell" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="iconoclastic" />
            <token id="48" string="theories" />
            <token id="49" string="of" />
            <token id="50" string="such" />
            <token id="51" string="academicians" />
            <token id="52" string="as" />
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
          </tokens>
        </chunking>
        <chunking id="4" string="Richard Wright and Malcolm X" type="NP">
          <tokens>
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
            <token id="42" string="and" />
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
          </tokens>
        </chunking>
        <chunking id="5" string="parts of the story" type="NP">
          <tokens>
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="6" string="the iconoclastic theories" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="iconoclastic" />
            <token id="48" string="theories" />
          </tokens>
        </chunking>
        <chunking id="7" string="who taught him at a Catholic school in segregated Savannah" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="taught" />
            <token id="22" string="him" />
            <token id="23" string="at" />
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="8" string="a Catholic school in segregated Savannah" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="9" string="Racial anger , protest lyrics ; The homespun homilies of his grandfather , the ruler-slapping discipline of the nuns who taught him at a Catholic school in segregated Savannah , Ga. , the racial anger in the writings of Richard Wright and Malcolm X , the iconoclastic theories of such academicians as Thomas Sowell and William Barclay Allen , even the protest lyrics of singer-songwriter Nina Simone -- all are parts of the story ." type="NP">
          <tokens>
            <token id="1" string="Racial" />
            <token id="2" string="anger" />
            <token id="3" string="," />
            <token id="4" string="protest" />
            <token id="5" string="lyrics" />
            <token id="6" string=";" />
            <token id="7" string="The" />
            <token id="8" string="homespun" />
            <token id="9" string="homilies" />
            <token id="10" string="of" />
            <token id="11" string="his" />
            <token id="12" string="grandfather" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="ruler-slapping" />
            <token id="16" string="discipline" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="nuns" />
            <token id="20" string="who" />
            <token id="21" string="taught" />
            <token id="22" string="him" />
            <token id="23" string="at" />
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
            <token id="30" string="," />
            <token id="31" string="Ga." />
            <token id="32" string="," />
            <token id="33" string="the" />
            <token id="34" string="racial" />
            <token id="35" string="anger" />
            <token id="36" string="in" />
            <token id="37" string="the" />
            <token id="38" string="writings" />
            <token id="39" string="of" />
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
            <token id="42" string="and" />
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="iconoclastic" />
            <token id="48" string="theories" />
            <token id="49" string="of" />
            <token id="50" string="such" />
            <token id="51" string="academicians" />
            <token id="52" string="as" />
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
            <token id="55" string="and" />
            <token id="56" string="William" />
            <token id="57" string="Barclay" />
            <token id="58" string="Allen" />
            <token id="59" string="," />
            <token id="60" string="even" />
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
            <token id="64" string="of" />
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
            <token id="68" string="--" />
            <token id="69" string="all" />
            <token id="70" string="are" />
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
            <token id="75" string="." />
          </tokens>
        </chunking>
        <chunking id="10" string="the protest lyrics of singer-songwriter Nina Simone" type="NP">
          <tokens>
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
            <token id="64" string="of" />
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
          </tokens>
        </chunking>
        <chunking id="11" string="Thomas Sowell" type="NP">
          <tokens>
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
          </tokens>
        </chunking>
        <chunking id="12" string="the protest lyrics of singer-songwriter Nina Simone -- all are parts of the story" type="NP">
          <tokens>
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
            <token id="64" string="of" />
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
            <token id="68" string="--" />
            <token id="69" string="all" />
            <token id="70" string="are" />
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="13" string="singer-songwriter Nina Simone" type="NP">
          <tokens>
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ga." type="NP">
          <tokens>
            <token id="31" string="Ga." />
          </tokens>
        </chunking>
        <chunking id="15" string="the story" type="NP">
          <tokens>
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="16" string="The homespun homilies" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="homespun" />
            <token id="9" string="homilies" />
          </tokens>
        </chunking>
        <chunking id="17" string="William Barclay Allen" type="NP">
          <tokens>
            <token id="56" string="William" />
            <token id="57" string="Barclay" />
            <token id="58" string="Allen" />
          </tokens>
        </chunking>
        <chunking id="18" string="the nuns" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="19" string="segregated Savannah" type="NP">
          <tokens>
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="20" string="the ruler-slapping discipline of the nuns who taught him at a Catholic school in segregated Savannah , Ga. , the racial anger in the writings of Richard Wright and Malcolm X , the iconoclastic theories of such academicians as Thomas Sowell and William Barclay Allen , even the protest lyrics of singer-songwriter Nina Simone -- all are parts of the story" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="ruler-slapping" />
            <token id="16" string="discipline" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="nuns" />
            <token id="20" string="who" />
            <token id="21" string="taught" />
            <token id="22" string="him" />
            <token id="23" string="at" />
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
            <token id="30" string="," />
            <token id="31" string="Ga." />
            <token id="32" string="," />
            <token id="33" string="the" />
            <token id="34" string="racial" />
            <token id="35" string="anger" />
            <token id="36" string="in" />
            <token id="37" string="the" />
            <token id="38" string="writings" />
            <token id="39" string="of" />
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
            <token id="42" string="and" />
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="iconoclastic" />
            <token id="48" string="theories" />
            <token id="49" string="of" />
            <token id="50" string="such" />
            <token id="51" string="academicians" />
            <token id="52" string="as" />
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
            <token id="55" string="and" />
            <token id="56" string="William" />
            <token id="57" string="Barclay" />
            <token id="58" string="Allen" />
            <token id="59" string="," />
            <token id="60" string="even" />
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
            <token id="64" string="of" />
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
            <token id="68" string="--" />
            <token id="69" string="all" />
            <token id="70" string="are" />
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="21" string="the ruler-slapping discipline" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="ruler-slapping" />
            <token id="16" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="22" string="the racial anger in the writings of Richard Wright and Malcolm X" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="racial" />
            <token id="35" string="anger" />
            <token id="36" string="in" />
            <token id="37" string="the" />
            <token id="38" string="writings" />
            <token id="39" string="of" />
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
            <token id="42" string="and" />
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
          </tokens>
        </chunking>
        <chunking id="23" string="his grandfather" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="24" string="the racial anger" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="racial" />
            <token id="35" string="anger" />
          </tokens>
        </chunking>
        <chunking id="25" string="a Catholic school" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
          </tokens>
        </chunking>
        <chunking id="26" string="are parts of the story" type="VP">
          <tokens>
            <token id="70" string="are" />
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="27" string="The homespun homilies of his grandfather" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="homespun" />
            <token id="9" string="homilies" />
            <token id="10" string="of" />
            <token id="11" string="his" />
            <token id="12" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="28" string="the writings" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="writings" />
          </tokens>
        </chunking>
        <chunking id="29" string="parts" type="NP">
          <tokens>
            <token id="71" string="parts" />
          </tokens>
        </chunking>
        <chunking id="30" string="him" type="NP">
          <tokens>
            <token id="22" string="him" />
          </tokens>
        </chunking>
        <chunking id="31" string="protest lyrics" type="NP">
          <tokens>
            <token id="4" string="protest" />
            <token id="5" string="lyrics" />
          </tokens>
        </chunking>
        <chunking id="32" string="such academicians" type="NP">
          <tokens>
            <token id="50" string="such" />
            <token id="51" string="academicians" />
          </tokens>
        </chunking>
        <chunking id="33" string="taught him at a Catholic school in segregated Savannah" type="VP">
          <tokens>
            <token id="21" string="taught" />
            <token id="22" string="him" />
            <token id="23" string="at" />
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="34" string="the protest lyrics" type="NP">
          <tokens>
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
          </tokens>
        </chunking>
        <chunking id="35" string="such academicians as Thomas Sowell" type="NP">
          <tokens>
            <token id="50" string="such" />
            <token id="51" string="academicians" />
            <token id="52" string="as" />
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
          </tokens>
        </chunking>
        <chunking id="36" string="Richard Wright" type="NP">
          <tokens>
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
          </tokens>
        </chunking>
        <chunking id="37" string="Racial anger" type="NP">
          <tokens>
            <token id="1" string="Racial" />
            <token id="2" string="anger" />
          </tokens>
        </chunking>
        <chunking id="38" string="Malcolm X" type="NP">
          <tokens>
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
          </tokens>
        </chunking>
        <chunking id="39" string="William Barclay Allen , even the protest lyrics of singer-songwriter Nina Simone -- all are parts of the story" type="NP">
          <tokens>
            <token id="56" string="William" />
            <token id="57" string="Barclay" />
            <token id="58" string="Allen" />
            <token id="59" string="," />
            <token id="60" string="even" />
            <token id="61" string="the" />
            <token id="62" string="protest" />
            <token id="63" string="lyrics" />
            <token id="64" string="of" />
            <token id="65" string="singer-songwriter" />
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
            <token id="68" string="--" />
            <token id="69" string="all" />
            <token id="70" string="are" />
            <token id="71" string="parts" />
            <token id="72" string="of" />
            <token id="73" string="the" />
            <token id="74" string="story" />
          </tokens>
        </chunking>
        <chunking id="40" string="the ruler-slapping discipline of the nuns who taught him at a Catholic school in segregated Savannah" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="ruler-slapping" />
            <token id="16" string="discipline" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="nuns" />
            <token id="20" string="who" />
            <token id="21" string="taught" />
            <token id="22" string="him" />
            <token id="23" string="at" />
            <token id="24" string="a" />
            <token id="25" string="Catholic" />
            <token id="26" string="school" />
            <token id="27" string="in" />
            <token id="28" string="segregated" />
            <token id="29" string="Savannah" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">anger</governor>
          <dependent id="1">Racial</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">anger</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">lyrics</governor>
          <dependent id="4">protest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">anger</governor>
          <dependent id="5">lyrics</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">homilies</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">homilies</governor>
          <dependent id="8">homespun</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">anger</governor>
          <dependent id="9">homilies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">grandfather</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">grandfather</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">homilies</governor>
          <dependent id="12">grandfather</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">discipline</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">discipline</governor>
          <dependent id="15">ruler-slapping</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">anger</governor>
          <dependent id="16">discipline</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">nuns</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">nuns</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">discipline</governor>
          <dependent id="19">nuns</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">taught</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">discipline</governor>
          <dependent id="21">taught</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">taught</governor>
          <dependent id="22">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">school</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">school</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">school</governor>
          <dependent id="25">Catholic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">taught</governor>
          <dependent id="26">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Savannah</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">Savannah</governor>
          <dependent id="28">segregated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">school</governor>
          <dependent id="29">Savannah</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">discipline</governor>
          <dependent id="31">Ga.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">anger</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">anger</governor>
          <dependent id="34">racial</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">discipline</governor>
          <dependent id="35">anger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">writings</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">writings</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">anger</governor>
          <dependent id="38">writings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Wright</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Wright</governor>
          <dependent id="40">Richard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">writings</governor>
          <dependent id="41">Wright</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">Wright</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">X</governor>
          <dependent id="43">Malcolm</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">Wright</governor>
          <dependent id="44">X</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">theories</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">theories</governor>
          <dependent id="47">iconoclastic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">discipline</governor>
          <dependent id="48">theories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">academicians</governor>
          <dependent id="49">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">academicians</governor>
          <dependent id="50">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">theories</governor>
          <dependent id="51">academicians</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">Sowell</governor>
          <dependent id="52">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="54">Sowell</governor>
          <dependent id="53">Thomas</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">academicians</governor>
          <dependent id="54">Sowell</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">discipline</governor>
          <dependent id="55">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="58">Allen</governor>
          <dependent id="56">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="58">Allen</governor>
          <dependent id="57">Barclay</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">discipline</governor>
          <dependent id="58">Allen</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="58">Allen</governor>
          <dependent id="60">even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="63">lyrics</governor>
          <dependent id="61">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="63">lyrics</governor>
          <dependent id="62">protest</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="58">Allen</governor>
          <dependent id="63">lyrics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="67">Simone</governor>
          <dependent id="64">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">Simone</governor>
          <dependent id="65">singer-songwriter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">Simone</governor>
          <dependent id="66">Nina</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="63">lyrics</governor>
          <dependent id="67">Simone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="71">parts</governor>
          <dependent id="69">all</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="71">parts</governor>
          <dependent id="70">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="63">lyrics</governor>
          <dependent id="71">parts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="74">story</governor>
          <dependent id="72">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="74">story</governor>
          <dependent id="73">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="71">parts</governor>
          <dependent id="74">story</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Catholic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="25" string="Catholic" />
          </tokens>
        </entity>
        <entity id="2" string="Ga." type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Ga." />
          </tokens>
        </entity>
        <entity id="3" string="Richard Wright" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Richard" />
            <token id="41" string="Wright" />
          </tokens>
        </entity>
        <entity id="4" string="William Barclay Allen" type="PERSON" score="0.0">
          <tokens>
            <token id="56" string="William" />
            <token id="57" string="Barclay" />
            <token id="58" string="Allen" />
          </tokens>
        </entity>
        <entity id="5" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Savannah" />
          </tokens>
        </entity>
        <entity id="6" string="Malcolm X" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Malcolm" />
            <token id="44" string="X" />
          </tokens>
        </entity>
        <entity id="7" string="Nina Simone" type="PERSON" score="0.0">
          <tokens>
            <token id="66" string="Nina" />
            <token id="67" string="Simone" />
          </tokens>
        </entity>
        <entity id="8" string="Thomas Sowell" type="PERSON" score="0.0">
          <tokens>
            <token id="53" string="Thomas" />
            <token id="54" string="Sowell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>As glimpsed in dozens of interviews and tens of thousands of pages of documents that Thomas has turned over to the Senate Judiciary Committee, these influences helped shape a set of beliefs that are now the subject of bitter controversy.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="glimpsed" lemma="glimpse" stem="glimps" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="dozens" lemma="dozen" stem="dozen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="tens" lemma="ten" stem="ten" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="documents" lemma="document" stem="document" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="23" string="Judiciary" lemma="Judiciary" stem="judiciari" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="24" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="influences" lemma="influence" stem="influenc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="shape" lemma="shape" stem="shape" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="set" lemma="set" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="beliefs" lemma="belief" stem="belief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="bitter" lemma="bitter" stem="bitter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (VP (VBN glimpsed) (PP (IN in) (NP (NP (NP (NNS dozens)) (PP (IN of) (NP (NNS interviews)))) (CC and) (NP (NP (QP (NNS tens) (IN of) (NNS thousands))) (PP (IN of) (NP (NP (NNS pages)) (PP (IN of) (NP (NP (NNS documents)) (SBAR (IN that) (S (NP (NNP Thomas)) (VP (VBZ has) (VP (VBN turned) (PRT (RP over)) (PP (TO to) (NP (DT the) (NNP Senate) (NNP Judiciary) (NNP Committee))))))))))))))))) (, ,) (NP (DT these) (NNS influences)) (VP (VBD helped) (VP (VB shape) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNS beliefs)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADVP (RB now)) (NP (NP (DT the) (NN subject)) (PP (IN of) (NP (JJ bitter) (NN controversy)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="documents that Thomas has turned over to the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="2" string="bitter controversy" type="NP">
          <tokens>
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="dozens of interviews and tens of thousands of pages of documents that Thomas has turned over to the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="4" string="dozens" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
            <token id="7" string="and" />
            <token id="8" string="tens" />
            <token id="9" string="of" />
            <token id="10" string="thousands" />
            <token id="11" string="of" />
            <token id="12" string="pages" />
            <token id="13" string="of" />
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="5" string="that Thomas has turned over to the Senate Judiciary Committee" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="6" string="are now the subject of bitter controversy" type="VP">
          <tokens>
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="7" string="tens of thousands" type="NP">
          <tokens>
            <token id="8" string="tens" />
            <token id="9" string="of" />
            <token id="10" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="9" string="helped shape a set of beliefs that are now the subject of bitter controversy" type="VP">
          <tokens>
            <token id="28" string="helped" />
            <token id="29" string="shape" />
            <token id="30" string="a" />
            <token id="31" string="set" />
            <token id="32" string="of" />
            <token id="33" string="beliefs" />
            <token id="34" string="that" />
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="10" string="has turned over to the Senate Judiciary Committee" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="11" string="beliefs that are now the subject of bitter controversy" type="NP">
          <tokens>
            <token id="33" string="beliefs" />
            <token id="34" string="that" />
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="12" string="tens of thousands of pages of documents that Thomas has turned over to the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="8" string="tens" />
            <token id="9" string="of" />
            <token id="10" string="thousands" />
            <token id="11" string="of" />
            <token id="12" string="pages" />
            <token id="13" string="of" />
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="13" string="beliefs" type="NP">
          <tokens>
            <token id="33" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="14" string="dozens of interviews" type="NP">
          <tokens>
            <token id="4" string="dozens" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="15" string="turned over to the Senate Judiciary Committee" type="VP">
          <tokens>
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="16" string="As glimpsed in dozens of interviews and tens of thousands of pages of documents that Thomas has turned over to the Senate Judiciary Committee" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="glimpsed" />
            <token id="3" string="in" />
            <token id="4" string="dozens" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
            <token id="7" string="and" />
            <token id="8" string="tens" />
            <token id="9" string="of" />
            <token id="10" string="thousands" />
            <token id="11" string="of" />
            <token id="12" string="pages" />
            <token id="13" string="of" />
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="17" string="that are now the subject of bitter controversy" type="SBAR">
          <tokens>
            <token id="34" string="that" />
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="18" string="the subject" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="subject" />
          </tokens>
        </chunking>
        <chunking id="19" string="shape a set of beliefs that are now the subject of bitter controversy" type="VP">
          <tokens>
            <token id="29" string="shape" />
            <token id="30" string="a" />
            <token id="31" string="set" />
            <token id="32" string="of" />
            <token id="33" string="beliefs" />
            <token id="34" string="that" />
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="20" string="dozens" type="NP">
          <tokens>
            <token id="4" string="dozens" />
          </tokens>
        </chunking>
        <chunking id="21" string="pages of documents that Thomas has turned over to the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="12" string="pages" />
            <token id="13" string="of" />
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="22" string="a set" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="set" />
          </tokens>
        </chunking>
        <chunking id="23" string="the subject of bitter controversy" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="24" string="documents" type="NP">
          <tokens>
            <token id="14" string="documents" />
          </tokens>
        </chunking>
        <chunking id="25" string="interviews" type="NP">
          <tokens>
            <token id="6" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="26" string="glimpsed in dozens of interviews and tens of thousands of pages of documents that Thomas has turned over to the Senate Judiciary Committee" type="VP">
          <tokens>
            <token id="2" string="glimpsed" />
            <token id="3" string="in" />
            <token id="4" string="dozens" />
            <token id="5" string="of" />
            <token id="6" string="interviews" />
            <token id="7" string="and" />
            <token id="8" string="tens" />
            <token id="9" string="of" />
            <token id="10" string="thousands" />
            <token id="11" string="of" />
            <token id="12" string="pages" />
            <token id="13" string="of" />
            <token id="14" string="documents" />
            <token id="15" string="that" />
            <token id="16" string="Thomas" />
            <token id="17" string="has" />
            <token id="18" string="turned" />
            <token id="19" string="over" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="27" string="pages" type="NP">
          <tokens>
            <token id="12" string="pages" />
          </tokens>
        </chunking>
        <chunking id="28" string="these influences" type="NP">
          <tokens>
            <token id="26" string="these" />
            <token id="27" string="influences" />
          </tokens>
        </chunking>
        <chunking id="29" string="a set of beliefs that are now the subject of bitter controversy" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="set" />
            <token id="32" string="of" />
            <token id="33" string="beliefs" />
            <token id="34" string="that" />
            <token id="35" string="are" />
            <token id="36" string="now" />
            <token id="37" string="the" />
            <token id="38" string="subject" />
            <token id="39" string="of" />
            <token id="40" string="bitter" />
            <token id="41" string="controversy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">glimpsed</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">helped</governor>
          <dependent id="2">glimpsed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">dozens</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">glimpsed</governor>
          <dependent id="4">dozens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">interviews</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dozens</governor>
          <dependent id="6">interviews</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">dozens</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">thousands</governor>
          <dependent id="8">tens</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">thousands</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">dozens</governor>
          <dependent id="10">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">pages</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">thousands</governor>
          <dependent id="12">pages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">documents</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pages</governor>
          <dependent id="14">documents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">turned</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">turned</governor>
          <dependent id="16">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">turned</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">documents</governor>
          <dependent id="18">turned</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">turned</governor>
          <dependent id="19">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Committee</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Committee</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Committee</governor>
          <dependent id="22">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Committee</governor>
          <dependent id="23">Judiciary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">turned</governor>
          <dependent id="24">Committee</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">influences</governor>
          <dependent id="26">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">helped</governor>
          <dependent id="27">influences</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">helped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">helped</governor>
          <dependent id="29">shape</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">set</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">shape</governor>
          <dependent id="31">set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">beliefs</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">set</governor>
          <dependent id="33">beliefs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">subject</governor>
          <dependent id="34">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="38">subject</governor>
          <dependent id="35">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">subject</governor>
          <dependent id="36">now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">subject</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">beliefs</governor>
          <dependent id="38">subject</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">controversy</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">controversy</governor>
          <dependent id="40">bitter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">subject</governor>
          <dependent id="41">controversy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="36" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Senate Judiciary Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="Senate" />
            <token id="23" string="Judiciary" />
            <token id="24" string="Committee" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Thomas takes immense pride in having staked out an independent course despite suffering what he said was a heavy personal toll in lost friends and public condemnation.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="immense" lemma="immense" stem="immens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="pride" lemma="pride" stem="pride" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="staked" lemma="stake" stem="stake" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="suffering" lemma="suffer" stem="suffer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="heavy" lemma="heavy" stem="heavi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="toll" lemma="toll" stem="toll" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="condemnation" lemma="condemnation" stem="condemn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thomas)) (VP (VBZ takes) (NP (JJ immense) (NN pride)) (PP (IN in) (S (VP (VBG having) (VP (VBN staked) (PP (IN out) (NP (DT an) (JJ independent) (NN course))) (PP (IN despite) (S (VP (VBG suffering) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBD said) (SBAR (S (VP (VBD was) (NP (NP (DT a) (JJ heavy) (JJ personal) (NN toll)) (PP (IN in) (NP (NP (VBN lost) (NNS friends)) (CC and) (NP (JJ public) (NN condemnation))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what he said was a heavy personal toll in lost friends and public condemnation" type="SBAR">
          <tokens>
            <token id="14" string="what" />
            <token id="15" string="he" />
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="2" string="lost friends" type="NP">
          <tokens>
            <token id="23" string="lost" />
            <token id="24" string="friends" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="a heavy personal toll" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
          </tokens>
        </chunking>
        <chunking id="5" string="a heavy personal toll in lost friends and public condemnation" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="6" string="said was a heavy personal toll in lost friends and public condemnation" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="7" string="takes immense pride in having staked out an independent course despite suffering what he said was a heavy personal toll in lost friends and public condemnation" type="VP">
          <tokens>
            <token id="2" string="takes" />
            <token id="3" string="immense" />
            <token id="4" string="pride" />
            <token id="5" string="in" />
            <token id="6" string="having" />
            <token id="7" string="staked" />
            <token id="8" string="out" />
            <token id="9" string="an" />
            <token id="10" string="independent" />
            <token id="11" string="course" />
            <token id="12" string="despite" />
            <token id="13" string="suffering" />
            <token id="14" string="what" />
            <token id="15" string="he" />
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="8" string="an independent course" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="independent" />
            <token id="11" string="course" />
          </tokens>
        </chunking>
        <chunking id="9" string="immense pride" type="NP">
          <tokens>
            <token id="3" string="immense" />
            <token id="4" string="pride" />
          </tokens>
        </chunking>
        <chunking id="10" string="lost friends and public condemnation" type="NP">
          <tokens>
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="11" string="public condemnation" type="NP">
          <tokens>
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="12" string="staked out an independent course despite suffering what he said was a heavy personal toll in lost friends and public condemnation" type="VP">
          <tokens>
            <token id="7" string="staked" />
            <token id="8" string="out" />
            <token id="9" string="an" />
            <token id="10" string="independent" />
            <token id="11" string="course" />
            <token id="12" string="despite" />
            <token id="13" string="suffering" />
            <token id="14" string="what" />
            <token id="15" string="he" />
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="13" string="suffering what he said was a heavy personal toll in lost friends and public condemnation" type="VP">
          <tokens>
            <token id="13" string="suffering" />
            <token id="14" string="what" />
            <token id="15" string="he" />
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="was a heavy personal toll in lost friends and public condemnation" type="SBAR">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="16" string="having staked out an independent course despite suffering what he said was a heavy personal toll in lost friends and public condemnation" type="VP">
          <tokens>
            <token id="6" string="having" />
            <token id="7" string="staked" />
            <token id="8" string="out" />
            <token id="9" string="an" />
            <token id="10" string="independent" />
            <token id="11" string="course" />
            <token id="12" string="despite" />
            <token id="13" string="suffering" />
            <token id="14" string="what" />
            <token id="15" string="he" />
            <token id="16" string="said" />
            <token id="17" string="was" />
            <token id="18" string="a" />
            <token id="19" string="heavy" />
            <token id="20" string="personal" />
            <token id="21" string="toll" />
            <token id="22" string="in" />
            <token id="23" string="lost" />
            <token id="24" string="friends" />
            <token id="25" string="and" />
            <token id="26" string="public" />
            <token id="27" string="condemnation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">takes</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">takes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">pride</governor>
          <dependent id="3">immense</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">takes</governor>
          <dependent id="4">pride</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">staked</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">staked</governor>
          <dependent id="6">having</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">takes</governor>
          <dependent id="7">staked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">course</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">course</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">course</governor>
          <dependent id="10">independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">staked</governor>
          <dependent id="11">course</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">suffering</governor>
          <dependent id="12">despite</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">staked</governor>
          <dependent id="13">suffering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">said</governor>
          <dependent id="14">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">suffering</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">toll</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">toll</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">toll</governor>
          <dependent id="19">heavy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">toll</governor>
          <dependent id="20">personal</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="21">toll</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">friends</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">friends</governor>
          <dependent id="23">lost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">toll</governor>
          <dependent id="24">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">friends</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">condemnation</governor>
          <dependent id="26">public</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">friends</governor>
          <dependent id="27">condemnation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Black &amp;apost;intellectual clones&amp;apost;; &amp;quot;I refuse to submit to the racially derogatory orthodoxy which says that all blacks should share the same opinion on . . . affirmative action, busing or welfare. . . .</content>
      <tokens>
        <token id="1" string="Black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="intellectual" lemma="intellectual" stem="intellectu" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="clones" lemma="clone" stem="clone" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="refuse" lemma="refuse" stem="refus" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="submit" lemma="submit" stem="submit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="racially" lemma="racially" stem="racial" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="derogatory" lemma="derogatory" stem="derogatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="orthodoxy" lemma="orthodoxy" stem="orthodoxi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="share" lemma="share" stem="share" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="busing" lemma="busing" stem="buse" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="welfare" lemma="welfare" stem="welfar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Black)) (`` `) (S (NP (NP (NP (NP (JJ intellectual)) (NP (NNS clones) (POS '))) (: ;) (S (`` ``) (NP (PRP I)) (VP (VBP refuse) (S (VP (TO to) (VP (VB submit) (PP (TO to) (NP (NP (DT the) (ADJP (RB racially) (JJ derogatory)) (NN orthodoxy)) (SBAR (WHNP (WDT which)) (S (VP (VBZ says) (ADVP (IN that) (DT all))))))))))))) (NP (NNS blacks)))) (VP (MD should) (VP (VB share) (NP (NP (DT the) (JJ same) (NN opinion)) (PP (IN on) (: ...) (NP (NP (JJ affirmative) (NN action)) (, ,) (NP (NN busing)) (CC or) (NP (NN welfare))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="clones '" type="NP">
          <tokens>
            <token id="4" string="clones" />
            <token id="5" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="the racially derogatory orthodoxy which says that all" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="should share the same opinion on ... affirmative action , busing or welfare" type="VP">
          <tokens>
            <token id="22" string="should" />
            <token id="23" string="share" />
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="opinion" />
            <token id="27" string="on" />
            <token id="28" string=". . ." />
            <token id="29" string="affirmative" />
            <token id="30" string="action" />
            <token id="31" string="," />
            <token id="32" string="busing" />
            <token id="33" string="or" />
            <token id="34" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="4" string="busing" type="NP">
          <tokens>
            <token id="32" string="busing" />
          </tokens>
        </chunking>
        <chunking id="5" string="racially derogatory" type="ADJP">
          <tokens>
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
          </tokens>
        </chunking>
        <chunking id="6" string="submit to the racially derogatory orthodoxy which says that all" type="VP">
          <tokens>
            <token id="11" string="submit" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="7" string="says that all" type="VP">
          <tokens>
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="8" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="blacks" type="NP">
          <tokens>
            <token id="21" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="10" string="Black" type="NP">
          <tokens>
            <token id="1" string="Black" />
          </tokens>
        </chunking>
        <chunking id="11" string="intellectual clones ' ; `` I refuse to submit to the racially derogatory orthodoxy which says that all" type="NP">
          <tokens>
            <token id="3" string="intellectual" />
            <token id="4" string="clones" />
            <token id="5" string="'" />
            <token id="6" string=";" />
            <token id="7" string="&quot;" />
            <token id="8" string="I" />
            <token id="9" string="refuse" />
            <token id="10" string="to" />
            <token id="11" string="submit" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="12" string="welfare" type="NP">
          <tokens>
            <token id="34" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="13" string="intellectual clones '" type="NP">
          <tokens>
            <token id="3" string="intellectual" />
            <token id="4" string="clones" />
            <token id="5" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="refuse to submit to the racially derogatory orthodoxy which says that all" type="VP">
          <tokens>
            <token id="9" string="refuse" />
            <token id="10" string="to" />
            <token id="11" string="submit" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="15" string="to submit to the racially derogatory orthodoxy which says that all" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="submit" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="16" string="affirmative action , busing or welfare" type="NP">
          <tokens>
            <token id="29" string="affirmative" />
            <token id="30" string="action" />
            <token id="31" string="," />
            <token id="32" string="busing" />
            <token id="33" string="or" />
            <token id="34" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="17" string="intellectual clones ' ; `` I refuse to submit to the racially derogatory orthodoxy which says that all blacks" type="NP">
          <tokens>
            <token id="3" string="intellectual" />
            <token id="4" string="clones" />
            <token id="5" string="'" />
            <token id="6" string=";" />
            <token id="7" string="&quot;" />
            <token id="8" string="I" />
            <token id="9" string="refuse" />
            <token id="10" string="to" />
            <token id="11" string="submit" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
            <token id="21" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="18" string="intellectual" type="NP">
          <tokens>
            <token id="3" string="intellectual" />
          </tokens>
        </chunking>
        <chunking id="19" string="the same opinion on ... affirmative action , busing or welfare" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="opinion" />
            <token id="27" string="on" />
            <token id="28" string=". . ." />
            <token id="29" string="affirmative" />
            <token id="30" string="action" />
            <token id="31" string="," />
            <token id="32" string="busing" />
            <token id="33" string="or" />
            <token id="34" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="20" string="share the same opinion on ... affirmative action , busing or welfare" type="VP">
          <tokens>
            <token id="23" string="share" />
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="opinion" />
            <token id="27" string="on" />
            <token id="28" string=". . ." />
            <token id="29" string="affirmative" />
            <token id="30" string="action" />
            <token id="31" string="," />
            <token id="32" string="busing" />
            <token id="33" string="or" />
            <token id="34" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="21" string="affirmative action" type="NP">
          <tokens>
            <token id="29" string="affirmative" />
            <token id="30" string="action" />
          </tokens>
        </chunking>
        <chunking id="22" string="the racially derogatory orthodoxy" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="racially" />
            <token id="15" string="derogatory" />
            <token id="16" string="orthodoxy" />
          </tokens>
        </chunking>
        <chunking id="23" string="the same opinion" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="24" string="which says that all" type="SBAR">
          <tokens>
            <token id="17" string="which" />
            <token id="18" string="says" />
            <token id="19" string="that" />
            <token id="20" string="all" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="23">share</governor>
          <dependent id="1">Black</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">share</governor>
          <dependent id="3">intellectual</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">intellectual</governor>
          <dependent id="4">clones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">clones</governor>
          <dependent id="5">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">refuse</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">intellectual</governor>
          <dependent id="9">refuse</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">submit</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">refuse</governor>
          <dependent id="11">submit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">orthodoxy</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">orthodoxy</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">derogatory</governor>
          <dependent id="14">racially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">orthodoxy</governor>
          <dependent id="15">derogatory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">submit</governor>
          <dependent id="16">orthodoxy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">says</governor>
          <dependent id="17">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">orthodoxy</governor>
          <dependent id="18">says</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">all</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">says</governor>
          <dependent id="20">all</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">intellectual</governor>
          <dependent id="21">blacks</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">share</governor>
          <dependent id="22">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">share</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">opinion</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">opinion</governor>
          <dependent id="25">same</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">share</governor>
          <dependent id="26">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">action</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">action</governor>
          <dependent id="29">affirmative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">opinion</governor>
          <dependent id="30">action</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">action</governor>
          <dependent id="32">busing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">action</governor>
          <dependent id="33">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">action</governor>
          <dependent id="34">welfare</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>I believe it is racist to act as though blacks are intellectual clones,&amp;quot; he said in a 1984 speech to black students at Yale Law School, where he earned his law degree.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="racist" lemma="racist" stem="racist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="act" lemma="act" stem="act" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="intellectual" lemma="intellectual" stem="intellectu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="clones" lemma="clone" stem="clone" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="speech" lemma="speech" stem="speech" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Law" lemma="Law" stem="law" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="earned" lemma="earn" stem="earn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="degree" lemma="degree" stem="degre" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP believe) (SBAR (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ racist) (S (VP (TO to) (VP (VB act) (SBAR (IN as) (S (SBAR (IN though) (S (NP (NNS blacks)) (VP (VBP are) (NP (JJ intellectual) (NNS clones))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said) (PP (IN in) (NP (DT a) (CD 1984) (NN speech))) (PP (TO to) (NP (JJ black) (NNS students))) (PP (IN at) (NP (NP (NNP Yale) (NNP Law) (NNP School)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP he)) (VP (VBD earned) (NP (PRP$ his) (NN law) (NN degree)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="believe it is racist to act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="VP">
          <tokens>
            <token id="2" string="believe" />
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="racist" />
            <token id="6" string="to" />
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="2" string="earned his law degree" type="VP">
          <tokens>
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="3" string="as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="SBAR">
          <tokens>
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="4" string="said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="blacks" type="NP">
          <tokens>
            <token id="10" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="Yale Law School" type="NP">
          <tokens>
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
          </tokens>
        </chunking>
        <chunking id="8" string="where he earned his law degree" type="SBAR">
          <tokens>
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="to act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="11" string="Yale Law School , where he earned his law degree" type="NP">
          <tokens>
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="12" string="his law degree" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="13" string="are intellectual clones" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
          </tokens>
        </chunking>
        <chunking id="14" string="intellectual clones" type="NP">
          <tokens>
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
          </tokens>
        </chunking>
        <chunking id="15" string="a 1984 speech" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
          </tokens>
        </chunking>
        <chunking id="16" string="act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="VP">
          <tokens>
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="17" string="though blacks are intellectual clones" type="SBAR">
          <tokens>
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
          </tokens>
        </chunking>
        <chunking id="18" string="black students" type="NP">
          <tokens>
            <token id="23" string="black" />
            <token id="24" string="students" />
          </tokens>
        </chunking>
        <chunking id="19" string="is racist to act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="racist" />
            <token id="6" string="to" />
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="20" string="where" type="WHADVP">
          <tokens>
            <token id="30" string="where" />
          </tokens>
        </chunking>
        <chunking id="21" string="racist to act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="ADJP">
          <tokens>
            <token id="5" string="racist" />
            <token id="6" string="to" />
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="it is racist to act as though blacks are intellectual clones , '' he said in a 1984 speech to black students at Yale Law School , where he earned his law degree" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="racist" />
            <token id="6" string="to" />
            <token id="7" string="act" />
            <token id="8" string="as" />
            <token id="9" string="though" />
            <token id="10" string="blacks" />
            <token id="11" string="are" />
            <token id="12" string="intellectual" />
            <token id="13" string="clones" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="he" />
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="1984" />
            <token id="21" string="speech" />
            <token id="22" string="to" />
            <token id="23" string="black" />
            <token id="24" string="students" />
            <token id="25" string="at" />
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
            <token id="29" string="," />
            <token id="30" string="where" />
            <token id="31" string="he" />
            <token id="32" string="earned" />
            <token id="33" string="his" />
            <token id="34" string="law" />
            <token id="35" string="degree" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">believe</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">racist</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">racist</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">believe</governor>
          <dependent id="5">racist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">act</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">racist</governor>
          <dependent id="7">act</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">said</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">clones</governor>
          <dependent id="9">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">clones</governor>
          <dependent id="10">blacks</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">clones</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">clones</governor>
          <dependent id="12">intellectual</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">said</governor>
          <dependent id="13">clones</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">act</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">speech</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">speech</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">speech</governor>
          <dependent id="20">1984</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">said</governor>
          <dependent id="21">speech</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">students</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">students</governor>
          <dependent id="23">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">said</governor>
          <dependent id="24">students</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">School</governor>
          <dependent id="25">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">School</governor>
          <dependent id="26">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">School</governor>
          <dependent id="27">Law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">said</governor>
          <dependent id="28">School</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">earned</governor>
          <dependent id="30">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">earned</governor>
          <dependent id="31">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">School</governor>
          <dependent id="32">earned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">degree</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">degree</governor>
          <dependent id="34">law</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">earned</governor>
          <dependent id="35">degree</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="Yale Law School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="Yale" />
            <token id="27" string="Law" />
            <token id="28" string="School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Thomas underscores his role as a minority figure within a minority by repeatedly quoting Robert Frost&amp;apost;s poetic recollection: &amp;quot;Two roads diverged in a wood, and I -- I took the one less traveled by, and that has made all the difference.&amp;quot;</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="underscores" lemma="underscore" stem="underscor" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="repeatedly" lemma="repeatedly" stem="repeatedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="quoting" lemma="quote" stem="quot" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Frost" lemma="Frost" stem="frost" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="poetic" lemma="poetic" stem="poetic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="recollection" lemma="recollection" stem="recollect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="roads" lemma="road" stem="road" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="diverged" lemma="diverge" stem="diverg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="wood" lemma="wood" stem="wood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="36" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="traveled" lemma="travel" stem="travel" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Thomas)) (VP (VBZ underscores) (NP (PRP$ his) (NN role)) (PP (IN as) (NP (NP (DT a) (NN minority) (NN figure)) (PP (IN within) (NP (DT a) (NN minority))))) (PP (IN by) (S (ADVP (RB repeatedly)) (VP (VBG quoting) (NP (NP (NNP Robert) (NNP Frost) (POS 's)) (JJ poetic) (NN recollection))))))) (: :) (`` ``) (S (NP (CD Two) (NNS roads)) (VP (VBD diverged) (PP (IN in) (NP (NP (DT a) (NN wood)) (, ,) (CC and) (NP (PRP I)))))) (: --) (S (NP (PRP I)) (VP (VBD took) (S (NP (DT the) (CD one)) (ADJP (JJR less)) (S (VP (VBN traveled) (PP (IN by))))))) (, ,) (CC and) (S (NP (DT that)) (VP (VBZ has) (VP (VBN made) (NP (PDT all) (DT the) (NN difference))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a minority" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="minority" />
          </tokens>
        </chunking>
        <chunking id="2" string="diverged in a wood , and I" type="VP">
          <tokens>
            <token id="24" string="diverged" />
            <token id="25" string="in" />
            <token id="26" string="a" />
            <token id="27" string="wood" />
            <token id="28" string="," />
            <token id="29" string="and" />
            <token id="30" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="has made all the difference" type="VP">
          <tokens>
            <token id="42" string="has" />
            <token id="43" string="made" />
            <token id="44" string="all" />
            <token id="45" string="the" />
            <token id="46" string="difference" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="quoting Robert Frost 's poetic recollection" type="VP">
          <tokens>
            <token id="14" string="quoting" />
            <token id="15" string="Robert" />
            <token id="16" string="Frost" />
            <token id="17" string="'s" />
            <token id="18" string="poetic" />
            <token id="19" string="recollection" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="30" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="less" type="ADJP">
          <tokens>
            <token id="36" string="less" />
          </tokens>
        </chunking>
        <chunking id="8" string="a minority figure within a minority" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="minority" />
            <token id="8" string="figure" />
            <token id="9" string="within" />
            <token id="10" string="a" />
            <token id="11" string="minority" />
          </tokens>
        </chunking>
        <chunking id="9" string="a wood" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="wood" />
          </tokens>
        </chunking>
        <chunking id="10" string="a minority figure" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="minority" />
            <token id="8" string="figure" />
          </tokens>
        </chunking>
        <chunking id="11" string="Robert Frost 's" type="NP">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Frost" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="a wood , and I" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="wood" />
            <token id="28" string="," />
            <token id="29" string="and" />
            <token id="30" string="I" />
          </tokens>
        </chunking>
        <chunking id="13" string="that" type="NP">
          <tokens>
            <token id="41" string="that" />
          </tokens>
        </chunking>
        <chunking id="14" string="traveled by" type="VP">
          <tokens>
            <token id="37" string="traveled" />
            <token id="38" string="by" />
          </tokens>
        </chunking>
        <chunking id="15" string="took the one less traveled by" type="VP">
          <tokens>
            <token id="33" string="took" />
            <token id="34" string="the" />
            <token id="35" string="one" />
            <token id="36" string="less" />
            <token id="37" string="traveled" />
            <token id="38" string="by" />
          </tokens>
        </chunking>
        <chunking id="16" string="Two roads" type="NP">
          <tokens>
            <token id="22" string="Two" />
            <token id="23" string="roads" />
          </tokens>
        </chunking>
        <chunking id="17" string="made all the difference" type="VP">
          <tokens>
            <token id="43" string="made" />
            <token id="44" string="all" />
            <token id="45" string="the" />
            <token id="46" string="difference" />
          </tokens>
        </chunking>
        <chunking id="18" string="underscores his role as a minority figure within a minority by repeatedly quoting Robert Frost 's poetic recollection" type="VP">
          <tokens>
            <token id="2" string="underscores" />
            <token id="3" string="his" />
            <token id="4" string="role" />
            <token id="5" string="as" />
            <token id="6" string="a" />
            <token id="7" string="minority" />
            <token id="8" string="figure" />
            <token id="9" string="within" />
            <token id="10" string="a" />
            <token id="11" string="minority" />
            <token id="12" string="by" />
            <token id="13" string="repeatedly" />
            <token id="14" string="quoting" />
            <token id="15" string="Robert" />
            <token id="16" string="Frost" />
            <token id="17" string="'s" />
            <token id="18" string="poetic" />
            <token id="19" string="recollection" />
          </tokens>
        </chunking>
        <chunking id="19" string="Robert Frost 's poetic recollection" type="NP">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Frost" />
            <token id="17" string="'s" />
            <token id="18" string="poetic" />
            <token id="19" string="recollection" />
          </tokens>
        </chunking>
        <chunking id="20" string="all the difference" type="NP">
          <tokens>
            <token id="44" string="all" />
            <token id="45" string="the" />
            <token id="46" string="difference" />
          </tokens>
        </chunking>
        <chunking id="21" string="the one" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="one" />
          </tokens>
        </chunking>
        <chunking id="22" string="his role" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="role" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">underscores</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">underscores</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">role</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">underscores</governor>
          <dependent id="4">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">figure</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">figure</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">figure</governor>
          <dependent id="7">minority</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">underscores</governor>
          <dependent id="8">figure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">minority</governor>
          <dependent id="9">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">minority</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">figure</governor>
          <dependent id="11">minority</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">quoting</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">quoting</governor>
          <dependent id="13">repeatedly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">underscores</governor>
          <dependent id="14">quoting</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Frost</governor>
          <dependent id="15">Robert</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">recollection</governor>
          <dependent id="16">Frost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Frost</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">recollection</governor>
          <dependent id="18">poetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">quoting</governor>
          <dependent id="19">recollection</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">roads</governor>
          <dependent id="22">Two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">diverged</governor>
          <dependent id="23">roads</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">underscores</governor>
          <dependent id="24">diverged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">wood</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">wood</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">diverged</governor>
          <dependent id="27">wood</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">wood</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">wood</governor>
          <dependent id="30">I</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">took</governor>
          <dependent id="32">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">underscores</governor>
          <dependent id="33">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">one</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">traveled</governor>
          <dependent id="35">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">traveled</governor>
          <dependent id="36">less</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">took</governor>
          <dependent id="37">traveled</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">traveled</governor>
          <dependent id="38">by</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">underscores</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">made</governor>
          <dependent id="41">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="43">made</governor>
          <dependent id="42">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">underscores</governor>
          <dependent id="43">made</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="46">difference</governor>
          <dependent id="44">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">difference</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">made</governor>
          <dependent id="46">difference</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Robert Frost" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Robert" />
            <token id="16" string="Frost" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="35" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="Two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>; Even his close friends have trouble explaining why Thomas took a different road.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="explaining" lemma="explain" stem="explain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (ADVP (RB Even)) (NP (PRP$ his) (JJ close) (NNS friends)) (VP (VBP have) (NP (NP (NN trouble)) (VP (VBG explaining) (SBAR (WHADVP (WRB why)) (S (NP (NNP Thomas)) (VP (VBD took) (NP (DT a) (JJ different) (NN road))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="trouble explaining why Thomas took a different road" type="NP">
          <tokens>
            <token id="7" string="trouble" />
            <token id="8" string="explaining" />
            <token id="9" string="why" />
            <token id="10" string="Thomas" />
            <token id="11" string="took" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
        <chunking id="2" string="explaining why Thomas took a different road" type="VP">
          <tokens>
            <token id="8" string="explaining" />
            <token id="9" string="why" />
            <token id="10" string="Thomas" />
            <token id="11" string="took" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
        <chunking id="3" string="took a different road" type="VP">
          <tokens>
            <token id="11" string="took" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
        <chunking id="4" string="why Thomas took a different road" type="SBAR">
          <tokens>
            <token id="9" string="why" />
            <token id="10" string="Thomas" />
            <token id="11" string="took" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
        <chunking id="5" string="why" type="WHADVP">
          <tokens>
            <token id="9" string="why" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="trouble" type="NP">
          <tokens>
            <token id="7" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="8" string="have trouble explaining why Thomas took a different road" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="trouble" />
            <token id="8" string="explaining" />
            <token id="9" string="why" />
            <token id="10" string="Thomas" />
            <token id="11" string="took" />
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
        <chunking id="9" string="his close friends" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="close" />
            <token id="5" string="friends" />
          </tokens>
        </chunking>
        <chunking id="10" string="a different road" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="different" />
            <token id="14" string="road" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">have</governor>
          <dependent id="2">Even</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">friends</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">friends</governor>
          <dependent id="4">close</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">have</governor>
          <dependent id="5">friends</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="7">trouble</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">trouble</governor>
          <dependent id="8">explaining</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">took</governor>
          <dependent id="9">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">took</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">explaining</governor>
          <dependent id="11">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">road</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">road</governor>
          <dependent id="13">different</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">took</governor>
          <dependent id="14">road</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>As a youth, Clarence Thomas shared the liberal attitudes of many bright young black people who were born into a segregated America and came of age after freedom rides, lunch room sit-ins and the 1964 Civil Rights Act began erasing the overt signs of racial discrimination.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="youth" lemma="youth" stem="youth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="shared" lemma="share" stem="share" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="10" string="attitudes" lemma="attitude" stem="attitud" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="bright" lemma="bright" stem="bright" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="segregated" lemma="segregate" stem="segreg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="freedom" lemma="freedom" stem="freedom" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="rides" lemma="ride" stem="ride" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="lunch" lemma="lunch" stem="lunch" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="sit-ins" lemma="sit-in" stem="sit-in" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="1964" lemma="1964" stem="1964" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="38" string="Civil" lemma="Civil" stem="civil" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="39" string="Rights" lemma="Rights" stem="right" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="40" string="Act" lemma="Act" stem="act" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="41" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="erasing" lemma="erase" stem="eras" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="overt" lemma="overt" stem="overt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (NP (DT a) (NN youth))) (, ,) (NP (NNP Clarence) (NNP Thomas)) (VP (VBD shared) (SBAR (S (NP (NP (DT the) (JJ liberal) (NNS attitudes)) (PP (IN of) (NP (NP (JJ many) (JJ bright) (JJ young) (JJ black) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VP (VBD were) (VP (VBN born) (PP (IN into) (NP (DT a) (VBN segregated) (NNP America))))) (CC and) (VP (VBD came) (PP (IN of) (NP (NN age))) (PP (IN after) (NP (NP (NN freedom) (NNS rides)) (, ,) (NP (NN lunch) (NN room) (NNS sit-ins)) (CC and) (NP (DT the) (CD 1964) (NNP Civil) (NNP Rights) (NNP Act))))))))))) (VP (VBD began) (S (VP (VBG erasing) (NP (NP (DT the) (JJ overt) (NNS signs)) (PP (IN of) (NP (JJ racial) (NN discrimination)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a youth" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="youth" />
          </tokens>
        </chunking>
        <chunking id="2" string="lunch room sit-ins" type="NP">
          <tokens>
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 1964 Civil Rights Act" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="4" string="were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="5" string="were born into a segregated America" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
          </tokens>
        </chunking>
        <chunking id="6" string="began erasing the overt signs of racial discrimination" type="VP">
          <tokens>
            <token id="41" string="began" />
            <token id="42" string="erasing" />
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
            <token id="46" string="of" />
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="7" string="freedom rides" type="NP">
          <tokens>
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
          </tokens>
        </chunking>
        <chunking id="8" string="the overt signs of racial discrimination" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
            <token id="46" string="of" />
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="9" string="the liberal attitudes of many bright young black people who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="liberal" />
            <token id="10" string="attitudes" />
            <token id="11" string="of" />
            <token id="12" string="many" />
            <token id="13" string="bright" />
            <token id="14" string="young" />
            <token id="15" string="black" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="10" string="the overt signs" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
          </tokens>
        </chunking>
        <chunking id="11" string="the liberal attitudes of many bright young black people who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act began erasing the overt signs of racial discrimination" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="liberal" />
            <token id="10" string="attitudes" />
            <token id="11" string="of" />
            <token id="12" string="many" />
            <token id="13" string="bright" />
            <token id="14" string="young" />
            <token id="15" string="black" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
            <token id="41" string="began" />
            <token id="42" string="erasing" />
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
            <token id="46" string="of" />
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="12" string="many bright young black people who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="bright" />
            <token id="14" string="young" />
            <token id="15" string="black" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="13" string="a segregated America" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
          </tokens>
        </chunking>
        <chunking id="14" string="many bright young black people" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="bright" />
            <token id="14" string="young" />
            <token id="15" string="black" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="born into a segregated America" type="VP">
          <tokens>
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
          </tokens>
        </chunking>
        <chunking id="16" string="the liberal attitudes" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="liberal" />
            <token id="10" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="17" string="shared the liberal attitudes of many bright young black people who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act began erasing the overt signs of racial discrimination" type="VP">
          <tokens>
            <token id="7" string="shared" />
            <token id="8" string="the" />
            <token id="9" string="liberal" />
            <token id="10" string="attitudes" />
            <token id="11" string="of" />
            <token id="12" string="many" />
            <token id="13" string="bright" />
            <token id="14" string="young" />
            <token id="15" string="black" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
            <token id="41" string="began" />
            <token id="42" string="erasing" />
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
            <token id="46" string="of" />
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="18" string="came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="VP">
          <tokens>
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="19" string="who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="were" />
            <token id="19" string="born" />
            <token id="20" string="into" />
            <token id="21" string="a" />
            <token id="22" string="segregated" />
            <token id="23" string="America" />
            <token id="24" string="and" />
            <token id="25" string="came" />
            <token id="26" string="of" />
            <token id="27" string="age" />
            <token id="28" string="after" />
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="20" string="erasing the overt signs of racial discrimination" type="VP">
          <tokens>
            <token id="42" string="erasing" />
            <token id="43" string="the" />
            <token id="44" string="overt" />
            <token id="45" string="signs" />
            <token id="46" string="of" />
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="21" string="racial discrimination" type="NP">
          <tokens>
            <token id="47" string="racial" />
            <token id="48" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="22" string="freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" type="NP">
          <tokens>
            <token id="29" string="freedom" />
            <token id="30" string="rides" />
            <token id="31" string="," />
            <token id="32" string="lunch" />
            <token id="33" string="room" />
            <token id="34" string="sit-ins" />
            <token id="35" string="and" />
            <token id="36" string="the" />
            <token id="37" string="1964" />
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </chunking>
        <chunking id="23" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="5" string="Clarence" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="24" string="age" type="NP">
          <tokens>
            <token id="27" string="age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">youth</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">youth</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">shared</governor>
          <dependent id="3">youth</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Thomas</governor>
          <dependent id="5">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">shared</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">shared</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">attitudes</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">attitudes</governor>
          <dependent id="9">liberal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">began</governor>
          <dependent id="10">attitudes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="12">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="13">bright</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="14">young</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">attitudes</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">born</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">born</governor>
          <dependent id="18">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">people</governor>
          <dependent id="19">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">America</governor>
          <dependent id="20">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">America</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">America</governor>
          <dependent id="22">segregated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">born</governor>
          <dependent id="23">America</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">born</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">born</governor>
          <dependent id="25">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">age</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">came</governor>
          <dependent id="27">age</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">rides</governor>
          <dependent id="28">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">rides</governor>
          <dependent id="29">freedom</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">came</governor>
          <dependent id="30">rides</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">sit-ins</governor>
          <dependent id="32">lunch</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">sit-ins</governor>
          <dependent id="33">room</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">rides</governor>
          <dependent id="34">sit-ins</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">rides</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">Act</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="40">Act</governor>
          <dependent id="37">1964</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Act</governor>
          <dependent id="38">Civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Act</governor>
          <dependent id="39">Rights</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">rides</governor>
          <dependent id="40">Act</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">shared</governor>
          <dependent id="41">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="41">began</governor>
          <dependent id="42">erasing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">signs</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">signs</governor>
          <dependent id="44">overt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">erasing</governor>
          <dependent id="45">signs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">discrimination</governor>
          <dependent id="46">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">discrimination</governor>
          <dependent id="47">racial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">signs</governor>
          <dependent id="48">discrimination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1964" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="1964" />
          </tokens>
        </entity>
        <entity id="2" string="America" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="America" />
          </tokens>
        </entity>
        <entity id="3" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="liberal" />
          </tokens>
        </entity>
        <entity id="4" string="Civil Rights Act" type="MISC" score="0.0">
          <tokens>
            <token id="38" string="Civil" />
            <token id="39" string="Rights" />
            <token id="40" string="Act" />
          </tokens>
        </entity>
        <entity id="5" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Clarence" />
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>As a Holy Cross College student in the turbulent 1960s, he joined black protesters, wore a beret and a leather jacket, and decorated his dormitory room with a poster of Malcolm X.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Holy" lemma="Holy" stem="holi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Cross" lemma="Cross" stem="cross" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="turbulent" lemma="turbulent" stem="turbul" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="1960s" lemma="1960" stem="1960" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="protesters" lemma="protester" stem="protest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wore" lemma="wear" stem="wore" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="beret" lemma="beret" stem="beret" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="leather" lemma="leather" stem="leather" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="jacket" lemma="jacket" stem="jacket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="decorated" lemma="decorate" stem="decor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="dormitory" lemma="dormitory" stem="dormitori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="poster" lemma="poster" stem="poster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Malcolm" lemma="Malcolm" stem="malcolm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="X" lemma="x" stem="x" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (NP (NP (DT a) (NNP Holy) (NNP Cross) (NNP College) (NN student)) (PP (IN in) (NP (DT the) (JJ turbulent) (NNS 1960s))))) (, ,) (NP (PRP he)) (VP (VP (VBD joined) (NP (JJ black) (NNS protesters))) (, ,) (VP (VBD wore) (NP (NP (DT a) (NN beret)) (CC and) (NP (DT a) (NN leather) (NN jacket)))) (, ,) (CC and) (VP (VBD decorated) (NP (PRP$ his) (NN dormitory) (NN room)) (PP (IN with) (NP (NP (DT a) (NN poster)) (PP (IN of) (NP (NNP Malcolm) (NN X))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Holy Cross College student in the turbulent 1960s" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="Holy" />
            <token id="4" string="Cross" />
            <token id="5" string="College" />
            <token id="6" string="student" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="turbulent" />
            <token id="10" string="1960s" />
          </tokens>
        </chunking>
        <chunking id="2" string="black protesters" type="NP">
          <tokens>
            <token id="14" string="black" />
            <token id="15" string="protesters" />
          </tokens>
        </chunking>
        <chunking id="3" string="a poster" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="poster" />
          </tokens>
        </chunking>
        <chunking id="4" string="joined black protesters , wore a beret and a leather jacket , and decorated his dormitory room with a poster of Malcolm X" type="VP">
          <tokens>
            <token id="13" string="joined" />
            <token id="14" string="black" />
            <token id="15" string="protesters" />
            <token id="16" string="," />
            <token id="17" string="wore" />
            <token id="18" string="a" />
            <token id="19" string="beret" />
            <token id="20" string="and" />
            <token id="21" string="a" />
            <token id="22" string="leather" />
            <token id="23" string="jacket" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="decorated" />
            <token id="27" string="his" />
            <token id="28" string="dormitory" />
            <token id="29" string="room" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="poster" />
            <token id="33" string="of" />
            <token id="34" string="Malcolm" />
            <token id="35" string="X" />
          </tokens>
        </chunking>
        <chunking id="5" string="a leather jacket" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="leather" />
            <token id="23" string="jacket" />
          </tokens>
        </chunking>
        <chunking id="6" string="his dormitory room" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="dormitory" />
            <token id="29" string="room" />
          </tokens>
        </chunking>
        <chunking id="7" string="a beret and a leather jacket" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="beret" />
            <token id="20" string="and" />
            <token id="21" string="a" />
            <token id="22" string="leather" />
            <token id="23" string="jacket" />
          </tokens>
        </chunking>
        <chunking id="8" string="a beret" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="beret" />
          </tokens>
        </chunking>
        <chunking id="9" string="decorated his dormitory room with a poster of Malcolm X" type="VP">
          <tokens>
            <token id="26" string="decorated" />
            <token id="27" string="his" />
            <token id="28" string="dormitory" />
            <token id="29" string="room" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="poster" />
            <token id="33" string="of" />
            <token id="34" string="Malcolm" />
            <token id="35" string="X" />
          </tokens>
        </chunking>
        <chunking id="10" string="a poster of Malcolm X" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="poster" />
            <token id="33" string="of" />
            <token id="34" string="Malcolm" />
            <token id="35" string="X" />
          </tokens>
        </chunking>
        <chunking id="11" string="wore a beret and a leather jacket" type="VP">
          <tokens>
            <token id="17" string="wore" />
            <token id="18" string="a" />
            <token id="19" string="beret" />
            <token id="20" string="and" />
            <token id="21" string="a" />
            <token id="22" string="leather" />
            <token id="23" string="jacket" />
          </tokens>
        </chunking>
        <chunking id="12" string="joined black protesters" type="VP">
          <tokens>
            <token id="13" string="joined" />
            <token id="14" string="black" />
            <token id="15" string="protesters" />
          </tokens>
        </chunking>
        <chunking id="13" string="a Holy Cross College student" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="Holy" />
            <token id="4" string="Cross" />
            <token id="5" string="College" />
            <token id="6" string="student" />
          </tokens>
        </chunking>
        <chunking id="14" string="Malcolm X" type="NP">
          <tokens>
            <token id="34" string="Malcolm" />
            <token id="35" string="X" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="the turbulent 1960s" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="turbulent" />
            <token id="10" string="1960s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">student</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">student</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">student</governor>
          <dependent id="3">Holy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">student</governor>
          <dependent id="4">Cross</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">student</governor>
          <dependent id="5">College</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">joined</governor>
          <dependent id="6">student</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">1960s</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">1960s</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">1960s</governor>
          <dependent id="9">turbulent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">student</governor>
          <dependent id="10">1960s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">joined</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">joined</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">protesters</governor>
          <dependent id="14">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">joined</governor>
          <dependent id="15">protesters</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">joined</governor>
          <dependent id="17">wore</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">beret</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">wore</governor>
          <dependent id="19">beret</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">beret</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">jacket</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">jacket</governor>
          <dependent id="22">leather</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">beret</governor>
          <dependent id="23">jacket</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">joined</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">joined</governor>
          <dependent id="26">decorated</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">room</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">room</governor>
          <dependent id="28">dormitory</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">decorated</governor>
          <dependent id="29">room</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">poster</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">poster</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">decorated</governor>
          <dependent id="32">poster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">X</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">X</governor>
          <dependent id="34">Malcolm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">poster</governor>
          <dependent id="35">X</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Malcolm X" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Malcolm" />
            <token id="35" string="X" />
          </tokens>
        </entity>
        <entity id="2" string="Holy Cross College" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Holy" />
            <token id="4" string="Cross" />
            <token id="5" string="College" />
          </tokens>
        </entity>
        <entity id="3" string="1960s" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1960s" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>But Thomas came to see his college years as wrongheaded.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="college" lemma="college" stem="colleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wrongheaded" lemma="wrongheaded" stem="wronghead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Thomas)) (VP (VBD came) (S (VP (TO to) (VP (VB see) (NP (PRP$ his) (NN college) (NNS years)) (PP (IN as) (ADJP (JJ wrongheaded))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his college years" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="see his college years as wrongheaded" type="VP">
          <tokens>
            <token id="5" string="see" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="years" />
            <token id="9" string="as" />
            <token id="10" string="wrongheaded" />
          </tokens>
        </chunking>
        <chunking id="4" string="came to see his college years as wrongheaded" type="VP">
          <tokens>
            <token id="3" string="came" />
            <token id="4" string="to" />
            <token id="5" string="see" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="years" />
            <token id="9" string="as" />
            <token id="10" string="wrongheaded" />
          </tokens>
        </chunking>
        <chunking id="5" string="wrongheaded" type="ADJP">
          <tokens>
            <token id="10" string="wrongheaded" />
          </tokens>
        </chunking>
        <chunking id="6" string="to see his college years as wrongheaded" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="see" />
            <token id="6" string="his" />
            <token id="7" string="college" />
            <token id="8" string="years" />
            <token id="9" string="as" />
            <token id="10" string="wrongheaded" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">came</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">came</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">came</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">see</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">came</governor>
          <dependent id="5">see</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">years</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">years</governor>
          <dependent id="7">college</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">see</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">wrongheaded</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">see</governor>
          <dependent id="10">wrongheaded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>His rightward shift -- or, by his account, his circling back to conservative values -- began while he was a Yale law student from 1971 to 1974.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="rightward" lemma="rightward" stem="rightward" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="shift" lemma="shift" stem="shift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="account" lemma="account" stem="account" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="circling" lemma="circle" stem="circl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="16" string="values" lemma="value" stem="valu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="24" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="1971" lemma="1971" stem="1971" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="29" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (JJ rightward) (NN shift)) (: --) (CC or) (PRN (, ,) (PP (IN by))) (NP (PRP$ his) (NN account)) (, ,)) (S (NP (PRP$ his)) (S (VP (VBG circling) (PRT (RB back)) (PP (TO to) (NP (JJ conservative) (NNS values))) (: --)))) (VP (VBD began) (SBAR (IN while) (S (NP (PRP he)) (VP (VBD was) (NP (NP (DT a) (NNP Yale) (NN law) (NN student)) (PP (IN from) (NP (CD 1971) (TO to) (CD 1974)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his account" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="account" />
          </tokens>
        </chunking>
        <chunking id="2" string="1971 to 1974" type="NP">
          <tokens>
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </chunking>
        <chunking id="3" string="His rightward shift" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="rightward" />
            <token id="3" string="shift" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Yale law student" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="Yale" />
            <token id="24" string="law" />
            <token id="25" string="student" />
          </tokens>
        </chunking>
        <chunking id="5" string="circling back to conservative values --" type="VP">
          <tokens>
            <token id="12" string="circling" />
            <token id="13" string="back" />
            <token id="14" string="to" />
            <token id="15" string="conservative" />
            <token id="16" string="values" />
            <token id="17" string="--" />
          </tokens>
        </chunking>
        <chunking id="6" string="his" type="NP">
          <tokens>
            <token id="11" string="his" />
          </tokens>
        </chunking>
        <chunking id="7" string="conservative values" type="NP">
          <tokens>
            <token id="15" string="conservative" />
            <token id="16" string="values" />
          </tokens>
        </chunking>
        <chunking id="8" string="was a Yale law student from 1971 to 1974" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="a" />
            <token id="23" string="Yale" />
            <token id="24" string="law" />
            <token id="25" string="student" />
            <token id="26" string="from" />
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </chunking>
        <chunking id="9" string="His rightward shift -- or , by his account ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="rightward" />
            <token id="3" string="shift" />
            <token id="4" string="--" />
            <token id="5" string="or" />
            <token id="6" string="," />
            <token id="7" string="by" />
            <token id="8" string="his" />
            <token id="9" string="account" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="began while he was a Yale law student from 1971 to 1974" type="VP">
          <tokens>
            <token id="18" string="began" />
            <token id="19" string="while" />
            <token id="20" string="he" />
            <token id="21" string="was" />
            <token id="22" string="a" />
            <token id="23" string="Yale" />
            <token id="24" string="law" />
            <token id="25" string="student" />
            <token id="26" string="from" />
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="20" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="while he was a Yale law student from 1971 to 1974" type="SBAR">
          <tokens>
            <token id="19" string="while" />
            <token id="20" string="he" />
            <token id="21" string="was" />
            <token id="22" string="a" />
            <token id="23" string="Yale" />
            <token id="24" string="law" />
            <token id="25" string="student" />
            <token id="26" string="from" />
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </chunking>
        <chunking id="13" string="a Yale law student from 1971 to 1974" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="Yale" />
            <token id="24" string="law" />
            <token id="25" string="student" />
            <token id="26" string="from" />
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">shift</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">shift</governor>
          <dependent id="2">rightward</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">began</governor>
          <dependent id="3">shift</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">shift</governor>
          <dependent id="5">or</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">shift</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">account</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">shift</governor>
          <dependent id="9">account</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">circling</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">began</governor>
          <dependent id="12">circling</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">circling</governor>
          <dependent id="13">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">values</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">values</governor>
          <dependent id="15">conservative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">circling</governor>
          <dependent id="16">values</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">began</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">student</governor>
          <dependent id="19">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">student</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">student</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">student</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">student</governor>
          <dependent id="23">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">student</governor>
          <dependent id="24">law</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">began</governor>
          <dependent id="25">student</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">1974</governor>
          <dependent id="26">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">1974</governor>
          <dependent id="27">1971</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">1974</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">student</governor>
          <dependent id="29">1974</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1971 to 1974" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="1971" />
            <token id="28" string="to" />
            <token id="29" string="1974" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Yale" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="Yale" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Thomas was admitted while an affirmative action program was in effect, although there is no evidence that he would not have gotten in without it.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="admitted" lemma="admit" stem="admit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="gotten" lemma="get" stem="gotten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thomas)) (VP (VBD was) (VP (VBN admitted) (SBAR (IN while) (S (NP (DT an) (JJ affirmative) (NN action) (NN program)) (VP (VBD was) (PP (IN in) (NP (NN effect)))))) (, ,) (SBAR (IN although) (S (NP (EX there)) (VP (VBZ is) (NP (DT no) (NN evidence)) (SBAR (IN that) (S (NP (PRP he)) (VP (MD would) (RB not) (VP (VB have) (VP (VBN gotten) (PP (IN in) (PP (IN without) (NP (PRP it)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would not have gotten in without it" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="an affirmative action program" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="affirmative" />
            <token id="7" string="action" />
            <token id="8" string="program" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="admitted while an affirmative action program was in effect , although there is no evidence that he would not have gotten in without it" type="VP">
          <tokens>
            <token id="3" string="admitted" />
            <token id="4" string="while" />
            <token id="5" string="an" />
            <token id="6" string="affirmative" />
            <token id="7" string="action" />
            <token id="8" string="program" />
            <token id="9" string="was" />
            <token id="10" string="in" />
            <token id="11" string="effect" />
            <token id="12" string="," />
            <token id="13" string="although" />
            <token id="14" string="there" />
            <token id="15" string="is" />
            <token id="16" string="no" />
            <token id="17" string="evidence" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="no evidence" type="NP">
          <tokens>
            <token id="16" string="no" />
            <token id="17" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="7" string="there" type="NP">
          <tokens>
            <token id="14" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="gotten in without it" type="VP">
          <tokens>
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="effect" type="NP">
          <tokens>
            <token id="11" string="effect" />
          </tokens>
        </chunking>
        <chunking id="10" string="is no evidence that he would not have gotten in without it" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="no" />
            <token id="17" string="evidence" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="have gotten in without it" type="VP">
          <tokens>
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="was in effect" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="in" />
            <token id="11" string="effect" />
          </tokens>
        </chunking>
        <chunking id="13" string="was admitted while an affirmative action program was in effect , although there is no evidence that he would not have gotten in without it" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="admitted" />
            <token id="4" string="while" />
            <token id="5" string="an" />
            <token id="6" string="affirmative" />
            <token id="7" string="action" />
            <token id="8" string="program" />
            <token id="9" string="was" />
            <token id="10" string="in" />
            <token id="11" string="effect" />
            <token id="12" string="," />
            <token id="13" string="although" />
            <token id="14" string="there" />
            <token id="15" string="is" />
            <token id="16" string="no" />
            <token id="17" string="evidence" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="that he would not have gotten in without it" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="although there is no evidence that he would not have gotten in without it" type="SBAR">
          <tokens>
            <token id="13" string="although" />
            <token id="14" string="there" />
            <token id="15" string="is" />
            <token id="16" string="no" />
            <token id="17" string="evidence" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="not" />
            <token id="22" string="have" />
            <token id="23" string="gotten" />
            <token id="24" string="in" />
            <token id="25" string="without" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="while an affirmative action program was in effect" type="SBAR">
          <tokens>
            <token id="4" string="while" />
            <token id="5" string="an" />
            <token id="6" string="affirmative" />
            <token id="7" string="action" />
            <token id="8" string="program" />
            <token id="9" string="was" />
            <token id="10" string="in" />
            <token id="11" string="effect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">admitted</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">admitted</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">effect</governor>
          <dependent id="4">while</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">program</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">program</governor>
          <dependent id="6">affirmative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">program</governor>
          <dependent id="7">action</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">effect</governor>
          <dependent id="8">program</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">effect</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">effect</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">admitted</governor>
          <dependent id="11">effect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">is</governor>
          <dependent id="13">although</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="15">is</governor>
          <dependent id="14">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">admitted</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">evidence</governor>
          <dependent id="16">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">is</governor>
          <dependent id="17">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">gotten</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">gotten</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">gotten</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">gotten</governor>
          <dependent id="21">not</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">gotten</governor>
          <dependent id="22">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">is</governor>
          <dependent id="23">gotten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">it</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">it</governor>
          <dependent id="25">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">gotten</governor>
          <dependent id="26">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Friend&amp;apost;s view; Whatever the reasons -- and his classmates and faculty members at Yale are unable to pinpoint any particular turning points or pivotal events -- Thomas &amp;quot;became more conservative as he went through the process of legal education,&amp;quot; said Harry Singleton, a friend.</content>
      <tokens>
        <token id="1" string="Friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Whatever" lemma="whatever" stem="whatev" pos="WDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="classmates" lemma="classmate" stem="classmat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="faculty" lemma="faculty" stem="faculti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="unable" lemma="unable" stem="unabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pinpoint" lemma="pinpoint" stem="pinpoint" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="particular" lemma="particular" stem="particular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="turning" lemma="turn" stem="turn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="points" lemma="point" stem="point" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="pivotal" lemma="pivotal" stem="pivot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="34" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="Harry" lemma="Harry" stem="harri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="47" string="Singleton" lemma="Singleton" stem="singleton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NN Friend) (POS 's)) (NN view)) (: ;) (SBAR (WHNP (WDT Whatever)) (S (NP (DT the) (NNS reasons)) (PRN (: --) (CC and) (S (NP (NP (PRP$ his) (NNS classmates)) (CC and) (NP (NP (NN faculty) (NNS members)) (PP (IN at) (NP (NNP Yale))))) (VP (VBP are) (ADJP (JJ unable) (S (VP (TO to) (VP (VB pinpoint) (S (NP (DT any)) (ADJP (JJ particular)) (S (VP (VBG turning) (NP (NP (NNS points)) (CC or) (NP (JJ pivotal) (NNS events)))))))))))) (: --)) (NP (NNP Thomas)) (VP (`` ``) (VBD became) (S (ADJP (RBR more) (JJ conservative) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD went)))))) (PP (IN through) (NP (NP (DT the) (NN process)) (PP (IN of) (NP (JJ legal) (NN education)))))))) (, ,) ('' '')) (VP (VBD said) (NP (NP (NNP Harry) (NNP Singleton)) (, ,) (NP (DT a) (NN friend)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a friend" type="NP">
          <tokens>
            <token id="49" string="a" />
            <token id="50" string="friend" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` became more conservative as he went through the process of legal education" type="VP">
          <tokens>
            <token id="30" string="&quot;" />
            <token id="31" string="became" />
            <token id="32" string="more" />
            <token id="33" string="conservative" />
            <token id="34" string="as" />
            <token id="35" string="he" />
            <token id="36" string="went" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="process" />
            <token id="40" string="of" />
            <token id="41" string="legal" />
            <token id="42" string="education" />
          </tokens>
        </chunking>
        <chunking id="3" string="went" type="VP">
          <tokens>
            <token id="36" string="went" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Harry Singleton , a friend" type="VP">
          <tokens>
            <token id="45" string="said" />
            <token id="46" string="Harry" />
            <token id="47" string="Singleton" />
            <token id="48" string="," />
            <token id="49" string="a" />
            <token id="50" string="friend" />
          </tokens>
        </chunking>
        <chunking id="5" string="Whatever the reasons -- and his classmates and faculty members at Yale are unable to pinpoint any particular turning points or pivotal events -- Thomas `` became more conservative as he went through the process of legal education" type="SBAR">
          <tokens>
            <token id="5" string="Whatever" />
            <token id="6" string="the" />
            <token id="7" string="reasons" />
            <token id="8" string="--" />
            <token id="9" string="and" />
            <token id="10" string="his" />
            <token id="11" string="classmates" />
            <token id="12" string="and" />
            <token id="13" string="faculty" />
            <token id="14" string="members" />
            <token id="15" string="at" />
            <token id="16" string="Yale" />
            <token id="17" string="are" />
            <token id="18" string="unable" />
            <token id="19" string="to" />
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
            <token id="28" string="--" />
            <token id="29" string="Thomas" />
            <token id="30" string="&quot;" />
            <token id="31" string="became" />
            <token id="32" string="more" />
            <token id="33" string="conservative" />
            <token id="34" string="as" />
            <token id="35" string="he" />
            <token id="36" string="went" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="process" />
            <token id="40" string="of" />
            <token id="41" string="legal" />
            <token id="42" string="education" />
          </tokens>
        </chunking>
        <chunking id="6" string="to pinpoint any particular turning points or pivotal events" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="29" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="Harry Singleton , a friend" type="NP">
          <tokens>
            <token id="46" string="Harry" />
            <token id="47" string="Singleton" />
            <token id="48" string="," />
            <token id="49" string="a" />
            <token id="50" string="friend" />
          </tokens>
        </chunking>
        <chunking id="9" string="any" type="NP">
          <tokens>
            <token id="21" string="any" />
          </tokens>
        </chunking>
        <chunking id="10" string="particular" type="ADJP">
          <tokens>
            <token id="22" string="particular" />
          </tokens>
        </chunking>
        <chunking id="11" string="legal education" type="NP">
          <tokens>
            <token id="41" string="legal" />
            <token id="42" string="education" />
          </tokens>
        </chunking>
        <chunking id="12" string="his classmates and faculty members at Yale" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="classmates" />
            <token id="12" string="and" />
            <token id="13" string="faculty" />
            <token id="14" string="members" />
            <token id="15" string="at" />
            <token id="16" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="13" string="are unable to pinpoint any particular turning points or pivotal events" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="unable" />
            <token id="19" string="to" />
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="14" string="the reasons" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="15" string="points or pivotal events" type="NP">
          <tokens>
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="16" string="Friend 's view" type="NP">
          <tokens>
            <token id="1" string="Friend" />
            <token id="2" string="'s" />
            <token id="3" string="view" />
          </tokens>
        </chunking>
        <chunking id="17" string="as he went" type="SBAR">
          <tokens>
            <token id="34" string="as" />
            <token id="35" string="he" />
            <token id="36" string="went" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="35" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="faculty members" type="NP">
          <tokens>
            <token id="13" string="faculty" />
            <token id="14" string="members" />
          </tokens>
        </chunking>
        <chunking id="20" string="pivotal events" type="NP">
          <tokens>
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="21" string="more conservative as he went" type="ADJP">
          <tokens>
            <token id="32" string="more" />
            <token id="33" string="conservative" />
            <token id="34" string="as" />
            <token id="35" string="he" />
            <token id="36" string="went" />
          </tokens>
        </chunking>
        <chunking id="22" string="turning points or pivotal events" type="VP">
          <tokens>
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="23" string="his classmates" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="classmates" />
          </tokens>
        </chunking>
        <chunking id="24" string="Yale" type="NP">
          <tokens>
            <token id="16" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="25" string="Friend 's" type="NP">
          <tokens>
            <token id="1" string="Friend" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="points" type="NP">
          <tokens>
            <token id="24" string="points" />
          </tokens>
        </chunking>
        <chunking id="27" string="Harry Singleton" type="NP">
          <tokens>
            <token id="46" string="Harry" />
            <token id="47" string="Singleton" />
          </tokens>
        </chunking>
        <chunking id="28" string="pinpoint any particular turning points or pivotal events" type="VP">
          <tokens>
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="29" string="unable to pinpoint any particular turning points or pivotal events" type="ADJP">
          <tokens>
            <token id="18" string="unable" />
            <token id="19" string="to" />
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
          </tokens>
        </chunking>
        <chunking id="30" string="the process" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="process" />
          </tokens>
        </chunking>
        <chunking id="31" string="the process of legal education" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="process" />
            <token id="40" string="of" />
            <token id="41" string="legal" />
            <token id="42" string="education" />
          </tokens>
        </chunking>
        <chunking id="32" string="faculty members at Yale" type="NP">
          <tokens>
            <token id="13" string="faculty" />
            <token id="14" string="members" />
            <token id="15" string="at" />
            <token id="16" string="Yale" />
          </tokens>
        </chunking>
        <chunking id="33" string="Friend 's view ; Whatever the reasons -- and his classmates and faculty members at Yale are unable to pinpoint any particular turning points or pivotal events -- Thomas `` became more conservative as he went through the process of legal education , ''" type="NP">
          <tokens>
            <token id="1" string="Friend" />
            <token id="2" string="'s" />
            <token id="3" string="view" />
            <token id="4" string=";" />
            <token id="5" string="Whatever" />
            <token id="6" string="the" />
            <token id="7" string="reasons" />
            <token id="8" string="--" />
            <token id="9" string="and" />
            <token id="10" string="his" />
            <token id="11" string="classmates" />
            <token id="12" string="and" />
            <token id="13" string="faculty" />
            <token id="14" string="members" />
            <token id="15" string="at" />
            <token id="16" string="Yale" />
            <token id="17" string="are" />
            <token id="18" string="unable" />
            <token id="19" string="to" />
            <token id="20" string="pinpoint" />
            <token id="21" string="any" />
            <token id="22" string="particular" />
            <token id="23" string="turning" />
            <token id="24" string="points" />
            <token id="25" string="or" />
            <token id="26" string="pivotal" />
            <token id="27" string="events" />
            <token id="28" string="--" />
            <token id="29" string="Thomas" />
            <token id="30" string="&quot;" />
            <token id="31" string="became" />
            <token id="32" string="more" />
            <token id="33" string="conservative" />
            <token id="34" string="as" />
            <token id="35" string="he" />
            <token id="36" string="went" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="process" />
            <token id="40" string="of" />
            <token id="41" string="legal" />
            <token id="42" string="education" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">view</governor>
          <dependent id="1">Friend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Friend</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">said</governor>
          <dependent id="3">view</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">conservative</governor>
          <dependent id="5">Whatever</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">reasons</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">became</governor>
          <dependent id="7">reasons</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">unable</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">classmates</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">unable</governor>
          <dependent id="11">classmates</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">classmates</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">members</governor>
          <dependent id="13">faculty</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">classmates</governor>
          <dependent id="14">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Yale</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">members</governor>
          <dependent id="16">Yale</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">unable</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="31">became</governor>
          <dependent id="18">unable</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">pinpoint</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">unable</governor>
          <dependent id="20">pinpoint</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">turning</governor>
          <dependent id="21">any</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">turning</governor>
          <dependent id="22">particular</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">pinpoint</governor>
          <dependent id="23">turning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">turning</governor>
          <dependent id="24">points</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">points</governor>
          <dependent id="25">or</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">events</governor>
          <dependent id="26">pivotal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">points</governor>
          <dependent id="27">events</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">became</governor>
          <dependent id="29">Thomas</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">view</governor>
          <dependent id="31">became</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">conservative</governor>
          <dependent id="32">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">became</governor>
          <dependent id="33">conservative</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">went</governor>
          <dependent id="34">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">went</governor>
          <dependent id="35">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">conservative</governor>
          <dependent id="36">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">process</governor>
          <dependent id="37">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">process</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">became</governor>
          <dependent id="39">process</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">education</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">education</governor>
          <dependent id="41">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">process</governor>
          <dependent id="42">education</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="45">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">Singleton</governor>
          <dependent id="46">Harry</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">said</governor>
          <dependent id="47">Singleton</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">friend</governor>
          <dependent id="49">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="47">Singleton</governor>
          <dependent id="50">friend</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Harry Singleton" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Harry" />
            <token id="47" string="Singleton" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="33" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Yale" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Yale" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>By the time Thomas arrived in Jefferson City, Mo., in 1974 to work for John Danforth, now Thomas&amp;apost; chief supporter in the Senate, then the Republican state attorney general, his attitudes were largely formed.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="arrived" lemma="arrive" stem="arriv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Jefferson" lemma="Jefferson" stem="jefferson" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Mo." lemma="Mo." stem="mo." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="chief" lemma="chief" stem="chief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="supporter" lemma="supporter" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="32" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="general" lemma="general" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="attitudes" lemma="attitude" stem="attitud" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="formed" lemma="form" stem="form" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (NP (NP (DT the) (NN time)) (SBAR (S (NP (NNP Thomas)) (VP (VBD arrived) (PP (IN in) (NP (NP (NNP Jefferson) (NNP City)) (, ,) (NP (NNP Mo.)) (, ,))) (PP (IN in) (NP (CD 1974))) (S (VP (TO to) (VP (VB work) (PP (IN for) (NP (NP (NNP John) (NNP Danforth)) (, ,) (ADVP (RB now)) (NP (NP (NP (NNP Thomas) (POS ')) (JJ chief) (NN supporter)) (PP (IN in) (NP (DT the) (NNP Senate))))))))))))) (, ,) (RB then) (NP (DT the) (JJ Republican) (NN state) (NN attorney) (NN general)))) (, ,) (NP (PRP$ his) (NNS attitudes)) (VP (VBD were) (ADJP (RB largely) (VBN formed))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the time Thomas arrived in Jefferson City , Mo. , in 1974 to work for John Danforth , now Thomas ' chief supporter in the Senate , then the Republican state attorney general" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
            <token id="4" string="Thomas" />
            <token id="5" string="arrived" />
            <token id="6" string="in" />
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
            <token id="9" string="," />
            <token id="10" string="Mo." />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="1974" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
            <token id="28" string="," />
            <token id="29" string="then" />
            <token id="30" string="the" />
            <token id="31" string="Republican" />
            <token id="32" string="state" />
            <token id="33" string="attorney" />
            <token id="34" string="general" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas ' chief supporter in the Senate" type="NP">
          <tokens>
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Republican state attorney general" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Republican" />
            <token id="32" string="state" />
            <token id="33" string="attorney" />
            <token id="34" string="general" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas '" type="NP">
          <tokens>
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mo." type="NP">
          <tokens>
            <token id="10" string="Mo." />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas ' chief supporter" type="NP">
          <tokens>
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
          </tokens>
        </chunking>
        <chunking id="8" string="his attitudes" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="9" string="arrived in Jefferson City , Mo. , in 1974 to work for John Danforth , now Thomas ' chief supporter in the Senate" type="VP">
          <tokens>
            <token id="5" string="arrived" />
            <token id="6" string="in" />
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
            <token id="9" string="," />
            <token id="10" string="Mo." />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="1974" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jefferson City , Mo. ," type="NP">
          <tokens>
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
            <token id="9" string="," />
            <token id="10" string="Mo." />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="1974" type="NP">
          <tokens>
            <token id="13" string="1974" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Senate" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="13" string="John Danforth , now Thomas ' chief supporter in the Senate" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="14" string="to work for John Danforth , now Thomas ' chief supporter in the Senate" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="15" string="the time" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="work for John Danforth , now Thomas ' chief supporter in the Senate" type="VP">
          <tokens>
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="17" string="Jefferson City" type="NP">
          <tokens>
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
          </tokens>
        </chunking>
        <chunking id="18" string="the time Thomas arrived in Jefferson City , Mo. , in 1974 to work for John Danforth , now Thomas ' chief supporter in the Senate" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
            <token id="4" string="Thomas" />
            <token id="5" string="arrived" />
            <token id="6" string="in" />
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
            <token id="9" string="," />
            <token id="10" string="Mo." />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="1974" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="19" string="were largely formed" type="VP">
          <tokens>
            <token id="38" string="were" />
            <token id="39" string="largely" />
            <token id="40" string="formed" />
          </tokens>
        </chunking>
        <chunking id="20" string="John Danforth" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="21" string="largely formed" type="ADJP">
          <tokens>
            <token id="39" string="largely" />
            <token id="40" string="formed" />
          </tokens>
        </chunking>
        <chunking id="22" string="Thomas arrived in Jefferson City , Mo. , in 1974 to work for John Danforth , now Thomas ' chief supporter in the Senate" type="SBAR">
          <tokens>
            <token id="4" string="Thomas" />
            <token id="5" string="arrived" />
            <token id="6" string="in" />
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
            <token id="9" string="," />
            <token id="10" string="Mo." />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="1974" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
            <token id="19" string="," />
            <token id="20" string="now" />
            <token id="21" string="Thomas" />
            <token id="22" string="'" />
            <token id="23" string="chief" />
            <token id="24" string="supporter" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Senate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">time</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">time</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">formed</governor>
          <dependent id="3">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">arrived</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">time</governor>
          <dependent id="5">arrived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">City</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">City</governor>
          <dependent id="7">Jefferson</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arrived</governor>
          <dependent id="8">City</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">City</governor>
          <dependent id="10">Mo.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1974</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arrived</governor>
          <dependent id="13">1974</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">work</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">arrived</governor>
          <dependent id="15">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Danforth</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Danforth</governor>
          <dependent id="17">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">work</governor>
          <dependent id="18">Danforth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">supporter</governor>
          <dependent id="20">now</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">supporter</governor>
          <dependent id="21">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Thomas</governor>
          <dependent id="22">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">supporter</governor>
          <dependent id="23">chief</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Danforth</governor>
          <dependent id="24">supporter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Senate</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Senate</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">supporter</governor>
          <dependent id="27">Senate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">general</governor>
          <dependent id="29">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">general</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">general</governor>
          <dependent id="31">Republican</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">general</governor>
          <dependent id="32">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">general</governor>
          <dependent id="33">attorney</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">time</governor>
          <dependent id="34">general</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">attitudes</governor>
          <dependent id="36">his</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="40">formed</governor>
          <dependent id="37">attitudes</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">formed</governor>
          <dependent id="38">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">formed</governor>
          <dependent id="39">largely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="40">formed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1974" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="31" string="Republican" />
          </tokens>
        </entity>
        <entity id="6" string="Jefferson City" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Jefferson" />
            <token id="8" string="City" />
          </tokens>
        </entity>
        <entity id="7" string="Mo." type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Mo." />
          </tokens>
        </entity>
        <entity id="8" string="John Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Danforth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;His philosophy by that point was that he felt that this country was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude,&amp;quot; said lawyer Harvey Tettlebaum, who worked with Thomas.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="affording" lemma="afford" stem="afford" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="opportunities" lemma="opportunity" stem="opportun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="rely" lemma="rely" stem="reli" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="nature" lemma="nature" stem="natur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="servitude" lemma="servitude" stem="servitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="Harvey" lemma="Harvey" stem="harvei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string="Tettlebaum" lemma="Tettlebaum" stem="tettlebaum" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="worked" lemma="work" stem="work" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (PRP$ His) (NN philosophy)) (PP (IN by) (NP (DT that) (NN point)))) (VP (VBD was) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD felt) (SBAR (IN that) (S (NP (DT this) (NN country)) (VP (VBD was) (VP (VBG affording) (NP (NNS people) (NNS opportunities)) (SBAR (SBAR (IN if) (S (NP (PRP they)) (VP (VBD were) (ADJP (JJ willing) (S (VP (TO to) (VP (VB work)))))))) (CC and) (SBAR (IN that) (S (S (VP (TO to) (VP (VB rely) (PP (IN on) (NP (NN government)))))) (VP (VBD was) (PP (IN in) (NP (NP (DT the) (NN nature)) (PP (IN of) (NP (NN servitude)))))))))))))))))) (, ,) ('' '') (VP (VBD said) (NP (NN lawyer))) (NP (NP (NNP Harvey) (NNP Tettlebaum)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD worked) (PP (IN with) (NP (NNP Thomas))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="servitude" type="NP">
          <tokens>
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="2" string="that to rely on government was in the nature of servitude" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="3" string="rely on government" type="VP">
          <tokens>
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
          </tokens>
        </chunking>
        <chunking id="4" string="that he felt that this country was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="felt" />
            <token id="11" string="that" />
            <token id="12" string="this" />
            <token id="13" string="country" />
            <token id="14" string="was" />
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="5" string="to work" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="work" />
          </tokens>
        </chunking>
        <chunking id="6" string="said lawyer" type="VP">
          <tokens>
            <token id="38" string="said" />
            <token id="39" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="7" string="that point" type="NP">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="point" />
          </tokens>
        </chunking>
        <chunking id="8" string="affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="VP">
          <tokens>
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="9" string="work" type="VP">
          <tokens>
            <token id="23" string="work" />
          </tokens>
        </chunking>
        <chunking id="10" string="Thomas" type="NP">
          <tokens>
            <token id="46" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="11" string="if they were willing to work" type="SBAR">
          <tokens>
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
          </tokens>
        </chunking>
        <chunking id="12" string="who worked with Thomas" type="SBAR">
          <tokens>
            <token id="43" string="who" />
            <token id="44" string="worked" />
            <token id="45" string="with" />
            <token id="46" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="13" string="to rely on government" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
          </tokens>
        </chunking>
        <chunking id="14" string="worked with Thomas" type="VP">
          <tokens>
            <token id="44" string="worked" />
            <token id="45" string="with" />
            <token id="46" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="15" string="His philosophy by that point" type="NP">
          <tokens>
            <token id="2" string="His" />
            <token id="3" string="philosophy" />
            <token id="4" string="by" />
            <token id="5" string="that" />
            <token id="6" string="point" />
          </tokens>
        </chunking>
        <chunking id="16" string="if they were willing to work and that to rely on government was in the nature of servitude" type="SBAR">
          <tokens>
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="17" string="willing to work" type="ADJP">
          <tokens>
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
          </tokens>
        </chunking>
        <chunking id="18" string="Harvey Tettlebaum" type="NP">
          <tokens>
            <token id="40" string="Harvey" />
            <token id="41" string="Tettlebaum" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="were willing to work" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
          </tokens>
        </chunking>
        <chunking id="21" string="His philosophy" type="NP">
          <tokens>
            <token id="2" string="His" />
            <token id="3" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="22" string="was that he felt that this country was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="felt" />
            <token id="11" string="that" />
            <token id="12" string="this" />
            <token id="13" string="country" />
            <token id="14" string="was" />
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="23" string="the nature" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="nature" />
          </tokens>
        </chunking>
        <chunking id="24" string="Harvey Tettlebaum , who worked with Thomas" type="NP">
          <tokens>
            <token id="40" string="Harvey" />
            <token id="41" string="Tettlebaum" />
            <token id="42" string="," />
            <token id="43" string="who" />
            <token id="44" string="worked" />
            <token id="45" string="with" />
            <token id="46" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="25" string="that this country was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="this" />
            <token id="13" string="country" />
            <token id="14" string="was" />
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="26" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="27" string="this country" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="28" string="government" type="NP">
          <tokens>
            <token id="29" string="government" />
          </tokens>
        </chunking>
        <chunking id="29" string="the nature of servitude" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="30" string="was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="31" string="people opportunities" type="NP">
          <tokens>
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
          </tokens>
        </chunking>
        <chunking id="32" string="was in the nature of servitude" type="VP">
          <tokens>
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
        <chunking id="33" string="lawyer" type="NP">
          <tokens>
            <token id="39" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="34" string="felt that this country was affording people opportunities if they were willing to work and that to rely on government was in the nature of servitude" type="VP">
          <tokens>
            <token id="10" string="felt" />
            <token id="11" string="that" />
            <token id="12" string="this" />
            <token id="13" string="country" />
            <token id="14" string="was" />
            <token id="15" string="affording" />
            <token id="16" string="people" />
            <token id="17" string="opportunities" />
            <token id="18" string="if" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="willing" />
            <token id="22" string="to" />
            <token id="23" string="work" />
            <token id="24" string="and" />
            <token id="25" string="that" />
            <token id="26" string="to" />
            <token id="27" string="rely" />
            <token id="28" string="on" />
            <token id="29" string="government" />
            <token id="30" string="was" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="nature" />
            <token id="34" string="of" />
            <token id="35" string="servitude" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">philosophy</governor>
          <dependent id="2">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">was</governor>
          <dependent id="3">philosophy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">point</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">point</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">philosophy</governor>
          <dependent id="6">point</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="38">said</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">felt</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">felt</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">was</governor>
          <dependent id="10">felt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">affording</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">country</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">affording</governor>
          <dependent id="13">country</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">affording</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">felt</governor>
          <dependent id="15">affording</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">opportunities</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">affording</governor>
          <dependent id="17">opportunities</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">willing</governor>
          <dependent id="18">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">willing</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">willing</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">affording</governor>
          <dependent id="21">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">work</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">willing</governor>
          <dependent id="23">work</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">willing</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">nature</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">rely</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="33">nature</governor>
          <dependent id="27">rely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">government</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">rely</governor>
          <dependent id="29">government</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">nature</governor>
          <dependent id="30">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">nature</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">nature</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">willing</governor>
          <dependent id="33">nature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">servitude</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">nature</governor>
          <dependent id="35">servitude</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">said</governor>
          <dependent id="39">lawyer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Tettlebaum</governor>
          <dependent id="40">Harvey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">said</governor>
          <dependent id="41">Tettlebaum</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">worked</governor>
          <dependent id="43">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="41">Tettlebaum</governor>
          <dependent id="44">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Thomas</governor>
          <dependent id="45">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">worked</governor>
          <dependent id="46">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Harvey Tettlebaum" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Harvey" />
            <token id="41" string="Tettlebaum" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Several years later he captured the attention of the Reagan transition team, which offered a civil rights job to a reluctant Thomas.</content>
      <tokens>
        <token id="1" string="Several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="captured" lemma="capture" stem="captur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="transition" lemma="transition" stem="transit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="offered" lemma="offer" stem="offer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reluctant" lemma="reluctant" stem="reluct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (JJ Several) (NNS years)) (RB later)) (NP (PRP he)) (VP (VBD captured) (NP (NP (DT the) (NN attention)) (PP (IN of) (NP (NP (DT the) (NNP Reagan) (NN transition) (NN team)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD offered) (NP (DT a) (JJ civil) (NNS rights) (NN job)) (PP (TO to) (NP (DT a) (JJ reluctant) (NNP Thomas)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Reagan transition team" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="transition" />
            <token id="12" string="team" />
          </tokens>
        </chunking>
        <chunking id="2" string="captured the attention of the Reagan transition team , which offered a civil rights job to a reluctant Thomas" type="VP">
          <tokens>
            <token id="5" string="captured" />
            <token id="6" string="the" />
            <token id="7" string="attention" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="transition" />
            <token id="12" string="team" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="offered" />
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
            <token id="20" string="to" />
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="the attention of the Reagan transition team , which offered a civil rights job to a reluctant Thomas" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="attention" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="transition" />
            <token id="12" string="team" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="offered" />
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
            <token id="20" string="to" />
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="Several years" type="NP">
          <tokens>
            <token id="1" string="Several" />
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="the attention" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="attention" />
          </tokens>
        </chunking>
        <chunking id="6" string="a civil rights job" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="a reluctant Thomas" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Reagan transition team , which offered a civil rights job to a reluctant Thomas" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Reagan" />
            <token id="11" string="transition" />
            <token id="12" string="team" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="offered" />
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
            <token id="20" string="to" />
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="9" string="which offered a civil rights job to a reluctant Thomas" type="SBAR">
          <tokens>
            <token id="14" string="which" />
            <token id="15" string="offered" />
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
            <token id="20" string="to" />
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="offered a civil rights job to a reluctant Thomas" type="VP">
          <tokens>
            <token id="15" string="offered" />
            <token id="16" string="a" />
            <token id="17" string="civil" />
            <token id="18" string="rights" />
            <token id="19" string="job" />
            <token id="20" string="to" />
            <token id="21" string="a" />
            <token id="22" string="reluctant" />
            <token id="23" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">years</governor>
          <dependent id="1">Several</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">later</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">captured</governor>
          <dependent id="3">later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">captured</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">captured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">attention</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">captured</governor>
          <dependent id="7">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">team</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">team</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">team</governor>
          <dependent id="10">Reagan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">team</governor>
          <dependent id="11">transition</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">attention</governor>
          <dependent id="12">team</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">offered</governor>
          <dependent id="14">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">team</governor>
          <dependent id="15">offered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">job</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">job</governor>
          <dependent id="17">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">job</governor>
          <dependent id="18">rights</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">offered</governor>
          <dependent id="19">job</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Thomas</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Thomas</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Thomas</governor>
          <dependent id="22">reluctant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">offered</governor>
          <dependent id="23">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Several years later" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Several" />
            <token id="2" string="years" />
            <token id="3" string="later" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>His friends urged him not to shun a rare opportunity to make policy, and he accepted successive jobs as assistant secretary of education for civil rights and chairman of the Equal Employment Opportunity Commission.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="urged" lemma="urge" stem="urg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="shun" lemma="shun" stem="shun" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="opportunity" lemma="opportunity" stem="opportun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="accepted" lemma="accept" stem="accept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="successive" lemma="successive" stem="success" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Equal" lemma="Equal" stem="equal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Employment" lemma="Employment" stem="employment" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="Opportunity" lemma="Opportunity" stem="opportun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ His) (NNS friends)) (VP (VBD urged) (S (NP (PRP him)) (RB not) (VP (TO to) (VP (VB shun) (NP (DT a) (JJ rare) (NN opportunity)) (S (VP (TO to) (VP (VB make) (NP (NN policy)))))))))) (, ,) (CC and) (S (NP (PRP he)) (VP (VBD accepted) (NP (JJ successive) (NNS jobs)) (PP (IN as) (NP (NP (NN assistant) (NN secretary)) (PP (IN of) (NP (NN education))))) (PP (IN for) (NP (NP (JJ civil) (NNS rights)) (CC and) (NP (NP (NN chairman)) (PP (IN of) (NP (DT the) (NNP Equal) (NNP Employment) (NNP Opportunity) (NNP Commission)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="urged him not to shun a rare opportunity to make policy" type="VP">
          <tokens>
            <token id="3" string="urged" />
            <token id="4" string="him" />
            <token id="5" string="not" />
            <token id="6" string="to" />
            <token id="7" string="shun" />
            <token id="8" string="a" />
            <token id="9" string="rare" />
            <token id="10" string="opportunity" />
            <token id="11" string="to" />
            <token id="12" string="make" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="2" string="assistant secretary of education" type="NP">
          <tokens>
            <token id="21" string="assistant" />
            <token id="22" string="secretary" />
            <token id="23" string="of" />
            <token id="24" string="education" />
          </tokens>
        </chunking>
        <chunking id="3" string="to make policy" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="make" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="assistant secretary" type="NP">
          <tokens>
            <token id="21" string="assistant" />
            <token id="22" string="secretary" />
          </tokens>
        </chunking>
        <chunking id="6" string="chairman of the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="29" string="chairman" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Equal" />
            <token id="33" string="Employment" />
            <token id="34" string="Opportunity" />
            <token id="35" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="7" string="successive jobs" type="NP">
          <tokens>
            <token id="18" string="successive" />
            <token id="19" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="8" string="chairman" type="NP">
          <tokens>
            <token id="29" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="9" string="a rare opportunity" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="rare" />
            <token id="10" string="opportunity" />
          </tokens>
        </chunking>
        <chunking id="10" string="education" type="NP">
          <tokens>
            <token id="24" string="education" />
          </tokens>
        </chunking>
        <chunking id="11" string="shun a rare opportunity to make policy" type="VP">
          <tokens>
            <token id="7" string="shun" />
            <token id="8" string="a" />
            <token id="9" string="rare" />
            <token id="10" string="opportunity" />
            <token id="11" string="to" />
            <token id="12" string="make" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="12" string="civil rights and chairman of the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="26" string="civil" />
            <token id="27" string="rights" />
            <token id="28" string="and" />
            <token id="29" string="chairman" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Equal" />
            <token id="33" string="Employment" />
            <token id="34" string="Opportunity" />
            <token id="35" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="13" string="accepted successive jobs as assistant secretary of education for civil rights and chairman of the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="17" string="accepted" />
            <token id="18" string="successive" />
            <token id="19" string="jobs" />
            <token id="20" string="as" />
            <token id="21" string="assistant" />
            <token id="22" string="secretary" />
            <token id="23" string="of" />
            <token id="24" string="education" />
            <token id="25" string="for" />
            <token id="26" string="civil" />
            <token id="27" string="rights" />
            <token id="28" string="and" />
            <token id="29" string="chairman" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Equal" />
            <token id="33" string="Employment" />
            <token id="34" string="Opportunity" />
            <token id="35" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="14" string="civil rights" type="NP">
          <tokens>
            <token id="26" string="civil" />
            <token id="27" string="rights" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="Equal" />
            <token id="33" string="Employment" />
            <token id="34" string="Opportunity" />
            <token id="35" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="16" string="His friends" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="friends" />
          </tokens>
        </chunking>
        <chunking id="17" string="make policy" type="VP">
          <tokens>
            <token id="12" string="make" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="18" string="policy" type="NP">
          <tokens>
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="to shun a rare opportunity to make policy" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="shun" />
            <token id="8" string="a" />
            <token id="9" string="rare" />
            <token id="10" string="opportunity" />
            <token id="11" string="to" />
            <token id="12" string="make" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">friends</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">urged</governor>
          <dependent id="2">friends</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">urged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">urged</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">shun</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">shun</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">urged</governor>
          <dependent id="7">shun</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">opportunity</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">opportunity</governor>
          <dependent id="9">rare</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">shun</governor>
          <dependent id="10">opportunity</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">make</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">shun</governor>
          <dependent id="12">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">make</governor>
          <dependent id="13">policy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">urged</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">accepted</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">urged</governor>
          <dependent id="17">accepted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">jobs</governor>
          <dependent id="18">successive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">accepted</governor>
          <dependent id="19">jobs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">secretary</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">secretary</governor>
          <dependent id="21">assistant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">accepted</governor>
          <dependent id="22">secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">education</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">secretary</governor>
          <dependent id="24">education</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">rights</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">rights</governor>
          <dependent id="26">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">accepted</governor>
          <dependent id="27">rights</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">rights</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">rights</governor>
          <dependent id="29">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Commission</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Commission</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Commission</governor>
          <dependent id="32">Equal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Commission</governor>
          <dependent id="33">Employment</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Commission</governor>
          <dependent id="34">Opportunity</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">chairman</governor>
          <dependent id="35">Commission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Equal Employment Opportunity Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="32" string="Equal" />
            <token id="33" string="Employment" />
            <token id="34" string="Opportunity" />
            <token id="35" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>A colorblind Constitution; In those jobs, Thomas began questioning preferences in jobs and education for racial minorities who had historically suffered discrimination.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="colorblind" lemma="colorblind" stem="colorblind" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="preferences" lemma="preference" stem="prefer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="historically" lemma="historically" stem="histor" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="suffered" lemma="suffer" stem="suffer" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT A) (JJ colorblind) (NNP Constitution)) (: ;) (S (PP (IN In) (NP (DT those) (NNS jobs))) (, ,) (NP (NNP Thomas)) (VP (VBD began) (S (VP (VBG questioning) (NP (NP (NNS preferences)) (PP (IN in) (NP (NNS jobs) (CC and) (NN education)))) (PP (IN for) (NP (NP (JJ racial) (NNS minorities)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (ADVP (RB historically)) (VP (VBN suffered) (NP (NN discrimination)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="questioning preferences in jobs and education for racial minorities who had historically suffered discrimination" type="VP">
          <tokens>
            <token id="11" string="questioning" />
            <token id="12" string="preferences" />
            <token id="13" string="in" />
            <token id="14" string="jobs" />
            <token id="15" string="and" />
            <token id="16" string="education" />
            <token id="17" string="for" />
            <token id="18" string="racial" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="2" string="suffered discrimination" type="VP">
          <tokens>
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="racial minorities who had historically suffered discrimination" type="NP">
          <tokens>
            <token id="18" string="racial" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="5" string="preferences" type="NP">
          <tokens>
            <token id="12" string="preferences" />
          </tokens>
        </chunking>
        <chunking id="6" string="jobs and education" type="NP">
          <tokens>
            <token id="14" string="jobs" />
            <token id="15" string="and" />
            <token id="16" string="education" />
          </tokens>
        </chunking>
        <chunking id="7" string="racial minorities" type="NP">
          <tokens>
            <token id="18" string="racial" />
            <token id="19" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="8" string="A colorblind Constitution ; In those jobs , Thomas began questioning preferences in jobs and education for racial minorities who had historically suffered discrimination ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="colorblind" />
            <token id="3" string="Constitution" />
            <token id="4" string=";" />
            <token id="5" string="In" />
            <token id="6" string="those" />
            <token id="7" string="jobs" />
            <token id="8" string="," />
            <token id="9" string="Thomas" />
            <token id="10" string="began" />
            <token id="11" string="questioning" />
            <token id="12" string="preferences" />
            <token id="13" string="in" />
            <token id="14" string="jobs" />
            <token id="15" string="and" />
            <token id="16" string="education" />
            <token id="17" string="for" />
            <token id="18" string="racial" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
            <token id="25" string="." />
          </tokens>
        </chunking>
        <chunking id="9" string="A colorblind Constitution" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="colorblind" />
            <token id="3" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="10" string="preferences in jobs and education" type="NP">
          <tokens>
            <token id="12" string="preferences" />
            <token id="13" string="in" />
            <token id="14" string="jobs" />
            <token id="15" string="and" />
            <token id="16" string="education" />
          </tokens>
        </chunking>
        <chunking id="11" string="those jobs" type="NP">
          <tokens>
            <token id="6" string="those" />
            <token id="7" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="12" string="began questioning preferences in jobs and education for racial minorities who had historically suffered discrimination" type="VP">
          <tokens>
            <token id="10" string="began" />
            <token id="11" string="questioning" />
            <token id="12" string="preferences" />
            <token id="13" string="in" />
            <token id="14" string="jobs" />
            <token id="15" string="and" />
            <token id="16" string="education" />
            <token id="17" string="for" />
            <token id="18" string="racial" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="13" string="discrimination" type="NP">
          <tokens>
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="14" string="had historically suffered discrimination" type="VP">
          <tokens>
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
        <chunking id="15" string="who had historically suffered discrimination" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="had" />
            <token id="22" string="historically" />
            <token id="23" string="suffered" />
            <token id="24" string="discrimination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Constitution</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Constitution</governor>
          <dependent id="2">colorblind</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Constitution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">jobs</governor>
          <dependent id="5">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">jobs</governor>
          <dependent id="6">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">began</governor>
          <dependent id="7">jobs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">began</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">Constitution</governor>
          <dependent id="10">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">began</governor>
          <dependent id="11">questioning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">questioning</governor>
          <dependent id="12">preferences</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">jobs</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">preferences</governor>
          <dependent id="14">jobs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">jobs</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">jobs</governor>
          <dependent id="16">education</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">minorities</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">minorities</governor>
          <dependent id="18">racial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">questioning</governor>
          <dependent id="19">minorities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">suffered</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">suffered</governor>
          <dependent id="21">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">suffered</governor>
          <dependent id="22">historically</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">minorities</governor>
          <dependent id="23">suffered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">suffered</governor>
          <dependent id="24">discrimination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Later, he began openly opposing such preferences, denouncing the Supreme Court decisions that upheld them and calling for a colorblind Constitution.</content>
      <tokens>
        <token id="1" string="Later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="opposing" lemma="oppose" stem="oppos" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="preferences" lemma="preference" stem="prefer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="denouncing" lemma="denounce" stem="denounc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="upheld" lemma="uphold" stem="upheld" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="colorblind" lemma="colorblind" stem="colorblind" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Later)) (, ,) (NP (PRP he)) (VP (VBD began) (S (VP (VP (ADVP (RB openly)) (VBG opposing) (NP (JJ such) (NNS preferences))) (, ,) (VP (VBG denouncing) (NP (NP (DT the) (NNP Supreme) (NNP Court) (NNS decisions)) (SBAR (WHNP (WDT that)) (S (VP (VBD upheld) (NP (PRP them))))))) (CC and) (VP (VBG calling) (PP (IN for) (NP (DT a) (JJ colorblind) (NNP Constitution))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="upheld them" type="VP">
          <tokens>
            <token id="16" string="upheld" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="such preferences" type="NP">
          <tokens>
            <token id="7" string="such" />
            <token id="8" string="preferences" />
          </tokens>
        </chunking>
        <chunking id="3" string="openly opposing such preferences , denouncing the Supreme Court decisions that upheld them and calling for a colorblind Constitution" type="VP">
          <tokens>
            <token id="5" string="openly" />
            <token id="6" string="opposing" />
            <token id="7" string="such" />
            <token id="8" string="preferences" />
            <token id="9" string="," />
            <token id="10" string="denouncing" />
            <token id="11" string="the" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="decisions" />
            <token id="15" string="that" />
            <token id="16" string="upheld" />
            <token id="17" string="them" />
            <token id="18" string="and" />
            <token id="19" string="calling" />
            <token id="20" string="for" />
            <token id="21" string="a" />
            <token id="22" string="colorblind" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Supreme Court decisions that upheld them" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="decisions" />
            <token id="15" string="that" />
            <token id="16" string="upheld" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="a colorblind Constitution" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="colorblind" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="openly opposing such preferences" type="VP">
          <tokens>
            <token id="5" string="openly" />
            <token id="6" string="opposing" />
            <token id="7" string="such" />
            <token id="8" string="preferences" />
          </tokens>
        </chunking>
        <chunking id="8" string="began openly opposing such preferences , denouncing the Supreme Court decisions that upheld them and calling for a colorblind Constitution" type="VP">
          <tokens>
            <token id="4" string="began" />
            <token id="5" string="openly" />
            <token id="6" string="opposing" />
            <token id="7" string="such" />
            <token id="8" string="preferences" />
            <token id="9" string="," />
            <token id="10" string="denouncing" />
            <token id="11" string="the" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="decisions" />
            <token id="15" string="that" />
            <token id="16" string="upheld" />
            <token id="17" string="them" />
            <token id="18" string="and" />
            <token id="19" string="calling" />
            <token id="20" string="for" />
            <token id="21" string="a" />
            <token id="22" string="colorblind" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="that upheld them" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="upheld" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="calling for a colorblind Constitution" type="VP">
          <tokens>
            <token id="19" string="calling" />
            <token id="20" string="for" />
            <token id="21" string="a" />
            <token id="22" string="colorblind" />
            <token id="23" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Supreme Court decisions" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="12" string="denouncing the Supreme Court decisions that upheld them" type="VP">
          <tokens>
            <token id="10" string="denouncing" />
            <token id="11" string="the" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="decisions" />
            <token id="15" string="that" />
            <token id="16" string="upheld" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">began</governor>
          <dependent id="1">Later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">began</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">began</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">opposing</governor>
          <dependent id="5">openly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">began</governor>
          <dependent id="6">opposing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">preferences</governor>
          <dependent id="7">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">opposing</governor>
          <dependent id="8">preferences</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">opposing</governor>
          <dependent id="10">denouncing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">decisions</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">decisions</governor>
          <dependent id="12">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">decisions</governor>
          <dependent id="13">Court</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">denouncing</governor>
          <dependent id="14">decisions</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">upheld</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">decisions</governor>
          <dependent id="16">upheld</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">upheld</governor>
          <dependent id="17">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">opposing</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">opposing</governor>
          <dependent id="19">calling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Constitution</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Constitution</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Constitution</governor>
          <dependent id="22">colorblind</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">calling</governor>
          <dependent id="23">Constitution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Some critics cynically attribute his ideological metamorphosis to opportunism.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cynically" lemma="cynically" stem="cynic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="attribute" lemma="attribute" stem="attribut" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="ideological" lemma="ideological" stem="ideolog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="metamorphosis" lemma="metamorphosis" stem="metamorphosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="opportunism" lemma="opportunism" stem="opportun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (NNS critics)) (ADVP (RB cynically)) (VP (VBP attribute) (NP (PRP$ his) (JJ ideological) (NN metamorphosis)) (PP (TO to) (NP (NN opportunism)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his ideological metamorphosis" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="ideological" />
            <token id="7" string="metamorphosis" />
          </tokens>
        </chunking>
        <chunking id="2" string="attribute his ideological metamorphosis to opportunism" type="VP">
          <tokens>
            <token id="4" string="attribute" />
            <token id="5" string="his" />
            <token id="6" string="ideological" />
            <token id="7" string="metamorphosis" />
            <token id="8" string="to" />
            <token id="9" string="opportunism" />
          </tokens>
        </chunking>
        <chunking id="3" string="opportunism" type="NP">
          <tokens>
            <token id="9" string="opportunism" />
          </tokens>
        </chunking>
        <chunking id="4" string="Some critics" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="critics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">critics</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">attribute</governor>
          <dependent id="2">critics</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">attribute</governor>
          <dependent id="3">cynically</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">attribute</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">metamorphosis</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">metamorphosis</governor>
          <dependent id="6">ideological</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">attribute</governor>
          <dependent id="7">metamorphosis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">opportunism</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">attribute</governor>
          <dependent id="9">opportunism</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Thomas, who has declined to be interviewed since his Supreme Court nomination, has not responded.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="declined" lemma="decline" stem="declin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="interviewed" lemma="interview" stem="interview" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="12" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="13" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="responded" lemma="respond" stem="respond" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN declined) (S (VP (TO to) (VP (VB be) (VP (VBN interviewed) (PP (IN since) (NP (PRP$ his) (NNP Supreme) (NNP Court) (NN nomination))))))))))) (, ,)) (VP (VBZ has) (RB not) (VP (VBN responded))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who has declined to be interviewed since his Supreme Court nomination" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="has" />
            <token id="5" string="declined" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="2" string="interviewed since his Supreme Court nomination" type="VP">
          <tokens>
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="responded" type="VP">
          <tokens>
            <token id="17" string="responded" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas , who has declined to be interviewed since his Supreme Court nomination ," type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="has" />
            <token id="5" string="declined" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="declined to be interviewed since his Supreme Court nomination" type="VP">
          <tokens>
            <token id="5" string="declined" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="7" string="be interviewed since his Supreme Court nomination" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="8" string="his Supreme Court nomination" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="9" string="to be interviewed since his Supreme Court nomination" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="10" string="has declined to be interviewed since his Supreme Court nomination" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="declined" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="interviewed" />
            <token id="9" string="since" />
            <token id="10" string="his" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="11" string="has not responded" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="not" />
            <token id="17" string="responded" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="17">responded</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">declined</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">declined</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Thomas</governor>
          <dependent id="5">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">interviewed</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">interviewed</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">declined</governor>
          <dependent id="8">interviewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">nomination</governor>
          <dependent id="9">since</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">nomination</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">nomination</governor>
          <dependent id="11">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">nomination</governor>
          <dependent id="12">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">interviewed</governor>
          <dependent id="13">nomination</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">responded</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">responded</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">responded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>But he has offered an explanation for his political change of heart.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="offered" lemma="offer" stem="offer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="explanation" lemma="explanation" stem="explan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (VP (VBZ has) (VP (VBN offered) (NP (NP (DT an) (NN explanation)) (PP (IN for) (NP (NP (PRP$ his) (JJ political) (NN change)) (PP (IN of) (NP (NN heart)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has offered an explanation for his political change of heart" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="offered" />
            <token id="5" string="an" />
            <token id="6" string="explanation" />
            <token id="7" string="for" />
            <token id="8" string="his" />
            <token id="9" string="political" />
            <token id="10" string="change" />
            <token id="11" string="of" />
            <token id="12" string="heart" />
          </tokens>
        </chunking>
        <chunking id="2" string="an explanation" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="explanation" />
          </tokens>
        </chunking>
        <chunking id="3" string="his political change" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="political" />
            <token id="10" string="change" />
          </tokens>
        </chunking>
        <chunking id="4" string="an explanation for his political change of heart" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="explanation" />
            <token id="7" string="for" />
            <token id="8" string="his" />
            <token id="9" string="political" />
            <token id="10" string="change" />
            <token id="11" string="of" />
            <token id="12" string="heart" />
          </tokens>
        </chunking>
        <chunking id="5" string="offered an explanation for his political change of heart" type="VP">
          <tokens>
            <token id="4" string="offered" />
            <token id="5" string="an" />
            <token id="6" string="explanation" />
            <token id="7" string="for" />
            <token id="8" string="his" />
            <token id="9" string="political" />
            <token id="10" string="change" />
            <token id="11" string="of" />
            <token id="12" string="heart" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="his political change of heart" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="political" />
            <token id="10" string="change" />
            <token id="11" string="of" />
            <token id="12" string="heart" />
          </tokens>
        </chunking>
        <chunking id="8" string="heart" type="NP">
          <tokens>
            <token id="12" string="heart" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">offered</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">offered</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">offered</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">offered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">explanation</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">offered</governor>
          <dependent id="6">explanation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">change</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">change</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">change</governor>
          <dependent id="9">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">explanation</governor>
          <dependent id="10">change</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">heart</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">change</governor>
          <dependent id="12">heart</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>In handwritten notes from his files, he recalled telling his Democratic grandparents why he had turned Republican.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="handwritten" lemma="handwritten" stem="handwritten" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="notes" lemma="note" stem="note" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="files" lemma="file" stem="file" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Republican" lemma="Republican" stem="republican" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (JJ handwritten) (NNS notes)) (PP (IN from) (NP (PRP$ his) (NNS files))))) (, ,) (NP (PRP he)) (VP (VBD recalled) (S (VP (VBG telling) (NP (PRP$ his) (JJ Democratic) (NNS grandparents)) (SBAR (WHADVP (WRB why)) (S (NP (PRP he)) (VP (VBD had) (VP (VBN turned) (NP (NNP Republican))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="recalled telling his Democratic grandparents why he had turned Republican" type="VP">
          <tokens>
            <token id="9" string="recalled" />
            <token id="10" string="telling" />
            <token id="11" string="his" />
            <token id="12" string="Democratic" />
            <token id="13" string="grandparents" />
            <token id="14" string="why" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="turned" />
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="2" string="his Democratic grandparents" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="Democratic" />
            <token id="13" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="3" string="why he had turned Republican" type="SBAR">
          <tokens>
            <token id="14" string="why" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="turned" />
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="4" string="handwritten notes" type="NP">
          <tokens>
            <token id="2" string="handwritten" />
            <token id="3" string="notes" />
          </tokens>
        </chunking>
        <chunking id="5" string="had turned Republican" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="turned" />
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="6" string="his files" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="files" />
          </tokens>
        </chunking>
        <chunking id="7" string="why" type="WHADVP">
          <tokens>
            <token id="14" string="why" />
          </tokens>
        </chunking>
        <chunking id="8" string="Republican" type="NP">
          <tokens>
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="9" string="handwritten notes from his files" type="NP">
          <tokens>
            <token id="2" string="handwritten" />
            <token id="3" string="notes" />
            <token id="4" string="from" />
            <token id="5" string="his" />
            <token id="6" string="files" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="turned Republican" type="VP">
          <tokens>
            <token id="17" string="turned" />
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="12" string="telling his Democratic grandparents why he had turned Republican" type="VP">
          <tokens>
            <token id="10" string="telling" />
            <token id="11" string="his" />
            <token id="12" string="Democratic" />
            <token id="13" string="grandparents" />
            <token id="14" string="why" />
            <token id="15" string="he" />
            <token id="16" string="had" />
            <token id="17" string="turned" />
            <token id="18" string="Republican" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">notes</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">notes</governor>
          <dependent id="2">handwritten</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">recalled</governor>
          <dependent id="3">notes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">files</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">files</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">notes</governor>
          <dependent id="6">files</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">recalled</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">recalled</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">recalled</governor>
          <dependent id="10">telling</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">grandparents</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">grandparents</governor>
          <dependent id="12">Democratic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">telling</governor>
          <dependent id="13">grandparents</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">turned</governor>
          <dependent id="14">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">turned</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">turned</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">telling</governor>
          <dependent id="17">turned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">turned</governor>
          <dependent id="18">Republican</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="Democratic" />
          </tokens>
        </entity>
        <entity id="2" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="Republican" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>&amp;quot;You all made me become Republican,&amp;quot; he told his incredulous grandparents.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Republican" lemma="Republican" stem="republican" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="incredulous" lemma="incredulous" stem="incredul" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP You)) (ADVP (DT all)) (VP (VBD made) (S (NP (PRP me)) (VP (VB become) (NP (NNP Republican)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD told) (NP (PRP$ his) (JJ incredulous) (NNS grandparents))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="made me become Republican" type="VP">
          <tokens>
            <token id="4" string="made" />
            <token id="5" string="me" />
            <token id="6" string="become" />
            <token id="7" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="2" string="me" type="NP">
          <tokens>
            <token id="5" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="Republican" type="NP">
          <tokens>
            <token id="7" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="4" string="told his incredulous grandparents" type="VP">
          <tokens>
            <token id="11" string="told" />
            <token id="12" string="his" />
            <token id="13" string="incredulous" />
            <token id="14" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="his incredulous grandparents" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="incredulous" />
            <token id="14" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="7" string="become Republican" type="VP">
          <tokens>
            <token id="6" string="become" />
            <token id="7" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="8" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">made</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">made</governor>
          <dependent id="3">all</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">told</governor>
          <dependent id="4">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">become</governor>
          <dependent id="5">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">made</governor>
          <dependent id="6">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">become</governor>
          <dependent id="7">Republican</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">told</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">told</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">grandparents</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">grandparents</governor>
          <dependent id="13">incredulous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">told</governor>
          <dependent id="14">grandparents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="Republican" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;Remember . . . when you told me that it wasn&amp;apost;t right to beg as long as I could work and get it myself?</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Remember" lemma="remember" stem="rememb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="beg" lemma="beg" stem="beg" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="myself" lemma="myself" stem="myself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (VP (VP (VP (VB Remember)) (: ...) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBD told) (NP (PRP me)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD was) (RB n't) (ADJP (JJ right) (S (VP (TO to) (VP (VB beg) (ADVP (ADVP (RB as) (RB long)) (SBAR (IN as) (S (NP (PRP I)) (VP (MD could) (VP (VB work))))))))))))))))) (CC and) (VP (VB get) (S (NP (PRP it)) (NP (PRP myself))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when you told me that it was n't right to beg as long as I could work" type="SBAR">
          <tokens>
            <token id="4" string="when" />
            <token id="5" string="you" />
            <token id="6" string="told" />
            <token id="7" string="me" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="2" string="right to beg as long as I could work" type="ADJP">
          <tokens>
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="3" string="Remember ... when you told me that it was n't right to beg as long as I could work" type="VP">
          <tokens>
            <token id="2" string="Remember" />
            <token id="3" string=". . ." />
            <token id="4" string="when" />
            <token id="5" string="you" />
            <token id="6" string="told" />
            <token id="7" string="me" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="4" string="that it was n't right to beg as long as I could work" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="5" string="Remember ... when you told me that it was n't right to beg as long as I could work and get it myself" type="VP">
          <tokens>
            <token id="2" string="Remember" />
            <token id="3" string=". . ." />
            <token id="4" string="when" />
            <token id="5" string="you" />
            <token id="6" string="told" />
            <token id="7" string="me" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
            <token id="21" string="and" />
            <token id="22" string="get" />
            <token id="23" string="it" />
            <token id="24" string="myself" />
          </tokens>
        </chunking>
        <chunking id="6" string="was n't right to beg as long as I could work" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="7" string="work" type="VP">
          <tokens>
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="18" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="myself" type="NP">
          <tokens>
            <token id="24" string="myself" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="told me that it was n't right to beg as long as I could work" type="VP">
          <tokens>
            <token id="6" string="told" />
            <token id="7" string="me" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="was" />
            <token id="11" string="n't" />
            <token id="12" string="right" />
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="12" string="to beg as long as I could work" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="13" string="beg as long as I could work" type="VP">
          <tokens>
            <token id="14" string="beg" />
            <token id="15" string="as" />
            <token id="16" string="long" />
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="14" string="when" type="WHADVP">
          <tokens>
            <token id="4" string="when" />
          </tokens>
        </chunking>
        <chunking id="15" string="could work" type="VP">
          <tokens>
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="16" string="Remember" type="VP">
          <tokens>
            <token id="2" string="Remember" />
          </tokens>
        </chunking>
        <chunking id="17" string="as I could work" type="SBAR">
          <tokens>
            <token id="17" string="as" />
            <token id="18" string="I" />
            <token id="19" string="could" />
            <token id="20" string="work" />
          </tokens>
        </chunking>
        <chunking id="18" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="19" string="you" type="NP">
          <tokens>
            <token id="5" string="you" />
          </tokens>
        </chunking>
        <chunking id="20" string="get it myself" type="VP">
          <tokens>
            <token id="22" string="get" />
            <token id="23" string="it" />
            <token id="24" string="myself" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Remember</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">told</governor>
          <dependent id="4">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">told</governor>
          <dependent id="5">you</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">Remember</governor>
          <dependent id="6">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">told</governor>
          <dependent id="7">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">right</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">right</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">right</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">right</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">told</governor>
          <dependent id="12">right</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">beg</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">right</governor>
          <dependent id="14">beg</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">long</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">beg</governor>
          <dependent id="16">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">work</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">work</governor>
          <dependent id="18">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">work</governor>
          <dependent id="19">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">long</governor>
          <dependent id="20">work</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Remember</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Remember</governor>
          <dependent id="22">get</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">myself</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">get</governor>
          <dependent id="24">myself</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>. . . Remember when you told me that if I ever amounted to anything it would be by the sweat of MY brow and MY elbow grease?</content>
      <tokens>
        <token id="1" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Remember" lemma="remember" stem="rememb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="amounted" lemma="amount" stem="amount" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="sweat" lemma="sweat" stem="sweat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="MY" lemma="MY" stem="my" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="brow" lemma="brow" stem="brow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="MY" lemma="my" stem="my" pos="NN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="elbow" lemma="elbow" stem="elbow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="grease" lemma="grease" stem="greas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (VP (: ...) (VB Remember) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBD told) (NP (PRP me)) (SBAR (IN that) (IN if) (S (NP (PRP I)) (ADVP (RB ever)) (VP (VBD amounted) (PP (TO to) (NP (NN anything))))))))) (NP (PRP it)) (VP (MD would) (VP (VB be) (PP (IN by) (NP (NP (DT the) (NN sweat)) (PP (IN of) (NP (NP (NNP MY) (NN brow)) (CC and) (NP (NN MY) (NN elbow) (NN grease))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when you told me that if I ever amounted to anything" type="SBAR">
          <tokens>
            <token id="3" string="when" />
            <token id="4" string="you" />
            <token id="5" string="told" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="if" />
            <token id="9" string="I" />
            <token id="10" string="ever" />
            <token id="11" string="amounted" />
            <token id="12" string="to" />
            <token id="13" string="anything" />
          </tokens>
        </chunking>
        <chunking id="2" string="that if I ever amounted to anything" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="if" />
            <token id="9" string="I" />
            <token id="10" string="ever" />
            <token id="11" string="amounted" />
            <token id="12" string="to" />
            <token id="13" string="anything" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="MY elbow grease" type="NP">
          <tokens>
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
          </tokens>
        </chunking>
        <chunking id="6" string="told me that if I ever amounted to anything" type="VP">
          <tokens>
            <token id="5" string="told" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="if" />
            <token id="9" string="I" />
            <token id="10" string="ever" />
            <token id="11" string="amounted" />
            <token id="12" string="to" />
            <token id="13" string="anything" />
          </tokens>
        </chunking>
        <chunking id="7" string="anything" type="NP">
          <tokens>
            <token id="13" string="anything" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="3" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="the sweat of MY brow and MY elbow grease" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="sweat" />
            <token id="20" string="of" />
            <token id="21" string="MY" />
            <token id="22" string="brow" />
            <token id="23" string="and" />
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
          </tokens>
        </chunking>
        <chunking id="10" string="amounted to anything" type="VP">
          <tokens>
            <token id="11" string="amounted" />
            <token id="12" string="to" />
            <token id="13" string="anything" />
          </tokens>
        </chunking>
        <chunking id="11" string="would be by the sweat of MY brow and MY elbow grease" type="VP">
          <tokens>
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="sweat" />
            <token id="20" string="of" />
            <token id="21" string="MY" />
            <token id="22" string="brow" />
            <token id="23" string="and" />
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
          </tokens>
        </chunking>
        <chunking id="12" string="... Remember when you told me that if I ever amounted to anything it would be by the sweat of MY brow and MY elbow grease ?" type="VP">
          <tokens>
            <token id="1" string=". . ." />
            <token id="2" string="Remember" />
            <token id="3" string="when" />
            <token id="4" string="you" />
            <token id="5" string="told" />
            <token id="6" string="me" />
            <token id="7" string="that" />
            <token id="8" string="if" />
            <token id="9" string="I" />
            <token id="10" string="ever" />
            <token id="11" string="amounted" />
            <token id="12" string="to" />
            <token id="13" string="anything" />
            <token id="14" string="it" />
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="sweat" />
            <token id="20" string="of" />
            <token id="21" string="MY" />
            <token id="22" string="brow" />
            <token id="23" string="and" />
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
            <token id="27" string="?" />
          </tokens>
        </chunking>
        <chunking id="13" string="me" type="NP">
          <tokens>
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="MY brow" type="NP">
          <tokens>
            <token id="21" string="MY" />
            <token id="22" string="brow" />
          </tokens>
        </chunking>
        <chunking id="15" string="be by the sweat of MY brow and MY elbow grease" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="sweat" />
            <token id="20" string="of" />
            <token id="21" string="MY" />
            <token id="22" string="brow" />
            <token id="23" string="and" />
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
          </tokens>
        </chunking>
        <chunking id="16" string="MY brow and MY elbow grease" type="NP">
          <tokens>
            <token id="21" string="MY" />
            <token id="22" string="brow" />
            <token id="23" string="and" />
            <token id="24" string="MY" />
            <token id="25" string="elbow" />
            <token id="26" string="grease" />
          </tokens>
        </chunking>
        <chunking id="17" string="the sweat" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="sweat" />
          </tokens>
        </chunking>
        <chunking id="18" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Remember</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">told</governor>
          <dependent id="3">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">told</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">sweat</governor>
          <dependent id="5">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">told</governor>
          <dependent id="6">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">amounted</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">amounted</governor>
          <dependent id="8">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">amounted</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">amounted</governor>
          <dependent id="10">ever</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">told</governor>
          <dependent id="11">amounted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">anything</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">amounted</governor>
          <dependent id="13">anything</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">sweat</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">sweat</governor>
          <dependent id="15">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">sweat</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">sweat</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">sweat</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">Remember</governor>
          <dependent id="19">sweat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">brow</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">brow</governor>
          <dependent id="21">MY</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">sweat</governor>
          <dependent id="22">brow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">brow</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">grease</governor>
          <dependent id="24">MY</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">grease</governor>
          <dependent id="25">elbow</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">brow</governor>
          <dependent id="26">grease</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>; &amp;quot;And remember when you said you would rather starve than have anyone give you something -- as long as you could work for it?</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="remember" lemma="remember" stem="rememb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="starve" lemma="starve" stem="starv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (CC And) (VP (VB remember) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBD said) (SBAR (S (NP (PRP you)) (VP (MD would) (VP (RB rather) (VP (VB starve)) (IN than) (VP (VB have) (S (NP (NN anyone)) (VP (VB give) (NP (PRP you)) (NP (NN something)))))))))))) (: --) (ADVP (ADVP (RB as) (RB long)) (PP (IN as) (NP (PRP you)))))) (VP (MD could) (VP (VB work) (PP (IN for) (NP (PRP it))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could work for it" type="VP">
          <tokens>
            <token id="23" string="could" />
            <token id="24" string="work" />
            <token id="25" string="for" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="remember when you said you would rather starve than have anyone give you something -- as long as you" type="VP">
          <tokens>
            <token id="4" string="remember" />
            <token id="5" string="when" />
            <token id="6" string="you" />
            <token id="7" string="said" />
            <token id="8" string="you" />
            <token id="9" string="would" />
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
            <token id="18" string="--" />
            <token id="19" string="as" />
            <token id="20" string="long" />
            <token id="21" string="as" />
            <token id="22" string="you" />
          </tokens>
        </chunking>
        <chunking id="3" string="would rather starve than have anyone give you something" type="VP">
          <tokens>
            <token id="9" string="would" />
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="4" string="when you said you would rather starve than have anyone give you something" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="you" />
            <token id="7" string="said" />
            <token id="8" string="you" />
            <token id="9" string="would" />
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="5" string="have anyone give you something" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="6" string="give you something" type="VP">
          <tokens>
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="starve" type="VP">
          <tokens>
            <token id="11" string="starve" />
          </tokens>
        </chunking>
        <chunking id="9" string="something" type="NP">
          <tokens>
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="said you would rather starve than have anyone give you something" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="you" />
            <token id="9" string="would" />
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="12" string="work for it" type="VP">
          <tokens>
            <token id="24" string="work" />
            <token id="25" string="for" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="anyone" type="NP">
          <tokens>
            <token id="14" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="14" string="you would rather starve than have anyone give you something" type="SBAR">
          <tokens>
            <token id="8" string="you" />
            <token id="9" string="would" />
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="15" string="rather starve than have anyone give you something" type="VP">
          <tokens>
            <token id="10" string="rather" />
            <token id="11" string="starve" />
            <token id="12" string="than" />
            <token id="13" string="have" />
            <token id="14" string="anyone" />
            <token id="15" string="give" />
            <token id="16" string="you" />
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="16" string="you" type="NP">
          <tokens>
            <token id="6" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">remember</governor>
          <dependent id="3">And</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="24">work</governor>
          <dependent id="4">remember</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">said</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">remember</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">starve</governor>
          <dependent id="8">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">starve</governor>
          <dependent id="9">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">starve</governor>
          <dependent id="10">rather</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">starve</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">starve</governor>
          <dependent id="12">than</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">starve</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">give</governor>
          <dependent id="14">anyone</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">have</governor>
          <dependent id="15">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="15">give</governor>
          <dependent id="16">you</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">give</governor>
          <dependent id="17">something</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">long</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">remember</governor>
          <dependent id="20">long</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">you</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">long</governor>
          <dependent id="22">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">work</governor>
          <dependent id="23">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">it</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">work</governor>
          <dependent id="26">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>. . . Politically, I had no choice: The only party openly standing for those values was the Republican Party.&amp;quot;</content>
      <tokens>
        <token id="1" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="choice" lemma="choice" stem="choic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="values" lemma="value" stem="valu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="Republican" lemma="Republican" stem="republican" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (ADJP (RB Politically)) (, ,) (NP (PRP I)) (VP (VBD had) (NP (NP (DT no) (NN choice)) (: :) (NP (NP (DT The) (JJ only) (NN party)) (VP (ADVP (RB openly)) (VBG standing) (SBAR (IN for) (S (NP (DT those) (NNS values)) (VP (VBD was) (NP (DT the) (NNP Republican) (NNP Party))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Republican Party" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="2" string="no choice" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="choice" />
          </tokens>
        </chunking>
        <chunking id="3" string="The only party openly standing for those values was the Republican Party" type="NP">
          <tokens>
            <token id="9" string="The" />
            <token id="10" string="only" />
            <token id="11" string="party" />
            <token id="12" string="openly" />
            <token id="13" string="standing" />
            <token id="14" string="for" />
            <token id="15" string="those" />
            <token id="16" string="values" />
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="4" string="The only party" type="NP">
          <tokens>
            <token id="9" string="The" />
            <token id="10" string="only" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
        <chunking id="5" string="Politically" type="ADJP">
          <tokens>
            <token id="2" string="Politically" />
          </tokens>
        </chunking>
        <chunking id="6" string="no choice : The only party openly standing for those values was the Republican Party" type="NP">
          <tokens>
            <token id="6" string="no" />
            <token id="7" string="choice" />
            <token id="8" string=":" />
            <token id="9" string="The" />
            <token id="10" string="only" />
            <token id="11" string="party" />
            <token id="12" string="openly" />
            <token id="13" string="standing" />
            <token id="14" string="for" />
            <token id="15" string="those" />
            <token id="16" string="values" />
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="7" string="for those values was the Republican Party" type="SBAR">
          <tokens>
            <token id="14" string="for" />
            <token id="15" string="those" />
            <token id="16" string="values" />
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="8" string="those values" type="NP">
          <tokens>
            <token id="15" string="those" />
            <token id="16" string="values" />
          </tokens>
        </chunking>
        <chunking id="9" string="was the Republican Party" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="had no choice : The only party openly standing for those values was the Republican Party" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="no" />
            <token id="7" string="choice" />
            <token id="8" string=":" />
            <token id="9" string="The" />
            <token id="10" string="only" />
            <token id="11" string="party" />
            <token id="12" string="openly" />
            <token id="13" string="standing" />
            <token id="14" string="for" />
            <token id="15" string="those" />
            <token id="16" string="values" />
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
        <chunking id="12" string="openly standing for those values was the Republican Party" type="VP">
          <tokens>
            <token id="12" string="openly" />
            <token id="13" string="standing" />
            <token id="14" string="for" />
            <token id="15" string="those" />
            <token id="16" string="values" />
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="5">had</governor>
          <dependent id="2">Politically</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">choice</governor>
          <dependent id="6">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="7">choice</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">party</governor>
          <dependent id="9">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">party</governor>
          <dependent id="10">only</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">choice</governor>
          <dependent id="11">party</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">standing</governor>
          <dependent id="12">openly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">party</governor>
          <dependent id="13">standing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">Party</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">values</governor>
          <dependent id="15">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">Party</governor>
          <dependent id="16">values</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">Party</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Party</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Party</governor>
          <dependent id="19">Republican</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">standing</governor>
          <dependent id="20">Party</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republican Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Republican" />
            <token id="20" string="Party" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="53-54" string="Thomas Sowell" id_sentence="5" />
      <mentions>
        <mention ids_tokens="29" string="Thomas" id_sentence="1" />
        <mention ids_tokens="8" string="Thomas" id_sentence="2" />
        <mention ids_tokens="1-2" string="Thomas'" id_sentence="3" />
        <mention ids_tokens="15" string="his" id_sentence="3" />
        <mention ids_tokens="4" string="his" id_sentence="4" />
        <mention ids_tokens="16" string="Thomas" id_sentence="6" />
        <mention ids_tokens="1" string="Thomas" id_sentence="7" />
        <mention ids_tokens="15" string="he" id_sentence="7" />
        <mention ids_tokens="8" string="I" id_sentence="8" />
        <mention ids_tokens="1" string="I" id_sentence="9" />
        <mention ids_tokens="16" string="he" id_sentence="9" />
        <mention ids_tokens="31" string="he" id_sentence="9" />
        <mention ids_tokens="33" string="his" id_sentence="9" />
        <mention ids_tokens="1" string="Thomas" id_sentence="10" />
        <mention ids_tokens="3" string="his" id_sentence="10" />
        <mention ids_tokens="30" string="I" id_sentence="10" />
        <mention ids_tokens="32" string="I" id_sentence="10" />
        <mention ids_tokens="3" string="his" id_sentence="11" />
        <mention ids_tokens="10" string="Thomas" id_sentence="11" />
        <mention ids_tokens="5-6" string="Clarence Thomas" id_sentence="12" />
        <mention ids_tokens="2" string="Thomas" id_sentence="14" />
        <mention ids_tokens="6" string="his" id_sentence="14" />
        <mention ids_tokens="1" string="His" id_sentence="15" />
        <mention ids_tokens="8" string="his" id_sentence="15" />
        <mention ids_tokens="11" string="his" id_sentence="15" />
        <mention ids_tokens="20" string="he" id_sentence="15" />
        <mention ids_tokens="22-29" string="a Yale law student from 1971 to 1974" id_sentence="15" />
        <mention ids_tokens="1" string="Thomas" id_sentence="16" />
        <mention ids_tokens="19" string="he" id_sentence="16" />
        <mention ids_tokens="29" string="Thomas" id_sentence="17" />
        <mention ids_tokens="4" string="Thomas" id_sentence="18" />
        <mention ids_tokens="21-22" string="Thomas'" id_sentence="18" />
        <mention ids_tokens="36" string="his" id_sentence="18" />
        <mention ids_tokens="2" string="His" id_sentence="19" />
        <mention ids_tokens="9" string="he" id_sentence="19" />
        <mention ids_tokens="46" string="Thomas" id_sentence="19" />
        <mention ids_tokens="4" string="he" id_sentence="20" />
        <mention ids_tokens="1" string="His" id_sentence="21" />
        <mention ids_tokens="4" string="him" id_sentence="21" />
        <mention ids_tokens="16" string="he" id_sentence="21" />
        <mention ids_tokens="9" string="Thomas" id_sentence="22" />
        <mention ids_tokens="3" string="he" id_sentence="23" />
        <mention ids_tokens="5" string="his" id_sentence="24" />
        <mention ids_tokens="1-13" string="Thomas , who has declined to be interviewed since his Supreme Court nomination" id_sentence="25" />
        <mention ids_tokens="1" string="Thomas" id_sentence="25" />
        <mention ids_tokens="10" string="his" id_sentence="25" />
        <mention ids_tokens="2" string="he" id_sentence="26" />
        <mention ids_tokens="8" string="his" id_sentence="26" />
        <mention ids_tokens="5" string="his" id_sentence="27" />
        <mention ids_tokens="8" string="he" id_sentence="27" />
        <mention ids_tokens="11" string="his" id_sentence="27" />
        <mention ids_tokens="15" string="he" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="3" type="PRONOMINAL">
      <referenced ids_tokens="2" string="You" id_sentence="28" />
      <mentions>
        <mention ids_tokens="4" string="I" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="his incredulous grandparents" id_sentence="28" />
      <mentions>
        <mention ids_tokens="7" string="me" id_sentence="29" />
        <mention ids_tokens="18" string="I" id_sentence="29" />
        <mention ids_tokens="24" string="myself" id_sentence="29" />
        <mention ids_tokens="6" string="me" id_sentence="30" />
        <mention ids_tokens="9" string="I" id_sentence="30" />
        <mention ids_tokens="6" string="you" id_sentence="31" />
        <mention ids_tokens="8" string="you" id_sentence="31" />
        <mention ids_tokens="16" string="you" id_sentence="31" />
        <mention ids_tokens="22" string="you" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="12" string="right" id_sentence="29" />
      <mentions>
        <mention ids_tokens="14" string="it" id_sentence="30" />
        <mention ids_tokens="26" string="it" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="11-12-13-14" string="the Senate Judiciary Committee" id_sentence="2" />
      <mentions>
        <mention ids_tokens="22-24" string="Senate Judiciary Committee" id_sentence="6" />
        <mention ids_tokens="26-27" string="the Senate" id_sentence="18" />
        <mention ids_tokens="27" string="Senate" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="22-23-24-25-26" string="the increasingly conservative Supreme Court" id_sentence="2" />
      <mentions>
        <mention ids_tokens="24-25" string="Supreme Court" id_sentence="3" />
        <mention ids_tokens="12-13" string="Supreme Court" id_sentence="23" />
        <mention ids_tokens="11-12" string="Supreme Court" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13" string="his Supreme Court nomination" id_sentence="25" />
      <mentions>
        <mention ids_tokens="24-26" string="Supreme Court nomination" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="a story of courage" id_sentence="4" />
      <mentions>
        <mention ids_tokens="73-74" string="the story" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="intellectual clones '" id_sentence="8" />
      <mentions>
        <mention ids_tokens="12-13" string="intellectual clones" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="26-27-28" string="Yale Law School" id_sentence="9" />
      <mentions>
        <mention ids_tokens="23" string="Yale" id_sentence="15" />
        <mention ids_tokens="16" string="Yale" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="his close friends" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1-2" string="His friends" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40" string="the liberal attitudes of many bright young black people who were born into a segregated America and came of age after freedom rides , lunch room sit-ins and the 1964 Civil Rights Act" id_sentence="12" />
      <mentions>
        <mention ids_tokens="36-37" string="his attitudes" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="27-28-29" string="1971 to 1974" id_sentence="15" />
      <mentions>
        <mention ids_tokens="13" string="1974" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="10-11" string="his classmates" id_sentence="17" />
      <mentions>
        <mention ids_tokens="19" string="they" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="18-19" string="successive jobs" id_sentence="21" />
      <mentions>
        <mention ids_tokens="6-7" string="those jobs" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23-24" string="racial minorities who had historically suffered discrimination" id_sentence="22" />
      <mentions>
        <mention ids_tokens="17" string="them" id_sentence="23" />
      </mentions>
    </coreference>
  </coreferences>
</document>
