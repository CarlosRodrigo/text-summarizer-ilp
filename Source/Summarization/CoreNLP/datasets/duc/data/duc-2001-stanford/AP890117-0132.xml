<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890117-0132">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The City Council today asked county prosecutors to investigate the conduct of a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="conduct" lemma="conduct" stem="conduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="policeman" lemma="policeman" stem="policeman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="secretly" lemma="secretly" stem="secretli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="filmed" lemma="film" stem="film" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="off-duty" lemma="off-duty" stem="off-duti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="policeman" lemma="policeman" stem="policeman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="plate-glass" lemma="plate-glass" stem="plate-glass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP City) (NNP Council) (NN today)) (VP (VBD asked) (NP (NN county) (NNS prosecutors)) (S (VP (TO to) (VP (VB investigate) (NP (NP (DT the) (NN conduct)) (PP (IN of) (NP (NP (DT a) (JJ white) (NN policeman)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADVP (RB secretly)) (VP (VBN filmed) (SBAR (IN while) (S (NP (PRP he)) (VP (VBD pushed) (NP (DT an) (JJ off-duty) (JJ black) (NN policeman)) (PP (IN through) (NP (DT a) (JJ plate-glass) (NN window))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an off-duty black policeman" type="NP">
          <tokens>
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="2" string="the conduct of a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="conduct" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="3" string="a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="4" string="The City Council today" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="City" />
            <token id="3" string="Council" />
            <token id="4" string="today" />
          </tokens>
        </chunking>
        <chunking id="5" string="pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="6" string="was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="7" string="while he pushed an off-duty black policeman through a plate-glass window" type="SBAR">
          <tokens>
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="8" string="asked county prosecutors to investigate the conduct of a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="5" string="asked" />
            <token id="6" string="county" />
            <token id="7" string="prosecutors" />
            <token id="8" string="to" />
            <token id="9" string="investigate" />
            <token id="10" string="the" />
            <token id="11" string="conduct" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="9" string="to investigate the conduct of a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="investigate" />
            <token id="10" string="the" />
            <token id="11" string="conduct" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="10" string="filmed while he pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="11" string="the conduct" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="12" string="who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="13" string="investigate the conduct of a white policeman who was secretly filmed while he pushed an off-duty black policeman through a plate-glass window" type="VP">
          <tokens>
            <token id="9" string="investigate" />
            <token id="10" string="the" />
            <token id="11" string="conduct" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
            <token id="16" string="who" />
            <token id="17" string="was" />
            <token id="18" string="secretly" />
            <token id="19" string="filmed" />
            <token id="20" string="while" />
            <token id="21" string="he" />
            <token id="22" string="pushed" />
            <token id="23" string="an" />
            <token id="24" string="off-duty" />
            <token id="25" string="black" />
            <token id="26" string="policeman" />
            <token id="27" string="through" />
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="14" string="a white policeman" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="white" />
            <token id="15" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="county prosecutors" type="NP">
          <tokens>
            <token id="6" string="county" />
            <token id="7" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="17" string="a plate-glass window" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="plate-glass" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">today</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">today</governor>
          <dependent id="2">City</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">today</governor>
          <dependent id="3">Council</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">asked</governor>
          <dependent id="4">today</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">asked</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">prosecutors</governor>
          <dependent id="6">county</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">asked</governor>
          <dependent id="7">prosecutors</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">investigate</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">asked</governor>
          <dependent id="9">investigate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">conduct</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">investigate</governor>
          <dependent id="11">conduct</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">policeman</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">policeman</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">policeman</governor>
          <dependent id="14">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">conduct</governor>
          <dependent id="15">policeman</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">filmed</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">filmed</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">filmed</governor>
          <dependent id="18">secretly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">policeman</governor>
          <dependent id="19">filmed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">pushed</governor>
          <dependent id="20">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">pushed</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">filmed</governor>
          <dependent id="22">pushed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">policeman</governor>
          <dependent id="23">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">policeman</governor>
          <dependent id="24">off-duty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">policeman</governor>
          <dependent id="25">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">pushed</governor>
          <dependent id="26">policeman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">window</governor>
          <dependent id="27">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">window</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">window</governor>
          <dependent id="29">plate-glass</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">pushed</governor>
          <dependent id="30">window</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="City" />
            <token id="3" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>``We&amp;apost;re certainly not happy to have an incident like this occurring, but we need all the information,&amp;apost;&amp;apost; said Councilman Thomas J. Clark of the council&amp;apost;s request for an investigation.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="occurring" lemma="occur" stem="occur" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Councilman" lemma="Councilman" stem="councilman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="J." lemma="J." stem="j." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Clark" lemma="Clark" stem="clark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="request" lemma="request" stem="request" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (PRP We)) (VP (VBP 're) (ADVP (RB certainly)) (RB not) (ADJP (JJ happy) (S (VP (TO to) (VP (VB have) (NP (NP (DT an) (NN incident)) (PP (IN like) (NP (NP (DT this)) (VP (VBG occurring))))))))))) (, ,) (CC but) (S (NP (PRP we)) (VP (VBP need) (NP (PDT all) (DT the) (NN information))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Councilman) (NNP Thomas) (NNP J.) (NNP Clark)) (PP (IN of) (NP (NP (NP (DT the) (NN council) (POS 's)) (NN request)) (PP (IN for) (NP (DT an) (NN investigation)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the council 's" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="council" />
            <token id="31" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="this" type="NP">
          <tokens>
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="16" string="we" />
          </tokens>
        </chunking>
        <chunking id="5" string="need all the information" type="VP">
          <tokens>
            <token id="17" string="need" />
            <token id="18" string="all" />
            <token id="19" string="the" />
            <token id="20" string="information" />
          </tokens>
        </chunking>
        <chunking id="6" string="an investigation" type="NP">
          <tokens>
            <token id="34" string="an" />
            <token id="35" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="7" string="this occurring" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="8" string="the council 's request for an investigation" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="council" />
            <token id="31" string="'s" />
            <token id="32" string="request" />
            <token id="33" string="for" />
            <token id="34" string="an" />
            <token id="35" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="9" string="an incident" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="incident" />
          </tokens>
        </chunking>
        <chunking id="10" string="occurring" type="VP">
          <tokens>
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="11" string="happy to have an incident like this occurring" type="ADJP">
          <tokens>
            <token id="6" string="happy" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="an" />
            <token id="10" string="incident" />
            <token id="11" string="like" />
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="12" string="Councilman Thomas J. Clark of the council 's request for an investigation" type="NP">
          <tokens>
            <token id="24" string="Councilman" />
            <token id="25" string="Thomas" />
            <token id="26" string="J." />
            <token id="27" string="Clark" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="council" />
            <token id="31" string="'s" />
            <token id="32" string="request" />
            <token id="33" string="for" />
            <token id="34" string="an" />
            <token id="35" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Councilman Thomas J. Clark" type="NP">
          <tokens>
            <token id="24" string="Councilman" />
            <token id="25" string="Thomas" />
            <token id="26" string="J." />
            <token id="27" string="Clark" />
          </tokens>
        </chunking>
        <chunking id="14" string="to have an incident like this occurring" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="an" />
            <token id="10" string="incident" />
            <token id="11" string="like" />
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="15" string="the council 's request" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="council" />
            <token id="31" string="'s" />
            <token id="32" string="request" />
          </tokens>
        </chunking>
        <chunking id="16" string="'re certainly not happy to have an incident like this occurring" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="certainly" />
            <token id="5" string="not" />
            <token id="6" string="happy" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="an" />
            <token id="10" string="incident" />
            <token id="11" string="like" />
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="17" string="have an incident like this occurring" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="an" />
            <token id="10" string="incident" />
            <token id="11" string="like" />
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="an incident like this occurring" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="incident" />
            <token id="11" string="like" />
            <token id="12" string="this" />
            <token id="13" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="20" string="all the information" type="NP">
          <tokens>
            <token id="18" string="all" />
            <token id="19" string="the" />
            <token id="20" string="information" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">happy</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">happy</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">happy</governor>
          <dependent id="4">certainly</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">happy</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="6">happy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">have</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">happy</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">incident</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">have</governor>
          <dependent id="10">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">this</governor>
          <dependent id="11">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">incident</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">this</governor>
          <dependent id="13">occurring</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">happy</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">need</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">happy</governor>
          <dependent id="17">need</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="20">information</governor>
          <dependent id="18">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">information</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">need</governor>
          <dependent id="20">information</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Clark</governor>
          <dependent id="24">Councilman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Clark</governor>
          <dependent id="25">Thomas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Clark</governor>
          <dependent id="26">J.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="27">Clark</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">request</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">council</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">request</governor>
          <dependent id="30">council</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">council</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Clark</governor>
          <dependent id="32">request</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">investigation</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">investigation</governor>
          <dependent id="34">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">request</governor>
          <dependent id="35">investigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas J. Clark" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Thomas" />
            <token id="26" string="J." />
            <token id="27" string="Clark" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Curt Livesay, an assisant Los Angeles County district attorney and head of the office&amp;apost;s Special Investigations Division, will lead the probe, said district attorney spokesman Andy Reynolds.</content>
      <tokens>
        <token id="1" string="Curt" lemma="Curt" stem="curt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Livesay" lemma="Livesay" stem="livesai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="assisant" lemma="assisant" stem="assis" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Investigations" lemma="Investigations" stem="investig" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Division" lemma="Division" stem="divis" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="lead" lemma="lead" stem="lead" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Andy" lemma="Andy" stem="andy" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Reynolds" lemma="Reynolds" stem="reynold" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NNP Curt) (NNP Livesay)) (, ,) (NP (NP (DT an) (JJ assisant) (NNP Los) (NNP Angeles) (NNP County) (NN district) (NN attorney) (CC and) (NN head)) (PP (IN of) (NP (NP (DT the) (NN office) (POS 's)) (NP (NP (JJ Special) (NNPS Investigations)) (NP (NNP Division)))))) (, ,)) (VP (MD will) (VP (VB lead) (NP (DT the) (NN probe))))) (, ,) (VP (VBD said)) (NP (NN district) (NN attorney) (NN spokesman) (NNP Andy) (NNP Reynolds)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Curt Livesay , an assisant Los Angeles County district attorney and head of the office 's Special Investigations Division ," type="NP">
          <tokens>
            <token id="1" string="Curt" />
            <token id="2" string="Livesay" />
            <token id="3" string="," />
            <token id="4" string="an" />
            <token id="5" string="assisant" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="County" />
            <token id="9" string="district" />
            <token id="10" string="attorney" />
            <token id="11" string="and" />
            <token id="12" string="head" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="office" />
            <token id="16" string="'s" />
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
            <token id="19" string="Division" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="the office 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="office" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="will lead the probe" type="VP">
          <tokens>
            <token id="21" string="will" />
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="probe" />
          </tokens>
        </chunking>
        <chunking id="4" string="Curt Livesay" type="NP">
          <tokens>
            <token id="1" string="Curt" />
            <token id="2" string="Livesay" />
          </tokens>
        </chunking>
        <chunking id="5" string="the probe" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="probe" />
          </tokens>
        </chunking>
        <chunking id="6" string="an assisant Los Angeles County district attorney and head of the office 's Special Investigations Division" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="assisant" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="County" />
            <token id="9" string="district" />
            <token id="10" string="attorney" />
            <token id="11" string="and" />
            <token id="12" string="head" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="office" />
            <token id="16" string="'s" />
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
            <token id="19" string="Division" />
          </tokens>
        </chunking>
        <chunking id="7" string="district attorney spokesman Andy Reynolds" type="NP">
          <tokens>
            <token id="27" string="district" />
            <token id="28" string="attorney" />
            <token id="29" string="spokesman" />
            <token id="30" string="Andy" />
            <token id="31" string="Reynolds" />
          </tokens>
        </chunking>
        <chunking id="8" string="the office 's Special Investigations Division" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="office" />
            <token id="16" string="'s" />
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
            <token id="19" string="Division" />
          </tokens>
        </chunking>
        <chunking id="9" string="an assisant Los Angeles County district attorney and head" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="assisant" />
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="County" />
            <token id="9" string="district" />
            <token id="10" string="attorney" />
            <token id="11" string="and" />
            <token id="12" string="head" />
          </tokens>
        </chunking>
        <chunking id="10" string="Special Investigations" type="NP">
          <tokens>
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
          </tokens>
        </chunking>
        <chunking id="11" string="Special Investigations Division" type="NP">
          <tokens>
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
            <token id="19" string="Division" />
          </tokens>
        </chunking>
        <chunking id="12" string="Division" type="NP">
          <tokens>
            <token id="19" string="Division" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="lead the probe" type="VP">
          <tokens>
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="probe" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Livesay</governor>
          <dependent id="1">Curt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">lead</governor>
          <dependent id="2">Livesay</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">attorney</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">attorney</governor>
          <dependent id="5">assisant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">attorney</governor>
          <dependent id="6">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">attorney</governor>
          <dependent id="7">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">attorney</governor>
          <dependent id="8">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">attorney</governor>
          <dependent id="9">district</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Livesay</governor>
          <dependent id="10">attorney</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">attorney</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">attorney</governor>
          <dependent id="12">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">office</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">office</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">attorney</governor>
          <dependent id="15">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">office</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">Investigations</governor>
          <dependent id="17">Special</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">office</governor>
          <dependent id="18">Investigations</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Investigations</governor>
          <dependent id="19">Division</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">lead</governor>
          <dependent id="21">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="22">lead</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">probe</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">lead</governor>
          <dependent id="24">probe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Reynolds</governor>
          <dependent id="27">district</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Reynolds</governor>
          <dependent id="28">attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Reynolds</governor>
          <dependent id="29">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Reynolds</governor>
          <dependent id="30">Andy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="31">Reynolds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Curt Livesay" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Curt" />
            <token id="2" string="Livesay" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles County" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Los" />
            <token id="7" string="Angeles" />
            <token id="8" string="County" />
          </tokens>
        </entity>
        <entity id="3" string="Andy Reynolds" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Andy" />
            <token id="31" string="Reynolds" />
          </tokens>
        </entity>
        <entity id="4" string="Special Investigations Division" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Special" />
            <token id="18" string="Investigations" />
            <token id="19" string="Division" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The black Hawthorne policeman, Sgt. Don Jackson, said he set up the self-styled ``sting&amp;apost;&amp;apost; in Long Beach to expose alleged police racism in the Los Angeles area.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Hawthorne" lemma="hawthorne" stem="hawthorn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="policeman" lemma="policeman" stem="policeman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Sgt." lemma="Sgt." stem="sgt." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="self-styled" lemma="self-styled" stem="self-styl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="sting" lemma="sting" stem="sting" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="21" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="expose" lemma="expose" stem="expos" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="30" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="31" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ black) (NN Hawthorne) (NN policeman)) (, ,) (NP (NNP Sgt.) (NNP Don) (NNP Jackson)) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD set) (PRT (RP up)) (NP (NP (DT the) (JJ self-styled) (`` ``) (NN sting) ('' '')) (PP (IN in) (NP (NNP Long) (NNP Beach)))) (S (VP (TO to) (VP (VB expose) (NP (JJ alleged) (NNS police) (NN racism)) (PP (IN in) (NP (DT the) (NNP Los) (NNP Angeles) (NN area)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Los Angeles area" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="2" string="alleged police racism" type="NP">
          <tokens>
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
          </tokens>
        </chunking>
        <chunking id="3" string="to expose alleged police racism in the Los Angeles area" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="expose" />
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="4" string="he set up the self-styled `` sting '' in Long Beach to expose alleged police racism in the Los Angeles area" type="SBAR">
          <tokens>
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="self-styled" />
            <token id="16" string="``" />
            <token id="17" string="sting" />
            <token id="18" string="''" />
            <token id="19" string="in" />
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
            <token id="22" string="to" />
            <token id="23" string="expose" />
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sgt. Don Jackson" type="NP">
          <tokens>
            <token id="6" string="Sgt." />
            <token id="7" string="Don" />
            <token id="8" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="the self-styled `` sting '' in Long Beach" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="self-styled" />
            <token id="16" string="``" />
            <token id="17" string="sting" />
            <token id="18" string="''" />
            <token id="19" string="in" />
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="7" string="the self-styled `` sting ''" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="self-styled" />
            <token id="16" string="``" />
            <token id="17" string="sting" />
            <token id="18" string="''" />
          </tokens>
        </chunking>
        <chunking id="8" string="expose alleged police racism in the Los Angeles area" type="VP">
          <tokens>
            <token id="23" string="expose" />
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he set up the self-styled `` sting '' in Long Beach to expose alleged police racism in the Los Angeles area" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="self-styled" />
            <token id="16" string="``" />
            <token id="17" string="sting" />
            <token id="18" string="''" />
            <token id="19" string="in" />
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
            <token id="22" string="to" />
            <token id="23" string="expose" />
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="10" string="set up the self-styled `` sting '' in Long Beach to expose alleged police racism in the Los Angeles area" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="self-styled" />
            <token id="16" string="``" />
            <token id="17" string="sting" />
            <token id="18" string="''" />
            <token id="19" string="in" />
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
            <token id="22" string="to" />
            <token id="23" string="expose" />
            <token id="24" string="alleged" />
            <token id="25" string="police" />
            <token id="26" string="racism" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
            <token id="31" string="area" />
          </tokens>
        </chunking>
        <chunking id="11" string="The black Hawthorne policeman , Sgt. Don Jackson ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="black" />
            <token id="3" string="Hawthorne" />
            <token id="4" string="policeman" />
            <token id="5" string="," />
            <token id="6" string="Sgt." />
            <token id="7" string="Don" />
            <token id="8" string="Jackson" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="The black Hawthorne policeman" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="black" />
            <token id="3" string="Hawthorne" />
            <token id="4" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="13" string="Long Beach" type="NP">
          <tokens>
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">policeman</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">policeman</governor>
          <dependent id="2">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">policeman</governor>
          <dependent id="3">Hawthorne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="4">policeman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Jackson</governor>
          <dependent id="6">Sgt.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Jackson</governor>
          <dependent id="7">Don</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">policeman</governor>
          <dependent id="8">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">set</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="12">set</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">set</governor>
          <dependent id="13">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">sting</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">sting</governor>
          <dependent id="15">self-styled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">set</governor>
          <dependent id="17">sting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Beach</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Beach</governor>
          <dependent id="20">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">sting</governor>
          <dependent id="21">Beach</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">expose</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">set</governor>
          <dependent id="23">expose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">racism</governor>
          <dependent id="24">alleged</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">racism</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">expose</governor>
          <dependent id="26">racism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">area</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">area</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">area</governor>
          <dependent id="29">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">area</governor>
          <dependent id="30">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">expose</governor>
          <dependent id="31">area</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Long" />
            <token id="21" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Don Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Don" />
            <token id="8" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Los" />
            <token id="30" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>An NBC-TV news camera crew arranged to follow Jackson during the sting Saturday night.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="NBC-TV" lemma="NBC-TV" stem="nbc-tv" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="camera" lemma="camera" stem="camera" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="arranged" lemma="arrange" stem="arrang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="follow" lemma="follow" stem="follow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="sting" lemma="sting" stem="sting" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT An) (NNP NBC-TV) (NN news) (NN camera) (NN crew)) (VP (VBD arranged) (S (VP (TO to) (VP (VB follow) (NP (NNP Jackson)) (PP (IN during) (NP (DT the) (NN sting))) (NP-TMP (NNP Saturday) (NN night)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="An NBC-TV news camera crew" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="NBC-TV" />
            <token id="3" string="news" />
            <token id="4" string="camera" />
            <token id="5" string="crew" />
          </tokens>
        </chunking>
        <chunking id="2" string="to follow Jackson during the sting Saturday night" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="follow" />
            <token id="9" string="Jackson" />
            <token id="10" string="during" />
            <token id="11" string="the" />
            <token id="12" string="sting" />
            <token id="13" string="Saturday" />
            <token id="14" string="night" />
          </tokens>
        </chunking>
        <chunking id="3" string="the sting" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="sting" />
          </tokens>
        </chunking>
        <chunking id="4" string="follow Jackson during the sting Saturday night" type="VP">
          <tokens>
            <token id="8" string="follow" />
            <token id="9" string="Jackson" />
            <token id="10" string="during" />
            <token id="11" string="the" />
            <token id="12" string="sting" />
            <token id="13" string="Saturday" />
            <token id="14" string="night" />
          </tokens>
        </chunking>
        <chunking id="5" string="arranged to follow Jackson during the sting Saturday night" type="VP">
          <tokens>
            <token id="6" string="arranged" />
            <token id="7" string="to" />
            <token id="8" string="follow" />
            <token id="9" string="Jackson" />
            <token id="10" string="during" />
            <token id="11" string="the" />
            <token id="12" string="sting" />
            <token id="13" string="Saturday" />
            <token id="14" string="night" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="9" string="Jackson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">crew</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">crew</governor>
          <dependent id="2">NBC-TV</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">crew</governor>
          <dependent id="3">news</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">crew</governor>
          <dependent id="4">camera</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">arranged</governor>
          <dependent id="5">crew</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">arranged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">follow</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">arranged</governor>
          <dependent id="8">follow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">follow</governor>
          <dependent id="9">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">sting</governor>
          <dependent id="10">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">sting</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">follow</governor>
          <dependent id="12">sting</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">night</governor>
          <dependent id="13">Saturday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">follow</governor>
          <dependent id="14">night</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="NBC-TV" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="NBC-TV" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="14" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Saturday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The incident was broadcast on NBC&amp;apost;s national news Monday night.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="broadcast" lemma="broadcast" stem="broadcast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN incident)) (VP (VBD was) (VP (VBN broadcast) (PP (IN on) (NP (NP (NNP NBC) (POS 's)) (JJ national) (NN news))) (NP-TMP (NNP Monday) (NN night)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was broadcast on NBC 's national news Monday night" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="broadcast" />
            <token id="5" string="on" />
            <token id="6" string="NBC" />
            <token id="7" string="'s" />
            <token id="8" string="national" />
            <token id="9" string="news" />
            <token id="10" string="Monday" />
            <token id="11" string="night" />
          </tokens>
        </chunking>
        <chunking id="2" string="broadcast on NBC 's national news Monday night" type="VP">
          <tokens>
            <token id="4" string="broadcast" />
            <token id="5" string="on" />
            <token id="6" string="NBC" />
            <token id="7" string="'s" />
            <token id="8" string="national" />
            <token id="9" string="news" />
            <token id="10" string="Monday" />
            <token id="11" string="night" />
          </tokens>
        </chunking>
        <chunking id="3" string="NBC 's" type="NP">
          <tokens>
            <token id="6" string="NBC" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="The incident" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="NBC 's national news" type="NP">
          <tokens>
            <token id="6" string="NBC" />
            <token id="7" string="'s" />
            <token id="8" string="national" />
            <token id="9" string="news" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">incident</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">broadcast</governor>
          <dependent id="2">incident</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">broadcast</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">broadcast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">news</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">news</governor>
          <dependent id="6">NBC</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">NBC</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">news</governor>
          <dependent id="8">national</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">broadcast</governor>
          <dependent id="9">news</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">night</governor>
          <dependent id="10">Monday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">broadcast</governor>
          <dependent id="11">night</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="night" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Monday" />
          </tokens>
        </entity>
        <entity id="3" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``We&amp;apost;ve never been able to come forth before with enough evidence (of alleged police racism).</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="forth" lemma="forth" stem="forth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP 've) (ADVP (RB never)) (VP (VBN been) (ADJP (JJ able) (S (VP (TO to) (VP (VB come) (ADVP (RB forth) (PP (IN before) (PP (IN with) (NP (JJ enough) (NN evidence) (PRN (-LRB- -LRB-) (PP (IN of) (NP (VBN alleged) (NN police) (NN racism))) (-RRB- -RRB-)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to come forth before with enough evidence -LRB- of alleged police racism -RRB-" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="come" />
            <token id="9" string="forth" />
            <token id="10" string="before" />
            <token id="11" string="with" />
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="come forth before with enough evidence -LRB- of alleged police racism -RRB-" type="VP">
          <tokens>
            <token id="8" string="come" />
            <token id="9" string="forth" />
            <token id="10" string="before" />
            <token id="11" string="with" />
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="been able to come forth before with enough evidence -LRB- of alleged police racism -RRB-" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="able" />
            <token id="7" string="to" />
            <token id="8" string="come" />
            <token id="9" string="forth" />
            <token id="10" string="before" />
            <token id="11" string="with" />
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="alleged police racism" type="NP">
          <tokens>
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
          </tokens>
        </chunking>
        <chunking id="5" string="enough evidence -LRB- of alleged police racism -RRB-" type="NP">
          <tokens>
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="'ve never been able to come forth before with enough evidence -LRB- of alleged police racism -RRB-" type="VP">
          <tokens>
            <token id="3" string="'ve" />
            <token id="4" string="never" />
            <token id="5" string="been" />
            <token id="6" string="able" />
            <token id="7" string="to" />
            <token id="8" string="come" />
            <token id="9" string="forth" />
            <token id="10" string="before" />
            <token id="11" string="with" />
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="8" string="able to come forth before with enough evidence -LRB- of alleged police racism -RRB-" type="ADJP">
          <tokens>
            <token id="6" string="able" />
            <token id="7" string="to" />
            <token id="8" string="come" />
            <token id="9" string="forth" />
            <token id="10" string="before" />
            <token id="11" string="with" />
            <token id="12" string="enough" />
            <token id="13" string="evidence" />
            <token id="14" string="(" />
            <token id="15" string="of" />
            <token id="16" string="alleged" />
            <token id="17" string="police" />
            <token id="18" string="racism" />
            <token id="19" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">able</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">able</governor>
          <dependent id="3">'ve</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">able</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">able</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">come</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">able</governor>
          <dependent id="8">come</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">come</governor>
          <dependent id="9">forth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">evidence</governor>
          <dependent id="10">before</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">evidence</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">evidence</governor>
          <dependent id="12">enough</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">forth</governor>
          <dependent id="13">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">racism</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">racism</governor>
          <dependent id="16">alleged</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">racism</governor>
          <dependent id="17">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">evidence</governor>
          <dependent id="18">racism</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Now, it is brought to your living room in living color,&amp;apost;&amp;apost; said Frank Berry, president of the Long Beach chapter of the National Association for the Advancement of Colored People.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="color" lemma="color" stem="color" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Frank" lemma="Frank" stem="frank" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Berry" lemma="Berry" stem="berri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="23" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="24" string="chapter" lemma="chapter" stem="chapter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="Advancement" lemma="Advancement" stem="advancement" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Colored" lemma="Colored" stem="color" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (ADVP (RB Now)) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN brought) (PP (TO to) (NP (PRP$ your) (NN living) (NN room))) (PP (IN in) (S (VP (VBG living) (NP (NN color)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Frank) (NNP Berry)) (, ,) (NP (NP (NN president)) (PP (IN of) (NP (NP (DT the) (NNP Long) (NNP Beach) (NN chapter)) (PP (IN of) (NP (NP (DT the) (NNP National) (NNP Association)) (PP (IN for) (NP (NP (DT the) (NNP Advancement)) (PP (IN of) (NP (NNP Colored) (NNS People))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="president" type="NP">
          <tokens>
            <token id="19" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="brought to your living room in living color" type="VP">
          <tokens>
            <token id="5" string="brought" />
            <token id="6" string="to" />
            <token id="7" string="your" />
            <token id="8" string="living" />
            <token id="9" string="room" />
            <token id="10" string="in" />
            <token id="11" string="living" />
            <token id="12" string="color" />
          </tokens>
        </chunking>
        <chunking id="3" string="president of the Long Beach chapter of the National Association for the Advancement of Colored People" type="NP">
          <tokens>
            <token id="19" string="president" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Long" />
            <token id="23" string="Beach" />
            <token id="24" string="chapter" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="National" />
            <token id="28" string="Association" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
        <chunking id="4" string="Colored People" type="NP">
          <tokens>
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
        <chunking id="5" string="color" type="NP">
          <tokens>
            <token id="12" string="color" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Advancement of Colored People" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Long Beach chapter" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Long" />
            <token id="23" string="Beach" />
            <token id="24" string="chapter" />
          </tokens>
        </chunking>
        <chunking id="8" string="the National Association for the Advancement of Colored People" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="National" />
            <token id="28" string="Association" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="is brought to your living room in living color" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="brought" />
            <token id="6" string="to" />
            <token id="7" string="your" />
            <token id="8" string="living" />
            <token id="9" string="room" />
            <token id="10" string="in" />
            <token id="11" string="living" />
            <token id="12" string="color" />
          </tokens>
        </chunking>
        <chunking id="11" string="your living room" type="NP">
          <tokens>
            <token id="7" string="your" />
            <token id="8" string="living" />
            <token id="9" string="room" />
          </tokens>
        </chunking>
        <chunking id="12" string="Frank Berry , president of the Long Beach chapter of the National Association for the Advancement of Colored People" type="NP">
          <tokens>
            <token id="16" string="Frank" />
            <token id="17" string="Berry" />
            <token id="18" string="," />
            <token id="19" string="president" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Long" />
            <token id="23" string="Beach" />
            <token id="24" string="chapter" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="National" />
            <token id="28" string="Association" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
        <chunking id="13" string="Frank Berry" type="NP">
          <tokens>
            <token id="16" string="Frank" />
            <token id="17" string="Berry" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Advancement" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
          </tokens>
        </chunking>
        <chunking id="15" string="living color" type="VP">
          <tokens>
            <token id="11" string="living" />
            <token id="12" string="color" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="the National Association" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="National" />
            <token id="28" string="Association" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Long Beach chapter of the National Association for the Advancement of Colored People" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Long" />
            <token id="23" string="Beach" />
            <token id="24" string="chapter" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="National" />
            <token id="28" string="Association" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">brought</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">brought</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">brought</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="5">brought</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">room</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">room</governor>
          <dependent id="7">your</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">room</governor>
          <dependent id="8">living</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">brought</governor>
          <dependent id="9">room</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">living</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">brought</governor>
          <dependent id="11">living</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">living</governor>
          <dependent id="12">color</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Berry</governor>
          <dependent id="16">Frank</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="17">Berry</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Berry</governor>
          <dependent id="19">president</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">chapter</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">chapter</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">chapter</governor>
          <dependent id="22">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">chapter</governor>
          <dependent id="23">Beach</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">president</governor>
          <dependent id="24">chapter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Association</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Association</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Association</governor>
          <dependent id="27">National</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">chapter</governor>
          <dependent id="28">Association</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Advancement</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Advancement</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">Association</governor>
          <dependent id="31">Advancement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">People</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">People</governor>
          <dependent id="33">Colored</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">Advancement</governor>
          <dependent id="34">People</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Frank Berry" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Frank" />
            <token id="17" string="Berry" />
          </tokens>
        </entity>
        <entity id="2" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="3" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Long" />
            <token id="23" string="Beach" />
          </tokens>
        </entity>
        <entity id="4" string="National Association for the Advancement of Colored People" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="National" />
            <token id="28" string="Association" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="Advancement" />
            <token id="32" string="of" />
            <token id="33" string="Colored" />
            <token id="34" string="People" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The police chief in Long Beach declined to comment pending an investigation.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="comment" lemma="comment" stem="comment" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN police) (NN chief)) (PP (IN in) (NP (NNP Long) (NNP Beach)))) (VP (VBD declined) (S (VP (TO to) (VP (VB comment) (PP (VBG pending) (NP (DT an) (NN investigation))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="comment pending an investigation" type="VP">
          <tokens>
            <token id="9" string="comment" />
            <token id="10" string="pending" />
            <token id="11" string="an" />
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="2" string="Long Beach" type="NP">
          <tokens>
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="3" string="The police chief" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="police" />
            <token id="3" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="declined to comment pending an investigation" type="VP">
          <tokens>
            <token id="7" string="declined" />
            <token id="8" string="to" />
            <token id="9" string="comment" />
            <token id="10" string="pending" />
            <token id="11" string="an" />
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="5" string="The police chief in Long Beach" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="police" />
            <token id="3" string="chief" />
            <token id="4" string="in" />
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="6" string="to comment pending an investigation" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="comment" />
            <token id="10" string="pending" />
            <token id="11" string="an" />
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="7" string="an investigation" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">chief</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">chief</governor>
          <dependent id="2">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">declined</governor>
          <dependent id="3">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Beach</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Beach</governor>
          <dependent id="5">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">chief</governor>
          <dependent id="6">Beach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">comment</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">declined</governor>
          <dependent id="9">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">investigation</governor>
          <dependent id="10">pending</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">investigation</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">comment</governor>
          <dependent id="12">investigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>City officials promised a thorough inquiry.</content>
      <tokens>
        <token id="1" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="promised" lemma="promise" stem="promis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="thorough" lemma="thorough" stem="thorough" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP City) (NNS officials)) (VP (VBD promised) (NP (DT a) (JJ thorough) (NN inquiry))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="promised a thorough inquiry" type="VP">
          <tokens>
            <token id="3" string="promised" />
            <token id="4" string="a" />
            <token id="5" string="thorough" />
            <token id="6" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="2" string="a thorough inquiry" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="thorough" />
            <token id="6" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="3" string="City officials" type="NP">
          <tokens>
            <token id="1" string="City" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">City</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">promised</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">promised</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">inquiry</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">inquiry</governor>
          <dependent id="5">thorough</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">promised</governor>
          <dependent id="6">inquiry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``We will pursue it aggressively,&amp;apost;&amp;apost; said Long Beach City Manager James Hanklad.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="pursue" lemma="pursue" stem="pursu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="aggressively" lemma="aggressively" stem="aggress" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Manager" lemma="Manager" stem="manag" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="14" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Hanklad" lemma="Hanklad" stem="hanklad" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (VP (MD will) (VP (VB pursue) (NP (PRP it)) (ADVP (RB aggressively))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Long) (NNP Beach) (NNP City) (NNP Manager) (NNP James) (NNP Hanklad)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pursue it aggressively" type="VP">
          <tokens>
            <token id="4" string="pursue" />
            <token id="5" string="it" />
            <token id="6" string="aggressively" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="will pursue it aggressively" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="pursue" />
            <token id="5" string="it" />
            <token id="6" string="aggressively" />
          </tokens>
        </chunking>
        <chunking id="6" string="Long Beach City Manager James Hanklad" type="NP">
          <tokens>
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
            <token id="13" string="Manager" />
            <token id="14" string="James" />
            <token id="15" string="Hanklad" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">pursue</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">pursue</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="4">pursue</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">pursue</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">pursue</governor>
          <dependent id="6">aggressively</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hanklad</governor>
          <dependent id="10">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hanklad</governor>
          <dependent id="11">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hanklad</governor>
          <dependent id="12">City</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hanklad</governor>
          <dependent id="13">Manager</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hanklad</governor>
          <dependent id="14">James</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="15">Hanklad</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach City" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
          </tokens>
        </entity>
        <entity id="2" string="Manager" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Manager" />
          </tokens>
        </entity>
        <entity id="3" string="James Hanklad" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="James" />
            <token id="15" string="Hanklad" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``If there is evidence of brutality, we will act accordingly.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="act" lemma="act" stem="act" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="accordingly" lemma="accordingly" stem="accordingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (EX there)) (VP (VBZ is) (NP (NP (NN evidence)) (PP (IN of) (NP (NN brutality))))))) (, ,) (NP (PRP we)) (VP (MD will) (VP (VB act) (ADVP (RB accordingly)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence" type="NP">
          <tokens>
            <token id="5" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="will act accordingly" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="act" />
            <token id="12" string="accordingly" />
          </tokens>
        </chunking>
        <chunking id="4" string="If there is evidence of brutality" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="there" />
            <token id="4" string="is" />
            <token id="5" string="evidence" />
            <token id="6" string="of" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="act accordingly" type="VP">
          <tokens>
            <token id="11" string="act" />
            <token id="12" string="accordingly" />
          </tokens>
        </chunking>
        <chunking id="6" string="is evidence of brutality" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="evidence" />
            <token id="6" string="of" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="7" string="evidence of brutality" type="NP">
          <tokens>
            <token id="5" string="evidence" />
            <token id="6" string="of" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="9" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="brutality" type="NP">
          <tokens>
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">is</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">is</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">act</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="5">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">brutality</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">evidence</governor>
          <dependent id="7">brutality</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">act</governor>
          <dependent id="9">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">act</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">act</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">act</governor>
          <dependent id="12">accordingly</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Long Beach Mayor Ernie Kell said on NBC&amp;apost;s ``Today&amp;apost;&amp;apost; show this morning that he was disturbed by the videotape.</content>
      <tokens>
        <token id="1" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="4" string="Ernie" lemma="Ernie" stem="ernie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Kell" lemma="Kell" stem="kell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="disturbed" lemma="disturb" stem="disturb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Long) (NNP Beach) (NNP Mayor) (NNP Ernie) (NNP Kell)) (VP (VBD said) (PP (IN on) (NP (NP (NNP NBC) (POS 's)) (`` ``) (NP (NN Today)) ('' ''))) (VP (VB show) (NP-TMP (DT this) (NN morning)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (VP (VBN disturbed) (PP (IN by) (NP (DT the) (NN videotape))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was disturbed by the videotape" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="disturbed" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="2" string="Long Beach Mayor Ernie Kell" type="NP">
          <tokens>
            <token id="1" string="Long" />
            <token id="2" string="Beach" />
            <token id="3" string="Mayor" />
            <token id="4" string="Ernie" />
            <token id="5" string="Kell" />
          </tokens>
        </chunking>
        <chunking id="3" string="Today" type="NP">
          <tokens>
            <token id="11" string="Today" />
          </tokens>
        </chunking>
        <chunking id="4" string="show this morning that he was disturbed by the videotape" type="VP">
          <tokens>
            <token id="13" string="show" />
            <token id="14" string="this" />
            <token id="15" string="morning" />
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="was" />
            <token id="19" string="disturbed" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="5" string="that he was disturbed by the videotape" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="was" />
            <token id="19" string="disturbed" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="6" string="NBC 's" type="NP">
          <tokens>
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the videotape" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="8" string="NBC 's `` Today ''" type="NP">
          <tokens>
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="``" />
            <token id="11" string="Today" />
            <token id="12" string="''" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="disturbed by the videotape" type="VP">
          <tokens>
            <token id="19" string="disturbed" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="11" string="said on NBC 's `` Today '' show this morning that he was disturbed by the videotape" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="on" />
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="``" />
            <token id="11" string="Today" />
            <token id="12" string="''" />
            <token id="13" string="show" />
            <token id="14" string="this" />
            <token id="15" string="morning" />
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="was" />
            <token id="19" string="disturbed" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="videotape" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="5">Kell</governor>
          <dependent id="1">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kell</governor>
          <dependent id="2">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kell</governor>
          <dependent id="3">Mayor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kell</governor>
          <dependent id="4">Ernie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">Kell</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">NBC</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">said</governor>
          <dependent id="8">NBC</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">NBC</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">NBC</governor>
          <dependent id="11">Today</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">said</governor>
          <dependent id="13">show</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">morning</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">show</governor>
          <dependent id="15">morning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">disturbed</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">disturbed</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">disturbed</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">show</governor>
          <dependent id="19">disturbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">videotape</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">videotape</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">disturbed</governor>
          <dependent id="22">videotape</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Today" />
          </tokens>
        </entity>
        <entity id="2" string="this morning" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="morning" />
          </tokens>
        </entity>
        <entity id="3" string="Ernie Kell" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Ernie" />
            <token id="5" string="Kell" />
          </tokens>
        </entity>
        <entity id="4" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="Mayor" />
          </tokens>
        </entity>
        <entity id="5" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>``I ... do not support racism or police brutality, nor do the vast majority of the citizens of Long Beach, and we&amp;apost;re a caring, thinking community and it disturbed us very much to see the tape,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="support" lemma="support" stem="support" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="vast" lemma="vast" stem="vast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="caring" lemma="caring" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="thinking" lemma="think" stem="think" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="disturbed" lemma="disturb" stem="disturb" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (: ...) (S (VP (VB do) (RB not) (VP (VB support) (NP (NN racism) (CC or) (NN police) (NN brutality))))) (, ,) (VP (CC nor) (VP (VBP do) (NP (NP (DT the) (JJ vast) (NN majority)) (PP (IN of) (NP (NP (DT the) (NNS citizens)) (PP (IN of) (NP (JJ Long) (NNP Beach))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP 're) (NP (DT a) (NN caring)) (, ,) (S (VP (VBG thinking) (NP (NN community)))))) (CC and) (S (NP (PRP it)) (VP (VBD disturbed) (NP (PRP us)) (ADVP (RB very) (RB much) (S (VP (TO to) (VP (VB see) (NP (DT the) (NN tape))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the vast majority" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="vast" />
            <token id="16" string="majority" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="the vast majority of the citizens of Long Beach" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="vast" />
            <token id="16" string="majority" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="citizens" />
            <token id="20" string="of" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="33" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="to see the tape" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="see" />
            <token id="40" string="the" />
            <token id="41" string="tape" />
          </tokens>
        </chunking>
        <chunking id="6" string="do not support racism or police brutality" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="not" />
            <token id="6" string="support" />
            <token id="7" string="racism" />
            <token id="8" string="or" />
            <token id="9" string="police" />
            <token id="10" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="7" string="the citizens of Long Beach" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="citizens" />
            <token id="20" string="of" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="25" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="'re a caring , thinking community" type="VP">
          <tokens>
            <token id="26" string="'re" />
            <token id="27" string="a" />
            <token id="28" string="caring" />
            <token id="29" string="," />
            <token id="30" string="thinking" />
            <token id="31" string="community" />
          </tokens>
        </chunking>
        <chunking id="10" string="thinking community" type="VP">
          <tokens>
            <token id="30" string="thinking" />
            <token id="31" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="community" type="NP">
          <tokens>
            <token id="31" string="community" />
          </tokens>
        </chunking>
        <chunking id="12" string="racism or police brutality" type="NP">
          <tokens>
            <token id="7" string="racism" />
            <token id="8" string="or" />
            <token id="9" string="police" />
            <token id="10" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="see the tape" type="VP">
          <tokens>
            <token id="39" string="see" />
            <token id="40" string="the" />
            <token id="41" string="tape" />
          </tokens>
        </chunking>
        <chunking id="14" string="nor do the vast majority of the citizens of Long Beach" type="VP">
          <tokens>
            <token id="12" string="nor" />
            <token id="13" string="do" />
            <token id="14" string="the" />
            <token id="15" string="vast" />
            <token id="16" string="majority" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="citizens" />
            <token id="20" string="of" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="15" string="the tape" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="tape" />
          </tokens>
        </chunking>
        <chunking id="16" string="Long Beach" type="NP">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="17" string="disturbed us very much to see the tape" type="VP">
          <tokens>
            <token id="34" string="disturbed" />
            <token id="35" string="us" />
            <token id="36" string="very" />
            <token id="37" string="much" />
            <token id="38" string="to" />
            <token id="39" string="see" />
            <token id="40" string="the" />
            <token id="41" string="tape" />
          </tokens>
        </chunking>
        <chunking id="18" string="a caring" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="caring" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="44" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="the citizens" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="21" string="us" type="NP">
          <tokens>
            <token id="35" string="us" />
          </tokens>
        </chunking>
        <chunking id="22" string="said" type="VP">
          <tokens>
            <token id="45" string="said" />
          </tokens>
        </chunking>
        <chunking id="23" string="support racism or police brutality" type="VP">
          <tokens>
            <token id="6" string="support" />
            <token id="7" string="racism" />
            <token id="8" string="or" />
            <token id="9" string="police" />
            <token id="10" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="24" string="do the vast majority of the citizens of Long Beach" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="the" />
            <token id="15" string="vast" />
            <token id="16" string="majority" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="citizens" />
            <token id="20" string="of" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">do</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">support</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">support</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">do</governor>
          <dependent id="6">support</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">brutality</governor>
          <dependent id="7">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">racism</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">racism</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">support</governor>
          <dependent id="10">brutality</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">do</governor>
          <dependent id="12">nor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="45">said</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">majority</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">majority</governor>
          <dependent id="15">vast</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">do</governor>
          <dependent id="16">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">citizens</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">citizens</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">majority</governor>
          <dependent id="19">citizens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Beach</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Beach</governor>
          <dependent id="21">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">citizens</governor>
          <dependent id="22">Beach</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">do</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">caring</governor>
          <dependent id="25">we</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">caring</governor>
          <dependent id="26">'re</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">caring</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">do</governor>
          <dependent id="28">caring</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">caring</governor>
          <dependent id="30">thinking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">thinking</governor>
          <dependent id="31">community</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">do</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">disturbed</governor>
          <dependent id="33">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">do</governor>
          <dependent id="34">disturbed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">disturbed</governor>
          <dependent id="35">us</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">much</governor>
          <dependent id="36">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">disturbed</governor>
          <dependent id="37">much</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">see</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">much</governor>
          <dependent id="39">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">tape</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">see</governor>
          <dependent id="41">tape</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">said</governor>
          <dependent id="44">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="45">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Long Beach, about 20 miles south of downtown Los Angeles, has about 450,000 people, including a sizeable black population.</content>
      <tokens>
        <token id="1" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="6" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="south" lemma="south" stem="south" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="downtown" lemma="downtown" stem="downtown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="450,000" lemma="450,000" stem="450,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sizeable" lemma="sizeable" stem="sizeabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Long) (NNP Beach)) (, ,) (ADVP (IN about) (ADVP (NP (CD 20) (NNS miles)) (RB south)) (PP (IN of) (NP (NN downtown)))) (NP (NNP Los) (NNP Angeles)) (, ,)) (VP (VBZ has) (NP (NP (RB about) (CD 450,000) (NNS people)) (, ,) (PP (VBG including) (NP (DT a) (JJ sizeable) (JJ black) (NN population))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="about 450,000 people" type="NP">
          <tokens>
            <token id="14" string="about" />
            <token id="15" string="450,000" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="a sizeable black population" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="sizeable" />
            <token id="21" string="black" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="3" string="Long Beach" type="NP">
          <tokens>
            <token id="1" string="Long" />
            <token id="2" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="4" string="20 miles" type="NP">
          <tokens>
            <token id="5" string="20" />
            <token id="6" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="has about 450,000 people , including a sizeable black population" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="about" />
            <token id="15" string="450,000" />
            <token id="16" string="people" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="a" />
            <token id="20" string="sizeable" />
            <token id="21" string="black" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="6" string="Los Angeles" type="NP">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="7" string="about 450,000 people , including a sizeable black population" type="NP">
          <tokens>
            <token id="14" string="about" />
            <token id="15" string="450,000" />
            <token id="16" string="people" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="a" />
            <token id="20" string="sizeable" />
            <token id="21" string="black" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="Long Beach , about 20 miles south of downtown Los Angeles ," type="NP">
          <tokens>
            <token id="1" string="Long" />
            <token id="2" string="Beach" />
            <token id="3" string="," />
            <token id="4" string="about" />
            <token id="5" string="20" />
            <token id="6" string="miles" />
            <token id="7" string="south" />
            <token id="8" string="of" />
            <token id="9" string="downtown" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="downtown" type="NP">
          <tokens>
            <token id="9" string="downtown" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">Beach</governor>
          <dependent id="1">Long</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">has</governor>
          <dependent id="2">Beach</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">Beach</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">miles</governor>
          <dependent id="5">20</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">south</governor>
          <dependent id="6">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">about</governor>
          <dependent id="7">south</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">downtown</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">about</governor>
          <dependent id="9">downtown</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Angeles</governor>
          <dependent id="10">Los</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Beach</governor>
          <dependent id="11">Angeles</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">people</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">people</governor>
          <dependent id="15">450,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">has</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">population</governor>
          <dependent id="18">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">population</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">population</governor>
          <dependent id="20">sizeable</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">population</governor>
          <dependent id="21">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">people</governor>
          <dependent id="22">population</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Long" />
            <token id="2" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
          </tokens>
        </entity>
        <entity id="3" string="450,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="450,000" />
          </tokens>
        </entity>
        <entity id="4" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Jackson and a companion were driving through a high-crime area of the city when their car was pulled over and Jackson got out.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="companion" lemma="companion" stem="companion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="driving" lemma="drive" stem="drive" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="high-crime" lemma="high-crime" stem="high-crim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pulled" lemma="pull" stem="pull" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="over" lemma="over" stem="over" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Jackson)) (CC and) (NP (DT a) (NN companion))) (VP (VBD were) (VP (VBG driving) (PP (IN through) (NP (NP (DT a) (JJ high-crime) (NN area)) (PP (IN of) (NP (DT the) (NN city))))) (SBAR (WHADVP (WRB when)) (S (S (NP (PRP$ their) (NN car)) (VP (VBD was) (VP (VBN pulled) (ADVP (RB over))))) (CC and) (S (NP (NNP Jackson)) (VP (VBD got) (PRT (RP out)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="pulled over" type="VP">
          <tokens>
            <token id="18" string="pulled" />
            <token id="19" string="over" />
          </tokens>
        </chunking>
        <chunking id="3" string="when their car was pulled over and Jackson got out" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="their" />
            <token id="16" string="car" />
            <token id="17" string="was" />
            <token id="18" string="pulled" />
            <token id="19" string="over" />
            <token id="20" string="and" />
            <token id="21" string="Jackson" />
            <token id="22" string="got" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="got out" type="VP">
          <tokens>
            <token id="22" string="got" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="a high-crime area" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="high-crime" />
            <token id="10" string="area" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson and a companion" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
            <token id="2" string="and" />
            <token id="3" string="a" />
            <token id="4" string="companion" />
          </tokens>
        </chunking>
        <chunking id="9" string="a companion" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="companion" />
          </tokens>
        </chunking>
        <chunking id="10" string="their car" type="NP">
          <tokens>
            <token id="15" string="their" />
            <token id="16" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="were driving through a high-crime area of the city when their car was pulled over and Jackson got out" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="driving" />
            <token id="7" string="through" />
            <token id="8" string="a" />
            <token id="9" string="high-crime" />
            <token id="10" string="area" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="city" />
            <token id="14" string="when" />
            <token id="15" string="their" />
            <token id="16" string="car" />
            <token id="17" string="was" />
            <token id="18" string="pulled" />
            <token id="19" string="over" />
            <token id="20" string="and" />
            <token id="21" string="Jackson" />
            <token id="22" string="got" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="12" string="driving through a high-crime area of the city when their car was pulled over and Jackson got out" type="VP">
          <tokens>
            <token id="6" string="driving" />
            <token id="7" string="through" />
            <token id="8" string="a" />
            <token id="9" string="high-crime" />
            <token id="10" string="area" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="city" />
            <token id="14" string="when" />
            <token id="15" string="their" />
            <token id="16" string="car" />
            <token id="17" string="was" />
            <token id="18" string="pulled" />
            <token id="19" string="over" />
            <token id="20" string="and" />
            <token id="21" string="Jackson" />
            <token id="22" string="got" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="13" string="a high-crime area of the city" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="high-crime" />
            <token id="10" string="area" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="city" />
          </tokens>
        </chunking>
        <chunking id="14" string="was pulled over" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="pulled" />
            <token id="19" string="over" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">driving</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Jackson</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">companion</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Jackson</governor>
          <dependent id="4">companion</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">driving</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">driving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">area</governor>
          <dependent id="7">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">area</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">area</governor>
          <dependent id="9">high-crime</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">driving</governor>
          <dependent id="10">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">city</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">city</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">area</governor>
          <dependent id="13">city</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">pulled</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">car</governor>
          <dependent id="15">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">pulled</governor>
          <dependent id="16">car</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">pulled</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">driving</governor>
          <dependent id="18">pulled</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">pulled</governor>
          <dependent id="19">over</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">pulled</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">got</governor>
          <dependent id="21">Jackson</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">pulled</governor>
          <dependent id="22">got</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">got</governor>
          <dependent id="23">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>The NBC-TV videotape shows a white officer attempting to search Jackson.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="NBC-TV" lemma="NBC-TV" stem="nbc-tv" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="attempting" lemma="attempt" stem="attempt" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="search" lemma="search" stem="search" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP NBC-TV) (NN videotape)) (VP (VBZ shows) (NP (NP (DT a) (JJ white) (NN officer)) (VP (VBG attempting) (S (VP (TO to) (VP (VB search) (NP (NNP Jackson)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shows a white officer attempting to search Jackson" type="VP">
          <tokens>
            <token id="4" string="shows" />
            <token id="5" string="a" />
            <token id="6" string="white" />
            <token id="7" string="officer" />
            <token id="8" string="attempting" />
            <token id="9" string="to" />
            <token id="10" string="search" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="2" string="a white officer" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="white" />
            <token id="7" string="officer" />
          </tokens>
        </chunking>
        <chunking id="3" string="a white officer attempting to search Jackson" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="white" />
            <token id="7" string="officer" />
            <token id="8" string="attempting" />
            <token id="9" string="to" />
            <token id="10" string="search" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="search Jackson" type="VP">
          <tokens>
            <token id="10" string="search" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="attempting to search Jackson" type="VP">
          <tokens>
            <token id="8" string="attempting" />
            <token id="9" string="to" />
            <token id="10" string="search" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="The NBC-TV videotape" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="NBC-TV" />
            <token id="3" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="8" string="to search Jackson" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="search" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">videotape</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">videotape</governor>
          <dependent id="2">NBC-TV</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">shows</governor>
          <dependent id="3">videotape</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">shows</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">officer</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">officer</governor>
          <dependent id="6">white</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">shows</governor>
          <dependent id="7">officer</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">officer</governor>
          <dependent id="8">attempting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">search</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">attempting</governor>
          <dependent id="10">search</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">search</governor>
          <dependent id="11">Jackson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="NBC-TV" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="NBC-TV" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The officer unleashed a stream of profanity and roughed up Jackson after he demanded to know why he was being searched.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="unleashed" lemma="unleash" stem="unleash" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="stream" lemma="stream" stem="stream" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="profanity" lemma="profanity" stem="profan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="roughed" lemma="rough" stem="rough" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="demanded" lemma="demand" stem="demand" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="searched" lemma="search" stem="search" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN officer)) (VP (VP (VBD unleashed) (NP (NP (DT a) (NN stream)) (PP (IN of) (NP (NN profanity))))) (CC and) (VP (VBD roughed) (PRT (RP up)) (NP (NNP Jackson))) (SBAR (IN after) (S (NP (PRP he)) (VP (VBD demanded) (S (VP (TO to) (VP (VB know) (SBAR (WHADVP (WRB why)) (S (NP (PRP he)) (VP (VBD was) (VP (VBG being) (VP (VBN searched))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="after he demanded to know why he was being searched" type="SBAR">
          <tokens>
            <token id="12" string="after" />
            <token id="13" string="he" />
            <token id="14" string="demanded" />
            <token id="15" string="to" />
            <token id="16" string="know" />
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="2" string="roughed up Jackson" type="VP">
          <tokens>
            <token id="9" string="roughed" />
            <token id="10" string="up" />
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="3" string="profanity" type="NP">
          <tokens>
            <token id="7" string="profanity" />
          </tokens>
        </chunking>
        <chunking id="4" string="know why he was being searched" type="VP">
          <tokens>
            <token id="16" string="know" />
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="5" string="why" type="WHADVP">
          <tokens>
            <token id="17" string="why" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="being searched" type="VP">
          <tokens>
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="8" string="to know why he was being searched" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="know" />
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="9" string="The officer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="a stream of profanity" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="stream" />
            <token id="6" string="of" />
            <token id="7" string="profanity" />
          </tokens>
        </chunking>
        <chunking id="11" string="a stream" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="stream" />
          </tokens>
        </chunking>
        <chunking id="12" string="searched" type="VP">
          <tokens>
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="13" string="demanded to know why he was being searched" type="VP">
          <tokens>
            <token id="14" string="demanded" />
            <token id="15" string="to" />
            <token id="16" string="know" />
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="14" string="was being searched" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="15" string="unleashed a stream of profanity and roughed up Jackson after he demanded to know why he was being searched" type="VP">
          <tokens>
            <token id="3" string="unleashed" />
            <token id="4" string="a" />
            <token id="5" string="stream" />
            <token id="6" string="of" />
            <token id="7" string="profanity" />
            <token id="8" string="and" />
            <token id="9" string="roughed" />
            <token id="10" string="up" />
            <token id="11" string="Jackson" />
            <token id="12" string="after" />
            <token id="13" string="he" />
            <token id="14" string="demanded" />
            <token id="15" string="to" />
            <token id="16" string="know" />
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="why he was being searched" type="SBAR">
          <tokens>
            <token id="17" string="why" />
            <token id="18" string="he" />
            <token id="19" string="was" />
            <token id="20" string="being" />
            <token id="21" string="searched" />
          </tokens>
        </chunking>
        <chunking id="18" string="unleashed a stream of profanity" type="VP">
          <tokens>
            <token id="3" string="unleashed" />
            <token id="4" string="a" />
            <token id="5" string="stream" />
            <token id="6" string="of" />
            <token id="7" string="profanity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">officer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">unleashed</governor>
          <dependent id="2">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">unleashed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">stream</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">unleashed</governor>
          <dependent id="5">stream</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">profanity</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">stream</governor>
          <dependent id="7">profanity</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">unleashed</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">unleashed</governor>
          <dependent id="9">roughed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">roughed</governor>
          <dependent id="10">up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">roughed</governor>
          <dependent id="11">Jackson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">demanded</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">demanded</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">unleashed</governor>
          <dependent id="14">demanded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">know</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">demanded</governor>
          <dependent id="16">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">searched</governor>
          <dependent id="17">why</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">searched</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">searched</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">searched</governor>
          <dependent id="20">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">know</governor>
          <dependent id="21">searched</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The incident renewed calls for a citizen board to review the Police Department.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="renewed" lemma="renew" stem="renew" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="review" lemma="review" stem="review" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN incident)) (VP (VBN renewed) (S (NP (NP (NNS calls)) (PP (IN for) (NP (DT a) (NN citizen) (NN board)))) (VP (TO to) (VP (VB review) (NP (DT the) (NNP Police) (NNP Department)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="calls for a citizen board" type="NP">
          <tokens>
            <token id="4" string="calls" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="citizen" />
            <token id="8" string="board" />
          </tokens>
        </chunking>
        <chunking id="2" string="calls" type="NP">
          <tokens>
            <token id="4" string="calls" />
          </tokens>
        </chunking>
        <chunking id="3" string="a citizen board" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="citizen" />
            <token id="8" string="board" />
          </tokens>
        </chunking>
        <chunking id="4" string="review the Police Department" type="VP">
          <tokens>
            <token id="10" string="review" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </chunking>
        <chunking id="5" string="The incident" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="incident" />
          </tokens>
        </chunking>
        <chunking id="6" string="to review the Police Department" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="review" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Police Department" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </chunking>
        <chunking id="8" string="renewed calls for a citizen board to review the Police Department" type="VP">
          <tokens>
            <token id="3" string="renewed" />
            <token id="4" string="calls" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="citizen" />
            <token id="8" string="board" />
            <token id="9" string="to" />
            <token id="10" string="review" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">incident</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">renewed</governor>
          <dependent id="2">incident</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">renewed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">renewed</governor>
          <dependent id="4">calls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">board</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">board</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">board</governor>
          <dependent id="7">citizen</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">calls</governor>
          <dependent id="8">board</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">review</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">renewed</governor>
          <dependent id="10">review</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Department</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Department</governor>
          <dependent id="12">Police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">review</governor>
          <dependent id="13">Department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The idea first was debated last year amid allegations of police brutality.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="debated" lemma="debate" stem="debat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="amid" lemma="amid" stem="amid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN idea)) (ADVP (RB first)) (VP (VBD was) (VP (VBN debated) (NP-TMP (JJ last) (NN year)) (PP (IN amid) (NP (NP (NNS allegations)) (PP (IN of) (NP (NN police) (NN brutality))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="allegations" type="NP">
          <tokens>
            <token id="9" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="2" string="police brutality" type="NP">
          <tokens>
            <token id="11" string="police" />
            <token id="12" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="was debated last year amid allegations of police brutality" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="debated" />
            <token id="6" string="last" />
            <token id="7" string="year" />
            <token id="8" string="amid" />
            <token id="9" string="allegations" />
            <token id="10" string="of" />
            <token id="11" string="police" />
            <token id="12" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="debated last year amid allegations of police brutality" type="VP">
          <tokens>
            <token id="5" string="debated" />
            <token id="6" string="last" />
            <token id="7" string="year" />
            <token id="8" string="amid" />
            <token id="9" string="allegations" />
            <token id="10" string="of" />
            <token id="11" string="police" />
            <token id="12" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="The idea" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="idea" />
          </tokens>
        </chunking>
        <chunking id="6" string="allegations of police brutality" type="NP">
          <tokens>
            <token id="9" string="allegations" />
            <token id="10" string="of" />
            <token id="11" string="police" />
            <token id="12" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">idea</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">debated</governor>
          <dependent id="2">idea</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">debated</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">debated</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">debated</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">year</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">debated</governor>
          <dependent id="7">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">allegations</governor>
          <dependent id="8">amid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">debated</governor>
          <dependent id="9">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">brutality</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">brutality</governor>
          <dependent id="11">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">allegations</governor>
          <dependent id="12">brutality</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="last" />
            <token id="7" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>But Jackson&amp;apost;s boss said the black officer was looking for trouble.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="boss" lemma="boss" stem="boss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Jackson) (POS 's)) (NN boss)) (VP (VBD said) (SBAR (S (NP (DT the) (JJ black) (NN officer)) (VP (VBD was) (VP (VBG looking) (PP (IN for) (NP (NN trouble)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was looking for trouble" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jackson 's boss" type="NP">
          <tokens>
            <token id="2" string="Jackson" />
            <token id="3" string="'s" />
            <token id="4" string="boss" />
          </tokens>
        </chunking>
        <chunking id="3" string="trouble" type="NP">
          <tokens>
            <token id="12" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson 's" type="NP">
          <tokens>
            <token id="2" string="Jackson" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the black officer was looking for trouble" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="officer" />
            <token id="9" string="was" />
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="6" string="the black officer" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the black officer was looking for trouble" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="officer" />
            <token id="9" string="was" />
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="8" string="looking for trouble" type="VP">
          <tokens>
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="trouble" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">boss</governor>
          <dependent id="2">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Jackson</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">boss</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">officer</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">officer</governor>
          <dependent id="7">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">looking</governor>
          <dependent id="8">officer</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">looking</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="10">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">trouble</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">looking</governor>
          <dependent id="12">trouble</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``I submit that if Mr. Jackson had stayed in the vehicle, as did the driver, this incident would not have occurred,&amp;apost;&amp;apost; Hawthorne Police Chief Kenneth R. Stonebraker said at a news conference Monday.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="submit" lemma="submit" stem="submit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stayed" lemma="stay" stem="stai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="vehicle" lemma="vehicle" stem="vehicl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="driver" lemma="driver" stem="driver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="occurred" lemma="occur" stem="occur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="30" string="Kenneth" lemma="Kenneth" stem="kenneth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="31" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Stonebraker" lemma="Stonebraker" stem="stonebrak" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP submit) (SBAR (IN that) (S (SBAR (IN if) (S (NP (NNP Mr.) (NNP Jackson)) (VP (VBD had) (VP (VBN stayed) (PP (IN in) (NP (NP (DT the) (NN vehicle)) (, ,) (SBAR (IN as) (S (VP (VBD did) (NP (DT the) (NN driver))))))))))) (, ,) (NP (DT this) (NN incident)) (VP (MD would) (RB not) (VP (VB have) (VP (VBN occurred)))))))) (, ,) ('' '') (NP (NNP Hawthorne) (NNP Police) (NNP Chief) (NNP Kenneth) (NNP R.) (NNP Stonebraker)) (VP (VBD said) (PP (IN at) (NP (DT a) (NN news) (NN conference))) (NP-TMP (NNP Monday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this incident" type="NP">
          <tokens>
            <token id="19" string="this" />
            <token id="20" string="incident" />
          </tokens>
        </chunking>
        <chunking id="2" string="have occurred" type="VP">
          <tokens>
            <token id="23" string="have" />
            <token id="24" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="3" string="a news conference" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="news" />
            <token id="37" string="conference" />
          </tokens>
        </chunking>
        <chunking id="4" string="the vehicle" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="5" string="occurred" type="VP">
          <tokens>
            <token id="24" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="6" string="would not have occurred" type="VP">
          <tokens>
            <token id="21" string="would" />
            <token id="22" string="not" />
            <token id="23" string="have" />
            <token id="24" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="said at a news conference Monday" type="VP">
          <tokens>
            <token id="33" string="said" />
            <token id="34" string="at" />
            <token id="35" string="a" />
            <token id="36" string="news" />
            <token id="37" string="conference" />
            <token id="38" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mr. Jackson" type="NP">
          <tokens>
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hawthorne Police Chief Kenneth R. Stonebraker" type="NP">
          <tokens>
            <token id="27" string="Hawthorne" />
            <token id="28" string="Police" />
            <token id="29" string="Chief" />
            <token id="30" string="Kenneth" />
            <token id="31" string="R." />
            <token id="32" string="Stonebraker" />
          </tokens>
        </chunking>
        <chunking id="11" string="submit that if Mr. Jackson had stayed in the vehicle , as did the driver , this incident would not have occurred" type="VP">
          <tokens>
            <token id="3" string="submit" />
            <token id="4" string="that" />
            <token id="5" string="if" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="had" />
            <token id="9" string="stayed" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
            <token id="18" string="," />
            <token id="19" string="this" />
            <token id="20" string="incident" />
            <token id="21" string="would" />
            <token id="22" string="not" />
            <token id="23" string="have" />
            <token id="24" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="12" string="stayed in the vehicle , as did the driver" type="VP">
          <tokens>
            <token id="9" string="stayed" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="13" string="the driver" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="14" string="if Mr. Jackson had stayed in the vehicle , as did the driver" type="SBAR">
          <tokens>
            <token id="5" string="if" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="had" />
            <token id="9" string="stayed" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="15" string="the vehicle , as did the driver" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="16" string="had stayed in the vehicle , as did the driver" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="stayed" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="17" string="did the driver" type="VP">
          <tokens>
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
        <chunking id="18" string="that if Mr. Jackson had stayed in the vehicle , as did the driver , this incident would not have occurred" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="if" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="had" />
            <token id="9" string="stayed" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="vehicle" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
            <token id="18" string="," />
            <token id="19" string="this" />
            <token id="20" string="incident" />
            <token id="21" string="would" />
            <token id="22" string="not" />
            <token id="23" string="have" />
            <token id="24" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="19" string="as did the driver" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="did" />
            <token id="16" string="the" />
            <token id="17" string="driver" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">submit</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="3">submit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">occurred</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">stayed</governor>
          <dependent id="5">if</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Jackson</governor>
          <dependent id="6">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stayed</governor>
          <dependent id="7">Jackson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">stayed</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">occurred</governor>
          <dependent id="9">stayed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">vehicle</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">vehicle</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stayed</governor>
          <dependent id="12">vehicle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">did</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">vehicle</governor>
          <dependent id="15">did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">driver</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">did</governor>
          <dependent id="17">driver</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">incident</governor>
          <dependent id="19">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">occurred</governor>
          <dependent id="20">incident</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">occurred</governor>
          <dependent id="21">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">occurred</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">occurred</governor>
          <dependent id="23">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">submit</governor>
          <dependent id="24">occurred</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Stonebraker</governor>
          <dependent id="27">Hawthorne</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Stonebraker</governor>
          <dependent id="28">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Stonebraker</governor>
          <dependent id="29">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Stonebraker</governor>
          <dependent id="30">Kenneth</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Stonebraker</governor>
          <dependent id="31">R.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="32">Stonebraker</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">conference</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">conference</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">conference</governor>
          <dependent id="36">news</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">said</governor>
          <dependent id="37">conference</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="33">said</governor>
          <dependent id="38">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="29" string="Chief" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="38" string="Monday" />
          </tokens>
        </entity>
        <entity id="4" string="Kenneth R. Stonebraker" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Kenneth" />
            <token id="31" string="R." />
            <token id="32" string="Stonebraker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Since the incident apparently was timed by Jackson to coincide with the birthday of Dr. Martin Luther King Jr. the confrontation should be considered ``nothing short of timed sensationalism at the risk of serious injury to all of the parties involved,&amp;apost;&amp;apost; Stonebraker said.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="timed" lemma="time" stem="time" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="coincide" lemma="coincide" stem="coincid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="birthday" lemma="birthday" stem="birthdai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="Luther" lemma="Luther" stem="luther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="confrontation" lemma="confrontation" stem="confront" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="timed" lemma="time" stem="time" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="sensationalism" lemma="sensationalism" stem="sensation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="injury" lemma="injury" stem="injuri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="parties" lemma="party" stem="parti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Stonebraker" lemma="Stonebraker" stem="stonebrak" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="46" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN Since) (S (NP (DT the) (NN incident)) (ADVP (RB apparently)) (VP (VBD was) (VP (VBN timed) (PP (IN by) (NP (NNP Jackson))) (S (VP (TO to) (VP (VB coincide) (PP (IN with) (NP (NP (DT the) (NN birthday)) (PP (IN of) (NP (NNP Dr.) (NNP Martin) (NNP Luther) (NNP King) (NNP Jr.)))))))))))) (NP (DT the) (NN confrontation)) (VP (MD should) (VP (VB be) (VP (VBN considered) (NP (`` ``) (NP (NN nothing)) (ADJP (JJ short) (PP (IN of) (NP (NP (VBN timed) (NN sensationalism)) (PP (IN at) (NP (NP (DT the) (NN risk)) (PP (IN of) (NP (JJ serious) (NN injury))))))))) (PP (TO to) (NP (NP (DT all)) (PP (IN of) (NP (NP (DT the) (NNS parties)) (VP (VBN involved)))))))))) (, ,) ('' '') (NP (NNP Stonebraker)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="38" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="nothing" type="NP">
          <tokens>
            <token id="26" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="3" string="the birthday" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` nothing short of timed sensationalism at the risk of serious injury" type="NP">
          <tokens>
            <token id="25" string="``" />
            <token id="26" string="nothing" />
            <token id="27" string="short" />
            <token id="28" string="of" />
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
          </tokens>
        </chunking>
        <chunking id="5" string="timed sensationalism" type="NP">
          <tokens>
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
          </tokens>
        </chunking>
        <chunking id="6" string="timed sensationalism at the risk of serious injury" type="NP">
          <tokens>
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stonebraker" type="NP">
          <tokens>
            <token id="45" string="Stonebraker" />
          </tokens>
        </chunking>
        <chunking id="8" string="the parties involved" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="parties" />
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="9" string="involved" type="VP">
          <tokens>
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="10" string="was timed by Jackson to coincide with the birthday of Dr. Martin Luther King Jr." type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="timed" />
            <token id="7" string="by" />
            <token id="8" string="Jackson" />
            <token id="9" string="to" />
            <token id="10" string="coincide" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="11" string="Since the incident apparently was timed by Jackson to coincide with the birthday of Dr. Martin Luther King Jr." type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="the" />
            <token id="3" string="incident" />
            <token id="4" string="apparently" />
            <token id="5" string="was" />
            <token id="6" string="timed" />
            <token id="7" string="by" />
            <token id="8" string="Jackson" />
            <token id="9" string="to" />
            <token id="10" string="coincide" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="12" string="the confrontation" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="confrontation" />
          </tokens>
        </chunking>
        <chunking id="13" string="the incident" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="incident" />
          </tokens>
        </chunking>
        <chunking id="14" string="all of the parties involved" type="NP">
          <tokens>
            <token id="38" string="all" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="parties" />
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="15" string="the risk" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="risk" />
          </tokens>
        </chunking>
        <chunking id="16" string="short of timed sensationalism at the risk of serious injury" type="ADJP">
          <tokens>
            <token id="27" string="short" />
            <token id="28" string="of" />
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
          </tokens>
        </chunking>
        <chunking id="17" string="serious injury" type="NP">
          <tokens>
            <token id="35" string="serious" />
            <token id="36" string="injury" />
          </tokens>
        </chunking>
        <chunking id="18" string="coincide with the birthday of Dr. Martin Luther King Jr." type="VP">
          <tokens>
            <token id="10" string="coincide" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="19" string="timed by Jackson to coincide with the birthday of Dr. Martin Luther King Jr." type="VP">
          <tokens>
            <token id="6" string="timed" />
            <token id="7" string="by" />
            <token id="8" string="Jackson" />
            <token id="9" string="to" />
            <token id="10" string="coincide" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="20" string="Jackson" type="NP">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="21" string="the birthday of Dr. Martin Luther King Jr." type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="22" string="the parties" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="parties" />
          </tokens>
        </chunking>
        <chunking id="23" string="Dr. Martin Luther King Jr." type="NP">
          <tokens>
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="24" string="should be considered `` nothing short of timed sensationalism at the risk of serious injury to all of the parties involved" type="VP">
          <tokens>
            <token id="22" string="should" />
            <token id="23" string="be" />
            <token id="24" string="considered" />
            <token id="25" string="``" />
            <token id="26" string="nothing" />
            <token id="27" string="short" />
            <token id="28" string="of" />
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
            <token id="37" string="to" />
            <token id="38" string="all" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="parties" />
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="25" string="considered `` nothing short of timed sensationalism at the risk of serious injury to all of the parties involved" type="VP">
          <tokens>
            <token id="24" string="considered" />
            <token id="25" string="``" />
            <token id="26" string="nothing" />
            <token id="27" string="short" />
            <token id="28" string="of" />
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
            <token id="37" string="to" />
            <token id="38" string="all" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="parties" />
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="26" string="to coincide with the birthday of Dr. Martin Luther King Jr." type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="coincide" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="birthday" />
            <token id="14" string="of" />
            <token id="15" string="Dr." />
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="27" string="be considered `` nothing short of timed sensationalism at the risk of serious injury to all of the parties involved" type="VP">
          <tokens>
            <token id="23" string="be" />
            <token id="24" string="considered" />
            <token id="25" string="``" />
            <token id="26" string="nothing" />
            <token id="27" string="short" />
            <token id="28" string="of" />
            <token id="29" string="timed" />
            <token id="30" string="sensationalism" />
            <token id="31" string="at" />
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
            <token id="37" string="to" />
            <token id="38" string="all" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="parties" />
            <token id="42" string="involved" />
          </tokens>
        </chunking>
        <chunking id="28" string="the risk of serious injury" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="risk" />
            <token id="34" string="of" />
            <token id="35" string="serious" />
            <token id="36" string="injury" />
          </tokens>
        </chunking>
        <chunking id="29" string="said" type="VP">
          <tokens>
            <token id="46" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">timed</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">incident</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">timed</governor>
          <dependent id="3">incident</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">timed</governor>
          <dependent id="4">apparently</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">timed</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">considered</governor>
          <dependent id="6">timed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Jackson</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">timed</governor>
          <dependent id="8">Jackson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">coincide</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">timed</governor>
          <dependent id="10">coincide</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">birthday</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">birthday</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">coincide</governor>
          <dependent id="13">birthday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Jr.</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Jr.</governor>
          <dependent id="15">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Jr.</governor>
          <dependent id="16">Martin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Jr.</governor>
          <dependent id="17">Luther</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Jr.</governor>
          <dependent id="18">King</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">birthday</governor>
          <dependent id="19">Jr.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">confrontation</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">considered</governor>
          <dependent id="21">confrontation</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">considered</governor>
          <dependent id="22">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">considered</governor>
          <dependent id="23">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="46">said</governor>
          <dependent id="24">considered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">considered</governor>
          <dependent id="26">nothing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">nothing</governor>
          <dependent id="27">short</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">sensationalism</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">sensationalism</governor>
          <dependent id="29">timed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">short</governor>
          <dependent id="30">sensationalism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">risk</governor>
          <dependent id="31">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">risk</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">sensationalism</governor>
          <dependent id="33">risk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">injury</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">injury</governor>
          <dependent id="35">serious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">risk</governor>
          <dependent id="36">injury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">all</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">considered</governor>
          <dependent id="38">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">parties</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">parties</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">all</governor>
          <dependent id="41">parties</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="41">parties</governor>
          <dependent id="42">involved</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">said</governor>
          <dependent id="45">Stonebraker</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="46">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Stonebraker" type="PERSON" score="0.0">
          <tokens>
            <token id="45" string="Stonebraker" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Martin Luther King Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Martin" />
            <token id="17" string="Luther" />
            <token id="18" string="King" />
            <token id="19" string="Jr." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``As a police chief,&amp;apost;&amp;apost; he added, ``I do not for one minute condone the unlawful use of force or police brutality.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="minute" lemma="minute" stem="minut" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="condone" lemma="condone" stem="condon" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="unlawful" lemma="unlawful" stem="unlaw" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN As) (NP (DT a) (NN police) (NN chief))) (PRN (, ,) ('' '') (S (NP (PRP he)) (VP (VBD added))) (, ,)) (`` ``) (NP (PRP I)) (VP (VBP do) (SBAR (RB not) (IN for) (S (NP (CD one) (NN minute)) (VP (VBP condone) (NP (NP (DT the) (JJ unlawful) (NN use)) (PP (IN of) (NP (NN force) (CC or) (NN police) (NN brutality)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="do not for one minute condone the unlawful use of force or police brutality" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="not" />
            <token id="15" string="for" />
            <token id="16" string="one" />
            <token id="17" string="minute" />
            <token id="18" string="condone" />
            <token id="19" string="the" />
            <token id="20" string="unlawful" />
            <token id="21" string="use" />
            <token id="22" string="of" />
            <token id="23" string="force" />
            <token id="24" string="or" />
            <token id="25" string="police" />
            <token id="26" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="2" string="condone the unlawful use of force or police brutality" type="VP">
          <tokens>
            <token id="18" string="condone" />
            <token id="19" string="the" />
            <token id="20" string="unlawful" />
            <token id="21" string="use" />
            <token id="22" string="of" />
            <token id="23" string="force" />
            <token id="24" string="or" />
            <token id="25" string="police" />
            <token id="26" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="force or police brutality" type="NP">
          <tokens>
            <token id="23" string="force" />
            <token id="24" string="or" />
            <token id="25" string="police" />
            <token id="26" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="a police chief" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="chief" />
          </tokens>
        </chunking>
        <chunking id="5" string="one minute" type="NP">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="minute" />
          </tokens>
        </chunking>
        <chunking id="6" string="the unlawful use of force or police brutality" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="unlawful" />
            <token id="21" string="use" />
            <token id="22" string="of" />
            <token id="23" string="force" />
            <token id="24" string="or" />
            <token id="25" string="police" />
            <token id="26" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="7" string="the unlawful use" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="unlawful" />
            <token id="21" string="use" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="added" type="VP">
          <tokens>
            <token id="9" string="added" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="not for one minute condone the unlawful use of force or police brutality" type="SBAR">
          <tokens>
            <token id="14" string="not" />
            <token id="15" string="for" />
            <token id="16" string="one" />
            <token id="17" string="minute" />
            <token id="18" string="condone" />
            <token id="19" string="the" />
            <token id="20" string="unlawful" />
            <token id="21" string="use" />
            <token id="22" string="of" />
            <token id="23" string="force" />
            <token id="24" string="or" />
            <token id="25" string="police" />
            <token id="26" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">chief</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">chief</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">chief</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">do</governor>
          <dependent id="5">chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">added</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">do</governor>
          <dependent id="9">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">do</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">condone</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">condone</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">minute</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">condone</governor>
          <dependent id="17">minute</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">do</governor>
          <dependent id="18">condone</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">use</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">use</governor>
          <dependent id="20">unlawful</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">condone</governor>
          <dependent id="21">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">brutality</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">brutality</governor>
          <dependent id="23">force</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">force</governor>
          <dependent id="24">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">force</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">use</governor>
          <dependent id="26">brutality</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one minute" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="minute" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The 30-year-old Jackson, who has been on a stress-related disability leave from his Hawthorne job for 22 months, contends the incident is typical of a pattern of racism by white officers in the Los Angeles area.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="30-year-old" lemma="30-year-old" stem="30-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="stress-related" lemma="stress-related" stem="stress-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="disability" lemma="disability" stem="disabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="leave" lemma="leave" stem="leav" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="contends" lemma="contend" stem="contend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="typical" lemma="typical" stem="typic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="37" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="38" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ 30-year-old) (NNP Jackson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN been) (PP (IN on) (NP (NP (DT a) (JJ stress-related) (NN disability) (NN leave)) (PP (IN from) (NP (PRP$ his) (NAC (NNP Hawthorne)) (NN job))))) (PP (IN for) (NP (CD 22) (NNS months))))))) (, ,)) (VP (VBZ contends) (SBAR (S (NP (DT the) (NN incident)) (VP (VBZ is) (ADJP (JJ typical) (PP (IN of) (NP (NP (DT a) (NN pattern)) (PP (IN of) (NP (NN racism)))))) (PP (IN by) (NP (NP (JJ white) (NNS officers)) (PP (IN in) (NP (DT the) (NNP Los) (NNP Angeles) (NN area))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who has been on a stress-related disability leave from his Hawthorne job for 22 months" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
            <token id="17" string="for" />
            <token id="18" string="22" />
            <token id="19" string="months" />
          </tokens>
        </chunking>
        <chunking id="2" string="a stress-related disability leave from his Hawthorne job" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="22 months" type="NP">
          <tokens>
            <token id="18" string="22" />
            <token id="19" string="months" />
          </tokens>
        </chunking>
        <chunking id="4" string="racism" type="NP">
          <tokens>
            <token id="30" string="racism" />
          </tokens>
        </chunking>
        <chunking id="5" string="a stress-related disability leave" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Los Angeles area" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="area" />
          </tokens>
        </chunking>
        <chunking id="7" string="The 30-year-old Jackson , who has been on a stress-related disability leave from his Hawthorne job for 22 months ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="30-year-old" />
            <token id="3" string="Jackson" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
            <token id="17" string="for" />
            <token id="18" string="22" />
            <token id="19" string="months" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="white officers" type="NP">
          <tokens>
            <token id="32" string="white" />
            <token id="33" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the incident is typical of a pattern of racism by white officers in the Los Angeles area" type="SBAR">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="incident" />
            <token id="24" string="is" />
            <token id="25" string="typical" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="pattern" />
            <token id="29" string="of" />
            <token id="30" string="racism" />
            <token id="31" string="by" />
            <token id="32" string="white" />
            <token id="33" string="officers" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="area" />
          </tokens>
        </chunking>
        <chunking id="10" string="has been on a stress-related disability leave from his Hawthorne job for 22 months" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
            <token id="17" string="for" />
            <token id="18" string="22" />
            <token id="19" string="months" />
          </tokens>
        </chunking>
        <chunking id="11" string="a pattern of racism" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="pattern" />
            <token id="29" string="of" />
            <token id="30" string="racism" />
          </tokens>
        </chunking>
        <chunking id="12" string="his Hawthorne job" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
          </tokens>
        </chunking>
        <chunking id="13" string="been on a stress-related disability leave from his Hawthorne job for 22 months" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="stress-related" />
            <token id="11" string="disability" />
            <token id="12" string="leave" />
            <token id="13" string="from" />
            <token id="14" string="his" />
            <token id="15" string="Hawthorne" />
            <token id="16" string="job" />
            <token id="17" string="for" />
            <token id="18" string="22" />
            <token id="19" string="months" />
          </tokens>
        </chunking>
        <chunking id="14" string="white officers in the Los Angeles area" type="NP">
          <tokens>
            <token id="32" string="white" />
            <token id="33" string="officers" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="area" />
          </tokens>
        </chunking>
        <chunking id="15" string="is typical of a pattern of racism by white officers in the Los Angeles area" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="typical" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="pattern" />
            <token id="29" string="of" />
            <token id="30" string="racism" />
            <token id="31" string="by" />
            <token id="32" string="white" />
            <token id="33" string="officers" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="area" />
          </tokens>
        </chunking>
        <chunking id="16" string="The 30-year-old Jackson" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="30-year-old" />
            <token id="3" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="17" string="typical of a pattern of racism" type="ADJP">
          <tokens>
            <token id="25" string="typical" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="pattern" />
            <token id="29" string="of" />
            <token id="30" string="racism" />
          </tokens>
        </chunking>
        <chunking id="18" string="a pattern" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="19" string="contends the incident is typical of a pattern of racism by white officers in the Los Angeles area" type="VP">
          <tokens>
            <token id="21" string="contends" />
            <token id="22" string="the" />
            <token id="23" string="incident" />
            <token id="24" string="is" />
            <token id="25" string="typical" />
            <token id="26" string="of" />
            <token id="27" string="a" />
            <token id="28" string="pattern" />
            <token id="29" string="of" />
            <token id="30" string="racism" />
            <token id="31" string="by" />
            <token id="32" string="white" />
            <token id="33" string="officers" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="area" />
          </tokens>
        </chunking>
        <chunking id="20" string="the incident" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Jackson</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Jackson</governor>
          <dependent id="2">30-year-old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">contends</governor>
          <dependent id="3">Jackson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">leave</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">leave</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">leave</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">leave</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">leave</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">leave</governor>
          <dependent id="10">stress-related</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">leave</governor>
          <dependent id="11">disability</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Jackson</governor>
          <dependent id="12">leave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">job</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">job</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">job</governor>
          <dependent id="15">Hawthorne</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">leave</governor>
          <dependent id="16">job</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">months</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">months</governor>
          <dependent id="18">22</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">leave</governor>
          <dependent id="19">months</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">contends</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">incident</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">typical</governor>
          <dependent id="23">incident</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">typical</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">contends</governor>
          <dependent id="25">typical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">pattern</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">pattern</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">typical</governor>
          <dependent id="28">pattern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">racism</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">pattern</governor>
          <dependent id="30">racism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">officers</governor>
          <dependent id="31">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">officers</governor>
          <dependent id="32">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">typical</governor>
          <dependent id="33">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">area</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">area</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">area</governor>
          <dependent id="36">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">area</governor>
          <dependent id="37">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">officers</governor>
          <dependent id="38">area</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="22 months" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="22" />
            <token id="19" string="months" />
          </tokens>
        </entity>
        <entity id="2" string="30-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="30-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
          </tokens>
        </entity>
        <entity id="5" string="Hawthorne" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Hawthorne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Jackson alleges racist slurs and actions forced him from the Hawthorne department.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="racist" lemma="racist" stem="racist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="slurs" lemma="slur" stem="slur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="forced" lemma="force" stem="forc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Hawthorne" lemma="hawthorne" stem="hawthorn" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jackson)) (VP (VBZ alleges) (SBAR (S (NP (JJ racist) (NNS slurs) (CC and) (NNS actions)) (VP (VBD forced) (NP (PRP him)) (PP (IN from) (NP (DT the) (NN Hawthorne) (NN department))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="racist slurs and actions forced him from the Hawthorne department" type="SBAR">
          <tokens>
            <token id="3" string="racist" />
            <token id="4" string="slurs" />
            <token id="5" string="and" />
            <token id="6" string="actions" />
            <token id="7" string="forced" />
            <token id="8" string="him" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Hawthorne" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="forced him from the Hawthorne department" type="VP">
          <tokens>
            <token id="7" string="forced" />
            <token id="8" string="him" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Hawthorne" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="racist slurs and actions" type="NP">
          <tokens>
            <token id="3" string="racist" />
            <token id="4" string="slurs" />
            <token id="5" string="and" />
            <token id="6" string="actions" />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Hawthorne department" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Hawthorne" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="alleges racist slurs and actions forced him from the Hawthorne department" type="VP">
          <tokens>
            <token id="2" string="alleges" />
            <token id="3" string="racist" />
            <token id="4" string="slurs" />
            <token id="5" string="and" />
            <token id="6" string="actions" />
            <token id="7" string="forced" />
            <token id="8" string="him" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Hawthorne" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">alleges</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">alleges</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">slurs</governor>
          <dependent id="3">racist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">forced</governor>
          <dependent id="4">slurs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">slurs</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">slurs</governor>
          <dependent id="6">actions</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">alleges</governor>
          <dependent id="7">forced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">forced</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">department</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">department</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">department</governor>
          <dependent id="11">Hawthorne</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">forced</governor>
          <dependent id="12">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Hawthorne" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Hawthorne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>He has a disability lawsuit pending, has filed racism complaints against the department and conducted a similar personal sting operation against Los Angeles police.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="disability" lemma="disability" stem="disabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="conducted" lemma="conduct" stem="conduct" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sting" lemma="sting" stem="sting" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="24" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBZ has) (NP (DT a) (NN disability) (NN lawsuit)) (VBG pending)) (, ,) (VP (VBZ has) (VP (VBN filed) (NP (NN racism) (NNS complaints)) (PP (IN against) (NP (DT the) (NN department))))) (CC and) (VP (VBD conducted) (NP (DT a) (JJ similar) (JJ personal) (NN sting) (NN operation)) (PP (IN against) (NP (NNP Los) (NNP Angeles) (NN police))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has a disability lawsuit pending , has filed racism complaints against the department and conducted a similar personal sting operation against Los Angeles police" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="a" />
            <token id="4" string="disability" />
            <token id="5" string="lawsuit" />
            <token id="6" string="pending" />
            <token id="7" string="," />
            <token id="8" string="has" />
            <token id="9" string="filed" />
            <token id="10" string="racism" />
            <token id="11" string="complaints" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="department" />
            <token id="15" string="and" />
            <token id="16" string="conducted" />
            <token id="17" string="a" />
            <token id="18" string="similar" />
            <token id="19" string="personal" />
            <token id="20" string="sting" />
            <token id="21" string="operation" />
            <token id="22" string="against" />
            <token id="23" string="Los" />
            <token id="24" string="Angeles" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="has a disability lawsuit pending" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="a" />
            <token id="4" string="disability" />
            <token id="5" string="lawsuit" />
            <token id="6" string="pending" />
          </tokens>
        </chunking>
        <chunking id="3" string="a similar personal sting operation" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="similar" />
            <token id="19" string="personal" />
            <token id="20" string="sting" />
            <token id="21" string="operation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the department" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="has filed racism complaints against the department" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="filed" />
            <token id="10" string="racism" />
            <token id="11" string="complaints" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="department" />
          </tokens>
        </chunking>
        <chunking id="6" string="filed racism complaints against the department" type="VP">
          <tokens>
            <token id="9" string="filed" />
            <token id="10" string="racism" />
            <token id="11" string="complaints" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="conducted a similar personal sting operation against Los Angeles police" type="VP">
          <tokens>
            <token id="16" string="conducted" />
            <token id="17" string="a" />
            <token id="18" string="similar" />
            <token id="19" string="personal" />
            <token id="20" string="sting" />
            <token id="21" string="operation" />
            <token id="22" string="against" />
            <token id="23" string="Los" />
            <token id="24" string="Angeles" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="racism complaints" type="NP">
          <tokens>
            <token id="10" string="racism" />
            <token id="11" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="10" string="a disability lawsuit" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="disability" />
            <token id="5" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="11" string="Los Angeles police" type="NP">
          <tokens>
            <token id="23" string="Los" />
            <token id="24" string="Angeles" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">has</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lawsuit</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">lawsuit</governor>
          <dependent id="4">disability</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">has</governor>
          <dependent id="5">lawsuit</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">has</governor>
          <dependent id="6">pending</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">filed</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">has</governor>
          <dependent id="9">filed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">complaints</governor>
          <dependent id="10">racism</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">filed</governor>
          <dependent id="11">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">department</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">department</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">filed</governor>
          <dependent id="14">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">has</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">has</governor>
          <dependent id="16">conducted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">operation</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">operation</governor>
          <dependent id="18">similar</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">operation</governor>
          <dependent id="19">personal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">operation</governor>
          <dependent id="20">sting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">conducted</governor>
          <dependent id="21">operation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">police</governor>
          <dependent id="22">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">police</governor>
          <dependent id="23">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">police</governor>
          <dependent id="24">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">conducted</governor>
          <dependent id="25">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Los" />
            <token id="24" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Jackson was riding as a passenger with Jeffrey Hill, a 30-year-old off-duty state corrections officer, when they were pulled over allegedly for straddling lanes, which they denied.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="riding" lemma="ride" stem="ride" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="passenger" lemma="passenger" stem="passeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Jeffrey" lemma="Jeffrey" stem="jeffrei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="30-year-old" lemma="30-year-old" stem="30-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="off-duty" lemma="off-duty" stem="off-duti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="corrections" lemma="correction" stem="correct" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pulled" lemma="pull" stem="pull" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="allegedly" lemma="allegedly" stem="allegedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="straddling" lemma="straddle" stem="straddl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="lanes" lemma="lane" stem="lane" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jackson)) (VP (VBD was) (VP (VBG riding) (PP (IN as) (NP (NP (DT a) (NN passenger)) (PP (IN with) (NP (NP (NNP Jeffrey) (NNP Hill)) (, ,) (NP (DT a) (JJ 30-year-old) (JJ off-duty) (NN state) (NNS corrections) (NN officer)) (, ,))))) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD were) (VP (VBN pulled) (PP (IN over) (ADVP (RB allegedly))) (PP (IN for) (S (VP (VBG straddling) (NP (NP (NNS lanes)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP they)) (VP (VBD denied)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Jeffrey Hill" type="NP">
          <tokens>
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="2" string="riding as a passenger with Jeffrey Hill , a 30-year-old off-duty state corrections officer , when they were pulled over allegedly for straddling lanes , which they denied" type="VP">
          <tokens>
            <token id="3" string="riding" />
            <token id="4" string="as" />
            <token id="5" string="a" />
            <token id="6" string="passenger" />
            <token id="7" string="with" />
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="30-year-old" />
            <token id="13" string="off-duty" />
            <token id="14" string="state" />
            <token id="15" string="corrections" />
            <token id="16" string="officer" />
            <token id="17" string="," />
            <token id="18" string="when" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="pulled" />
            <token id="22" string="over" />
            <token id="23" string="allegedly" />
            <token id="24" string="for" />
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jeffrey Hill , a 30-year-old off-duty state corrections officer ," type="NP">
          <tokens>
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="30-year-old" />
            <token id="13" string="off-duty" />
            <token id="14" string="state" />
            <token id="15" string="corrections" />
            <token id="16" string="officer" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="a passenger with Jeffrey Hill , a 30-year-old off-duty state corrections officer ," type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="passenger" />
            <token id="7" string="with" />
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="30-year-old" />
            <token id="13" string="off-duty" />
            <token id="14" string="state" />
            <token id="15" string="corrections" />
            <token id="16" string="officer" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="a 30-year-old off-duty state corrections officer" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="30-year-old" />
            <token id="13" string="off-duty" />
            <token id="14" string="state" />
            <token id="15" string="corrections" />
            <token id="16" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="18" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="which they denied" type="SBAR">
          <tokens>
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="was riding as a passenger with Jeffrey Hill , a 30-year-old off-duty state corrections officer , when they were pulled over allegedly for straddling lanes , which they denied" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="riding" />
            <token id="4" string="as" />
            <token id="5" string="a" />
            <token id="6" string="passenger" />
            <token id="7" string="with" />
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="30-year-old" />
            <token id="13" string="off-duty" />
            <token id="14" string="state" />
            <token id="15" string="corrections" />
            <token id="16" string="officer" />
            <token id="17" string="," />
            <token id="18" string="when" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="pulled" />
            <token id="22" string="over" />
            <token id="23" string="allegedly" />
            <token id="24" string="for" />
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="11" string="straddling lanes , which they denied" type="VP">
          <tokens>
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="12" string="pulled over allegedly for straddling lanes , which they denied" type="VP">
          <tokens>
            <token id="21" string="pulled" />
            <token id="22" string="over" />
            <token id="23" string="allegedly" />
            <token id="24" string="for" />
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="13" string="lanes" type="NP">
          <tokens>
            <token id="26" string="lanes" />
          </tokens>
        </chunking>
        <chunking id="14" string="when they were pulled over allegedly for straddling lanes , which they denied" type="SBAR">
          <tokens>
            <token id="18" string="when" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="pulled" />
            <token id="22" string="over" />
            <token id="23" string="allegedly" />
            <token id="24" string="for" />
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="15" string="were pulled over allegedly for straddling lanes , which they denied" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="pulled" />
            <token id="22" string="over" />
            <token id="23" string="allegedly" />
            <token id="24" string="for" />
            <token id="25" string="straddling" />
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="16" string="lanes , which they denied" type="NP">
          <tokens>
            <token id="26" string="lanes" />
            <token id="27" string="," />
            <token id="28" string="which" />
            <token id="29" string="they" />
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="17" string="denied" type="VP">
          <tokens>
            <token id="30" string="denied" />
          </tokens>
        </chunking>
        <chunking id="18" string="a passenger" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="passenger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">riding</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">riding</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">riding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">passenger</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">passenger</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">riding</governor>
          <dependent id="6">passenger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Hill</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Hill</governor>
          <dependent id="8">Jeffrey</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">passenger</governor>
          <dependent id="9">Hill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">officer</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">officer</governor>
          <dependent id="12">30-year-old</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">officer</governor>
          <dependent id="13">off-duty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">officer</governor>
          <dependent id="14">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">officer</governor>
          <dependent id="15">corrections</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Hill</governor>
          <dependent id="16">officer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">pulled</governor>
          <dependent id="18">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">pulled</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">pulled</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">riding</governor>
          <dependent id="21">pulled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">allegedly</governor>
          <dependent id="22">over</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">pulled</governor>
          <dependent id="23">allegedly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">straddling</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">pulled</governor>
          <dependent id="25">straddling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">straddling</governor>
          <dependent id="26">lanes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">denied</governor>
          <dependent id="28">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">denied</governor>
          <dependent id="29">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">lanes</governor>
          <dependent id="30">denied</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jeffrey Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jeffrey" />
            <token id="9" string="Hill" />
          </tokens>
        </entity>
        <entity id="2" string="30-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="30-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Jackson got out after the car stopped and police approached.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="approached" lemma="approach" stem="approach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Jackson)) (VP (VBD got) (PRT (RP out)) (SBAR (IN after) (S (NP (DT the) (NN car)) (VP (VBD stopped)))))) (CC and) (S (NP (NN police)) (VP (VBD approached))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police" type="NP">
          <tokens>
            <token id="9" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="stopped" type="VP">
          <tokens>
            <token id="7" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="approached" type="VP">
          <tokens>
            <token id="10" string="approached" />
          </tokens>
        </chunking>
        <chunking id="5" string="got out after the car stopped" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="out" />
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="car" />
            <token id="7" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="6" string="after the car stopped" type="SBAR">
          <tokens>
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="car" />
            <token id="7" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="7" string="the car" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="car" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">got</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">got</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">got</governor>
          <dependent id="3">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">stopped</governor>
          <dependent id="4">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">car</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stopped</governor>
          <dependent id="6">car</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">got</governor>
          <dependent id="7">stopped</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">got</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">approached</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">got</governor>
          <dependent id="10">approached</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>During an argument, Long Beach Officer Mark Dickey ordered Jackson to face a building and put his hands behind his head.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="argument" lemma="argument" stem="argument" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="ordered" lemma="order" stem="order" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="face" lemma="face" stem="face" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="building" lemma="building" stem="build" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (DT an) (NN argument))) (, ,) (NP (NNP Long) (NNP Beach) (NNP Officer) (NNP Mark) (NNP Dickey)) (VP (VP (VBD ordered) (S (NP (NNP Jackson)) (VP (TO to) (VP (VB face) (NP (DT a) (NN building)))))) (CC and) (VP (VBD put) (NP (PRP$ his) (NNS hands)) (PP (IN behind) (NP (PRP$ his) (NN head))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ordered Jackson to face a building" type="VP">
          <tokens>
            <token id="10" string="ordered" />
            <token id="11" string="Jackson" />
            <token id="12" string="to" />
            <token id="13" string="face" />
            <token id="14" string="a" />
            <token id="15" string="building" />
          </tokens>
        </chunking>
        <chunking id="2" string="put his hands behind his head" type="VP">
          <tokens>
            <token id="17" string="put" />
            <token id="18" string="his" />
            <token id="19" string="hands" />
            <token id="20" string="behind" />
            <token id="21" string="his" />
            <token id="22" string="head" />
          </tokens>
        </chunking>
        <chunking id="3" string="his hands" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="hands" />
          </tokens>
        </chunking>
        <chunking id="4" string="his head" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="head" />
          </tokens>
        </chunking>
        <chunking id="5" string="Long Beach Officer Mark Dickey" type="NP">
          <tokens>
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
            <token id="7" string="Officer" />
            <token id="8" string="Mark" />
            <token id="9" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="6" string="to face a building" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="face" />
            <token id="14" string="a" />
            <token id="15" string="building" />
          </tokens>
        </chunking>
        <chunking id="7" string="a building" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="building" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="9" string="an argument" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="argument" />
          </tokens>
        </chunking>
        <chunking id="10" string="face a building" type="VP">
          <tokens>
            <token id="13" string="face" />
            <token id="14" string="a" />
            <token id="15" string="building" />
          </tokens>
        </chunking>
        <chunking id="11" string="ordered Jackson to face a building and put his hands behind his head" type="VP">
          <tokens>
            <token id="10" string="ordered" />
            <token id="11" string="Jackson" />
            <token id="12" string="to" />
            <token id="13" string="face" />
            <token id="14" string="a" />
            <token id="15" string="building" />
            <token id="16" string="and" />
            <token id="17" string="put" />
            <token id="18" string="his" />
            <token id="19" string="hands" />
            <token id="20" string="behind" />
            <token id="21" string="his" />
            <token id="22" string="head" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">argument</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">argument</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ordered</governor>
          <dependent id="3">argument</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Dickey</governor>
          <dependent id="5">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Dickey</governor>
          <dependent id="6">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Dickey</governor>
          <dependent id="7">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Dickey</governor>
          <dependent id="8">Mark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">ordered</governor>
          <dependent id="9">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">ordered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">ordered</governor>
          <dependent id="11">Jackson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">face</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">ordered</governor>
          <dependent id="13">face</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">building</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">face</governor>
          <dependent id="15">building</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">ordered</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">ordered</governor>
          <dependent id="17">put</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">hands</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">put</governor>
          <dependent id="19">hands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">head</governor>
          <dependent id="20">behind</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">head</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">put</governor>
          <dependent id="22">head</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Mark Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Mark" />
            <token id="9" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Jackson complied, and moments later was pushed through a plate-glass store window.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="complied" lemma="comply" stem="compli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="moments" lemma="moment" stem="moment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pushed" lemma="push" stem="push" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="plate-glass" lemma="plate-glass" stem="plate-glass" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="store" lemma="store" stem="store" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Jackson)) (VP (VBD complied))) (, ,) (CC and) (S (NP (NNS moments)) (ADVP (RB later)) (VP (VBD was) (VP (VBN pushed) (PP (IN through) (NP (DT a) (JJ plate-glass) (NN store) (NN window)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="moments" type="NP">
          <tokens>
            <token id="5" string="moments" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="3" string="a plate-glass store window" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="plate-glass" />
            <token id="12" string="store" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="4" string="was pushed through a plate-glass store window" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="pushed" />
            <token id="9" string="through" />
            <token id="10" string="a" />
            <token id="11" string="plate-glass" />
            <token id="12" string="store" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="5" string="pushed through a plate-glass store window" type="VP">
          <tokens>
            <token id="8" string="pushed" />
            <token id="9" string="through" />
            <token id="10" string="a" />
            <token id="11" string="plate-glass" />
            <token id="12" string="store" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="6" string="complied" type="VP">
          <tokens>
            <token id="2" string="complied" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">complied</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">complied</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">complied</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">pushed</governor>
          <dependent id="5">moments</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">pushed</governor>
          <dependent id="6">later</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">pushed</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">complied</governor>
          <dependent id="8">pushed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">window</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">window</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">window</governor>
          <dependent id="11">plate-glass</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">window</governor>
          <dependent id="12">store</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">pushed</governor>
          <dependent id="13">window</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>``I&amp;apost;m all right.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (RB all) (ADJP (RB right))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="right" type="ADJP">
          <tokens>
            <token id="5" string="right" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m all right" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="all" />
            <token id="5" string="right" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">right</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">right</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">right</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">right</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="5" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>OK, no problem,&amp;apost;&amp;apost; said Jackson on the videotape.</content>
      <tokens>
        <token id="1" string="OK" lemma="ok" stem="ok" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (INTJ (UH OK)) (, ,) (NP (DT no) (NN problem)) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Jackson)) (PP (IN on) (NP (DT the) (NN videotape)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no problem" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="problem" />
          </tokens>
        </chunking>
        <chunking id="2" string="the videotape" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson" type="NP">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="7" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson on the videotape" type="NP">
          <tokens>
            <token id="8" string="Jackson" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="videotape" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="7">said</governor>
          <dependent id="1">OK</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">problem</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="4">problem</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">said</governor>
          <dependent id="8">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">videotape</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">videotape</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Jackson</governor>
          <dependent id="11">videotape</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Police booked Jackson for investigation of interfering with police and challenging a police officer.</content>
      <tokens>
        <token id="1" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="booked" lemma="book" stem="book" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="interfering" lemma="interfere" stem="interf" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="challenging" lemma="challenge" stem="challeng" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Police)) (VP (VBD booked) (NP (NP (NNP Jackson)) (PP (IN for) (NP (NP (NN investigation)) (PP (IN of) (S (VP (VP (VBG interfering) (PP (IN with) (NP (NN police)))) (CC and) (VP (VBG challenging) (NP (DT a) (NN police) (NN officer)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="interfering with police and challenging a police officer" type="VP">
          <tokens>
            <token id="7" string="interfering" />
            <token id="8" string="with" />
            <token id="9" string="police" />
            <token id="10" string="and" />
            <token id="11" string="challenging" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="police" type="NP">
          <tokens>
            <token id="9" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="challenging a police officer" type="VP">
          <tokens>
            <token id="11" string="challenging" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="4" string="a police officer" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="booked Jackson for investigation of interfering with police and challenging a police officer" type="VP">
          <tokens>
            <token id="2" string="booked" />
            <token id="3" string="Jackson" />
            <token id="4" string="for" />
            <token id="5" string="investigation" />
            <token id="6" string="of" />
            <token id="7" string="interfering" />
            <token id="8" string="with" />
            <token id="9" string="police" />
            <token id="10" string="and" />
            <token id="11" string="challenging" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="investigation of interfering with police and challenging a police officer" type="NP">
          <tokens>
            <token id="5" string="investigation" />
            <token id="6" string="of" />
            <token id="7" string="interfering" />
            <token id="8" string="with" />
            <token id="9" string="police" />
            <token id="10" string="and" />
            <token id="11" string="challenging" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="interfering with police" type="VP">
          <tokens>
            <token id="7" string="interfering" />
            <token id="8" string="with" />
            <token id="9" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson" type="NP">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="9" string="investigation" type="NP">
          <tokens>
            <token id="5" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jackson for investigation of interfering with police and challenging a police officer" type="NP">
          <tokens>
            <token id="3" string="Jackson" />
            <token id="4" string="for" />
            <token id="5" string="investigation" />
            <token id="6" string="of" />
            <token id="7" string="interfering" />
            <token id="8" string="with" />
            <token id="9" string="police" />
            <token id="10" string="and" />
            <token id="11" string="challenging" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="11" string="Police" type="NP">
          <tokens>
            <token id="1" string="Police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">booked</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">booked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">booked</governor>
          <dependent id="3">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">investigation</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Jackson</governor>
          <dependent id="5">investigation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">interfering</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">investigation</governor>
          <dependent id="7">interfering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">police</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">interfering</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">interfering</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">interfering</governor>
          <dependent id="11">challenging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">officer</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officer</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">challenging</governor>
          <dependent id="14">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Hill was issued a traffic citation.</content>
      <tokens>
        <token id="1" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="issued" lemma="issue" stem="issu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="citation" lemma="citation" stem="citat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Hill)) (VP (VBD was) (VP (VBN issued) (NP (DT a) (NN traffic) (NN citation)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hill" type="NP">
          <tokens>
            <token id="1" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="2" string="issued a traffic citation" type="VP">
          <tokens>
            <token id="3" string="issued" />
            <token id="4" string="a" />
            <token id="5" string="traffic" />
            <token id="6" string="citation" />
          </tokens>
        </chunking>
        <chunking id="3" string="a traffic citation" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="traffic" />
            <token id="6" string="citation" />
          </tokens>
        </chunking>
        <chunking id="4" string="was issued a traffic citation" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="issued" />
            <token id="4" string="a" />
            <token id="5" string="traffic" />
            <token id="6" string="citation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">issued</governor>
          <dependent id="1">Hill</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">issued</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">issued</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">citation</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">citation</governor>
          <dependent id="5">traffic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">issued</governor>
          <dependent id="6">citation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Hill" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>``The officer simply used violence,&amp;apost;&amp;apost; Jackson said Monday.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN officer)) (ADVP (RB simply)) (VP (VBD used) (NP (NN violence)))) (, ,) ('' '') (NP (NNP Jackson)) (VP (VBD said) (NP-TMP (NNP Monday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The officer" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="used violence" type="VP">
          <tokens>
            <token id="5" string="used" />
            <token id="6" string="violence" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Monday" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson" type="NP">
          <tokens>
            <token id="9" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="violence" type="NP">
          <tokens>
            <token id="6" string="violence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officer</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">used</governor>
          <dependent id="3">officer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">used</governor>
          <dependent id="4">simply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="5">used</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">used</governor>
          <dependent id="6">violence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">said</governor>
          <dependent id="11">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Monday" />
          </tokens>
        </entity>
        <entity id="3" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>``I already cooperated and told him he could search me,&amp;apost;&amp;apost; Jackson said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="cooperated" lemma="cooperate" stem="cooper" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="search" lemma="search" stem="search" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (ADVP (RB already)) (VP (VP (VBD cooperated)) (CC and) (VP (VBD told) (NP (PRP him)) (SBAR (S (NP (PRP he)) (VP (MD could) (VP (VB search) (NP (PRP me))))))))) (, ,) ('' '') (NP (NNP Jackson)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he could search me" type="SBAR">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="could" />
            <token id="10" string="search" />
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="search me" type="VP">
          <tokens>
            <token id="10" string="search" />
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="cooperated" type="VP">
          <tokens>
            <token id="4" string="cooperated" />
          </tokens>
        </chunking>
        <chunking id="4" string="cooperated and told him he could search me" type="VP">
          <tokens>
            <token id="4" string="cooperated" />
            <token id="5" string="and" />
            <token id="6" string="told" />
            <token id="7" string="him" />
            <token id="8" string="he" />
            <token id="9" string="could" />
            <token id="10" string="search" />
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="me" type="NP">
          <tokens>
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="could search me" type="VP">
          <tokens>
            <token id="9" string="could" />
            <token id="10" string="search" />
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="8" string="told him he could search me" type="VP">
          <tokens>
            <token id="6" string="told" />
            <token id="7" string="him" />
            <token id="8" string="he" />
            <token id="9" string="could" />
            <token id="10" string="search" />
            <token id="11" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jackson" type="NP">
          <tokens>
            <token id="14" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">cooperated</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">cooperated</governor>
          <dependent id="3">already</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="4">cooperated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">cooperated</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">cooperated</governor>
          <dependent id="6">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">told</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">search</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">search</governor>
          <dependent id="9">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">told</governor>
          <dependent id="10">search</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">search</governor>
          <dependent id="11">me</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>``I had already had my hands up and was turned to the window and he slammed my face in it.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="slammed" lemma="slam" stem="slam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD had) (ADVP (RB already)) (VP (VP (VBN had) (NP (PRP$ my) (NNS hands)) (ADVP (RB up))) (CC and) (VP (VBD was) (VP (VBN turned) (PP (TO to) (NP (DT the) (NN window)))))))) (CC and) (S (NP (PRP he)) (VP (VBD slammed) (NP (PRP$ my) (NN face)) (PP (IN in) (NP (PRP it))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="had my hands up" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="my" />
            <token id="7" string="hands" />
            <token id="8" string="up" />
          </tokens>
        </chunking>
        <chunking id="2" string="the window" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="window" />
          </tokens>
        </chunking>
        <chunking id="3" string="turned to the window" type="VP">
          <tokens>
            <token id="11" string="turned" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="window" />
          </tokens>
        </chunking>
        <chunking id="4" string="slammed my face in it" type="VP">
          <tokens>
            <token id="17" string="slammed" />
            <token id="18" string="my" />
            <token id="19" string="face" />
            <token id="20" string="in" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="my face" type="NP">
          <tokens>
            <token id="18" string="my" />
            <token id="19" string="face" />
          </tokens>
        </chunking>
        <chunking id="6" string="was turned to the window" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="turned" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="window" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="had my hands up and was turned to the window" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="my" />
            <token id="7" string="hands" />
            <token id="8" string="up" />
            <token id="9" string="and" />
            <token id="10" string="was" />
            <token id="11" string="turned" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="window" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="my hands" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="hands" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="had already had my hands up and was turned to the window" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="already" />
            <token id="5" string="had" />
            <token id="6" string="my" />
            <token id="7" string="hands" />
            <token id="8" string="up" />
            <token id="9" string="and" />
            <token id="10" string="was" />
            <token id="11" string="turned" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="window" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">had</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">had</governor>
          <dependent id="4">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">hands</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="7">hands</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">had</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">had</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">turned</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">had</governor>
          <dependent id="11">turned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">window</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">window</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">turned</governor>
          <dependent id="14">window</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">had</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">slammed</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">had</governor>
          <dependent id="17">slammed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">face</governor>
          <dependent id="18">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">slammed</governor>
          <dependent id="19">face</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">it</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">slammed</governor>
          <dependent id="21">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Jackson received support at a Monday night ceremony in Los Angeles commemorating King&amp;apost;s birthday.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="received" lemma="receive" stem="receiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="8" string="ceremony" lemma="ceremony" stem="ceremoni" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="commemorating" lemma="commemorate" stem="commemor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="birthday" lemma="birthday" stem="birthdai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jackson)) (VP (VBD received) (NP (NN support)) (PP (IN at) (NP (DT a) (NNP Monday) (NN night) (NN ceremony))) (PP (IN in) (NP (NP (NNP Los) (NNP Angeles)) (VP (VBG commemorating) (NP (NP (NNP King) (POS 's)) (NN birthday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="King 's birthday" type="NP">
          <tokens>
            <token id="13" string="King" />
            <token id="14" string="'s" />
            <token id="15" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="2" string="Los Angeles commemorating King 's birthday" type="NP">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="commemorating" />
            <token id="13" string="King" />
            <token id="14" string="'s" />
            <token id="15" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="3" string="King 's" type="NP">
          <tokens>
            <token id="13" string="King" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="received support at a Monday night ceremony in Los Angeles commemorating King 's birthday" type="VP">
          <tokens>
            <token id="2" string="received" />
            <token id="3" string="support" />
            <token id="4" string="at" />
            <token id="5" string="a" />
            <token id="6" string="Monday" />
            <token id="7" string="night" />
            <token id="8" string="ceremony" />
            <token id="9" string="in" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="commemorating" />
            <token id="13" string="King" />
            <token id="14" string="'s" />
            <token id="15" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="6" string="Los Angeles" type="NP">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="7" string="support" type="NP">
          <tokens>
            <token id="3" string="support" />
          </tokens>
        </chunking>
        <chunking id="8" string="commemorating King 's birthday" type="VP">
          <tokens>
            <token id="12" string="commemorating" />
            <token id="13" string="King" />
            <token id="14" string="'s" />
            <token id="15" string="birthday" />
          </tokens>
        </chunking>
        <chunking id="9" string="a Monday night ceremony" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="Monday" />
            <token id="7" string="night" />
            <token id="8" string="ceremony" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">received</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">received</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">received</governor>
          <dependent id="3">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">ceremony</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">ceremony</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">ceremony</governor>
          <dependent id="6">Monday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">ceremony</governor>
          <dependent id="7">night</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">received</governor>
          <dependent id="8">ceremony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Angeles</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Angeles</governor>
          <dependent id="10">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">received</governor>
          <dependent id="11">Angeles</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">Angeles</governor>
          <dependent id="12">commemorating</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">birthday</governor>
          <dependent id="13">King</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">King</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">commemorating</governor>
          <dependent id="15">birthday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="7" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Monday" />
          </tokens>
        </entity>
        <entity id="5" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>``I&amp;apost;m deeply concerned since it strikes me as a period when police violence and excessive force is rampant,&amp;apost;&amp;apost; said Mark Ridley-Thomas, executive director of the Southern Christian Leadership Conference&amp;apost;s Los Angeles chapter.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="deeply" lemma="deeply" stem="deepli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="concerned" lemma="concerned" stem="concern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="strikes" lemma="strike" stem="strike" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rampant" lemma="rampant" stem="rampant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="Ridley-Thomas" lemma="Ridley-Thomas" stem="ridley-thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="executive" lemma="executive" stem="execut" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="Christian" lemma="Christian" stem="christian" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="Leadership" lemma="Leadership" stem="leadership" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="34" string="Conference" lemma="Conference" stem="confer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="37" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="38" string="chapter" lemma="chapter" stem="chapter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (RB deeply) (JJ concerned) (SBAR (IN since) (S (NP (PRP it)) (VP (VBZ strikes) (NP (PRP me)) (PP (IN as) (NP (NP (DT a) (NN period)) (SBAR (WHADVP (WRB when)) (S (NP (NP (NN police) (NN violence)) (CC and) (NP (JJ excessive) (NN force))) (VP (VBZ is) (ADJP (JJ rampant))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Mark) (NNP Ridley-Thomas)) (, ,) (NP (NP (JJ executive) (NN director)) (PP (IN of) (NP (NP (DT the) (NNP Southern) (NNP Christian) (NNP Leadership) (NNP Conference) (POS 's)) (NNP Los) (NNP Angeles) (NN chapter))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Southern Christian Leadership Conference 's Los Angeles chapter" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Southern" />
            <token id="32" string="Christian" />
            <token id="33" string="Leadership" />
            <token id="34" string="Conference" />
            <token id="35" string="'s" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="chapter" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Southern Christian Leadership Conference 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Southern" />
            <token id="32" string="Christian" />
            <token id="33" string="Leadership" />
            <token id="34" string="Conference" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="a period" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="period" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="executive director" type="NP">
          <tokens>
            <token id="27" string="executive" />
            <token id="28" string="director" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="excessive force" type="NP">
          <tokens>
            <token id="17" string="excessive" />
            <token id="18" string="force" />
          </tokens>
        </chunking>
        <chunking id="8" string="deeply concerned since it strikes me as a period when police violence and excessive force is rampant" type="ADJP">
          <tokens>
            <token id="4" string="deeply" />
            <token id="5" string="concerned" />
            <token id="6" string="since" />
            <token id="7" string="it" />
            <token id="8" string="strikes" />
            <token id="9" string="me" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="period" />
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="9" string="police violence and excessive force" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="13" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="a period when police violence and excessive force is rampant" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="period" />
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="12" string="when police violence and excessive force is rampant" type="SBAR">
          <tokens>
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="13" string="executive director of the Southern Christian Leadership Conference 's Los Angeles chapter" type="NP">
          <tokens>
            <token id="27" string="executive" />
            <token id="28" string="director" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Southern" />
            <token id="32" string="Christian" />
            <token id="33" string="Leadership" />
            <token id="34" string="Conference" />
            <token id="35" string="'s" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="chapter" />
          </tokens>
        </chunking>
        <chunking id="14" string="rampant" type="ADJP">
          <tokens>
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="15" string="'m deeply concerned since it strikes me as a period when police violence and excessive force is rampant" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="deeply" />
            <token id="5" string="concerned" />
            <token id="6" string="since" />
            <token id="7" string="it" />
            <token id="8" string="strikes" />
            <token id="9" string="me" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="period" />
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="16" string="police violence" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="violence" />
          </tokens>
        </chunking>
        <chunking id="17" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="18" string="strikes me as a period when police violence and excessive force is rampant" type="VP">
          <tokens>
            <token id="8" string="strikes" />
            <token id="9" string="me" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="period" />
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="19" string="Mark Ridley-Thomas" type="NP">
          <tokens>
            <token id="24" string="Mark" />
            <token id="25" string="Ridley-Thomas" />
          </tokens>
        </chunking>
        <chunking id="20" string="since it strikes me as a period when police violence and excessive force is rampant" type="SBAR">
          <tokens>
            <token id="6" string="since" />
            <token id="7" string="it" />
            <token id="8" string="strikes" />
            <token id="9" string="me" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="period" />
            <token id="13" string="when" />
            <token id="14" string="police" />
            <token id="15" string="violence" />
            <token id="16" string="and" />
            <token id="17" string="excessive" />
            <token id="18" string="force" />
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="21" string="Mark Ridley-Thomas , executive director of the Southern Christian Leadership Conference 's Los Angeles chapter" type="NP">
          <tokens>
            <token id="24" string="Mark" />
            <token id="25" string="Ridley-Thomas" />
            <token id="26" string="," />
            <token id="27" string="executive" />
            <token id="28" string="director" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Southern" />
            <token id="32" string="Christian" />
            <token id="33" string="Leadership" />
            <token id="34" string="Conference" />
            <token id="35" string="'s" />
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
            <token id="38" string="chapter" />
          </tokens>
        </chunking>
        <chunking id="22" string="is rampant" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="rampant" />
          </tokens>
        </chunking>
        <chunking id="23" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">concerned</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">concerned</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">concerned</governor>
          <dependent id="4">deeply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="5">concerned</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">strikes</governor>
          <dependent id="6">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">strikes</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">concerned</governor>
          <dependent id="8">strikes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">strikes</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">period</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">period</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">strikes</governor>
          <dependent id="12">period</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">rampant</governor>
          <dependent id="13">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">violence</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">rampant</governor>
          <dependent id="15">violence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">violence</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">force</governor>
          <dependent id="17">excessive</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">violence</governor>
          <dependent id="18">force</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">rampant</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">period</governor>
          <dependent id="20">rampant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Ridley-Thomas</governor>
          <dependent id="24">Mark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="25">Ridley-Thomas</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">director</governor>
          <dependent id="27">executive</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Ridley-Thomas</governor>
          <dependent id="28">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">chapter</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">Conference</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Conference</governor>
          <dependent id="31">Southern</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Conference</governor>
          <dependent id="32">Christian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Conference</governor>
          <dependent id="33">Leadership</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">chapter</governor>
          <dependent id="34">Conference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Conference</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">chapter</governor>
          <dependent id="36">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">chapter</governor>
          <dependent id="37">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">director</governor>
          <dependent id="38">chapter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Southern Christian Leadership Conference" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Southern" />
            <token id="32" string="Christian" />
            <token id="33" string="Leadership" />
            <token id="34" string="Conference" />
          </tokens>
        </entity>
        <entity id="2" string="Mark Ridley-Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Mark" />
            <token id="25" string="Ridley-Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Los" />
            <token id="37" string="Angeles" />
          </tokens>
        </entity>
        <entity id="4" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>``I&amp;apost;m more so offended since the Hawthorne Police Department, which has no jurisdiction, is making judgment.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="offended" lemma="offended" stem="offend" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="jurisdiction" lemma="jurisdiction" stem="jurisdict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="judgment" lemma="judgment" stem="judgment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (ADJP (ADJP (RBR more) (RB so) (JJ offended)) (SBAR (IN since) (S (NP (NP (DT the) (NNP Hawthorne) (NNP Police) (NNP Department)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (NP (DT no) (NN jurisdiction))))) (, ,)) (VP (VBZ is) (VP (VBG making) (NP (NN judgment)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m more so offended since the Hawthorne Police Department , which has no jurisdiction , is making judgment" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="more" />
            <token id="5" string="so" />
            <token id="6" string="offended" />
            <token id="7" string="since" />
            <token id="8" string="the" />
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
            <token id="17" string="," />
            <token id="18" string="is" />
            <token id="19" string="making" />
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="2" string="is making judgment" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="making" />
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="3" string="no jurisdiction" type="NP">
          <tokens>
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="since the Hawthorne Police Department , which has no jurisdiction , is making judgment" type="SBAR">
          <tokens>
            <token id="7" string="since" />
            <token id="8" string="the" />
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
            <token id="17" string="," />
            <token id="18" string="is" />
            <token id="19" string="making" />
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="6" string="making judgment" type="VP">
          <tokens>
            <token id="19" string="making" />
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="7" string="which has no jurisdiction" type="SBAR">
          <tokens>
            <token id="13" string="which" />
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
          </tokens>
        </chunking>
        <chunking id="8" string="judgment" type="NP">
          <tokens>
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Hawthorne Police Department , which has no jurisdiction ," type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
          </tokens>
        </chunking>
        <chunking id="11" string="more so offended" type="ADJP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="so" />
            <token id="6" string="offended" />
          </tokens>
        </chunking>
        <chunking id="12" string="has no jurisdiction" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
          </tokens>
        </chunking>
        <chunking id="13" string="more so offended since the Hawthorne Police Department , which has no jurisdiction , is making judgment" type="ADJP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="so" />
            <token id="6" string="offended" />
            <token id="7" string="since" />
            <token id="8" string="the" />
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="has" />
            <token id="15" string="no" />
            <token id="16" string="jurisdiction" />
            <token id="17" string="," />
            <token id="18" string="is" />
            <token id="19" string="making" />
            <token id="20" string="judgment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">offended</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">offended</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">offended</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">offended</governor>
          <dependent id="5">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">offended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">making</governor>
          <dependent id="7">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Department</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Department</governor>
          <dependent id="9">Hawthorne</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Department</governor>
          <dependent id="10">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">making</governor>
          <dependent id="11">Department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">has</governor>
          <dependent id="13">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">Department</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">jurisdiction</governor>
          <dependent id="15">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">has</governor>
          <dependent id="16">jurisdiction</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">making</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">offended</governor>
          <dependent id="19">making</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">making</governor>
          <dependent id="20">judgment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hawthorne Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Hawthorne" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Jackson said he chose Long Beach police because of complaints to the Police Misconduct Lawyer&amp;apost;s Referral Service of Los Angeles.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="chose" lemma="choose" stem="chose" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Misconduct" lemma="Misconduct" stem="misconduct" pos="NNP" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="15" string="Lawyer" lemma="Lawyer" stem="lawyer" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Referral" lemma="Referral" stem="referr" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="21" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jackson)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD chose) (NP (NNP Long) (NNP Beach) (NN police)) (PP (IN because) (PP (IN of) (NP (NNS complaints)))) (PP (TO to) (NP (NP (NP (DT the) (NNP Police) (NNP Misconduct) (NNP Lawyer) (POS 's)) (NNP Referral) (NNP Service)) (PP (IN of) (NP (NNP Los) (NNP Angeles))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Police Misconduct Lawyer 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="said he chose Long Beach police because of complaints to the Police Misconduct Lawyer 's Referral Service of Los Angeles" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="chose" />
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
            <token id="7" string="police" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="complaints" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
            <token id="17" string="Referral" />
            <token id="18" string="Service" />
            <token id="19" string="of" />
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="3" string="complaints" type="NP">
          <tokens>
            <token id="10" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Police Misconduct Lawyer 's Referral Service of Los Angeles" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
            <token id="17" string="Referral" />
            <token id="18" string="Service" />
            <token id="19" string="of" />
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Police Misconduct Lawyer 's Referral Service" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
            <token id="17" string="Referral" />
            <token id="18" string="Service" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="he chose Long Beach police because of complaints to the Police Misconduct Lawyer 's Referral Service of Los Angeles" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="chose" />
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
            <token id="7" string="police" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="complaints" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
            <token id="17" string="Referral" />
            <token id="18" string="Service" />
            <token id="19" string="of" />
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="8" string="chose Long Beach police because of complaints to the Police Misconduct Lawyer 's Referral Service of Los Angeles" type="VP">
          <tokens>
            <token id="4" string="chose" />
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
            <token id="7" string="police" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="complaints" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="Police" />
            <token id="14" string="Misconduct" />
            <token id="15" string="Lawyer" />
            <token id="16" string="'s" />
            <token id="17" string="Referral" />
            <token id="18" string="Service" />
            <token id="19" string="of" />
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="9" string="Los Angeles" type="NP">
          <tokens>
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="Long Beach police" type="NP">
          <tokens>
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
            <token id="7" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">chose</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">chose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">police</governor>
          <dependent id="5">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">police</governor>
          <dependent id="6">Beach</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">chose</governor>
          <dependent id="7">police</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">complaints</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">complaints</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chose</governor>
          <dependent id="10">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Service</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Lawyer</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Lawyer</governor>
          <dependent id="13">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Lawyer</governor>
          <dependent id="14">Misconduct</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">Service</governor>
          <dependent id="15">Lawyer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Lawyer</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Service</governor>
          <dependent id="17">Referral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chose</governor>
          <dependent id="18">Service</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Angeles</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Angeles</governor>
          <dependent id="20">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Service</governor>
          <dependent id="21">Angeles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Misconduct" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="14" string="Misconduct" />
          </tokens>
        </entity>
        <entity id="2" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Long" />
            <token id="6" string="Beach" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Los" />
            <token id="21" string="Angeles" />
          </tokens>
        </entity>
        <entity id="5" string="Lawyer" type="TITLE" score="0.0">
          <tokens>
            <token id="15" string="Lawyer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>David Lynn of the referral service said 50 misconduct complaints were filed with his group against the Long Beach police.</content>
      <tokens>
        <token id="1" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Lynn" lemma="Lynn" stem="lynn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="referral" lemma="referral" stem="referr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="19" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP David) (NNP Lynn)) (PP (IN of) (NP (DT the) (NN referral) (NN service)))) (VP (VBD said) (SBAR (S (NP (CD 50) (NN misconduct) (NNS complaints)) (VP (VBD were) (VP (VBN filed) (PP (IN with) (NP (NP (PRP$ his) (NN group)) (PP (IN against) (NP (DT the) (NNP Long) (NNP Beach) (NN police)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="50 misconduct complaints" type="NP">
          <tokens>
            <token id="8" string="50" />
            <token id="9" string="misconduct" />
            <token id="10" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="filed with his group against the Long Beach police" type="VP">
          <tokens>
            <token id="12" string="filed" />
            <token id="13" string="with" />
            <token id="14" string="his" />
            <token id="15" string="group" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="his group" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="group" />
          </tokens>
        </chunking>
        <chunking id="4" string="his group against the Long Beach police" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="group" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="were filed with his group against the Long Beach police" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="filed" />
            <token id="13" string="with" />
            <token id="14" string="his" />
            <token id="15" string="group" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Long Beach police" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="the referral service" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="referral" />
            <token id="6" string="service" />
          </tokens>
        </chunking>
        <chunking id="8" string="David Lynn" type="NP">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Lynn" />
          </tokens>
        </chunking>
        <chunking id="9" string="50 misconduct complaints were filed with his group against the Long Beach police" type="SBAR">
          <tokens>
            <token id="8" string="50" />
            <token id="9" string="misconduct" />
            <token id="10" string="complaints" />
            <token id="11" string="were" />
            <token id="12" string="filed" />
            <token id="13" string="with" />
            <token id="14" string="his" />
            <token id="15" string="group" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="10" string="said 50 misconduct complaints were filed with his group against the Long Beach police" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="50" />
            <token id="9" string="misconduct" />
            <token id="10" string="complaints" />
            <token id="11" string="were" />
            <token id="12" string="filed" />
            <token id="13" string="with" />
            <token id="14" string="his" />
            <token id="15" string="group" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="David Lynn of the referral service" type="NP">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Lynn" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="referral" />
            <token id="6" string="service" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lynn</governor>
          <dependent id="1">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="2">Lynn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">service</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">service</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">service</governor>
          <dependent id="5">referral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Lynn</governor>
          <dependent id="6">service</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">complaints</governor>
          <dependent id="8">50</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">complaints</governor>
          <dependent id="9">misconduct</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">filed</governor>
          <dependent id="10">complaints</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">filed</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="12">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">group</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">group</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">filed</governor>
          <dependent id="15">group</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">police</governor>
          <dependent id="16">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">police</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">police</governor>
          <dependent id="18">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">police</governor>
          <dependent id="19">Beach</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">group</governor>
          <dependent id="20">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="50" />
          </tokens>
        </entity>
        <entity id="3" string="David Lynn" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Lynn" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Of those, 27 were filed by minorities, and 24 of those involved confrontations with white officers.</content>
      <tokens>
        <token id="1" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="27" lemma="27" stem="27" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="confrontations" lemma="confrontation" stem="confront" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Of) (NP (DT those))) (, ,) (NP (CD 27)) (VP (VBD were) (VP (VBN filed) (PP (IN by) (NP (NP (NNS minorities)) (, ,) (CC and) (NP (NP (CD 24)) (PP (IN of) (NP (NP (DT those)) (VP (VBN involved) (NP (NNS confrontations)) (PP (IN with) (NP (JJ white) (NNS officers))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="those involved confrontations with white officers" type="NP">
          <tokens>
            <token id="13" string="those" />
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="11" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="confrontations" type="NP">
          <tokens>
            <token id="15" string="confrontations" />
          </tokens>
        </chunking>
        <chunking id="4" string="27" type="NP">
          <tokens>
            <token id="4" string="27" />
          </tokens>
        </chunking>
        <chunking id="5" string="minorities" type="NP">
          <tokens>
            <token id="8" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="6" string="minorities , and 24 of those involved confrontations with white officers" type="NP">
          <tokens>
            <token id="8" string="minorities" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="24" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="24 of those involved confrontations with white officers" type="NP">
          <tokens>
            <token id="11" string="24" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="were filed by minorities , and 24 of those involved confrontations with white officers" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="filed" />
            <token id="7" string="by" />
            <token id="8" string="minorities" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="24" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="white officers" type="NP">
          <tokens>
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="10" string="filed by minorities , and 24 of those involved confrontations with white officers" type="VP">
          <tokens>
            <token id="6" string="filed" />
            <token id="7" string="by" />
            <token id="8" string="minorities" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="24" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="involved confrontations with white officers" type="VP">
          <tokens>
            <token id="14" string="involved" />
            <token id="15" string="confrontations" />
            <token id="16" string="with" />
            <token id="17" string="white" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="12" string="those" type="NP">
          <tokens>
            <token id="2" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">those</governor>
          <dependent id="1">Of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">filed</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">filed</governor>
          <dependent id="4">27</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">filed</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">minorities</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">filed</governor>
          <dependent id="8">minorities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">minorities</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">minorities</governor>
          <dependent id="11">24</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">those</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">24</governor>
          <dependent id="13">those</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">those</governor>
          <dependent id="14">involved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">involved</governor>
          <dependent id="15">confrontations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">officers</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">officers</governor>
          <dependent id="17">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">involved</governor>
          <dependent id="18">officers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="24" />
          </tokens>
        </entity>
        <entity id="2" string="27" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="27" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="2-3" string="City Council" id_sentence="1" />
      <mentions>
        <mention ids_tokens="29-31" string="the council's" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="6-7" string="county prosecutors" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="2" />
        <mention ids_tokens="16" string="we" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13" string="an incident like this occurring" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The incident" id_sentence="6" />
        <mention ids_tokens="1-2" string="The incident" id_sentence="19" />
        <mention ids_tokens="19-20" string="this incident" id_sentence="22" />
        <mention ids_tokens="2-3" string="the incident" id_sentence="23" />
        <mention ids_tokens="22-23" string="the incident" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="6-7-8" string="Los Angeles County" id_sentence="3" />
      <mentions>
        <mention ids_tokens="29-30" string="Los Angeles" id_sentence="4" />
        <mention ids_tokens="10-11" string="Los Angeles" id_sentence="15" />
        <mention ids_tokens="36-37" string="Los Angeles" id_sentence="25" />
        <mention ids_tokens="23-24" string="Los Angeles" id_sentence="27" />
        <mention ids_tokens="36-37" string="Los Angeles" id_sentence="40" />
        <mention ids_tokens="20-21" string="Los Angeles" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Long Beach City" id_sentence="11" />
      <mentions>
        <mention ids_tokens="20-21" string="Long Beach" id_sentence="4" />
        <mention ids_tokens="22-23" string="Long Beach" id_sentence="8" />
        <mention ids_tokens="5-6" string="Long Beach" id_sentence="9" />
        <mention ids_tokens="21-22" string="Long Beach" id_sentence="14" />
        <mention ids_tokens="1-11" string="Long Beach , about 20 miles south of downtown Los Angeles" id_sentence="15" />
        <mention ids_tokens="1-2" string="Long Beach" id_sentence="15" />
        <mention ids_tokens="12-13" string="the city" id_sentence="16" />
        <mention ids_tokens="5-6" string="Long Beach" id_sentence="42" />
        <mention ids_tokens="18-19" string="Long Beach" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="6-7-8" string="Sgt. Don Jackson" id_sentence="4" />
      <mentions>
        <mention ids_tokens="9" string="Jackson" id_sentence="5" />
        <mention ids_tokens="7" string="your" id_sentence="8" />
        <mention ids_tokens="1" string="Jackson" id_sentence="16" />
        <mention ids_tokens="21" string="Jackson" id_sentence="16" />
        <mention ids_tokens="11" string="Jackson" id_sentence="17" />
        <mention ids_tokens="11" string="Jackson" id_sentence="18" />
        <mention ids_tokens="2-3" string="Jackson's" id_sentence="21" />
        <mention ids_tokens="6-7" string="Mr. Jackson" id_sentence="22" />
        <mention ids_tokens="8" string="Jackson" id_sentence="23" />
        <mention ids_tokens="12" string="I" id_sentence="24" />
        <mention ids_tokens="1-3" string="The 30-year-old Jackson" id_sentence="25" />
        <mention ids_tokens="3" string="Jackson" id_sentence="25" />
        <mention ids_tokens="14" string="his" id_sentence="25" />
        <mention ids_tokens="1" string="Jackson" id_sentence="26" />
        <mention ids_tokens="8" string="him" id_sentence="26" />
        <mention ids_tokens="1" string="He" id_sentence="27" />
        <mention ids_tokens="1" string="Jackson" id_sentence="28" />
        <mention ids_tokens="1" string="Jackson" id_sentence="29" />
        <mention ids_tokens="11" string="Jackson" id_sentence="30" />
        <mention ids_tokens="1" string="Jackson" id_sentence="31" />
        <mention ids_tokens="2" string="I" id_sentence="32" />
        <mention ids_tokens="8-11" string="Jackson on the videotape" id_sentence="33" />
        <mention ids_tokens="3-14" string="Jackson for investigation of interfering with police and challenging a police officer" id_sentence="34" />
        <mention ids_tokens="9" string="Jackson" id_sentence="36" />
        <mention ids_tokens="2" string="I" id_sentence="37" />
        <mention ids_tokens="11" string="me" id_sentence="37" />
        <mention ids_tokens="14" string="Jackson" id_sentence="37" />
        <mention ids_tokens="2" string="I" id_sentence="38" />
        <mention ids_tokens="6" string="my" id_sentence="38" />
        <mention ids_tokens="18" string="my" id_sentence="38" />
        <mention ids_tokens="1" string="Jackson" id_sentence="39" />
        <mention ids_tokens="1" string="Jackson" id_sentence="42" />
        <mention ids_tokens="3" string="he" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20-21" string="the self-styled `` sting '' in Long Beach" id_sentence="4" />
      <mentions>
        <mention ids_tokens="11-12" string="the sting" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="2" string="NBC-TV" id_sentence="5" />
      <mentions>
        <mention ids_tokens="6-7" string="NBC's" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="alleged police racism" id_sentence="7" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="29" string="Chief" id_sentence="22" />
      <mentions>
        <mention ids_tokens="1-6" string="The police chief in Long Beach" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="1-2" string="City officials" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="11" />
        <mention ids_tokens="9" string="we" id_sentence="12" />
        <mention ids_tokens="25" string="we" id_sentence="14" />
        <mention ids_tokens="35" string="us" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a thorough inquiry" id_sentence="10" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Long Beach Mayor Ernie Kell" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="14" />
        <mention ids_tokens="44" string="he" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="11-12" string="police brutality" id_sentence="20" />
      <mentions>
        <mention ids_tokens="7-10" string="racism or police brutality" id_sentence="14" />
        <mention ids_tokens="33" string="it" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="15-16" string="their car" id_sentence="16" />
      <mentions>
        <mention ids_tokens="5-6" string="the car" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11" string="a white officer attempting to search Jackson" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1-2" string="The officer" id_sentence="18" />
        <mention ids_tokens="13" string="he" id_sentence="18" />
        <mention ids_tokens="18" string="he" id_sentence="18" />
        <mention ids_tokens="2-3" string="The officer" id_sentence="36" />
        <mention ids_tokens="7" string="him" id_sentence="37" />
        <mention ids_tokens="8" string="he" id_sentence="37" />
        <mention ids_tokens="16" string="he" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16" string="the Hawthorne Police Department , which has no jurisdiction" id_sentence="41" />
      <mentions>
        <mention ids_tokens="11-13" string="the Police Department" id_sentence="19" />
        <mention ids_tokens="10-12" string="the Hawthorne department" id_sentence="26" />
        <mention ids_tokens="13-14" string="the department" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="27-28-29-30-31-32" string="Hawthorne Police Chief Kenneth R. Stonebraker" id_sentence="22" />
      <mentions>
        <mention ids_tokens="45" string="Stonebraker" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="King 's birthday" id_sentence="39" />
      <mentions>
        <mention ids_tokens="12-19" string="the birthday of Dr. Martin Luther King Jr." id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="32-33-34-35-36-37-38" string="white officers in the Los Angeles area" id_sentence="25" />
      <mentions>
        <mention ids_tokens="19" string="they" id_sentence="28" />
        <mention ids_tokens="29" string="they" id_sentence="28" />
        <mention ids_tokens="17-18" string="white officers" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="10-11" string="racism complaints" id_sentence="27" />
      <mentions>
        <mention ids_tokens="10" string="complaints" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="1" string="Police" id_sentence="34" />
      <mentions>
        <mention ids_tokens="23-25" string="Los Angeles police" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="8-9" string="Jeffrey Hill" id_sentence="28" />
      <mentions>
        <mention ids_tokens="1" string="Hill" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="18-19" string="his hands" id_sentence="30" />
      <mentions>
        <mention ids_tokens="6-7" string="my hands" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13" string="a plate-glass store window" id_sentence="31" />
      <mentions>
        <mention ids_tokens="13-14" string="the window" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="a Monday night ceremony" id_sentence="39" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="24-25-26-27-28-29-30-31-32-33-34-35-36-37-38" string="Mark Ridley-Thomas , executive director of the Southern Christian Leadership Conference 's Los Angeles chapter" id_sentence="40" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20" string="the Long Beach police" id_sentence="43" />
      <mentions>
        <mention ids_tokens="5-7" string="Long Beach police" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20-21" string="the Police Misconduct Lawyer 's Referral Service of Los Angeles" id_sentence="42" />
      <mentions>
        <mention ids_tokens="4-6" string="the referral service" id_sentence="43" />
      </mentions>
    </coreference>
  </coreferences>
</document>
