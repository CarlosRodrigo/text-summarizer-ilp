<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA071590-0068">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Over the past two years, the Ventura County district attorney&amp;apost;s office in four separate incidents has declined to prosecute suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers, records show.</content>
      <tokens>
        <token id="1" string="Over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Ventura" lemma="Ventura" stem="ventura" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="16" string="separate" lemma="separate" stem="separ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="incidents" lemma="incident" stem="incid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="declined" lemma="decline" stem="declin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="contended" lemma="contend" stem="contend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="32" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="various" lemma="various" stem="variou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="offenses" lemma="offens" stem="offens" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="40" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="show" lemma="show" stem="show" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Over) (NP (DT the) (JJ past) (CD two) (NNS years))) (, ,) (NP (NP (NP (DT the) (NNP Ventura) (NNP County) (NN district) (NN attorney) (POS 's)) (NN office)) (PP (IN in) (NP (CD four) (JJ separate) (NNS incidents)))) (VP (VBZ has) (VP (VBN declined) (S (VP (TO to) (VP (VB prosecute) (NP (NP (NNS suspects)) (SBAR (WHNP (WP who)) (S (VP (VBD contended) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD were) (NP (NP (NNS victims)) (PP (IN of) (NP (NN police) (NN brutality)))) (SBAR (IN while) (S (S (VP (VBG being) (VP (VBN arrested) (PP (IN for) (NP (JJ various) (NNS offenses))) (PP (IN by) (NP (NNP Oxnard) (NNS officers)))))) (, ,) (NP (NNS records)) (VP (VBP show)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="victims of police brutality" type="NP">
          <tokens>
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="2" string="to prosecute suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="prosecute" />
            <token id="22" string="suspects" />
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="3" string="while being arrested for various offenses by Oxnard officers , records show" type="SBAR">
          <tokens>
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Ventura County district attorney 's office in four separate incidents" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Ventura" />
            <token id="9" string="County" />
            <token id="10" string="district" />
            <token id="11" string="attorney" />
            <token id="12" string="'s" />
            <token id="13" string="office" />
            <token id="14" string="in" />
            <token id="15" string="four" />
            <token id="16" string="separate" />
            <token id="17" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="5" string="suspects" type="NP">
          <tokens>
            <token id="22" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="6" string="Oxnard officers" type="NP">
          <tokens>
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="being arrested for various offenses by Oxnard officers" type="VP">
          <tokens>
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="9" string="various offenses" type="NP">
          <tokens>
            <token id="36" string="various" />
            <token id="37" string="offenses" />
          </tokens>
        </chunking>
        <chunking id="10" string="arrested for various offenses by Oxnard officers" type="VP">
          <tokens>
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="12" string="declined to prosecute suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="19" string="declined" />
            <token id="20" string="to" />
            <token id="21" string="prosecute" />
            <token id="22" string="suspects" />
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="13" string="records" type="NP">
          <tokens>
            <token id="42" string="records" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Ventura County district attorney 's office" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Ventura" />
            <token id="9" string="County" />
            <token id="10" string="district" />
            <token id="11" string="attorney" />
            <token id="12" string="'s" />
            <token id="13" string="office" />
          </tokens>
        </chunking>
        <chunking id="15" string="show" type="VP">
          <tokens>
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="16" string="four separate incidents" type="NP">
          <tokens>
            <token id="15" string="four" />
            <token id="16" string="separate" />
            <token id="17" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="17" string="suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="NP">
          <tokens>
            <token id="22" string="suspects" />
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="18" string="who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="26" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="has declined to prosecute suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="18" string="has" />
            <token id="19" string="declined" />
            <token id="20" string="to" />
            <token id="21" string="prosecute" />
            <token id="22" string="suspects" />
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="21" string="prosecute suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="21" string="prosecute" />
            <token id="22" string="suspects" />
            <token id="23" string="who" />
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="22" string="contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" type="VP">
          <tokens>
            <token id="24" string="contended" />
            <token id="25" string="that" />
            <token id="26" string="they" />
            <token id="27" string="were" />
            <token id="28" string="victims" />
            <token id="29" string="of" />
            <token id="30" string="police" />
            <token id="31" string="brutality" />
            <token id="32" string="while" />
            <token id="33" string="being" />
            <token id="34" string="arrested" />
            <token id="35" string="for" />
            <token id="36" string="various" />
            <token id="37" string="offenses" />
            <token id="38" string="by" />
            <token id="39" string="Oxnard" />
            <token id="40" string="officers" />
            <token id="41" string="," />
            <token id="42" string="records" />
            <token id="43" string="show" />
          </tokens>
        </chunking>
        <chunking id="23" string="the past two years" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="past" />
            <token id="4" string="two" />
            <token id="5" string="years" />
          </tokens>
        </chunking>
        <chunking id="24" string="police brutality" type="NP">
          <tokens>
            <token id="30" string="police" />
            <token id="31" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="25" string="the Ventura County district attorney 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Ventura" />
            <token id="9" string="County" />
            <token id="10" string="district" />
            <token id="11" string="attorney" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="victims" type="NP">
          <tokens>
            <token id="28" string="victims" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">years</governor>
          <dependent id="1">Over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">years</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">years</governor>
          <dependent id="3">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">years</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">declined</governor>
          <dependent id="5">years</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">attorney</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">attorney</governor>
          <dependent id="8">Ventura</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">attorney</governor>
          <dependent id="9">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">attorney</governor>
          <dependent id="10">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">office</governor>
          <dependent id="11">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">attorney</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">declined</governor>
          <dependent id="13">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">incidents</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">incidents</governor>
          <dependent id="15">four</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">incidents</governor>
          <dependent id="16">separate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">office</governor>
          <dependent id="17">incidents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">declined</governor>
          <dependent id="18">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">prosecute</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">declined</governor>
          <dependent id="21">prosecute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">prosecute</governor>
          <dependent id="22">suspects</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">contended</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">suspects</governor>
          <dependent id="24">contended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">victims</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">victims</governor>
          <dependent id="26">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">victims</governor>
          <dependent id="27">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">contended</governor>
          <dependent id="28">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">brutality</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">brutality</governor>
          <dependent id="30">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">victims</governor>
          <dependent id="31">brutality</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">show</governor>
          <dependent id="32">while</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">arrested</governor>
          <dependent id="33">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="43">show</governor>
          <dependent id="34">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">offenses</governor>
          <dependent id="35">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">offenses</governor>
          <dependent id="36">various</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">arrested</governor>
          <dependent id="37">offenses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">officers</governor>
          <dependent id="38">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">officers</governor>
          <dependent id="39">Oxnard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">arrested</governor>
          <dependent id="40">officers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">show</governor>
          <dependent id="42">records</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">victims</governor>
          <dependent id="43">show</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="four" />
          </tokens>
        </entity>
        <entity id="3" string="the past two years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="past" />
            <token id="4" string="two" />
            <token id="5" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="Ventura County" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Ventura" />
            <token id="9" string="County" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>In a fifth and more recent incident, the district attorney&amp;apost;s office declined to file a charge of assaulting an officer against an Oxnard man who says he and several other guests at a June 15 private party were beaten by Oxnard police.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fifth" lemma="fifth" stem="fifth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="assaulting" lemma="assault" stem="assault" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="guests" lemma="guest" stem="guest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="37" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="44" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT a) (ADJP (ADJP (JJ fifth)) (CC and) (ADJP (RBR more) (JJ recent))) (NN incident))) (, ,) (S (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VBD declined) (S (VP (TO to) (VP (VB file) (NP (NP (DT a) (NN charge)) (PP (IN of) (S (VP (VBG assaulting) (NP (NP (DT an) (NN officer)) (PP (IN against) (NP (DT an) (NNP Oxnard) (NN man))) (SBAR (WHNP (WP who)) (S (VP (VBZ says) (NP (PRP he))))))))))))))) (CC and) (S (NP (NP (JJ several) (JJ other) (NNS guests)) (PP (IN at) (NP (DT a) (NNP June) (CD 15) (JJ private) (NN party)))) (VP (VBD were) (VP (VBN beaten) (PP (IN by) (NP (NNP Oxnard) (NNS police)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="several other guests at a June 15 private party" type="NP">
          <tokens>
            <token id="31" string="several" />
            <token id="32" string="other" />
            <token id="33" string="guests" />
            <token id="34" string="at" />
            <token id="35" string="a" />
            <token id="36" string="June" />
            <token id="37" string="15" />
            <token id="38" string="private" />
            <token id="39" string="party" />
          </tokens>
        </chunking>
        <chunking id="2" string="a charge" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="charge" />
          </tokens>
        </chunking>
        <chunking id="3" string="fifth and more recent" type="ADJP">
          <tokens>
            <token id="3" string="fifth" />
            <token id="4" string="and" />
            <token id="5" string="more" />
            <token id="6" string="recent" />
          </tokens>
        </chunking>
        <chunking id="4" string="says he" type="VP">
          <tokens>
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="5" string="beaten by Oxnard police" type="VP">
          <tokens>
            <token id="41" string="beaten" />
            <token id="42" string="by" />
            <token id="43" string="Oxnard" />
            <token id="44" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="a charge of assaulting an officer against an Oxnard man who says he" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="charge" />
            <token id="19" string="of" />
            <token id="20" string="assaulting" />
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="several other guests" type="NP">
          <tokens>
            <token id="31" string="several" />
            <token id="32" string="other" />
            <token id="33" string="guests" />
          </tokens>
        </chunking>
        <chunking id="8" string="more recent" type="ADJP">
          <tokens>
            <token id="5" string="more" />
            <token id="6" string="recent" />
          </tokens>
        </chunking>
        <chunking id="9" string="a fifth and more recent incident" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="fifth" />
            <token id="4" string="and" />
            <token id="5" string="more" />
            <token id="6" string="recent" />
            <token id="7" string="incident" />
          </tokens>
        </chunking>
        <chunking id="10" string="to file a charge of assaulting an officer against an Oxnard man who says he" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="file" />
            <token id="17" string="a" />
            <token id="18" string="charge" />
            <token id="19" string="of" />
            <token id="20" string="assaulting" />
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="file a charge of assaulting an officer against an Oxnard man who says he" type="VP">
          <tokens>
            <token id="16" string="file" />
            <token id="17" string="a" />
            <token id="18" string="charge" />
            <token id="19" string="of" />
            <token id="20" string="assaulting" />
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="the district attorney 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="district" />
            <token id="11" string="attorney" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="an officer" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="officer" />
          </tokens>
        </chunking>
        <chunking id="14" string="who says he" type="SBAR">
          <tokens>
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="fifth" type="ADJP">
          <tokens>
            <token id="3" string="fifth" />
          </tokens>
        </chunking>
        <chunking id="16" string="declined to file a charge of assaulting an officer against an Oxnard man who says he" type="VP">
          <tokens>
            <token id="14" string="declined" />
            <token id="15" string="to" />
            <token id="16" string="file" />
            <token id="17" string="a" />
            <token id="18" string="charge" />
            <token id="19" string="of" />
            <token id="20" string="assaulting" />
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="assaulting an officer against an Oxnard man who says he" type="VP">
          <tokens>
            <token id="20" string="assaulting" />
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="were beaten by Oxnard police" type="VP">
          <tokens>
            <token id="40" string="were" />
            <token id="41" string="beaten" />
            <token id="42" string="by" />
            <token id="43" string="Oxnard" />
            <token id="44" string="police" />
          </tokens>
        </chunking>
        <chunking id="19" string="an officer against an Oxnard man who says he" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="officer" />
            <token id="23" string="against" />
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
            <token id="27" string="who" />
            <token id="28" string="says" />
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="an Oxnard man" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="Oxnard" />
            <token id="26" string="man" />
          </tokens>
        </chunking>
        <chunking id="21" string="he" type="NP">
          <tokens>
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="22" string="a June 15 private party" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="June" />
            <token id="37" string="15" />
            <token id="38" string="private" />
            <token id="39" string="party" />
          </tokens>
        </chunking>
        <chunking id="23" string="the district attorney 's office" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="district" />
            <token id="11" string="attorney" />
            <token id="12" string="'s" />
            <token id="13" string="office" />
          </tokens>
        </chunking>
        <chunking id="24" string="Oxnard police" type="NP">
          <tokens>
            <token id="43" string="Oxnard" />
            <token id="44" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="7">incident</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">incident</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">incident</governor>
          <dependent id="3">fifth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">fifth</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">recent</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">fifth</governor>
          <dependent id="6">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">declined</governor>
          <dependent id="7">incident</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">attorney</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">attorney</governor>
          <dependent id="10">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">office</governor>
          <dependent id="11">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">attorney</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">declined</governor>
          <dependent id="13">office</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">file</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">declined</governor>
          <dependent id="16">file</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">charge</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">file</governor>
          <dependent id="18">charge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">assaulting</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">charge</governor>
          <dependent id="20">assaulting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">officer</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">assaulting</governor>
          <dependent id="22">officer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">man</governor>
          <dependent id="23">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">man</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">man</governor>
          <dependent id="25">Oxnard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">officer</governor>
          <dependent id="26">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">says</governor>
          <dependent id="27">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">officer</governor>
          <dependent id="28">says</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">says</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">declined</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">guests</governor>
          <dependent id="31">several</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">guests</governor>
          <dependent id="32">other</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="41">beaten</governor>
          <dependent id="33">guests</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">party</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">party</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">party</governor>
          <dependent id="36">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="39">party</governor>
          <dependent id="37">15</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">party</governor>
          <dependent id="38">private</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">guests</governor>
          <dependent id="39">party</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="41">beaten</governor>
          <dependent id="40">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">declined</governor>
          <dependent id="41">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">police</governor>
          <dependent id="42">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">police</governor>
          <dependent id="43">Oxnard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">beaten</governor>
          <dependent id="44">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="assaulting" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="20" string="assaulting" />
          </tokens>
        </entity>
        <entity id="2" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="3" string="June 15" type="DATE" score="0.0">
          <tokens>
            <token id="36" string="June" />
            <token id="37" string="15" />
          </tokens>
        </entity>
        <entity id="4" string="fifth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="fifth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Instead, Anthony Flores, 22, was charged with five misdemeanor counts of resisting arrest.</content>
      <tokens>
        <token id="1" string="Instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Anthony" lemma="Anthony" stem="anthoni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="12" string="misdemeanor" lemma="misdemeanor" stem="misdemeanor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="resisting" lemma="resist" stem="resist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Instead)) (, ,) (NP (NP (NNP Anthony) (NNP Flores)) (, ,) (NP (CD 22)) (, ,)) (VP (VBD was) (VP (VBN charged) (PP (IN with) (NP (NP (CD five) (NN misdemeanor) (NNS counts)) (PP (IN of) (S (VP (VBG resisting) (NP (NN arrest))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="resisting arrest" type="VP">
          <tokens>
            <token id="15" string="resisting" />
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="2" string="arrest" type="NP">
          <tokens>
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="3" string="charged with five misdemeanor counts of resisting arrest" type="VP">
          <tokens>
            <token id="9" string="charged" />
            <token id="10" string="with" />
            <token id="11" string="five" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="counts" />
            <token id="14" string="of" />
            <token id="15" string="resisting" />
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="was charged with five misdemeanor counts of resisting arrest" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="charged" />
            <token id="10" string="with" />
            <token id="11" string="five" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="counts" />
            <token id="14" string="of" />
            <token id="15" string="resisting" />
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="5" string="five misdemeanor counts of resisting arrest" type="NP">
          <tokens>
            <token id="11" string="five" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="counts" />
            <token id="14" string="of" />
            <token id="15" string="resisting" />
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="6" string="Anthony Flores , 22 ," type="NP">
          <tokens>
            <token id="3" string="Anthony" />
            <token id="4" string="Flores" />
            <token id="5" string="," />
            <token id="6" string="22" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="five misdemeanor counts" type="NP">
          <tokens>
            <token id="11" string="five" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="counts" />
          </tokens>
        </chunking>
        <chunking id="8" string="Anthony Flores" type="NP">
          <tokens>
            <token id="3" string="Anthony" />
            <token id="4" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="9" string="22" type="NP">
          <tokens>
            <token id="6" string="22" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">charged</governor>
          <dependent id="1">Instead</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Flores</governor>
          <dependent id="3">Anthony</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">charged</governor>
          <dependent id="4">Flores</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Flores</governor>
          <dependent id="6">22</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">charged</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">charged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">counts</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">counts</governor>
          <dependent id="11">five</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">counts</governor>
          <dependent id="12">misdemeanor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">charged</governor>
          <dependent id="13">counts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">resisting</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">counts</governor>
          <dependent id="15">resisting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">resisting</governor>
          <dependent id="16">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Anthony Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Anthony" />
            <token id="4" string="Flores" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="five" />
          </tokens>
        </entity>
        <entity id="3" string="22" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="22" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The men involved in three of the five incidents have filed police brutality lawsuits against the city, the department or the police officers involved.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="incidents" lemma="incident" stem="incid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS men)) (VP (VBN involved) (PP (IN in) (NP (NP (CD three)) (PP (IN of) (NP (DT the) (CD five) (NNS incidents))))))) (VP (VBP have) (VP (VBN filed) (NP (NN police) (NN brutality) (NNS lawsuits)) (PP (IN against) (NP (NP (DT the) (NN city)) (, ,) (NP (DT the) (NN department)) (CC or) (NP (NP (DT the) (NN police) (NNS officers)) (VP (VBN involved))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="The men involved in three of the five incidents" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="men" />
            <token id="3" string="involved" />
            <token id="4" string="in" />
            <token id="5" string="three" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="five" />
            <token id="9" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="3" string="The men" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="men" />
          </tokens>
        </chunking>
        <chunking id="4" string="the police officers involved" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="police" />
            <token id="24" string="officers" />
            <token id="25" string="involved" />
          </tokens>
        </chunking>
        <chunking id="5" string="three" type="NP">
          <tokens>
            <token id="5" string="three" />
          </tokens>
        </chunking>
        <chunking id="6" string="police brutality lawsuits" type="NP">
          <tokens>
            <token id="12" string="police" />
            <token id="13" string="brutality" />
            <token id="14" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="7" string="the police officers" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="police" />
            <token id="24" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the city , the department or the police officers involved" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="department" />
            <token id="21" string="or" />
            <token id="22" string="the" />
            <token id="23" string="police" />
            <token id="24" string="officers" />
            <token id="25" string="involved" />
          </tokens>
        </chunking>
        <chunking id="9" string="involved in three of the five incidents" type="VP">
          <tokens>
            <token id="3" string="involved" />
            <token id="4" string="in" />
            <token id="5" string="three" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="five" />
            <token id="9" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="10" string="the department" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="involved" type="VP">
          <tokens>
            <token id="25" string="involved" />
          </tokens>
        </chunking>
        <chunking id="12" string="three of the five incidents" type="NP">
          <tokens>
            <token id="5" string="three" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="five" />
            <token id="9" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="13" string="filed police brutality lawsuits against the city , the department or the police officers involved" type="VP">
          <tokens>
            <token id="11" string="filed" />
            <token id="12" string="police" />
            <token id="13" string="brutality" />
            <token id="14" string="lawsuits" />
            <token id="15" string="against" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="department" />
            <token id="21" string="or" />
            <token id="22" string="the" />
            <token id="23" string="police" />
            <token id="24" string="officers" />
            <token id="25" string="involved" />
          </tokens>
        </chunking>
        <chunking id="14" string="the five incidents" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="five" />
            <token id="9" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="15" string="have filed police brutality lawsuits against the city , the department or the police officers involved" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="filed" />
            <token id="12" string="police" />
            <token id="13" string="brutality" />
            <token id="14" string="lawsuits" />
            <token id="15" string="against" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="department" />
            <token id="21" string="or" />
            <token id="22" string="the" />
            <token id="23" string="police" />
            <token id="24" string="officers" />
            <token id="25" string="involved" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">men</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">filed</governor>
          <dependent id="2">men</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">men</governor>
          <dependent id="3">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">three</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">involved</governor>
          <dependent id="5">three</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">incidents</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">incidents</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">incidents</governor>
          <dependent id="8">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">three</governor>
          <dependent id="9">incidents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">filed</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">filed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">lawsuits</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">lawsuits</governor>
          <dependent id="13">brutality</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">filed</governor>
          <dependent id="14">lawsuits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">city</governor>
          <dependent id="15">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">city</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">filed</governor>
          <dependent id="17">city</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">department</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">city</governor>
          <dependent id="20">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">city</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">officers</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">officers</governor>
          <dependent id="23">police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">city</governor>
          <dependent id="24">officers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">officers</governor>
          <dependent id="25">involved</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="three" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The suits, which seek unspecified damages and medical and legal expenses, are pending.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="suits" lemma="suit" stem="suit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="seek" lemma="seek" stem="seek" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="unspecified" lemma="unspecified" stem="unspecifi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="expenses" lemma="expense" stem="expens" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS suits)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP seek) (NP (NP (JJ unspecified) (NNS damages)) (CC and) (NP (JJ medical) (CC and) (JJ legal) (NNS expenses)))))) (, ,)) (VP (VBP are) (ADJP (VBG pending))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="which seek unspecified damages and medical and legal expenses" type="SBAR">
          <tokens>
            <token id="4" string="which" />
            <token id="5" string="seek" />
            <token id="6" string="unspecified" />
            <token id="7" string="damages" />
            <token id="8" string="and" />
            <token id="9" string="medical" />
            <token id="10" string="and" />
            <token id="11" string="legal" />
            <token id="12" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="2" string="The suits , which seek unspecified damages and medical and legal expenses ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suits" />
            <token id="3" string="," />
            <token id="4" string="which" />
            <token id="5" string="seek" />
            <token id="6" string="unspecified" />
            <token id="7" string="damages" />
            <token id="8" string="and" />
            <token id="9" string="medical" />
            <token id="10" string="and" />
            <token id="11" string="legal" />
            <token id="12" string="expenses" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="pending" type="ADJP">
          <tokens>
            <token id="15" string="pending" />
          </tokens>
        </chunking>
        <chunking id="4" string="seek unspecified damages and medical and legal expenses" type="VP">
          <tokens>
            <token id="5" string="seek" />
            <token id="6" string="unspecified" />
            <token id="7" string="damages" />
            <token id="8" string="and" />
            <token id="9" string="medical" />
            <token id="10" string="and" />
            <token id="11" string="legal" />
            <token id="12" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="5" string="are pending" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="pending" />
          </tokens>
        </chunking>
        <chunking id="6" string="unspecified damages" type="NP">
          <tokens>
            <token id="6" string="unspecified" />
            <token id="7" string="damages" />
          </tokens>
        </chunking>
        <chunking id="7" string="The suits" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suits" />
          </tokens>
        </chunking>
        <chunking id="8" string="medical and legal expenses" type="NP">
          <tokens>
            <token id="9" string="medical" />
            <token id="10" string="and" />
            <token id="11" string="legal" />
            <token id="12" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="9" string="unspecified damages and medical and legal expenses" type="NP">
          <tokens>
            <token id="6" string="unspecified" />
            <token id="7" string="damages" />
            <token id="8" string="and" />
            <token id="9" string="medical" />
            <token id="10" string="and" />
            <token id="11" string="legal" />
            <token id="12" string="expenses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">suits</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">pending</governor>
          <dependent id="2">suits</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">seek</governor>
          <dependent id="4">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">suits</governor>
          <dependent id="5">seek</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">damages</governor>
          <dependent id="6">unspecified</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">seek</governor>
          <dependent id="7">damages</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">damages</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">expenses</governor>
          <dependent id="9">medical</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">medical</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">medical</governor>
          <dependent id="11">legal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">damages</governor>
          <dependent id="12">expenses</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">pending</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">pending</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Two of the incidents have led to an investigation by the Police Department&amp;apost;s internal affairs division.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="incidents" lemma="incident" stem="incid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="led" lemma="lead" stem="led" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="internal" lemma="internal" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="affairs" lemma="affair" stem="affair" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="division" lemma="division" stem="divis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD Two)) (PP (IN of) (NP (DT the) (NNS incidents)))) (VP (VBP have) (VP (VBN led) (PP (TO to) (NP (DT an) (NN investigation))) (PP (IN by) (NP (NP (DT the) (NNP Police) (NNP Department) (POS 's)) (JJ internal) (NNS affairs) (NN division))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Police Department 's" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="led to an investigation by the Police Department 's internal affairs division" type="VP">
          <tokens>
            <token id="6" string="led" />
            <token id="7" string="to" />
            <token id="8" string="an" />
            <token id="9" string="investigation" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
            <token id="14" string="'s" />
            <token id="15" string="internal" />
            <token id="16" string="affairs" />
            <token id="17" string="division" />
          </tokens>
        </chunking>
        <chunking id="3" string="Two of the incidents" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="4" string="have led to an investigation by the Police Department 's internal affairs division" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="led" />
            <token id="7" string="to" />
            <token id="8" string="an" />
            <token id="9" string="investigation" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
            <token id="14" string="'s" />
            <token id="15" string="internal" />
            <token id="16" string="affairs" />
            <token id="17" string="division" />
          </tokens>
        </chunking>
        <chunking id="5" string="Two" type="NP">
          <tokens>
            <token id="1" string="Two" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Police Department 's internal affairs division" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
            <token id="14" string="'s" />
            <token id="15" string="internal" />
            <token id="16" string="affairs" />
            <token id="17" string="division" />
          </tokens>
        </chunking>
        <chunking id="7" string="the incidents" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="incidents" />
          </tokens>
        </chunking>
        <chunking id="8" string="an investigation" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">led</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">incidents</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">incidents</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Two</governor>
          <dependent id="4">incidents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">led</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">investigation</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">investigation</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">led</governor>
          <dependent id="9">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">division</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Department</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Department</governor>
          <dependent id="12">Police</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">division</governor>
          <dependent id="13">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Department</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">division</governor>
          <dependent id="15">internal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">division</governor>
          <dependent id="16">affairs</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">led</governor>
          <dependent id="17">division</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Deputy Dist.</content>
      <tokens>
        <token id="1" string="Deputy" lemma="Deputy" stem="deputi" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Dist" lemma="Dist" stem="dist" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NNP Deputy) (NNP Dist) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Deputy Dist ." type="NP">
          <tokens>
            <token id="1" string="Deputy" />
            <token id="2" string="Dist" />
            <token id="3" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Dist</governor>
          <dependent id="1">Deputy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Dist</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Atty. Edward Brodie, misdemeanor supervisor for the office, said the decisions not to prosecute the suspects do not necessarily mean that Oxnard police were not justified in making the arrests.</content>
      <tokens>
        <token id="1" string="Atty." lemma="Atty." stem="atty." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="misdemeanor" lemma="misdemeanor" stem="misdemeanor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="supervisor" lemma="supervisor" stem="supervisor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="necessarily" lemma="necessarily" stem="necessarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="justified" lemma="justified" stem="justifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="arrests" lemma="arrest" stem="arrest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Atty.) (NNP Edward) (NNP Brodie)) (, ,) (NP (NP (NN misdemeanor) (NN supervisor)) (PP (IN for) (NP (DT the) (NN office)))) (, ,)) (VP (VBD said) (NP (DT the) (NNS decisions)) (S (RB not) (VP (TO to) (VP (VB prosecute) (SBAR (S (NP (DT the) (NNS suspects)) (VP (VBP do) (RB not) (ADVP (RB necessarily)) (VP (VB mean) (SBAR (IN that) (S (NP (NNP Oxnard) (NNS police)) (VP (VBD were) (RB not) (ADJP (JJ justified) (PP (IN in) (S (VP (VBG making) (NP (DT the) (NNS arrests))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="misdemeanor supervisor" type="NP">
          <tokens>
            <token id="5" string="misdemeanor" />
            <token id="6" string="supervisor" />
          </tokens>
        </chunking>
        <chunking id="2" string="the office" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="prosecute the suspects do not necessarily mean that Oxnard police were not justified in making the arrests" type="VP">
          <tokens>
            <token id="16" string="prosecute" />
            <token id="17" string="the" />
            <token id="18" string="suspects" />
            <token id="19" string="do" />
            <token id="20" string="not" />
            <token id="21" string="necessarily" />
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="4" string="the suspects do not necessarily mean that Oxnard police were not justified in making the arrests" type="SBAR">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="suspects" />
            <token id="19" string="do" />
            <token id="20" string="not" />
            <token id="21" string="necessarily" />
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="5" string="mean that Oxnard police were not justified in making the arrests" type="VP">
          <tokens>
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="6" string="the decisions" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the decisions not to prosecute the suspects do not necessarily mean that Oxnard police were not justified in making the arrests" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="the" />
            <token id="13" string="decisions" />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="prosecute" />
            <token id="17" string="the" />
            <token id="18" string="suspects" />
            <token id="19" string="do" />
            <token id="20" string="not" />
            <token id="21" string="necessarily" />
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Oxnard police were not justified in making the arrests" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="9" string="making the arrests" type="VP">
          <tokens>
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="10" string="the arrests" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="11" string="were not justified in making the arrests" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="12" string="Atty. Edward Brodie" type="NP">
          <tokens>
            <token id="1" string="Atty." />
            <token id="2" string="Edward" />
            <token id="3" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="13" string="the suspects" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="14" string="Atty. Edward Brodie , misdemeanor supervisor for the office ," type="NP">
          <tokens>
            <token id="1" string="Atty." />
            <token id="2" string="Edward" />
            <token id="3" string="Brodie" />
            <token id="4" string="," />
            <token id="5" string="misdemeanor" />
            <token id="6" string="supervisor" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="office" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="justified in making the arrests" type="ADJP">
          <tokens>
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="16" string="do not necessarily mean that Oxnard police were not justified in making the arrests" type="VP">
          <tokens>
            <token id="19" string="do" />
            <token id="20" string="not" />
            <token id="21" string="necessarily" />
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="17" string="to prosecute the suspects do not necessarily mean that Oxnard police were not justified in making the arrests" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="prosecute" />
            <token id="17" string="the" />
            <token id="18" string="suspects" />
            <token id="19" string="do" />
            <token id="20" string="not" />
            <token id="21" string="necessarily" />
            <token id="22" string="mean" />
            <token id="23" string="that" />
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
            <token id="26" string="were" />
            <token id="27" string="not" />
            <token id="28" string="justified" />
            <token id="29" string="in" />
            <token id="30" string="making" />
            <token id="31" string="the" />
            <token id="32" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="18" string="misdemeanor supervisor for the office" type="NP">
          <tokens>
            <token id="5" string="misdemeanor" />
            <token id="6" string="supervisor" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="office" />
          </tokens>
        </chunking>
        <chunking id="19" string="Oxnard police" type="NP">
          <tokens>
            <token id="24" string="Oxnard" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Brodie</governor>
          <dependent id="1">Atty.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Brodie</governor>
          <dependent id="2">Edward</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="3">Brodie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">supervisor</governor>
          <dependent id="5">misdemeanor</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Brodie</governor>
          <dependent id="6">supervisor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">office</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">office</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">supervisor</governor>
          <dependent id="9">office</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">decisions</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">said</governor>
          <dependent id="13">decisions</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">prosecute</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">prosecute</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">said</governor>
          <dependent id="16">prosecute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">suspects</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">mean</governor>
          <dependent id="18">suspects</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">mean</governor>
          <dependent id="19">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">mean</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">mean</governor>
          <dependent id="21">necessarily</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">prosecute</governor>
          <dependent id="22">mean</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">justified</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">police</governor>
          <dependent id="24">Oxnard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">justified</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">justified</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">justified</governor>
          <dependent id="27">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">mean</governor>
          <dependent id="28">justified</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">making</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">justified</governor>
          <dependent id="30">making</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">arrests</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">making</governor>
          <dependent id="32">arrests</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="Edward Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Edward" />
            <token id="3" string="Brodie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>In each of the four cases, Brodie said, his office did not prosecute because it found that police did not provide enough evidence to prove the charges &amp;quot;beyond a reasonable doubt.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="provide" lemma="provide" stem="provid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="reasonable" lemma="reasonable" stem="reason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT each)) (PP (IN of) (NP (DT the) (CD four) (NNS cases))))) (PRN (, ,) (NP (NNP Brodie)) (VP (VBD said)) (, ,)) (NP (PRP$ his) (NN office)) (VP (VBD did) (RB not) (VP (VB prosecute) (SBAR (IN because) (S (NP (PRP it)) (VP (VBD found) (SBAR (IN that) (S (NP (NN police)) (VP (VBD did) (RB not) (VP (VB provide) (NP (JJ enough) (NN evidence)) (S (VP (TO to) (VP (VB prove) (NP (DT the) (NNS charges)) (`` ``) (PP (IN beyond) (NP (DT a) (JJ reasonable) (NN doubt))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="his office" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="found that police did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="18" string="found" />
            <token id="19" string="that" />
            <token id="20" string="police" />
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="3" string="the charges" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="charges" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="6" string="to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="7" string="each" type="NP">
          <tokens>
            <token id="2" string="each" />
          </tokens>
        </chunking>
        <chunking id="8" string="did not prosecute because it found that police did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="13" string="did" />
            <token id="14" string="not" />
            <token id="15" string="prosecute" />
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="found" />
            <token id="19" string="that" />
            <token id="20" string="police" />
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="9" string="police" type="NP">
          <tokens>
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="10" string="because it found that police did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="SBAR">
          <tokens>
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="found" />
            <token id="19" string="that" />
            <token id="20" string="police" />
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="11" string="that police did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="police" />
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="12" string="the four cases" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="four" />
            <token id="6" string="cases" />
          </tokens>
        </chunking>
        <chunking id="13" string="each of the four cases" type="NP">
          <tokens>
            <token id="2" string="each" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="four" />
            <token id="6" string="cases" />
          </tokens>
        </chunking>
        <chunking id="14" string="Brodie" type="NP">
          <tokens>
            <token id="8" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="15" string="did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="16" string="a reasonable doubt" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="provide enough evidence to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="19" string="prosecute because it found that police did not provide enough evidence to prove the charges `` beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="15" string="prosecute" />
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="found" />
            <token id="19" string="that" />
            <token id="20" string="police" />
            <token id="21" string="did" />
            <token id="22" string="not" />
            <token id="23" string="provide" />
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
            <token id="26" string="to" />
            <token id="27" string="prove" />
            <token id="28" string="the" />
            <token id="29" string="charges" />
            <token id="30" string="&quot;" />
            <token id="31" string="beyond" />
            <token id="32" string="a" />
            <token id="33" string="reasonable" />
            <token id="34" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="20" string="enough evidence" type="NP">
          <tokens>
            <token id="24" string="enough" />
            <token id="25" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">each</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">prosecute</governor>
          <dependent id="2">each</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">cases</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">cases</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">cases</governor>
          <dependent id="5">four</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">each</governor>
          <dependent id="6">cases</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Brodie</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">prosecute</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">office</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">prosecute</governor>
          <dependent id="12">office</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">prosecute</governor>
          <dependent id="13">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">prosecute</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">prosecute</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">found</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">found</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">prosecute</governor>
          <dependent id="18">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">provide</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">provide</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">provide</governor>
          <dependent id="21">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">provide</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">found</governor>
          <dependent id="23">provide</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">evidence</governor>
          <dependent id="24">enough</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">provide</governor>
          <dependent id="25">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">prove</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">provide</governor>
          <dependent id="27">prove</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">charges</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">prove</governor>
          <dependent id="29">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">doubt</governor>
          <dependent id="31">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">doubt</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">doubt</governor>
          <dependent id="33">reasonable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">prove</governor>
          <dependent id="34">doubt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="four" />
          </tokens>
        </entity>
        <entity id="2" string="Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Brodie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>But Jean Farley, a supervisor for the Ventura County public defender&amp;apost;s office, said it is extremely rare for the district attorney&amp;apost;s office not to prosecute a suspect who is accused by police.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Jean" lemma="Jean" stem="jean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Farley" lemma="Farley" stem="farlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="supervisor" lemma="supervisor" stem="supervisor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Ventura" lemma="Ventura" stem="ventura" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="defender" lemma="defender" stem="defend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="extremely" lemma="extremely" stem="extrem" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Jean) (NNP Farley)) (, ,) (NP (NP (DT a) (NN supervisor)) (PP (IN for) (NP (NP (DT the) (NNP Ventura) (NNP County) (NN public) (NN defender) (POS 's)) (NN office)))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB extremely) (JJ rare) (PP (IN for) (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office) (S (RB not) (VP (TO to) (VP (VB prosecute) (NP (NP (DT a) (NN suspect)) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (VP (VBN accused) (PP (IN by) (NP (NN police)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a supervisor for the Ventura County public defender 's office" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="supervisor" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="Ventura" />
            <token id="10" string="County" />
            <token id="11" string="public" />
            <token id="12" string="defender" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jean Farley , a supervisor for the Ventura County public defender 's office ," type="NP">
          <tokens>
            <token id="2" string="Jean" />
            <token id="3" string="Farley" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="supervisor" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="Ventura" />
            <token id="10" string="County" />
            <token id="11" string="public" />
            <token id="12" string="defender" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="it is extremely rare for the district attorney 's office not to prosecute a suspect who is accused by police" type="SBAR">
          <tokens>
            <token id="17" string="it" />
            <token id="18" string="is" />
            <token id="19" string="extremely" />
            <token id="20" string="rare" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
            <token id="26" string="office" />
            <token id="27" string="not" />
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="said it is extremely rare for the district attorney 's office not to prosecute a suspect who is accused by police" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="it" />
            <token id="18" string="is" />
            <token id="19" string="extremely" />
            <token id="20" string="rare" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
            <token id="26" string="office" />
            <token id="27" string="not" />
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="a suspect" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="6" string="is extremely rare for the district attorney 's office not to prosecute a suspect who is accused by police" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="extremely" />
            <token id="20" string="rare" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
            <token id="26" string="office" />
            <token id="27" string="not" />
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jean Farley" type="NP">
          <tokens>
            <token id="2" string="Jean" />
            <token id="3" string="Farley" />
          </tokens>
        </chunking>
        <chunking id="9" string="a suspect who is accused by police" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="10" string="accused by police" type="VP">
          <tokens>
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="police" type="NP">
          <tokens>
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="to prosecute a suspect who is accused by police" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="13" string="the district attorney 's" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Ventura County public defender 's office" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Ventura" />
            <token id="10" string="County" />
            <token id="11" string="public" />
            <token id="12" string="defender" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="15" string="the district attorney 's office not to prosecute a suspect who is accused by police" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
            <token id="26" string="office" />
            <token id="27" string="not" />
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="16" string="prosecute a suspect who is accused by police" type="VP">
          <tokens>
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="17" string="extremely rare for the district attorney 's office not to prosecute a suspect who is accused by police" type="ADJP">
          <tokens>
            <token id="19" string="extremely" />
            <token id="20" string="rare" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="district" />
            <token id="24" string="attorney" />
            <token id="25" string="'s" />
            <token id="26" string="office" />
            <token id="27" string="not" />
            <token id="28" string="to" />
            <token id="29" string="prosecute" />
            <token id="30" string="a" />
            <token id="31" string="suspect" />
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="18" string="a supervisor" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="supervisor" />
          </tokens>
        </chunking>
        <chunking id="19" string="who is accused by police" type="SBAR">
          <tokens>
            <token id="32" string="who" />
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="20" string="is accused by police" type="VP">
          <tokens>
            <token id="33" string="is" />
            <token id="34" string="accused" />
            <token id="35" string="by" />
            <token id="36" string="police" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Ventura County public defender 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Ventura" />
            <token id="10" string="County" />
            <token id="11" string="public" />
            <token id="12" string="defender" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="16">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Farley</governor>
          <dependent id="2">Jean</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="3">Farley</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">supervisor</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Farley</governor>
          <dependent id="6">supervisor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">office</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">defender</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">defender</governor>
          <dependent id="9">Ventura</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">defender</governor>
          <dependent id="10">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">defender</governor>
          <dependent id="11">public</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">office</governor>
          <dependent id="12">defender</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">defender</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">supervisor</governor>
          <dependent id="14">office</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">rare</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">rare</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">rare</governor>
          <dependent id="19">extremely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="20">rare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">office</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">attorney</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">attorney</governor>
          <dependent id="23">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">office</governor>
          <dependent id="24">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">attorney</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">rare</governor>
          <dependent id="26">office</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">prosecute</governor>
          <dependent id="27">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">prosecute</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">office</governor>
          <dependent id="29">prosecute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">suspect</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">prosecute</governor>
          <dependent id="31">suspect</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="34">accused</governor>
          <dependent id="32">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">accused</governor>
          <dependent id="33">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">suspect</governor>
          <dependent id="34">accused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">police</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">accused</governor>
          <dependent id="36">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jean Farley" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Jean" />
            <token id="3" string="Farley" />
          </tokens>
        </entity>
        <entity id="2" string="Ventura County" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Ventura" />
            <token id="10" string="County" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The district attorney&amp;apost;s office may have declined to prosecute the suspects because police brutality has been alleged, she said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="declined" lemma="decline" stem="declin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (MD may) (VP (VB have) (VP (VBN declined) (S (VP (TO to) (VP (VB prosecute) (NP (DT the) (NNS suspects)) (SBAR (IN because) (S (NP (NN police) (NN brutality)) (VP (VBZ has) (VP (VBN been) (VP (VBN alleged))))))))))))) (, ,) (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="because police brutality has been alleged" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="2" string="has been alleged" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="3" string="The district attorney 's office" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
            <token id="5" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="to prosecute the suspects because police brutality has been alleged" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="prosecute" />
            <token id="11" string="the" />
            <token id="12" string="suspects" />
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="5" string="been alleged" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="6" string="alleged" type="VP">
          <tokens>
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="7" string="prosecute the suspects because police brutality has been alleged" type="VP">
          <tokens>
            <token id="10" string="prosecute" />
            <token id="11" string="the" />
            <token id="12" string="suspects" />
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="8" string="the suspects" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="9" string="The district attorney 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="may have declined to prosecute the suspects because police brutality has been alleged" type="VP">
          <tokens>
            <token id="6" string="may" />
            <token id="7" string="have" />
            <token id="8" string="declined" />
            <token id="9" string="to" />
            <token id="10" string="prosecute" />
            <token id="11" string="the" />
            <token id="12" string="suspects" />
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="have declined to prosecute the suspects because police brutality has been alleged" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="declined" />
            <token id="9" string="to" />
            <token id="10" string="prosecute" />
            <token id="11" string="the" />
            <token id="12" string="suspects" />
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="13" string="police brutality" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="14" string="declined to prosecute the suspects because police brutality has been alleged" type="VP">
          <tokens>
            <token id="8" string="declined" />
            <token id="9" string="to" />
            <token id="10" string="prosecute" />
            <token id="11" string="the" />
            <token id="12" string="suspects" />
            <token id="13" string="because" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">attorney</governor>
          <dependent id="2">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">office</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">attorney</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">declined</governor>
          <dependent id="5">office</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">declined</governor>
          <dependent id="6">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">declined</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="8">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">prosecute</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">declined</governor>
          <dependent id="10">prosecute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">suspects</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">prosecute</governor>
          <dependent id="12">suspects</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">alleged</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">brutality</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">alleged</governor>
          <dependent id="15">brutality</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">alleged</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">alleged</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">prosecute</governor>
          <dependent id="18">alleged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Prosecution is usually turned down when the arresting officer is suspected of using excessive force, she said.</content>
      <tokens>
        <token id="1" string="Prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="arresting" lemma="arrest" stem="arrest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Prosecution)) (VP (VBZ is) (ADVP (RB usually)) (VP (VBN turned) (PRT (RP down)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (VBG arresting) (NN officer)) (VP (VBZ is) (VP (VBN suspected) (PP (IN of) (S (VP (VBG using) (NP (JJ excessive) (NN force)))))))))))) (, ,) (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suspected of using excessive force" type="VP">
          <tokens>
            <token id="11" string="suspected" />
            <token id="12" string="of" />
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="2" string="is usually turned down when the arresting officer is suspected of using excessive force" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="usually" />
            <token id="4" string="turned" />
            <token id="5" string="down" />
            <token id="6" string="when" />
            <token id="7" string="the" />
            <token id="8" string="arresting" />
            <token id="9" string="officer" />
            <token id="10" string="is" />
            <token id="11" string="suspected" />
            <token id="12" string="of" />
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="when the arresting officer is suspected of using excessive force" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="the" />
            <token id="8" string="arresting" />
            <token id="9" string="officer" />
            <token id="10" string="is" />
            <token id="11" string="suspected" />
            <token id="12" string="of" />
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="4" string="the arresting officer" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="arresting" />
            <token id="9" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="using excessive force" type="VP">
          <tokens>
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="6" string="turned down when the arresting officer is suspected of using excessive force" type="VP">
          <tokens>
            <token id="4" string="turned" />
            <token id="5" string="down" />
            <token id="6" string="when" />
            <token id="7" string="the" />
            <token id="8" string="arresting" />
            <token id="9" string="officer" />
            <token id="10" string="is" />
            <token id="11" string="suspected" />
            <token id="12" string="of" />
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="excessive force" type="NP">
          <tokens>
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="is suspected of using excessive force" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="suspected" />
            <token id="12" string="of" />
            <token id="13" string="using" />
            <token id="14" string="excessive" />
            <token id="15" string="force" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="17" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="Prosecution" type="NP">
          <tokens>
            <token id="1" string="Prosecution" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">turned</governor>
          <dependent id="1">Prosecution</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">turned</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">turned</governor>
          <dependent id="3">usually</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="4">turned</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">turned</governor>
          <dependent id="5">down</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">suspected</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">officer</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">officer</governor>
          <dependent id="8">arresting</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">suspected</governor>
          <dependent id="9">officer</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">suspected</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">turned</governor>
          <dependent id="11">suspected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">using</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">suspected</governor>
          <dependent id="13">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">force</governor>
          <dependent id="14">excessive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">using</governor>
          <dependent id="15">force</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Assistant Police Chief William Kady declined to discuss the brutality allegations against the Oxnard officers because of pending litigation.</content>
      <tokens>
        <token id="1" string="Assistant" lemma="Assistant" stem="assistant" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="4" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Kady" lemma="Kady" stem="kadi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="discuss" lemma="discuss" stem="discuss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="litigation" lemma="litigation" stem="litig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Assistant) (NNP Police) (NNP Chief) (NNP William) (NNP Kady)) (VP (VBD declined) (S (VP (TO to) (VP (VB discuss) (NP (NP (DT the) (NN brutality) (NNS allegations)) (PP (IN against) (NP (DT the) (NNP Oxnard) (NNS officers)))) (PP (IN because) (IN of) (NP (VBG pending) (NN litigation))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the brutality allegations against the Oxnard officers" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="brutality" />
            <token id="11" string="allegations" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Oxnard officers" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="the brutality allegations" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="brutality" />
            <token id="11" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="4" string="declined to discuss the brutality allegations against the Oxnard officers because of pending litigation" type="VP">
          <tokens>
            <token id="6" string="declined" />
            <token id="7" string="to" />
            <token id="8" string="discuss" />
            <token id="9" string="the" />
            <token id="10" string="brutality" />
            <token id="11" string="allegations" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
            <token id="16" string="because" />
            <token id="17" string="of" />
            <token id="18" string="pending" />
            <token id="19" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="5" string="pending litigation" type="NP">
          <tokens>
            <token id="18" string="pending" />
            <token id="19" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="6" string="Assistant Police Chief William Kady" type="NP">
          <tokens>
            <token id="1" string="Assistant" />
            <token id="2" string="Police" />
            <token id="3" string="Chief" />
            <token id="4" string="William" />
            <token id="5" string="Kady" />
          </tokens>
        </chunking>
        <chunking id="7" string="discuss the brutality allegations against the Oxnard officers because of pending litigation" type="VP">
          <tokens>
            <token id="8" string="discuss" />
            <token id="9" string="the" />
            <token id="10" string="brutality" />
            <token id="11" string="allegations" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
            <token id="16" string="because" />
            <token id="17" string="of" />
            <token id="18" string="pending" />
            <token id="19" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="to discuss the brutality allegations against the Oxnard officers because of pending litigation" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="discuss" />
            <token id="9" string="the" />
            <token id="10" string="brutality" />
            <token id="11" string="allegations" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
            <token id="16" string="because" />
            <token id="17" string="of" />
            <token id="18" string="pending" />
            <token id="19" string="litigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Kady</governor>
          <dependent id="1">Assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kady</governor>
          <dependent id="2">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kady</governor>
          <dependent id="3">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Kady</governor>
          <dependent id="4">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">declined</governor>
          <dependent id="5">Kady</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">discuss</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">declined</governor>
          <dependent id="8">discuss</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">allegations</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">allegations</governor>
          <dependent id="10">brutality</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">discuss</governor>
          <dependent id="11">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">officers</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">officers</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">officers</governor>
          <dependent id="14">Oxnard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">allegations</governor>
          <dependent id="15">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">litigation</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">because</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">litigation</governor>
          <dependent id="18">pending</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">discuss</governor>
          <dependent id="19">litigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="William Kady" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="William" />
            <token id="5" string="Kady" />
          </tokens>
        </entity>
        <entity id="3" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="Chief" />
          </tokens>
        </entity>
        <entity id="4" string="Assistant" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Assistant" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>He said, however, that the decisions by the district attorney&amp;apost;s office not to prosecute the suspects do not reflect poorly on the department.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reflect" lemma="reflect" stem="reflect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="poorly" lemma="poorly" stem="poorli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (, ,) (ADVP (RB however)) (, ,) (SBAR (IN that) (S (NP (NP (DT the) (NNS decisions)) (PP (IN by) (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office) (S (RB not) (VP (TO to) (VP (VB prosecute) (NP (DT the) (NNS suspects)))))))) (VP (VBP do) (RB not) (VP (VB reflect) (ADVP (RB poorly)) (PP (IN on) (NP (DT the) (NN department)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reflect poorly on the department" type="VP">
          <tokens>
            <token id="22" string="reflect" />
            <token id="23" string="poorly" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="the decisions by the district attorney 's office not to prosecute the suspects" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="decisions" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="not" />
            <token id="16" string="to" />
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="3" string="the district attorney 's office not to prosecute the suspects" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="not" />
            <token id="16" string="to" />
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="4" string="the decisions" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the decisions by the district attorney 's office not to prosecute the suspects do not reflect poorly on the department" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="decisions" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="not" />
            <token id="16" string="to" />
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
            <token id="20" string="do" />
            <token id="21" string="not" />
            <token id="22" string="reflect" />
            <token id="23" string="poorly" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="6" string="the suspects" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="7" string="the district attorney 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="the department" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="do not reflect poorly on the department" type="VP">
          <tokens>
            <token id="20" string="do" />
            <token id="21" string="not" />
            <token id="22" string="reflect" />
            <token id="23" string="poorly" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="10" string="to prosecute the suspects" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="11" string="said , however , that the decisions by the district attorney 's office not to prosecute the suspects do not reflect poorly on the department" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="," />
            <token id="4" string="however" />
            <token id="5" string="," />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="decisions" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="not" />
            <token id="16" string="to" />
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
            <token id="20" string="do" />
            <token id="21" string="not" />
            <token id="22" string="reflect" />
            <token id="23" string="poorly" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="prosecute the suspects" type="VP">
          <tokens>
            <token id="17" string="prosecute" />
            <token id="18" string="the" />
            <token id="19" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">said</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">reflect</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">decisions</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">reflect</governor>
          <dependent id="8">decisions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">office</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">attorney</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">attorney</governor>
          <dependent id="11">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">office</governor>
          <dependent id="12">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">attorney</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">decisions</governor>
          <dependent id="14">office</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">prosecute</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">prosecute</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">office</governor>
          <dependent id="17">prosecute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">suspects</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">prosecute</governor>
          <dependent id="19">suspects</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">reflect</governor>
          <dependent id="20">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">reflect</governor>
          <dependent id="21">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="22">reflect</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">reflect</governor>
          <dependent id="23">poorly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">department</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">department</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">reflect</governor>
          <dependent id="26">department</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I don&amp;apost;t think our reputation is any worse than any other department&amp;apost;s,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (SBAR (S (NP (PRP$ our) (NN reputation)) (VP (VBZ is) (ADJP (ADJP (NP (DT any)) (JJR worse)) (PP (IN than) (NP (DT any) (JJ other) (NN department) (POS 's)))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="our reputation" type="NP">
          <tokens>
            <token id="6" string="our" />
            <token id="7" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="2" string="any worse than any other department 's" type="ADJP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="worse" />
            <token id="11" string="than" />
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="do n't think our reputation is any worse than any other department 's" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="think" />
            <token id="6" string="our" />
            <token id="7" string="reputation" />
            <token id="8" string="is" />
            <token id="9" string="any" />
            <token id="10" string="worse" />
            <token id="11" string="than" />
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="think our reputation is any worse than any other department 's" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="our" />
            <token id="7" string="reputation" />
            <token id="8" string="is" />
            <token id="9" string="any" />
            <token id="10" string="worse" />
            <token id="11" string="than" />
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="any other department 's" type="NP">
          <tokens>
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="any worse" type="ADJP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="worse" />
          </tokens>
        </chunking>
        <chunking id="8" string="any" type="NP">
          <tokens>
            <token id="9" string="any" />
          </tokens>
        </chunking>
        <chunking id="9" string="is any worse than any other department 's" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="any" />
            <token id="10" string="worse" />
            <token id="11" string="than" />
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="our reputation is any worse than any other department 's" type="SBAR">
          <tokens>
            <token id="6" string="our" />
            <token id="7" string="reputation" />
            <token id="8" string="is" />
            <token id="9" string="any" />
            <token id="10" string="worse" />
            <token id="11" string="than" />
            <token id="12" string="any" />
            <token id="13" string="other" />
            <token id="14" string="department" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">think</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">think</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">reputation</governor>
          <dependent id="6">our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">worse</governor>
          <dependent id="7">reputation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">worse</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="10">worse</governor>
          <dependent id="9">any</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">think</governor>
          <dependent id="10">worse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">department</governor>
          <dependent id="11">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">department</governor>
          <dependent id="12">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">department</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">worse</governor>
          <dependent id="14">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">department</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>&amp;quot;There is always going to be a disagreement over how much force is used.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="disagreement" lemma="disagreement" stem="disagr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBZ is) (ADVP (RB always)) (VP (VBG going) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (NN disagreement)) (PP (IN over) (SBAR (WHADJP (WRB how) (JJ much)) (S (NP (NN force)) (VP (VBZ is) (VP (VBN used)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="is used" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="3" string="be a disagreement over how much force is used" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
            <token id="10" string="over" />
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="4" string="going to be a disagreement over how much force is used" type="VP">
          <tokens>
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
            <token id="10" string="over" />
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be a disagreement over how much force is used" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
            <token id="10" string="over" />
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="6" string="a disagreement over how much force is used" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
            <token id="10" string="over" />
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="7" string="a disagreement" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
          </tokens>
        </chunking>
        <chunking id="8" string="used" type="VP">
          <tokens>
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="9" string="force" type="NP">
          <tokens>
            <token id="13" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="how much force is used" type="SBAR">
          <tokens>
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
        <chunking id="11" string="is always going to be a disagreement over how much force is used" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="always" />
            <token id="5" string="going" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="a" />
            <token id="9" string="disagreement" />
            <token id="10" string="over" />
            <token id="11" string="how" />
            <token id="12" string="much" />
            <token id="13" string="force" />
            <token id="14" string="is" />
            <token id="15" string="used" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="5">going</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">going</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">going</governor>
          <dependent id="4">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">disagreement</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">disagreement</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">disagreement</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">going</governor>
          <dependent id="9">disagreement</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">used</governor>
          <dependent id="10">over</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">much</governor>
          <dependent id="11">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">used</governor>
          <dependent id="12">much</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">used</governor>
          <dependent id="13">force</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">used</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">disagreement</governor>
          <dependent id="15">used</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>The latest incident involving an accusation of police brutality stemmed from the June 15 clash between 18 officers and about 12 party guests at a house in the 1300 block of South E Street.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="involving" lemma="involve" stem="involv" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="accusation" lemma="accusation" stem="accus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="stemmed" lemma="stem" stem="stem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="clash" lemma="clash" stem="clash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="guests" lemma="guest" stem="guest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="1300" lemma="1300" stem="1300" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="block" lemma="block" stem="block" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="E" lemma="E" stem="e" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="Street" lemma="Street" stem="street" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJS latest) (NN incident)) (PP (VBG involving) (NP (NP (DT an) (NN accusation)) (PP (IN of) (NP (NN police) (NN brutality)))))) (VP (VBD stemmed) (PP (PP (IN from) (NP (NP (DT the) (NNP June) (CD 15) (NN clash)) (PP (IN between) (NP (CD 18) (NNS officers))))) (CC and) (PP (IN about) (NP (CD 12) (NN party) (NNS guests)))) (PP (IN at) (NP (NP (DT a) (NN house)) (PP (IN in) (NP (NP (DT the) (CD 1300) (NN block)) (PP (IN of) (NP (NNP South) (NNP E) (NNP Street)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The latest incident involving an accusation of police brutality" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="latest" />
            <token id="3" string="incident" />
            <token id="4" string="involving" />
            <token id="5" string="an" />
            <token id="6" string="accusation" />
            <token id="7" string="of" />
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="2" string="a house in the 1300 block of South E Street" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="house" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1300" />
            <token id="30" string="block" />
            <token id="31" string="of" />
            <token id="32" string="South" />
            <token id="33" string="E" />
            <token id="34" string="Street" />
          </tokens>
        </chunking>
        <chunking id="3" string="a house" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="house" />
          </tokens>
        </chunking>
        <chunking id="4" string="The latest incident" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="latest" />
            <token id="3" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="the June 15 clash between 18 officers" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="June" />
            <token id="14" string="15" />
            <token id="15" string="clash" />
            <token id="16" string="between" />
            <token id="17" string="18" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 1300 block" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="1300" />
            <token id="30" string="block" />
          </tokens>
        </chunking>
        <chunking id="7" string="South E Street" type="NP">
          <tokens>
            <token id="32" string="South" />
            <token id="33" string="E" />
            <token id="34" string="Street" />
          </tokens>
        </chunking>
        <chunking id="8" string="18 officers" type="NP">
          <tokens>
            <token id="17" string="18" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="12 party guests" type="NP">
          <tokens>
            <token id="21" string="12" />
            <token id="22" string="party" />
            <token id="23" string="guests" />
          </tokens>
        </chunking>
        <chunking id="10" string="the June 15 clash" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="June" />
            <token id="14" string="15" />
            <token id="15" string="clash" />
          </tokens>
        </chunking>
        <chunking id="11" string="an accusation of police brutality" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="accusation" />
            <token id="7" string="of" />
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="12" string="police brutality" type="NP">
          <tokens>
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="an accusation" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="accusation" />
          </tokens>
        </chunking>
        <chunking id="14" string="stemmed from the June 15 clash between 18 officers and about 12 party guests at a house in the 1300 block of South E Street" type="VP">
          <tokens>
            <token id="10" string="stemmed" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="June" />
            <token id="14" string="15" />
            <token id="15" string="clash" />
            <token id="16" string="between" />
            <token id="17" string="18" />
            <token id="18" string="officers" />
            <token id="19" string="and" />
            <token id="20" string="about" />
            <token id="21" string="12" />
            <token id="22" string="party" />
            <token id="23" string="guests" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="house" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1300" />
            <token id="30" string="block" />
            <token id="31" string="of" />
            <token id="32" string="South" />
            <token id="33" string="E" />
            <token id="34" string="Street" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 1300 block of South E Street" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="1300" />
            <token id="30" string="block" />
            <token id="31" string="of" />
            <token id="32" string="South" />
            <token id="33" string="E" />
            <token id="34" string="Street" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">incident</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">incident</governor>
          <dependent id="2">latest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">stemmed</governor>
          <dependent id="3">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">accusation</governor>
          <dependent id="4">involving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">accusation</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">incident</governor>
          <dependent id="6">accusation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">brutality</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">brutality</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">accusation</governor>
          <dependent id="9">brutality</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">stemmed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">stemmed</governor>
          <dependent id="10">stemmed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">clash</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">clash</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">clash</governor>
          <dependent id="13">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">clash</governor>
          <dependent id="14">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stemmed</governor>
          <dependent id="15">clash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">officers</governor>
          <dependent id="16">between</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">officers</governor>
          <dependent id="17">18</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">clash</governor>
          <dependent id="18">officers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">stemmed</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">guests</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">guests</governor>
          <dependent id="21">12</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">guests</governor>
          <dependent id="22">party</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stemmed</governor>
          <dependent id="23">guests</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">house</governor>
          <dependent id="24">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">house</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stemmed</governor>
          <dependent id="26">house</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">block</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">block</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">block</governor>
          <dependent id="29">1300</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">house</governor>
          <dependent id="30">block</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Street</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Street</governor>
          <dependent id="32">South</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Street</governor>
          <dependent id="33">E</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">block</governor>
          <dependent id="34">Street</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="12" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="12" />
          </tokens>
        </entity>
        <entity id="2" string="June 15" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="June" />
            <token id="14" string="15" />
          </tokens>
        </entity>
        <entity id="3" string="18" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="18" />
          </tokens>
        </entity>
        <entity id="4" string="1300" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="1300" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>It began when four officers answered complaints about a loud party.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="answered" lemma="answer" stem="answer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="loud" lemma="loud" stem="loud" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD began) (SBAR (WHADVP (WRB when)) (S (NP (CD four) (NNS officers)) (VP (VBN answered) (NP (NP (NNS complaints)) (PP (IN about) (NP (DT a) (JJ loud) (NN party)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="four officers" type="NP">
          <tokens>
            <token id="4" string="four" />
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="complaints about a loud party" type="NP">
          <tokens>
            <token id="7" string="complaints" />
            <token id="8" string="about" />
            <token id="9" string="a" />
            <token id="10" string="loud" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
        <chunking id="3" string="answered complaints about a loud party" type="VP">
          <tokens>
            <token id="6" string="answered" />
            <token id="7" string="complaints" />
            <token id="8" string="about" />
            <token id="9" string="a" />
            <token id="10" string="loud" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
        <chunking id="4" string="when four officers answered complaints about a loud party" type="SBAR">
          <tokens>
            <token id="3" string="when" />
            <token id="4" string="four" />
            <token id="5" string="officers" />
            <token id="6" string="answered" />
            <token id="7" string="complaints" />
            <token id="8" string="about" />
            <token id="9" string="a" />
            <token id="10" string="loud" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
        <chunking id="5" string="complaints" type="NP">
          <tokens>
            <token id="7" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="began when four officers answered complaints about a loud party" type="VP">
          <tokens>
            <token id="2" string="began" />
            <token id="3" string="when" />
            <token id="4" string="four" />
            <token id="5" string="officers" />
            <token id="6" string="answered" />
            <token id="7" string="complaints" />
            <token id="8" string="about" />
            <token id="9" string="a" />
            <token id="10" string="loud" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="3" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="a loud party" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="loud" />
            <token id="11" string="party" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">began</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">began</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">answered</governor>
          <dependent id="3">when</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">officers</governor>
          <dependent id="4">four</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">answered</governor>
          <dependent id="5">officers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">began</governor>
          <dependent id="6">answered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">answered</governor>
          <dependent id="7">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">party</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">party</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">party</governor>
          <dependent id="10">loud</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">complaints</governor>
          <dependent id="11">party</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>A police report said Flores started the fight by shoving a policeman.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fight" lemma="fight" stem="fight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="shoving" lemma="shove" stem="shove" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="policeman" lemma="policeman" stem="policeman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NN police) (NN report)) (VP (VBD said) (SBAR (S (NP (NNP Flores)) (VP (VBD started) (NP (DT the) (NN fight)) (PP (IN by) (S (VP (VBG shoving) (NP (DT a) (NN policeman))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shoving a policeman" type="VP">
          <tokens>
            <token id="10" string="shoving" />
            <token id="11" string="a" />
            <token id="12" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="2" string="A police report" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="police" />
            <token id="3" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="a policeman" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="4" string="Flores started the fight by shoving a policeman" type="SBAR">
          <tokens>
            <token id="5" string="Flores" />
            <token id="6" string="started" />
            <token id="7" string="the" />
            <token id="8" string="fight" />
            <token id="9" string="by" />
            <token id="10" string="shoving" />
            <token id="11" string="a" />
            <token id="12" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="5" string="the fight" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="fight" />
          </tokens>
        </chunking>
        <chunking id="6" string="started the fight by shoving a policeman" type="VP">
          <tokens>
            <token id="6" string="started" />
            <token id="7" string="the" />
            <token id="8" string="fight" />
            <token id="9" string="by" />
            <token id="10" string="shoving" />
            <token id="11" string="a" />
            <token id="12" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="7" string="said Flores started the fight by shoving a policeman" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="Flores" />
            <token id="6" string="started" />
            <token id="7" string="the" />
            <token id="8" string="fight" />
            <token id="9" string="by" />
            <token id="10" string="shoving" />
            <token id="11" string="a" />
            <token id="12" string="policeman" />
          </tokens>
        </chunking>
        <chunking id="8" string="Flores" type="NP">
          <tokens>
            <token id="5" string="Flores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">report</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">report</governor>
          <dependent id="2">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">started</governor>
          <dependent id="5">Flores</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="6">started</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">fight</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">started</governor>
          <dependent id="8">fight</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">shoving</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">started</governor>
          <dependent id="10">shoving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">policeman</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">shoving</governor>
          <dependent id="12">policeman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Flores and his brothers, Alex, 19, and Luis Jr., 24 -- all of whom suffered gashes and scrapes on their heads and bodies -- said the officers beat them without provocation.</content>
      <tokens>
        <token id="1" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="brothers" lemma="brother" stem="brother" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Alex" lemma="Alex" stem="alex" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Luis" lemma="Luis" stem="lui" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="whom" lemma="whom" stem="whom" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="gashes" lemma="gash" stem="gash" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="scrapes" lemma="scrape" stem="scrape" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="heads" lemma="head" stem="head" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="bodies" lemma="body" stem="bodi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="provocation" lemma="provocation" stem="provoc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Flores)) (CC and) (NP (PRP$ his) (NNS brothers))) (, ,) (NP (NP (NNP Alex)) (, ,) (NP (CD 19)) (, ,)) (CC and) (NP (NP (NNP Luis) (NNP Jr.)) (, ,) (NP (NP (CD 24)) (PRN (: --) (SBAR (WHNP (DT all) (WHPP (IN of) (WHNP (WP whom)))) (S (VP (VP (VBD suffered) (NP (NNS gashes))) (CC and) (VP (VBZ scrapes) (PP (IN on) (NP (PRP$ their) (NNS heads) (CC and) (NNS bodies))))))) (: --))))) (VP (VBD said) (SBAR (S (NP (DT the) (NNS officers)) (VP (VBD beat) (NP (PRP them)) (PP (IN without) (NP (NN provocation))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Luis Jr. , 24 -- all of whom suffered gashes and scrapes on their heads and bodies --" type="NP">
          <tokens>
            <token id="11" string="Luis" />
            <token id="12" string="Jr." />
            <token id="13" string="," />
            <token id="14" string="24" />
            <token id="15" string="--" />
            <token id="16" string="all" />
            <token id="17" string="of" />
            <token id="18" string="whom" />
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
            <token id="21" string="and" />
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
            <token id="28" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="14" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="the officers beat them without provocation" type="SBAR">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="officers" />
            <token id="32" string="beat" />
            <token id="33" string="them" />
            <token id="34" string="without" />
            <token id="35" string="provocation" />
          </tokens>
        </chunking>
        <chunking id="4" string="Alex" type="NP">
          <tokens>
            <token id="6" string="Alex" />
          </tokens>
        </chunking>
        <chunking id="5" string="19" type="NP">
          <tokens>
            <token id="8" string="19" />
          </tokens>
        </chunking>
        <chunking id="6" string="beat them without provocation" type="VP">
          <tokens>
            <token id="32" string="beat" />
            <token id="33" string="them" />
            <token id="34" string="without" />
            <token id="35" string="provocation" />
          </tokens>
        </chunking>
        <chunking id="7" string="suffered gashes" type="VP">
          <tokens>
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
          </tokens>
        </chunking>
        <chunking id="8" string="scrapes on their heads and bodies" type="VP">
          <tokens>
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="9" string="their heads and bodies" type="NP">
          <tokens>
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="Flores" type="NP">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="12" string="gashes" type="NP">
          <tokens>
            <token id="20" string="gashes" />
          </tokens>
        </chunking>
        <chunking id="13" string="Flores and his brothers" type="NP">
          <tokens>
            <token id="1" string="Flores" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="brothers" />
          </tokens>
        </chunking>
        <chunking id="14" string="24 -- all of whom suffered gashes and scrapes on their heads and bodies --" type="NP">
          <tokens>
            <token id="14" string="24" />
            <token id="15" string="--" />
            <token id="16" string="all" />
            <token id="17" string="of" />
            <token id="18" string="whom" />
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
            <token id="21" string="and" />
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
            <token id="28" string="--" />
          </tokens>
        </chunking>
        <chunking id="15" string="all of whom suffered gashes and scrapes on their heads and bodies" type="SBAR">
          <tokens>
            <token id="16" string="all" />
            <token id="17" string="of" />
            <token id="18" string="whom" />
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
            <token id="21" string="and" />
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="16" string="Flores and his brothers , Alex , 19 , and Luis Jr. , 24 -- all of whom suffered gashes and scrapes on their heads and bodies --" type="NP">
          <tokens>
            <token id="1" string="Flores" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="brothers" />
            <token id="5" string="," />
            <token id="6" string="Alex" />
            <token id="7" string="," />
            <token id="8" string="19" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="Luis" />
            <token id="12" string="Jr." />
            <token id="13" string="," />
            <token id="14" string="24" />
            <token id="15" string="--" />
            <token id="16" string="all" />
            <token id="17" string="of" />
            <token id="18" string="whom" />
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
            <token id="21" string="and" />
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
            <token id="28" string="--" />
          </tokens>
        </chunking>
        <chunking id="17" string="Alex , 19 ," type="NP">
          <tokens>
            <token id="6" string="Alex" />
            <token id="7" string="," />
            <token id="8" string="19" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="18" string="the officers" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="officers" />
          </tokens>
        </chunking>
        <chunking id="19" string="his brothers" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="brothers" />
          </tokens>
        </chunking>
        <chunking id="20" string="Luis Jr." type="NP">
          <tokens>
            <token id="11" string="Luis" />
            <token id="12" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="21" string="said the officers beat them without provocation" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="the" />
            <token id="31" string="officers" />
            <token id="32" string="beat" />
            <token id="33" string="them" />
            <token id="34" string="without" />
            <token id="35" string="provocation" />
          </tokens>
        </chunking>
        <chunking id="22" string="provocation" type="NP">
          <tokens>
            <token id="35" string="provocation" />
          </tokens>
        </chunking>
        <chunking id="23" string="suffered gashes and scrapes on their heads and bodies" type="VP">
          <tokens>
            <token id="19" string="suffered" />
            <token id="20" string="gashes" />
            <token id="21" string="and" />
            <token id="22" string="scrapes" />
            <token id="23" string="on" />
            <token id="24" string="their" />
            <token id="25" string="heads" />
            <token id="26" string="and" />
            <token id="27" string="bodies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="1">Flores</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Flores</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">brothers</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Flores</governor>
          <dependent id="4">brothers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Flores</governor>
          <dependent id="6">Alex</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Alex</governor>
          <dependent id="8">19</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Flores</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Jr.</governor>
          <dependent id="11">Luis</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Flores</governor>
          <dependent id="12">Jr.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Jr.</governor>
          <dependent id="14">24</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">whom</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">whom</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">suffered</governor>
          <dependent id="18">whom</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">24</governor>
          <dependent id="19">suffered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">suffered</governor>
          <dependent id="20">gashes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">suffered</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">suffered</governor>
          <dependent id="22">scrapes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">heads</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">heads</governor>
          <dependent id="24">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">scrapes</governor>
          <dependent id="25">heads</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">heads</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">heads</governor>
          <dependent id="27">bodies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">officers</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">beat</governor>
          <dependent id="31">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="32">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">beat</governor>
          <dependent id="33">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">provocation</governor>
          <dependent id="34">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">beat</governor>
          <dependent id="35">provocation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="24" />
          </tokens>
        </entity>
        <entity id="2" string="Alex" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Alex" />
          </tokens>
        </entity>
        <entity id="3" string="19" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="19" />
          </tokens>
        </entity>
        <entity id="4" string="Luis Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Luis" />
            <token id="12" string="Jr." />
          </tokens>
        </entity>
        <entity id="5" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Police had arrested Flores on suspicion of assaulting an officer and of resisting arrest but the district attorney&amp;apost;s office decided two weeks later to prosecute Flores on the five misdemeanor counts of resisting arrest.</content>
      <tokens>
        <token id="1" string="Police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="assaulting" lemma="assault" stem="assault" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="resisting" lemma="resist" stem="resist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="31" string="misdemeanor" lemma="misdemeanor" stem="misdemeanor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="32" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="resisting" lemma="resist" stem="resist" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="35" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Police)) (VP (VBD had) (VP (VBN arrested) (NP (NNP Flores)) (PP (PP (IN on) (NP (NP (NN suspicion)) (PP (IN of) (S (VP (VBG assaulting) (NP (DT an) (NN officer))))))) (CC and) (PP (IN of) (S (VP (VBG resisting) (NP (NN arrest))))))))) (CC but) (S (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VBD decided) (NP-TMP (CD two) (NNS weeks) (RB later)) (S (VP (TO to) (VP (VB prosecute) (NP (NP (NNP Flores)) (PP (IN on) (NP (NP (DT the) (CD five) (NN misdemeanor) (NNS counts)) (PP (IN of) (S (VP (VBG resisting) (NP (NN arrest))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suspicion of assaulting an officer" type="NP">
          <tokens>
            <token id="6" string="suspicion" />
            <token id="7" string="of" />
            <token id="8" string="assaulting" />
            <token id="9" string="an" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="the five misdemeanor counts" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
          </tokens>
        </chunking>
        <chunking id="3" string="arrest" type="NP">
          <tokens>
            <token id="14" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="suspicion" type="NP">
          <tokens>
            <token id="6" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="5" string="assaulting an officer" type="VP">
          <tokens>
            <token id="8" string="assaulting" />
            <token id="9" string="an" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="Police" type="NP">
          <tokens>
            <token id="1" string="Police" />
          </tokens>
        </chunking>
        <chunking id="7" string="had arrested Flores on suspicion of assaulting an officer and of resisting arrest" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="arrested" />
            <token id="4" string="Flores" />
            <token id="5" string="on" />
            <token id="6" string="suspicion" />
            <token id="7" string="of" />
            <token id="8" string="assaulting" />
            <token id="9" string="an" />
            <token id="10" string="officer" />
            <token id="11" string="and" />
            <token id="12" string="of" />
            <token id="13" string="resisting" />
            <token id="14" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="8" string="Flores" type="NP">
          <tokens>
            <token id="4" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="9" string="arrested Flores on suspicion of assaulting an officer and of resisting arrest" type="VP">
          <tokens>
            <token id="3" string="arrested" />
            <token id="4" string="Flores" />
            <token id="5" string="on" />
            <token id="6" string="suspicion" />
            <token id="7" string="of" />
            <token id="8" string="assaulting" />
            <token id="9" string="an" />
            <token id="10" string="officer" />
            <token id="11" string="and" />
            <token id="12" string="of" />
            <token id="13" string="resisting" />
            <token id="14" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="resisting arrest" type="VP">
          <tokens>
            <token id="13" string="resisting" />
            <token id="14" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="11" string="an officer" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="12" string="the district attorney 's" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="district" />
            <token id="18" string="attorney" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="decided two weeks later to prosecute Flores on the five misdemeanor counts of resisting arrest" type="VP">
          <tokens>
            <token id="21" string="decided" />
            <token id="22" string="two" />
            <token id="23" string="weeks" />
            <token id="24" string="later" />
            <token id="25" string="to" />
            <token id="26" string="prosecute" />
            <token id="27" string="Flores" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
            <token id="33" string="of" />
            <token id="34" string="resisting" />
            <token id="35" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="14" string="Flores on the five misdemeanor counts of resisting arrest" type="NP">
          <tokens>
            <token id="27" string="Flores" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
            <token id="33" string="of" />
            <token id="34" string="resisting" />
            <token id="35" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="15" string="prosecute Flores on the five misdemeanor counts of resisting arrest" type="VP">
          <tokens>
            <token id="26" string="prosecute" />
            <token id="27" string="Flores" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
            <token id="33" string="of" />
            <token id="34" string="resisting" />
            <token id="35" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="16" string="the five misdemeanor counts of resisting arrest" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
            <token id="33" string="of" />
            <token id="34" string="resisting" />
            <token id="35" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="17" string="the district attorney 's office" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="district" />
            <token id="18" string="attorney" />
            <token id="19" string="'s" />
            <token id="20" string="office" />
          </tokens>
        </chunking>
        <chunking id="18" string="to prosecute Flores on the five misdemeanor counts of resisting arrest" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="prosecute" />
            <token id="27" string="Flores" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="five" />
            <token id="31" string="misdemeanor" />
            <token id="32" string="counts" />
            <token id="33" string="of" />
            <token id="34" string="resisting" />
            <token id="35" string="arrest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">arrested</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">arrested</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">arrested</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">arrested</governor>
          <dependent id="4">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">suspicion</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">arrested</governor>
          <dependent id="6">suspicion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">assaulting</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">suspicion</governor>
          <dependent id="8">assaulting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officer</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">assaulting</governor>
          <dependent id="10">officer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">suspicion</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">resisting</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">suspicion</governor>
          <dependent id="13">resisting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">resisting</governor>
          <dependent id="14">arrest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">arrested</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">attorney</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">attorney</governor>
          <dependent id="17">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">office</governor>
          <dependent id="18">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">attorney</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">decided</governor>
          <dependent id="20">office</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">arrested</governor>
          <dependent id="21">decided</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">weeks</governor>
          <dependent id="22">two</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="21">decided</governor>
          <dependent id="23">weeks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">weeks</governor>
          <dependent id="24">later</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">prosecute</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">decided</governor>
          <dependent id="26">prosecute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">prosecute</governor>
          <dependent id="27">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">counts</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">counts</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">counts</governor>
          <dependent id="30">five</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">counts</governor>
          <dependent id="31">misdemeanor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Flores</governor>
          <dependent id="32">counts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">resisting</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="32">counts</governor>
          <dependent id="34">resisting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">resisting</governor>
          <dependent id="35">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="assaulting" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="8" string="assaulting" />
          </tokens>
        </entity>
        <entity id="2" string="two weeks later" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="two" />
            <token id="23" string="weeks" />
            <token id="24" string="later" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="30" string="five" />
          </tokens>
        </entity>
        <entity id="4" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>&amp;quot;Based upon my review of all the reports, the charges were the most appropriate charges to file,&amp;quot; said Deputy Dist.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="upon" lemma="upon" stem="upon" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reports" lemma="report" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="appropriate" lemma="appropriate" stem="appropri" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Deputy" lemma="Deputy" stem="deputi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="Dist" lemma="Dist" stem="dist" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (PP (VBN Based) (PP (IN upon) (NP (NP (PRP$ my) (NN review)) (PP (IN of) (NP (PDT all) (DT the) (NNS reports)))))) (, ,) (NP (DT the) (NNS charges)) (VP (VBD were) (NP (DT the) (ADJP (RBS most) (JJ appropriate)) (NNS charges)) (S (VP (TO to) (VP (VB file)))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Deputy) (NNP Dist)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="file" type="VP">
          <tokens>
            <token id="19" string="file" />
          </tokens>
        </chunking>
        <chunking id="2" string="the charges" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="charges" />
          </tokens>
        </chunking>
        <chunking id="3" string="most appropriate" type="ADJP">
          <tokens>
            <token id="15" string="most" />
            <token id="16" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most appropriate charges" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="most" />
            <token id="16" string="appropriate" />
            <token id="17" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="Deputy Dist" type="NP">
          <tokens>
            <token id="23" string="Deputy" />
            <token id="24" string="Dist" />
          </tokens>
        </chunking>
        <chunking id="6" string="all the reports" type="NP">
          <tokens>
            <token id="7" string="all" />
            <token id="8" string="the" />
            <token id="9" string="reports" />
          </tokens>
        </chunking>
        <chunking id="7" string="my review" type="NP">
          <tokens>
            <token id="4" string="my" />
            <token id="5" string="review" />
          </tokens>
        </chunking>
        <chunking id="8" string="my review of all the reports" type="NP">
          <tokens>
            <token id="4" string="my" />
            <token id="5" string="review" />
            <token id="6" string="of" />
            <token id="7" string="all" />
            <token id="8" string="the" />
            <token id="9" string="reports" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="were the most appropriate charges to file" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="the" />
            <token id="15" string="most" />
            <token id="16" string="appropriate" />
            <token id="17" string="charges" />
            <token id="18" string="to" />
            <token id="19" string="file" />
          </tokens>
        </chunking>
        <chunking id="11" string="to file" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="file" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">review</governor>
          <dependent id="2">Based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">review</governor>
          <dependent id="3">upon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">review</governor>
          <dependent id="4">my</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">charges</governor>
          <dependent id="5">review</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">reports</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="9">reports</governor>
          <dependent id="7">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">reports</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">review</governor>
          <dependent id="9">reports</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">charges</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">charges</governor>
          <dependent id="12">charges</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">charges</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">charges</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">appropriate</governor>
          <dependent id="15">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">charges</governor>
          <dependent id="16">appropriate</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="17">charges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">file</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">charges</governor>
          <dependent id="19">file</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Dist</governor>
          <dependent id="23">Deputy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="24">Dist</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Atty. Donald Gran, who declined to elaborate.</content>
      <tokens>
        <token id="1" string="Atty." lemma="Atty." stem="atty." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Donald" lemma="Donald" stem="donald" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Gran" lemma="Gran" stem="gran" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="elaborate" lemma="elaborate" stem="elabor" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NNP Atty.) (NNP Donald) (NNP Gran)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD declined) (S (VP (TO to) (VP (VB elaborate))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="elaborate" type="VP">
          <tokens>
            <token id="8" string="elaborate" />
          </tokens>
        </chunking>
        <chunking id="2" string="Atty. Donald Gran" type="NP">
          <tokens>
            <token id="1" string="Atty." />
            <token id="2" string="Donald" />
            <token id="3" string="Gran" />
          </tokens>
        </chunking>
        <chunking id="3" string="who declined to elaborate" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="declined" />
            <token id="7" string="to" />
            <token id="8" string="elaborate" />
          </tokens>
        </chunking>
        <chunking id="4" string="declined to elaborate" type="VP">
          <tokens>
            <token id="6" string="declined" />
            <token id="7" string="to" />
            <token id="8" string="elaborate" />
          </tokens>
        </chunking>
        <chunking id="5" string="to elaborate" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="elaborate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Gran</governor>
          <dependent id="1">Atty.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Gran</governor>
          <dependent id="2">Donald</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Gran</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">declined</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Gran</governor>
          <dependent id="6">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">elaborate</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">declined</governor>
          <dependent id="8">elaborate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Donald Gran" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Donald" />
            <token id="3" string="Gran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Police Chief Robert Owens has ordered an investigation into the incident.</content>
      <tokens>
        <token id="1" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="3" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Owens" lemma="Owens" stem="owen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ordered" lemma="order" stem="order" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Police) (NNP Chief) (NNP Robert) (NNP Owens)) (VP (VBZ has) (VP (VBN ordered) (NP (DT an) (NN investigation)) (PP (IN into) (NP (DT the) (NN incident))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ordered an investigation into the incident" type="VP">
          <tokens>
            <token id="6" string="ordered" />
            <token id="7" string="an" />
            <token id="8" string="investigation" />
            <token id="9" string="into" />
            <token id="10" string="the" />
            <token id="11" string="incident" />
          </tokens>
        </chunking>
        <chunking id="2" string="has ordered an investigation into the incident" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="ordered" />
            <token id="7" string="an" />
            <token id="8" string="investigation" />
            <token id="9" string="into" />
            <token id="10" string="the" />
            <token id="11" string="incident" />
          </tokens>
        </chunking>
        <chunking id="3" string="Police Chief Robert Owens" type="NP">
          <tokens>
            <token id="1" string="Police" />
            <token id="2" string="Chief" />
            <token id="3" string="Robert" />
            <token id="4" string="Owens" />
          </tokens>
        </chunking>
        <chunking id="4" string="the incident" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="an investigation" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Owens</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Owens</governor>
          <dependent id="2">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Owens</governor>
          <dependent id="3">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">ordered</governor>
          <dependent id="4">Owens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">ordered</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">ordered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">investigation</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">ordered</governor>
          <dependent id="8">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">incident</governor>
          <dependent id="9">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">incident</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ordered</governor>
          <dependent id="11">incident</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Robert Owens" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Robert" />
            <token id="4" string="Owens" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="2" string="Chief" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>In an incident April 7, Sergio E. Gonzalez, 19, accused Oxnard officers of ordering a police dog to attack him before he was arrested.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sergio" lemma="Sergio" stem="sergio" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="E." lemma="E." stem="e." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ordering" lemma="order" stem="order" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="attack" lemma="attack" stem="attack" pos="VB" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT an) (NN incident)) (NP-TMP (NNP April) (CD 7)))) (, ,) (NP (NP (NNP Sergio) (NNP E.) (NNP Gonzalez)) (, ,) (NP (CD 19)) (, ,)) (VP (VBN accused) (NP (NP (NNP Oxnard) (NNS officers)) (PP (IN of) (S (VP (VBG ordering) (NP (DT a) (NN police) (NN dog)))))) (S (VP (TO to) (VP (VB attack) (NP (PRP him)) (SBAR (IN before) (S (NP (PRP he)) (VP (VBD was) (VP (VBN arrested))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to attack him before he was arrested" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="attack" />
            <token id="23" string="him" />
            <token id="24" string="before" />
            <token id="25" string="he" />
            <token id="26" string="was" />
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="2" string="attack him before he was arrested" type="VP">
          <tokens>
            <token id="22" string="attack" />
            <token id="23" string="him" />
            <token id="24" string="before" />
            <token id="25" string="he" />
            <token id="26" string="was" />
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="3" string="arrested" type="VP">
          <tokens>
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="4" string="accused Oxnard officers of ordering a police dog to attack him before he was arrested" type="VP">
          <tokens>
            <token id="13" string="accused" />
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
            <token id="16" string="of" />
            <token id="17" string="ordering" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="dog" />
            <token id="21" string="to" />
            <token id="22" string="attack" />
            <token id="23" string="him" />
            <token id="24" string="before" />
            <token id="25" string="he" />
            <token id="26" string="was" />
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="5" string="19" type="NP">
          <tokens>
            <token id="11" string="19" />
          </tokens>
        </chunking>
        <chunking id="6" string="ordering a police dog" type="VP">
          <tokens>
            <token id="17" string="ordering" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="Oxnard officers" type="NP">
          <tokens>
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="Oxnard officers of ordering a police dog" type="NP">
          <tokens>
            <token id="14" string="Oxnard" />
            <token id="15" string="officers" />
            <token id="16" string="of" />
            <token id="17" string="ordering" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="10" string="before he was arrested" type="SBAR">
          <tokens>
            <token id="24" string="before" />
            <token id="25" string="he" />
            <token id="26" string="was" />
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="11" string="an incident" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="incident" />
          </tokens>
        </chunking>
        <chunking id="12" string="a police dog" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="13" string="was arrested" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="14" string="an incident April 7" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="incident" />
            <token id="4" string="April" />
            <token id="5" string="7" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sergio E. Gonzalez" type="NP">
          <tokens>
            <token id="7" string="Sergio" />
            <token id="8" string="E." />
            <token id="9" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="16" string="Sergio E. Gonzalez , 19 ," type="NP">
          <tokens>
            <token id="7" string="Sergio" />
            <token id="8" string="E." />
            <token id="9" string="Gonzalez" />
            <token id="10" string="," />
            <token id="11" string="19" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">incident</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">incident</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">accused</governor>
          <dependent id="3">incident</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">incident</governor>
          <dependent id="4">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">April</governor>
          <dependent id="5">7</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Gonzalez</governor>
          <dependent id="7">Sergio</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Gonzalez</governor>
          <dependent id="8">E.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">accused</governor>
          <dependent id="9">Gonzalez</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Gonzalez</governor>
          <dependent id="11">19</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">accused</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">officers</governor>
          <dependent id="14">Oxnard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">accused</governor>
          <dependent id="15">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">ordering</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">officers</governor>
          <dependent id="17">ordering</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">dog</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">dog</governor>
          <dependent id="19">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">ordering</governor>
          <dependent id="20">dog</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">attack</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">accused</governor>
          <dependent id="22">attack</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">attack</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">arrested</governor>
          <dependent id="24">before</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">arrested</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">arrested</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">attack</governor>
          <dependent id="27">arrested</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="April 7" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="April" />
            <token id="5" string="7" />
          </tokens>
        </entity>
        <entity id="3" string="19" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="19" />
          </tokens>
        </entity>
        <entity id="4" string="Sergio E. Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Sergio" />
            <token id="8" string="E." />
            <token id="9" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="5" string="attack" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="attack" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>In a suit filed June 29, Gonzalez said he was standing on Sunkist Circle when the dog attacked him, biting him on the arm and left shoulder.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Sunkist" lemma="Sunkist" stem="sunkist" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Circle" lemma="Circle" stem="circl" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="attacked" lemma="attack" stem="attack" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="biting" lemma="bite" stem="bite" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="arm" lemma="arm" stem="arm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="29" string="shoulder" lemma="shoulder" stem="shoulder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (NN suit)) (VP (VBN filed) (NP-TMP (NNP June) (CD 29))))) (, ,) (NP (NNP Gonzalez)) (VP (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG standing) (PP (IN on) (NP (NP (NNP Sunkist) (NNP Circle)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN dog)) (VP (VBD attacked) (NP (PRP him)) (, ,) (S (VP (VBG biting) (NP (PRP him)) (PP (IN on) (NP (DT the) (NN arm))))))))))))))) (CC and) (VP (VBD left) (NP (NN shoulder)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a suit filed June 29" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="suit" />
            <token id="4" string="filed" />
            <token id="5" string="June" />
            <token id="6" string="29" />
          </tokens>
        </chunking>
        <chunking id="2" string="said he was standing on Sunkist Circle when the dog attacked him , biting him on the arm" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="standing" />
            <token id="13" string="on" />
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="3" string="shoulder" type="NP">
          <tokens>
            <token id="29" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="4" string="the dog" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="dog" />
          </tokens>
        </chunking>
        <chunking id="5" string="the arm" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="when the dog attacked him , biting him on the arm" type="SBAR">
          <tokens>
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="9" string="Sunkist Circle" type="NP">
          <tokens>
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
          </tokens>
        </chunking>
        <chunking id="10" string="Gonzalez" type="NP">
          <tokens>
            <token id="8" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="11" string="a suit" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="suit" />
          </tokens>
        </chunking>
        <chunking id="12" string="filed June 29" type="VP">
          <tokens>
            <token id="4" string="filed" />
            <token id="5" string="June" />
            <token id="6" string="29" />
          </tokens>
        </chunking>
        <chunking id="13" string="left shoulder" type="VP">
          <tokens>
            <token id="28" string="left" />
            <token id="29" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="14" string="attacked him , biting him on the arm" type="VP">
          <tokens>
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="15" string="said he was standing on Sunkist Circle when the dog attacked him , biting him on the arm and left shoulder" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="standing" />
            <token id="13" string="on" />
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
            <token id="27" string="and" />
            <token id="28" string="left" />
            <token id="29" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="16" string="standing on Sunkist Circle when the dog attacked him , biting him on the arm" type="VP">
          <tokens>
            <token id="12" string="standing" />
            <token id="13" string="on" />
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="was standing on Sunkist Circle when the dog attacked him , biting him on the arm" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="standing" />
            <token id="13" string="on" />
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="19" string="biting him on the arm" type="VP">
          <tokens>
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="20" string="he was standing on Sunkist Circle when the dog attacked him , biting him on the arm" type="SBAR">
          <tokens>
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="standing" />
            <token id="13" string="on" />
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
        <chunking id="21" string="Sunkist Circle when the dog attacked him , biting him on the arm" type="NP">
          <tokens>
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
            <token id="16" string="when" />
            <token id="17" string="the" />
            <token id="18" string="dog" />
            <token id="19" string="attacked" />
            <token id="20" string="him" />
            <token id="21" string="," />
            <token id="22" string="biting" />
            <token id="23" string="him" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="arm" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">suit</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">suit</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">said</governor>
          <dependent id="3">suit</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">suit</governor>
          <dependent id="4">filed</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">filed</governor>
          <dependent id="5">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">June</governor>
          <dependent id="6">29</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Gonzalez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">standing</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">standing</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="12">standing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Circle</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Circle</governor>
          <dependent id="14">Sunkist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">standing</governor>
          <dependent id="15">Circle</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">attacked</governor>
          <dependent id="16">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">dog</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">attacked</governor>
          <dependent id="18">dog</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Circle</governor>
          <dependent id="19">attacked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">attacked</governor>
          <dependent id="20">him</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">attacked</governor>
          <dependent id="22">biting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">biting</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">arm</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">arm</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">biting</governor>
          <dependent id="26">arm</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">said</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">said</governor>
          <dependent id="28">left</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">left</governor>
          <dependent id="29">shoulder</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sunkist Circle" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Sunkist" />
            <token id="15" string="Circle" />
          </tokens>
        </entity>
        <entity id="2" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="3" string="June 29" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="June" />
            <token id="6" string="29" />
          </tokens>
        </entity>
        <entity id="4" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="28" string="left" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Gonzalez was taken to St. John&amp;apost;s Regional Medical Center, where he underwent surgery and spent two weeks recovering from his injuries.</content>
      <tokens>
        <token id="1" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Regional" lemma="Regional" stem="region" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="underwent" lemma="undergo" stem="underw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="19" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="20" string="recovering" lemma="recover" stem="recov" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Gonzalez)) (VP (VBD was) (VP (VBN taken) (PP (TO to) (NP (NP (NNP St.) (NNP John) (POS 's)) (NNP Regional) (NNP Medical) (NNP Center))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP he)) (VP (VP (VBD underwent) (NP (NN surgery))) (CC and) (VP (VBD spent) (NP (CD two) (NNS weeks)) (S (VP (VBG recovering) (PP (IN from) (NP (PRP$ his) (NNS injuries))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spent two weeks recovering from his injuries" type="VP">
          <tokens>
            <token id="17" string="spent" />
            <token id="18" string="two" />
            <token id="19" string="weeks" />
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="2" string="recovering from his injuries" type="VP">
          <tokens>
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="3" string="underwent surgery and spent two weeks recovering from his injuries" type="VP">
          <tokens>
            <token id="14" string="underwent" />
            <token id="15" string="surgery" />
            <token id="16" string="and" />
            <token id="17" string="spent" />
            <token id="18" string="two" />
            <token id="19" string="weeks" />
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="4" string="taken to St. John 's Regional Medical Center , where he underwent surgery and spent two weeks recovering from his injuries" type="VP">
          <tokens>
            <token id="3" string="taken" />
            <token id="4" string="to" />
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="Regional" />
            <token id="9" string="Medical" />
            <token id="10" string="Center" />
            <token id="11" string="," />
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="underwent" />
            <token id="15" string="surgery" />
            <token id="16" string="and" />
            <token id="17" string="spent" />
            <token id="18" string="two" />
            <token id="19" string="weeks" />
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="5" string="St. John 's" type="NP">
          <tokens>
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="underwent surgery" type="VP">
          <tokens>
            <token id="14" string="underwent" />
            <token id="15" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="7" string="where he underwent surgery and spent two weeks recovering from his injuries" type="SBAR">
          <tokens>
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="underwent" />
            <token id="15" string="surgery" />
            <token id="16" string="and" />
            <token id="17" string="spent" />
            <token id="18" string="two" />
            <token id="19" string="weeks" />
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gonzalez" type="NP">
          <tokens>
            <token id="1" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="9" string="two weeks" type="NP">
          <tokens>
            <token id="18" string="two" />
            <token id="19" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="10" string="was taken to St. John 's Regional Medical Center , where he underwent surgery and spent two weeks recovering from his injuries" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="taken" />
            <token id="4" string="to" />
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="Regional" />
            <token id="9" string="Medical" />
            <token id="10" string="Center" />
            <token id="11" string="," />
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="underwent" />
            <token id="15" string="surgery" />
            <token id="16" string="and" />
            <token id="17" string="spent" />
            <token id="18" string="two" />
            <token id="19" string="weeks" />
            <token id="20" string="recovering" />
            <token id="21" string="from" />
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="11" string="his injuries" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="12" string="St. John 's Regional Medical Center" type="NP">
          <tokens>
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="Regional" />
            <token id="9" string="Medical" />
            <token id="10" string="Center" />
          </tokens>
        </chunking>
        <chunking id="13" string="where" type="WHADVP">
          <tokens>
            <token id="12" string="where" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="surgery" type="NP">
          <tokens>
            <token id="15" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">taken</governor>
          <dependent id="1">Gonzalez</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">taken</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Center</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">John</governor>
          <dependent id="5">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">Center</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">John</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Center</governor>
          <dependent id="8">Regional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Center</governor>
          <dependent id="9">Medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">taken</governor>
          <dependent id="10">Center</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">underwent</governor>
          <dependent id="12">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">underwent</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">taken</governor>
          <dependent id="14">underwent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">underwent</governor>
          <dependent id="15">surgery</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">underwent</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">underwent</governor>
          <dependent id="17">spent</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">weeks</governor>
          <dependent id="18">two</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">spent</governor>
          <dependent id="19">weeks</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">spent</governor>
          <dependent id="20">recovering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">injuries</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">injuries</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">recovering</governor>
          <dependent id="23">injuries</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="2" string="two weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="two" />
            <token id="19" string="weeks" />
          </tokens>
        </entity>
        <entity id="3" string="St. John 's Regional Medical Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="St." />
            <token id="6" string="John" />
            <token id="7" string="'s" />
            <token id="8" string="Regional" />
            <token id="9" string="Medical" />
            <token id="10" string="Center" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Edward M. Fox, an attorney representing Gonzalez, said his client, a gardener, might suffer some permanent injury to his right arm.</content>
      <tokens>
        <token id="1" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Fox" lemma="Fox" stem="fox" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="client" lemma="client" stem="client" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="gardener" lemma="gardener" stem="garden" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="suffer" lemma="suffer" stem="suffer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="permanent" lemma="permanent" stem="perman" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="injury" lemma="injury" stem="injuri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="25" string="arm" lemma="arm" stem="arm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Edward) (NNP M.) (NNP Fox)) (, ,) (NP (NP (DT an) (NN attorney)) (VP (VBG representing) (NP (NNP Gonzalez)))) (, ,)) (VP (VBD said) (SBAR (S (NP (NP (PRP$ his) (NN client)) (, ,) (NP (DT a) (NN gardener)) (, ,)) (VP (MD might) (VP (VB suffer) (NP (DT some) (JJ permanent) (NN injury)) (PP (TO to) (NP (PRP$ his) (JJ right) (NN arm)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="representing Gonzalez" type="VP">
          <tokens>
            <token id="7" string="representing" />
            <token id="8" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="2" string="his client , a gardener , might suffer some permanent injury to his right arm" type="SBAR">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="client" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="gardener" />
            <token id="16" string="," />
            <token id="17" string="might" />
            <token id="18" string="suffer" />
            <token id="19" string="some" />
            <token id="20" string="permanent" />
            <token id="21" string="injury" />
            <token id="22" string="to" />
            <token id="23" string="his" />
            <token id="24" string="right" />
            <token id="25" string="arm" />
          </tokens>
        </chunking>
        <chunking id="3" string="his client , a gardener ," type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="client" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="gardener" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="his right arm" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="right" />
            <token id="25" string="arm" />
          </tokens>
        </chunking>
        <chunking id="5" string="some permanent injury" type="NP">
          <tokens>
            <token id="19" string="some" />
            <token id="20" string="permanent" />
            <token id="21" string="injury" />
          </tokens>
        </chunking>
        <chunking id="6" string="a gardener" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="7" string="his client" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="client" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gonzalez" type="NP">
          <tokens>
            <token id="8" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="9" string="might suffer some permanent injury to his right arm" type="VP">
          <tokens>
            <token id="17" string="might" />
            <token id="18" string="suffer" />
            <token id="19" string="some" />
            <token id="20" string="permanent" />
            <token id="21" string="injury" />
            <token id="22" string="to" />
            <token id="23" string="his" />
            <token id="24" string="right" />
            <token id="25" string="arm" />
          </tokens>
        </chunking>
        <chunking id="10" string="said his client , a gardener , might suffer some permanent injury to his right arm" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="his" />
            <token id="12" string="client" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="gardener" />
            <token id="16" string="," />
            <token id="17" string="might" />
            <token id="18" string="suffer" />
            <token id="19" string="some" />
            <token id="20" string="permanent" />
            <token id="21" string="injury" />
            <token id="22" string="to" />
            <token id="23" string="his" />
            <token id="24" string="right" />
            <token id="25" string="arm" />
          </tokens>
        </chunking>
        <chunking id="11" string="an attorney representing Gonzalez" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="attorney" />
            <token id="7" string="representing" />
            <token id="8" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="12" string="suffer some permanent injury to his right arm" type="VP">
          <tokens>
            <token id="18" string="suffer" />
            <token id="19" string="some" />
            <token id="20" string="permanent" />
            <token id="21" string="injury" />
            <token id="22" string="to" />
            <token id="23" string="his" />
            <token id="24" string="right" />
            <token id="25" string="arm" />
          </tokens>
        </chunking>
        <chunking id="13" string="Edward M. Fox , an attorney representing Gonzalez ," type="NP">
          <tokens>
            <token id="1" string="Edward" />
            <token id="2" string="M." />
            <token id="3" string="Fox" />
            <token id="4" string="," />
            <token id="5" string="an" />
            <token id="6" string="attorney" />
            <token id="7" string="representing" />
            <token id="8" string="Gonzalez" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="an attorney" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="15" string="Edward M. Fox" type="NP">
          <tokens>
            <token id="1" string="Edward" />
            <token id="2" string="M." />
            <token id="3" string="Fox" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Fox</governor>
          <dependent id="1">Edward</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Fox</governor>
          <dependent id="2">M.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="3">Fox</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">attorney</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Fox</governor>
          <dependent id="6">attorney</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">attorney</governor>
          <dependent id="7">representing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">representing</governor>
          <dependent id="8">Gonzalez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">client</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">suffer</governor>
          <dependent id="12">client</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">gardener</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">client</governor>
          <dependent id="15">gardener</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">suffer</governor>
          <dependent id="17">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="18">suffer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">injury</governor>
          <dependent id="19">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">injury</governor>
          <dependent id="20">permanent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">suffer</governor>
          <dependent id="21">injury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">arm</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">arm</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">arm</governor>
          <dependent id="24">right</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">suffer</governor>
          <dependent id="25">arm</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="24" string="right" />
          </tokens>
        </entity>
        <entity id="3" string="Edward M. Fox" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Edward" />
            <token id="2" string="M." />
            <token id="3" string="Fox" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>According to a police report filed by Officer Michael Cole, police were sent to a parking lot outside the Oxnard Moose Lodge to investigate a report of an altercation between several men after a wedding reception.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Cole" lemma="Cole" stem="cole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="parking" lemma="parking" stem="park" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Moose" lemma="Moose" stem="moos" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="Lodge" lemma="Lodge" stem="lodg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="wedding" lemma="wedding" stem="wed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="reception" lemma="reception" stem="recept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (NP (DT a) (NN police) (NN report)) (VP (VBN filed) (PP (IN by) (NP (NNP Officer) (NNP Michael) (NNP Cole))))))) (, ,) (NP (NNS police)) (VP (VBD were) (VP (VBN sent) (PP (TO to) (NP (NP (DT a) (NN parking) (NN lot)) (PP (IN outside) (NP (DT the) (NNP Oxnard) (NNP Moose) (NNP Lodge))))) (S (VP (TO to) (VP (VB investigate) (NP (NP (DT a) (NN report)) (PP (IN of) (NP (NP (DT an) (NN altercation)) (PP (IN between) (NP (JJ several) (NNS men)))))) (PP (IN after) (NP (DT a) (NN wedding) (NN reception)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Officer Michael Cole" type="NP">
          <tokens>
            <token id="8" string="Officer" />
            <token id="9" string="Michael" />
            <token id="10" string="Cole" />
          </tokens>
        </chunking>
        <chunking id="2" string="a police report" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="a report of an altercation between several men" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="report" />
            <token id="28" string="of" />
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
          </tokens>
        </chunking>
        <chunking id="4" string="sent to a parking lot outside the Oxnard Moose Lodge to investigate a report of an altercation between several men after a wedding reception" type="VP">
          <tokens>
            <token id="14" string="sent" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="parking" />
            <token id="18" string="lot" />
            <token id="19" string="outside" />
            <token id="20" string="the" />
            <token id="21" string="Oxnard" />
            <token id="22" string="Moose" />
            <token id="23" string="Lodge" />
            <token id="24" string="to" />
            <token id="25" string="investigate" />
            <token id="26" string="a" />
            <token id="27" string="report" />
            <token id="28" string="of" />
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
            <token id="34" string="after" />
            <token id="35" string="a" />
            <token id="36" string="wedding" />
            <token id="37" string="reception" />
          </tokens>
        </chunking>
        <chunking id="5" string="a parking lot outside the Oxnard Moose Lodge" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parking" />
            <token id="18" string="lot" />
            <token id="19" string="outside" />
            <token id="20" string="the" />
            <token id="21" string="Oxnard" />
            <token id="22" string="Moose" />
            <token id="23" string="Lodge" />
          </tokens>
        </chunking>
        <chunking id="6" string="police" type="NP">
          <tokens>
            <token id="12" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="to investigate a report of an altercation between several men after a wedding reception" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="investigate" />
            <token id="26" string="a" />
            <token id="27" string="report" />
            <token id="28" string="of" />
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
            <token id="34" string="after" />
            <token id="35" string="a" />
            <token id="36" string="wedding" />
            <token id="37" string="reception" />
          </tokens>
        </chunking>
        <chunking id="8" string="a report" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="several men" type="NP">
          <tokens>
            <token id="32" string="several" />
            <token id="33" string="men" />
          </tokens>
        </chunking>
        <chunking id="10" string="a parking lot" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parking" />
            <token id="18" string="lot" />
          </tokens>
        </chunking>
        <chunking id="11" string="a police report filed by Officer Michael Cole" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="report" />
            <token id="6" string="filed" />
            <token id="7" string="by" />
            <token id="8" string="Officer" />
            <token id="9" string="Michael" />
            <token id="10" string="Cole" />
          </tokens>
        </chunking>
        <chunking id="12" string="an altercation between several men" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Oxnard Moose Lodge" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Oxnard" />
            <token id="22" string="Moose" />
            <token id="23" string="Lodge" />
          </tokens>
        </chunking>
        <chunking id="14" string="investigate a report of an altercation between several men after a wedding reception" type="VP">
          <tokens>
            <token id="25" string="investigate" />
            <token id="26" string="a" />
            <token id="27" string="report" />
            <token id="28" string="of" />
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
            <token id="34" string="after" />
            <token id="35" string="a" />
            <token id="36" string="wedding" />
            <token id="37" string="reception" />
          </tokens>
        </chunking>
        <chunking id="15" string="a wedding reception" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="wedding" />
            <token id="37" string="reception" />
          </tokens>
        </chunking>
        <chunking id="16" string="filed by Officer Michael Cole" type="VP">
          <tokens>
            <token id="6" string="filed" />
            <token id="7" string="by" />
            <token id="8" string="Officer" />
            <token id="9" string="Michael" />
            <token id="10" string="Cole" />
          </tokens>
        </chunking>
        <chunking id="17" string="an altercation" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="18" string="were sent to a parking lot outside the Oxnard Moose Lodge to investigate a report of an altercation between several men after a wedding reception" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="sent" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="parking" />
            <token id="18" string="lot" />
            <token id="19" string="outside" />
            <token id="20" string="the" />
            <token id="21" string="Oxnard" />
            <token id="22" string="Moose" />
            <token id="23" string="Lodge" />
            <token id="24" string="to" />
            <token id="25" string="investigate" />
            <token id="26" string="a" />
            <token id="27" string="report" />
            <token id="28" string="of" />
            <token id="29" string="an" />
            <token id="30" string="altercation" />
            <token id="31" string="between" />
            <token id="32" string="several" />
            <token id="33" string="men" />
            <token id="34" string="after" />
            <token id="35" string="a" />
            <token id="36" string="wedding" />
            <token id="37" string="reception" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">report</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">report</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">report</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">sent</governor>
          <dependent id="5">report</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">report</governor>
          <dependent id="6">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Cole</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Cole</governor>
          <dependent id="8">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Cole</governor>
          <dependent id="9">Michael</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">filed</governor>
          <dependent id="10">Cole</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">sent</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">sent</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">lot</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">lot</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">lot</governor>
          <dependent id="17">parking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">sent</governor>
          <dependent id="18">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Lodge</governor>
          <dependent id="19">outside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Lodge</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lodge</governor>
          <dependent id="21">Oxnard</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lodge</governor>
          <dependent id="22">Moose</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">lot</governor>
          <dependent id="23">Lodge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">investigate</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">sent</governor>
          <dependent id="25">investigate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">report</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">investigate</governor>
          <dependent id="27">report</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">altercation</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">altercation</governor>
          <dependent id="29">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">report</governor>
          <dependent id="30">altercation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">men</governor>
          <dependent id="31">between</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">men</governor>
          <dependent id="32">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">altercation</governor>
          <dependent id="33">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">reception</governor>
          <dependent id="34">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">reception</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">reception</governor>
          <dependent id="36">wedding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">investigate</governor>
          <dependent id="37">reception</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Cole" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Michael" />
            <token id="10" string="Cole" />
          </tokens>
        </entity>
        <entity id="2" string="Oxnard Moose Lodge" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Oxnard" />
            <token id="22" string="Moose" />
            <token id="23" string="Lodge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Cole&amp;apost;s report said Gonzalez was found hiding in the parking lot and &amp;quot;was bit by a police service dog during the arrest.&amp;quot;</content>
      <tokens>
        <token id="1" string="Cole" lemma="Cole" stem="cole" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="hiding" lemma="hide" stem="hide" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="parking" lemma="parking" stem="park" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="bit" lemma="bite" stem="bit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Cole) (POS 's)) (NN report)) (VP (VP (VBD said) (SBAR (S (NP (NNP Gonzalez)) (VP (VBD was) (VP (VBN found) (S (VP (VBG hiding) (PP (IN in) (NP (DT the) (NN parking) (NN lot)))))))))) (CC and) (`` ``) (VP (VBD was) (VP (VBN bit) (PP (IN by) (NP (DT a) (NN police) (NN service) (NN dog))) (PP (IN during) (NP (DT the) (NN arrest)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="bit by a police service dog during the arrest" type="VP">
          <tokens>
            <token id="16" string="bit" />
            <token id="17" string="by" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="service" />
            <token id="21" string="dog" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="2" string="the arrest" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Gonzalez was found hiding in the parking lot and `` was bit by a police service dog during the arrest" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="Gonzalez" />
            <token id="6" string="was" />
            <token id="7" string="found" />
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
            <token id="13" string="and" />
            <token id="14" string="&quot;" />
            <token id="15" string="was" />
            <token id="16" string="bit" />
            <token id="17" string="by" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="service" />
            <token id="21" string="dog" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="Gonzalez was found hiding in the parking lot" type="SBAR">
          <tokens>
            <token id="5" string="Gonzalez" />
            <token id="6" string="was" />
            <token id="7" string="found" />
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="5" string="Cole 's" type="NP">
          <tokens>
            <token id="1" string="Cole" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="hiding in the parking lot" type="VP">
          <tokens>
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="7" string="a police service dog" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="service" />
            <token id="21" string="dog" />
          </tokens>
        </chunking>
        <chunking id="8" string="Cole 's report" type="NP">
          <tokens>
            <token id="1" string="Cole" />
            <token id="2" string="'s" />
            <token id="3" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="Gonzalez" type="NP">
          <tokens>
            <token id="5" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="10" string="said Gonzalez was found hiding in the parking lot" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="Gonzalez" />
            <token id="6" string="was" />
            <token id="7" string="found" />
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="11" string="found hiding in the parking lot" type="VP">
          <tokens>
            <token id="7" string="found" />
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="12" string="was found hiding in the parking lot" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="found" />
            <token id="8" string="hiding" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="13" string="was bit by a police service dog during the arrest" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="bit" />
            <token id="17" string="by" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="service" />
            <token id="21" string="dog" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="14" string="the parking lot" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="parking" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">report</governor>
          <dependent id="1">Cole</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Cole</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">found</governor>
          <dependent id="5">Gonzalez</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">found</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">found</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">found</governor>
          <dependent id="8">hiding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">lot</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">lot</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">lot</governor>
          <dependent id="11">parking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">hiding</governor>
          <dependent id="12">lot</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">said</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">bit</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">said</governor>
          <dependent id="16">bit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">dog</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">dog</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">dog</governor>
          <dependent id="19">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">dog</governor>
          <dependent id="20">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">bit</governor>
          <dependent id="21">dog</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">arrest</governor>
          <dependent id="22">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">arrest</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">bit</governor>
          <dependent id="24">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Gonzalez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The report, however, does not say why the dog attacked Gonzalez or whether Gonzalez resisted arrest.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="attacked" lemma="attack" stem="attack" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="resisted" lemma="resist" stem="resist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN report)) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ does) (RB not) (VP (VB say) (SBAR (SBAR (WHADVP (WRB why)) (S (NP (DT the) (NN dog)) (VP (VBN attacked) (NP (NNP Gonzalez))))) (CC or) (SBAR (IN whether) (S (NP (NNP Gonzalez)) (VP (VBD resisted) (NP (NN arrest)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
          </tokens>
        </chunking>
        <chunking id="2" string="Gonzalez" type="NP">
          <tokens>
            <token id="13" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="3" string="does not say why the dog attacked Gonzalez or whether Gonzalez resisted arrest" type="VP">
          <tokens>
            <token id="6" string="does" />
            <token id="7" string="not" />
            <token id="8" string="say" />
            <token id="9" string="why" />
            <token id="10" string="the" />
            <token id="11" string="dog" />
            <token id="12" string="attacked" />
            <token id="13" string="Gonzalez" />
            <token id="14" string="or" />
            <token id="15" string="whether" />
            <token id="16" string="Gonzalez" />
            <token id="17" string="resisted" />
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="arrest" type="NP">
          <tokens>
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="5" string="why" type="WHADVP">
          <tokens>
            <token id="9" string="why" />
          </tokens>
        </chunking>
        <chunking id="6" string="the dog" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dog" />
          </tokens>
        </chunking>
        <chunking id="7" string="resisted arrest" type="VP">
          <tokens>
            <token id="17" string="resisted" />
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="8" string="why the dog attacked Gonzalez or whether Gonzalez resisted arrest" type="SBAR">
          <tokens>
            <token id="9" string="why" />
            <token id="10" string="the" />
            <token id="11" string="dog" />
            <token id="12" string="attacked" />
            <token id="13" string="Gonzalez" />
            <token id="14" string="or" />
            <token id="15" string="whether" />
            <token id="16" string="Gonzalez" />
            <token id="17" string="resisted" />
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="9" string="why the dog attacked Gonzalez" type="SBAR">
          <tokens>
            <token id="9" string="why" />
            <token id="10" string="the" />
            <token id="11" string="dog" />
            <token id="12" string="attacked" />
            <token id="13" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="10" string="attacked Gonzalez" type="VP">
          <tokens>
            <token id="12" string="attacked" />
            <token id="13" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="11" string="whether Gonzalez resisted arrest" type="SBAR">
          <tokens>
            <token id="15" string="whether" />
            <token id="16" string="Gonzalez" />
            <token id="17" string="resisted" />
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="12" string="say why the dog attacked Gonzalez or whether Gonzalez resisted arrest" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="why" />
            <token id="10" string="the" />
            <token id="11" string="dog" />
            <token id="12" string="attacked" />
            <token id="13" string="Gonzalez" />
            <token id="14" string="or" />
            <token id="15" string="whether" />
            <token id="16" string="Gonzalez" />
            <token id="17" string="resisted" />
            <token id="18" string="arrest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">report</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">say</governor>
          <dependent id="2">report</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">say</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">say</governor>
          <dependent id="6">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">say</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">attacked</governor>
          <dependent id="9">why</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">dog</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">attacked</governor>
          <dependent id="11">dog</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">say</governor>
          <dependent id="12">attacked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">attacked</governor>
          <dependent id="13">Gonzalez</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">attacked</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">resisted</governor>
          <dependent id="15">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">resisted</governor>
          <dependent id="16">Gonzalez</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">attacked</governor>
          <dependent id="17">resisted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">resisted</governor>
          <dependent id="18">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Gonzalez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Police arrested Gonzalez on suspicion of disturbing the peace, Brodie said.</content>
      <tokens>
        <token id="1" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="arrested" lemma="arrest" stem="arrest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="disturbing" lemma="disturb" stem="disturb" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="peace" lemma="peace" stem="peac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Police)) (VP (VBD arrested) (NP (NP (NNP Gonzalez)) (PP (IN on) (NP (NP (NN suspicion)) (PP (IN of) (S (VP (VBG disturbing) (NP (DT the) (NN peace)))))))))) (, ,) (NP (NNP Brodie)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Gonzalez" type="NP">
          <tokens>
            <token id="3" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="2" string="suspicion" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="3" string="Gonzalez on suspicion of disturbing the peace" type="NP">
          <tokens>
            <token id="3" string="Gonzalez" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disturbing" />
            <token id="8" string="the" />
            <token id="9" string="peace" />
          </tokens>
        </chunking>
        <chunking id="4" string="suspicion of disturbing the peace" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disturbing" />
            <token id="8" string="the" />
            <token id="9" string="peace" />
          </tokens>
        </chunking>
        <chunking id="5" string="the peace" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="peace" />
          </tokens>
        </chunking>
        <chunking id="6" string="arrested Gonzalez on suspicion of disturbing the peace" type="VP">
          <tokens>
            <token id="2" string="arrested" />
            <token id="3" string="Gonzalez" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disturbing" />
            <token id="8" string="the" />
            <token id="9" string="peace" />
          </tokens>
        </chunking>
        <chunking id="7" string="Brodie" type="NP">
          <tokens>
            <token id="11" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="8" string="disturbing the peace" type="VP">
          <tokens>
            <token id="7" string="disturbing" />
            <token id="8" string="the" />
            <token id="9" string="peace" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="Police" type="NP">
          <tokens>
            <token id="1" string="Police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">arrested</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="2">arrested</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">arrested</governor>
          <dependent id="3">Gonzalez</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">suspicion</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Gonzalez</governor>
          <dependent id="5">suspicion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">disturbing</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">suspicion</governor>
          <dependent id="7">disturbing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">peace</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">disturbing</governor>
          <dependent id="9">peace</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Brodie</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="2" string="Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Brodie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>But the district attorney&amp;apost;s office declined to file any charges because the police report failed to show that Gonzalez was involved in the altercation, Brodie said.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (CC But) (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VBD declined) (S (VP (TO to) (VP (VB file) (NP (DT any) (NNS charges)) (SBAR (IN because) (S (NP (DT the) (NN police) (NN report)) (VP (VBD failed) (S (VP (TO to) (VP (VB show) (SBAR (IN that) (S (NP (NNP Gonzalez)) (VP (VBD was) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN altercation)))))))))))))))))) (, ,) (NP (NNP Brodie)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="because the police report failed to show that Gonzalez was involved in the altercation" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="police" />
            <token id="15" string="report" />
            <token id="16" string="failed" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="2" string="failed to show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="16" string="failed" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="3" string="that Gonzalez was involved in the altercation" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="4" string="any charges" type="NP">
          <tokens>
            <token id="10" string="any" />
            <token id="11" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="involved in the altercation" type="VP">
          <tokens>
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="6" string="to show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="7" string="file any charges because the police report failed to show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="9" string="file" />
            <token id="10" string="any" />
            <token id="11" string="charges" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="police" />
            <token id="15" string="report" />
            <token id="16" string="failed" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gonzalez" type="NP">
          <tokens>
            <token id="20" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="9" string="the district attorney 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="district" />
            <token id="4" string="attorney" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="11" string="the altercation" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="12" string="declined to file any charges because the police report failed to show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="7" string="declined" />
            <token id="8" string="to" />
            <token id="9" string="file" />
            <token id="10" string="any" />
            <token id="11" string="charges" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="police" />
            <token id="15" string="report" />
            <token id="16" string="failed" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Brodie" type="NP">
          <tokens>
            <token id="27" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="14" string="to file any charges because the police report failed to show that Gonzalez was involved in the altercation" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="file" />
            <token id="10" string="any" />
            <token id="11" string="charges" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="police" />
            <token id="15" string="report" />
            <token id="16" string="failed" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Gonzalez" />
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="15" string="the police report" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="police" />
            <token id="15" string="report" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="the district attorney 's office" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="district" />
            <token id="4" string="attorney" />
            <token id="5" string="'s" />
            <token id="6" string="office" />
          </tokens>
        </chunking>
        <chunking id="18" string="was involved in the altercation" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="involved" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="altercation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">declined</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">attorney</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">attorney</governor>
          <dependent id="3">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">office</governor>
          <dependent id="4">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">attorney</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">declined</governor>
          <dependent id="6">office</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="7">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">file</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">declined</governor>
          <dependent id="9">file</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">charges</governor>
          <dependent id="10">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">file</governor>
          <dependent id="11">charges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">failed</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">report</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">report</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">failed</governor>
          <dependent id="15">report</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">file</governor>
          <dependent id="16">failed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">show</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">failed</governor>
          <dependent id="18">show</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">involved</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">involved</governor>
          <dependent id="20">Gonzalez</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">involved</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">show</governor>
          <dependent id="22">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">altercation</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">altercation</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">involved</governor>
          <dependent id="25">altercation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="27">Brodie</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="2" string="Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Brodie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Fox said Gonzalez did not attend the wedding but was visiting a friend nearby and went to the parking lot to find out what was causing the commotion.</content>
      <tokens>
        <token id="1" string="Fox" lemma="Fox" stem="fox" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Gonzalez" lemma="Gonzalez" stem="gonzalez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="attend" lemma="attend" stem="attend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="wedding" lemma="wedding" stem="wed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="visiting" lemma="visit" stem="visit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="nearby" lemma="nearby" stem="nearbi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="parking" lemma="parking" stem="park" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="commotion" lemma="commotion" stem="commot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fox)) (VP (VP (VBD said) (SBAR (S (NP (NNP Gonzalez)) (VP (VP (VBD did) (RB not) (VP (VB attend) (NP (DT the) (NN wedding)))) (CC but) (VP (VBD was) (VP (VBG visiting) (NP (DT a) (NN friend) (JJ nearby)))))))) (CC and) (VP (VBD went) (PP (TO to) (NP (DT the) (NN parking) (NN lot))) (S (VP (TO to) (VP (VB find) (PRT (RP out)) (SBAR (WHNP (WP what)) (S (VP (VBD was) (VP (VBG causing) (NP (DT the) (NN commotion))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was visiting a friend nearby" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="2" string="said Gonzalez did not attend the wedding but was visiting a friend nearby and went to the parking lot to find out what was causing the commotion" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Gonzalez" />
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
            <token id="9" string="but" />
            <token id="10" string="was" />
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
            <token id="15" string="and" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="the" />
            <token id="19" string="parking" />
            <token id="20" string="lot" />
            <token id="21" string="to" />
            <token id="22" string="find" />
            <token id="23" string="out" />
            <token id="24" string="what" />
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="3" string="the commotion" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="4" string="to find out what was causing the commotion" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="find" />
            <token id="23" string="out" />
            <token id="24" string="what" />
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="5" string="what was causing the commotion" type="SBAR">
          <tokens>
            <token id="24" string="what" />
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="6" string="a friend nearby" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="7" string="causing the commotion" type="VP">
          <tokens>
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="8" string="find out what was causing the commotion" type="VP">
          <tokens>
            <token id="22" string="find" />
            <token id="23" string="out" />
            <token id="24" string="what" />
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="9" string="Fox" type="NP">
          <tokens>
            <token id="1" string="Fox" />
          </tokens>
        </chunking>
        <chunking id="10" string="the wedding" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="wedding" />
          </tokens>
        </chunking>
        <chunking id="11" string="Gonzalez did not attend the wedding but was visiting a friend nearby" type="SBAR">
          <tokens>
            <token id="3" string="Gonzalez" />
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
            <token id="9" string="but" />
            <token id="10" string="was" />
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="12" string="Gonzalez" type="NP">
          <tokens>
            <token id="3" string="Gonzalez" />
          </tokens>
        </chunking>
        <chunking id="13" string="went to the parking lot to find out what was causing the commotion" type="VP">
          <tokens>
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="the" />
            <token id="19" string="parking" />
            <token id="20" string="lot" />
            <token id="21" string="to" />
            <token id="22" string="find" />
            <token id="23" string="out" />
            <token id="24" string="what" />
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
        <chunking id="14" string="attend the wedding" type="VP">
          <tokens>
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
          </tokens>
        </chunking>
        <chunking id="15" string="visiting a friend nearby" type="VP">
          <tokens>
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="16" string="said Gonzalez did not attend the wedding but was visiting a friend nearby" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Gonzalez" />
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
            <token id="9" string="but" />
            <token id="10" string="was" />
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="17" string="did not attend the wedding but was visiting a friend nearby" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
            <token id="9" string="but" />
            <token id="10" string="was" />
            <token id="11" string="visiting" />
            <token id="12" string="a" />
            <token id="13" string="friend" />
            <token id="14" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="18" string="did not attend the wedding" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="attend" />
            <token id="7" string="the" />
            <token id="8" string="wedding" />
          </tokens>
        </chunking>
        <chunking id="19" string="the parking lot" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="parking" />
            <token id="20" string="lot" />
          </tokens>
        </chunking>
        <chunking id="20" string="was causing the commotion" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="causing" />
            <token id="27" string="the" />
            <token id="28" string="commotion" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Fox</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">attend</governor>
          <dependent id="3">Gonzalez</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">attend</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">attend</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">attend</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">wedding</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">attend</governor>
          <dependent id="8">wedding</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">attend</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">visiting</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">attend</governor>
          <dependent id="11">visiting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">friend</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">visiting</governor>
          <dependent id="13">friend</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">friend</governor>
          <dependent id="14">nearby</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="16">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">lot</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">lot</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">lot</governor>
          <dependent id="19">parking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">went</governor>
          <dependent id="20">lot</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">find</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">went</governor>
          <dependent id="22">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">find</governor>
          <dependent id="23">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">causing</governor>
          <dependent id="24">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">causing</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">find</governor>
          <dependent id="26">causing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">commotion</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">causing</governor>
          <dependent id="28">commotion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gonzalez" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Gonzalez" />
          </tokens>
        </entity>
        <entity id="2" string="Fox" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fox" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>In a third incident, Louis M. Cornett, a retired teacher and licensed gun dealer, said he was beaten on Oct. 20 while in custody at Oxnard police headquarters.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="4" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Louis" lemma="Louis" stem="loui" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="retired" lemma="retired" stem="retir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="licensed" lemma="licensed" stem="licens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="gun" lemma="gun" stem="gun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="dealer" lemma="dealer" stem="dealer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="custody" lemma="custody" stem="custodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="headquarters" lemma="headquarters" stem="headquart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT a) (JJ third) (NN incident))) (, ,) (NP (NP (NNP Louis) (NNP M.) (NNP Cornett)) (, ,) (NP (NP (DT a) (JJ retired) (NN teacher)) (CC and) (NP (JJ licensed) (NN gun) (NN dealer))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBN beaten) (PP (IN on) (NP (NNP Oct.) (CD 20))) (PP (IN while) (IN in) (NP (NP (NN custody)) (PP (IN at) (NP (NNP Oxnard) (NN police) (NN headquarters)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a retired teacher" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="retired" />
            <token id="12" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="2" string="beaten on Oct. 20 while in custody at Oxnard police headquarters" type="VP">
          <tokens>
            <token id="21" string="beaten" />
            <token id="22" string="on" />
            <token id="23" string="Oct." />
            <token id="24" string="20" />
            <token id="25" string="while" />
            <token id="26" string="in" />
            <token id="27" string="custody" />
            <token id="28" string="at" />
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="3" string="a third incident" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="third" />
            <token id="4" string="incident" />
          </tokens>
        </chunking>
        <chunking id="4" string="Louis M. Cornett , a retired teacher and licensed gun dealer ," type="NP">
          <tokens>
            <token id="6" string="Louis" />
            <token id="7" string="M." />
            <token id="8" string="Cornett" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="retired" />
            <token id="12" string="teacher" />
            <token id="13" string="and" />
            <token id="14" string="licensed" />
            <token id="15" string="gun" />
            <token id="16" string="dealer" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="custody" type="NP">
          <tokens>
            <token id="27" string="custody" />
          </tokens>
        </chunking>
        <chunking id="6" string="custody at Oxnard police headquarters" type="NP">
          <tokens>
            <token id="27" string="custody" />
            <token id="28" string="at" />
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="7" string="said he was beaten on Oct. 20 while in custody at Oxnard police headquarters" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="beaten" />
            <token id="22" string="on" />
            <token id="23" string="Oct." />
            <token id="24" string="20" />
            <token id="25" string="while" />
            <token id="26" string="in" />
            <token id="27" string="custody" />
            <token id="28" string="at" />
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="8" string="licensed gun dealer" type="NP">
          <tokens>
            <token id="14" string="licensed" />
            <token id="15" string="gun" />
            <token id="16" string="dealer" />
          </tokens>
        </chunking>
        <chunking id="9" string="was beaten on Oct. 20 while in custody at Oxnard police headquarters" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="beaten" />
            <token id="22" string="on" />
            <token id="23" string="Oct." />
            <token id="24" string="20" />
            <token id="25" string="while" />
            <token id="26" string="in" />
            <token id="27" string="custody" />
            <token id="28" string="at" />
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="10" string="a retired teacher and licensed gun dealer" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="retired" />
            <token id="12" string="teacher" />
            <token id="13" string="and" />
            <token id="14" string="licensed" />
            <token id="15" string="gun" />
            <token id="16" string="dealer" />
          </tokens>
        </chunking>
        <chunking id="11" string="Oct. 20" type="NP">
          <tokens>
            <token id="23" string="Oct." />
            <token id="24" string="20" />
          </tokens>
        </chunking>
        <chunking id="12" string="Oxnard police headquarters" type="NP">
          <tokens>
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="13" string="Louis M. Cornett" type="NP">
          <tokens>
            <token id="6" string="Louis" />
            <token id="7" string="M." />
            <token id="8" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="he was beaten on Oct. 20 while in custody at Oxnard police headquarters" type="SBAR">
          <tokens>
            <token id="19" string="he" />
            <token id="20" string="was" />
            <token id="21" string="beaten" />
            <token id="22" string="on" />
            <token id="23" string="Oct." />
            <token id="24" string="20" />
            <token id="25" string="while" />
            <token id="26" string="in" />
            <token id="27" string="custody" />
            <token id="28" string="at" />
            <token id="29" string="Oxnard" />
            <token id="30" string="police" />
            <token id="31" string="headquarters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">incident</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">incident</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">incident</governor>
          <dependent id="3">third</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="4">incident</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Cornett</governor>
          <dependent id="6">Louis</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Cornett</governor>
          <dependent id="7">M.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="8">Cornett</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">teacher</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">teacher</governor>
          <dependent id="11">retired</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Cornett</governor>
          <dependent id="12">teacher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">teacher</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">dealer</governor>
          <dependent id="14">licensed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">dealer</governor>
          <dependent id="15">gun</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">teacher</governor>
          <dependent id="16">dealer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">beaten</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">beaten</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="21">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Oct.</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">beaten</governor>
          <dependent id="23">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">Oct.</governor>
          <dependent id="24">20</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">custody</governor>
          <dependent id="25">while</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">custody</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">beaten</governor>
          <dependent id="27">custody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">headquarters</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">headquarters</governor>
          <dependent id="29">Oxnard</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">headquarters</governor>
          <dependent id="30">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">custody</governor>
          <dependent id="31">headquarters</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="Oct. 20" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Oct." />
            <token id="24" string="20" />
          </tokens>
        </entity>
        <entity id="4" string="Louis M. Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Louis" />
            <token id="7" string="M." />
            <token id="8" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Cornett said the altercation began as he was returning home after scouting out a site for quail hunting near Santa Maria.</content>
      <tokens>
        <token id="1" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="returning" lemma="return" stem="return" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="scouting" lemma="scout" stem="scout" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="site" lemma="site" stem="site" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="quail" lemma="quail" stem="quail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="hunting" lemma="hunting" stem="hunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Maria" lemma="Maria" stem="maria" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Cornett)) (VP (VBD said) (SBAR (S (NP (DT the) (NN altercation)) (VP (VBD began) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD was) (VP (VBG returning) (NP (NN home)) (PP (IN after) (S (VP (VBG scouting) (PRT (RP out)) (NP (NP (DT a) (NN site)) (PP (IN for) (NP (NP (NN quail) (NN hunting)) (PP (IN near) (NP (NNP Santa) (NNP Maria))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was returning home after scouting out a site for quail hunting near Santa Maria" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="2" string="the altercation began as he was returning home after scouting out a site for quail hunting near Santa Maria" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="altercation" />
            <token id="5" string="began" />
            <token id="6" string="as" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="3" string="returning home after scouting out a site for quail hunting near Santa Maria" type="VP">
          <tokens>
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="4" string="quail hunting" type="NP">
          <tokens>
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
          </tokens>
        </chunking>
        <chunking id="5" string="as he was returning home after scouting out a site for quail hunting near Santa Maria" type="SBAR">
          <tokens>
            <token id="6" string="as" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="6" string="home" type="NP">
          <tokens>
            <token id="10" string="home" />
          </tokens>
        </chunking>
        <chunking id="7" string="Santa Maria" type="NP">
          <tokens>
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="8" string="said the altercation began as he was returning home after scouting out a site for quail hunting near Santa Maria" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="altercation" />
            <token id="5" string="began" />
            <token id="6" string="as" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="9" string="scouting out a site for quail hunting near Santa Maria" type="VP">
          <tokens>
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="10" string="a site for quail hunting near Santa Maria" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="11" string="began as he was returning home after scouting out a site for quail hunting near Santa Maria" type="VP">
          <tokens>
            <token id="5" string="began" />
            <token id="6" string="as" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="returning" />
            <token id="10" string="home" />
            <token id="11" string="after" />
            <token id="12" string="scouting" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="site" />
            <token id="16" string="for" />
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="12" string="the altercation" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Cornett" type="NP">
          <tokens>
            <token id="1" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="14" string="a site" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="site" />
          </tokens>
        </chunking>
        <chunking id="15" string="quail hunting near Santa Maria" type="NP">
          <tokens>
            <token id="17" string="quail" />
            <token id="18" string="hunting" />
            <token id="19" string="near" />
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Cornett</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">altercation</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">began</governor>
          <dependent id="4">altercation</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">began</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">returning</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">returning</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">returning</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">began</governor>
          <dependent id="9">returning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">returning</governor>
          <dependent id="10">home</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">scouting</governor>
          <dependent id="11">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">returning</governor>
          <dependent id="12">scouting</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">scouting</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">site</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">scouting</governor>
          <dependent id="15">site</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">hunting</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">hunting</governor>
          <dependent id="17">quail</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">site</governor>
          <dependent id="18">hunting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Maria</governor>
          <dependent id="19">near</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Maria</governor>
          <dependent id="20">Santa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">hunting</governor>
          <dependent id="21">Maria</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Cornett" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Maria" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Santa" />
            <token id="21" string="Maria" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Officer Robert Camarillo said in a police report that Cornett was arrested in the 3600 block of Taffrail Road on suspicion of brandishing a weapon, resisting arrest and possessing a loaded firearm.</content>
      <tokens>
        <token id="1" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="3600" lemma="3600" stem="3600" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="block" lemma="block" stem="block" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Taffrail" lemma="Taffrail" stem="taffrail" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Road" lemma="Road" stem="road" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="brandishing" lemma="brandish" stem="brandish" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="weapon" lemma="weapon" stem="weapon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="resisting" lemma="resist" stem="resist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="possessing" lemma="possess" stem="possess" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="loaded" lemma="loaded" stem="load" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="firearm" lemma="firearm" stem="firearm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Officer) (NNP Robert) (NNP Camarillo)) (VP (VBD said) (PP (IN in) (NP (DT a) (NN police) (NN report))) (SBAR (WHNP (WDT that)) (S (NP (NNP Cornett)) (VP (VBD was) (VP (VBN arrested) (PP (IN in) (NP (NP (DT the) (CD 3600) (NN block)) (PP (IN of) (NP (NNP Taffrail) (NNP Road))))) (PP (IN on) (NP (NP (NN suspicion)) (PP (IN of) (S (VP (VP (VBG brandishing) (NP (DT a) (NN weapon))) (, ,) (VP (VBG resisting) (NP (NN arrest))) (CC and) (VP (VBG possessing) (NP (DT a) (JJ loaded) (NN firearm))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said in a police report that Cornett was arrested in the 3600 block of Taffrail Road on suspicion of brandishing a weapon , resisting arrest and possessing a loaded firearm" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="police" />
            <token id="8" string="report" />
            <token id="9" string="that" />
            <token id="10" string="Cornett" />
            <token id="11" string="was" />
            <token id="12" string="arrested" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
            <token id="17" string="of" />
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
            <token id="20" string="on" />
            <token id="21" string="suspicion" />
            <token id="22" string="of" />
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Cornett was arrested in the 3600 block of Taffrail Road on suspicion of brandishing a weapon , resisting arrest and possessing a loaded firearm" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Cornett" />
            <token id="11" string="was" />
            <token id="12" string="arrested" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
            <token id="17" string="of" />
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
            <token id="20" string="on" />
            <token id="21" string="suspicion" />
            <token id="22" string="of" />
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="3" string="a police report" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="police" />
            <token id="8" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="possessing a loaded firearm" type="VP">
          <tokens>
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="5" string="arrest" type="NP">
          <tokens>
            <token id="28" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="6" string="was arrested in the 3600 block of Taffrail Road on suspicion of brandishing a weapon , resisting arrest and possessing a loaded firearm" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="arrested" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
            <token id="17" string="of" />
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
            <token id="20" string="on" />
            <token id="21" string="suspicion" />
            <token id="22" string="of" />
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="7" string="suspicion" type="NP">
          <tokens>
            <token id="21" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 3600 block of Taffrail Road" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
            <token id="17" string="of" />
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
          </tokens>
        </chunking>
        <chunking id="9" string="resisting arrest" type="VP">
          <tokens>
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="brandishing a weapon , resisting arrest and possessing a loaded firearm" type="VP">
          <tokens>
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="11" string="Officer Robert Camarillo" type="NP">
          <tokens>
            <token id="1" string="Officer" />
            <token id="2" string="Robert" />
            <token id="3" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 3600 block" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
          </tokens>
        </chunking>
        <chunking id="13" string="a loaded firearm" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="14" string="Cornett" type="NP">
          <tokens>
            <token id="10" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="15" string="a weapon" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="16" string="arrested in the 3600 block of Taffrail Road on suspicion of brandishing a weapon , resisting arrest and possessing a loaded firearm" type="VP">
          <tokens>
            <token id="12" string="arrested" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="3600" />
            <token id="16" string="block" />
            <token id="17" string="of" />
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
            <token id="20" string="on" />
            <token id="21" string="suspicion" />
            <token id="22" string="of" />
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="17" string="Taffrail Road" type="NP">
          <tokens>
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
          </tokens>
        </chunking>
        <chunking id="18" string="suspicion of brandishing a weapon , resisting arrest and possessing a loaded firearm" type="NP">
          <tokens>
            <token id="21" string="suspicion" />
            <token id="22" string="of" />
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
            <token id="26" string="," />
            <token id="27" string="resisting" />
            <token id="28" string="arrest" />
            <token id="29" string="and" />
            <token id="30" string="possessing" />
            <token id="31" string="a" />
            <token id="32" string="loaded" />
            <token id="33" string="firearm" />
          </tokens>
        </chunking>
        <chunking id="19" string="brandishing a weapon" type="VP">
          <tokens>
            <token id="23" string="brandishing" />
            <token id="24" string="a" />
            <token id="25" string="weapon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Camarillo</governor>
          <dependent id="1">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Camarillo</governor>
          <dependent id="2">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Camarillo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">report</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">report</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">report</governor>
          <dependent id="7">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">said</governor>
          <dependent id="8">report</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">arrested</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">arrested</governor>
          <dependent id="10">Cornett</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">arrested</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="12">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">block</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">block</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">block</governor>
          <dependent id="15">3600</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">arrested</governor>
          <dependent id="16">block</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Road</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Road</governor>
          <dependent id="18">Taffrail</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">block</governor>
          <dependent id="19">Road</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">suspicion</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">arrested</governor>
          <dependent id="21">suspicion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">brandishing</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">suspicion</governor>
          <dependent id="23">brandishing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">weapon</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">brandishing</governor>
          <dependent id="25">weapon</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">brandishing</governor>
          <dependent id="27">resisting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">resisting</governor>
          <dependent id="28">arrest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">brandishing</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">brandishing</governor>
          <dependent id="30">possessing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">firearm</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">firearm</governor>
          <dependent id="32">loaded</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">possessing</governor>
          <dependent id="33">firearm</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="3600" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="3600" />
          </tokens>
        </entity>
        <entity id="2" string="Robert Camarillo" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Robert" />
            <token id="3" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="3" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Cornett" />
          </tokens>
        </entity>
        <entity id="4" string="Taffrail Road" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Taffrail" />
            <token id="19" string="Road" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Camarillo said in the report that he stopped Cornett while investigating a complaint of a man waving a gun from a car and threatening youngsters packed into another vehicle.</content>
      <tokens>
        <token id="1" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="waving" lemma="wave" stem="wave" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="gun" lemma="gun" stem="gun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="threatening" lemma="threatening" stem="threaten" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="youngsters" lemma="youngster" stem="youngster" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="packed" lemma="pack" stem="pack" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="vehicle" lemma="vehicle" stem="vehicl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Camarillo)) (VP (VBD said) (PP (IN in) (NP (DT the) (NN report))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD stopped) (NP (NNP Cornett)) (SBAR (IN while) (S (S (VP (VBG investigating) (NP (NP (DT a) (NN complaint)) (PP (IN of) (NP (NP (DT a) (NN man)) (VP (VBG waving) (NP (DT a) (NN gun)) (PP (IN from) (NP (NP (DT a) (NN car)) (CC and) (NP (JJ threatening) (NNS youngsters)))))))))) (VP (VBD packed) (PP (IN into) (NP (DT another) (NN vehicle)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a man waving a gun from a car and threatening youngsters" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="2" string="a car and threatening youngsters" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="3" string="Camarillo" type="NP">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="4" string="waving a gun from a car and threatening youngsters" type="VP">
          <tokens>
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="5" string="stopped Cornett while investigating a complaint of a man waving a gun from a car and threatening youngsters packed into another vehicle" type="VP">
          <tokens>
            <token id="8" string="stopped" />
            <token id="9" string="Cornett" />
            <token id="10" string="while" />
            <token id="11" string="investigating" />
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
            <token id="26" string="packed" />
            <token id="27" string="into" />
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="6" string="a gun" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="gun" />
          </tokens>
        </chunking>
        <chunking id="7" string="a complaint of a man waving a gun from a car and threatening youngsters" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="8" string="another vehicle" type="NP">
          <tokens>
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="9" string="a car" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="while investigating a complaint of a man waving a gun from a car and threatening youngsters packed into another vehicle" type="SBAR">
          <tokens>
            <token id="10" string="while" />
            <token id="11" string="investigating" />
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
            <token id="26" string="packed" />
            <token id="27" string="into" />
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="11" string="threatening youngsters" type="NP">
          <tokens>
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="12" string="Cornett" type="NP">
          <tokens>
            <token id="9" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="13" string="said in the report that he stopped Cornett while investigating a complaint of a man waving a gun from a car and threatening youngsters packed into another vehicle" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="report" />
            <token id="6" string="that" />
            <token id="7" string="he" />
            <token id="8" string="stopped" />
            <token id="9" string="Cornett" />
            <token id="10" string="while" />
            <token id="11" string="investigating" />
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
            <token id="26" string="packed" />
            <token id="27" string="into" />
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="14" string="that he stopped Cornett while investigating a complaint of a man waving a gun from a car and threatening youngsters packed into another vehicle" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="he" />
            <token id="8" string="stopped" />
            <token id="9" string="Cornett" />
            <token id="10" string="while" />
            <token id="11" string="investigating" />
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
            <token id="26" string="packed" />
            <token id="27" string="into" />
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="15" string="investigating a complaint of a man waving a gun from a car and threatening youngsters" type="VP">
          <tokens>
            <token id="11" string="investigating" />
            <token id="12" string="a" />
            <token id="13" string="complaint" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="man" />
            <token id="17" string="waving" />
            <token id="18" string="a" />
            <token id="19" string="gun" />
            <token id="20" string="from" />
            <token id="21" string="a" />
            <token id="22" string="car" />
            <token id="23" string="and" />
            <token id="24" string="threatening" />
            <token id="25" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="16" string="the report" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="report" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="a man" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="man" />
          </tokens>
        </chunking>
        <chunking id="19" string="a complaint" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="20" string="packed into another vehicle" type="VP">
          <tokens>
            <token id="26" string="packed" />
            <token id="27" string="into" />
            <token id="28" string="another" />
            <token id="29" string="vehicle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Camarillo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">report</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">report</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">said</governor>
          <dependent id="5">report</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">stopped</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">stopped</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="8">stopped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">stopped</governor>
          <dependent id="9">Cornett</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">packed</governor>
          <dependent id="10">while</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="26">packed</governor>
          <dependent id="11">investigating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">complaint</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">investigating</governor>
          <dependent id="13">complaint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">man</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">man</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">complaint</governor>
          <dependent id="16">man</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">man</governor>
          <dependent id="17">waving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">gun</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">waving</governor>
          <dependent id="19">gun</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">car</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">car</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">waving</governor>
          <dependent id="22">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">car</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">youngsters</governor>
          <dependent id="24">threatening</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">car</governor>
          <dependent id="25">youngsters</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">stopped</governor>
          <dependent id="26">packed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">vehicle</governor>
          <dependent id="27">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">vehicle</governor>
          <dependent id="28">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">packed</governor>
          <dependent id="29">vehicle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Camarillo" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="2" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Camarillo said Cornett fit the description of the man who allegedly brandished the weapon.</content>
      <tokens>
        <token id="1" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="fit" lemma="fit" stem="fit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="description" lemma="description" stem="descript" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="allegedly" lemma="allegedly" stem="allegedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="brandished" lemma="brandish" stem="brandish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="weapon" lemma="weapon" stem="weapon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Camarillo)) (VP (VBD said) (S (NP (NNP Cornett)) (VP (VB fit) (NP (NP (DT the) (NN description)) (PP (IN of) (NP (NP (DT the) (NN man)) (SBAR (WHNP (WP who)) (S (ADVP (RB allegedly)) (VP (VBD brandished) (NP (DT the) (NN weapon))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the man" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="man" />
          </tokens>
        </chunking>
        <chunking id="2" string="the man who allegedly brandished the weapon" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="man" />
            <token id="10" string="who" />
            <token id="11" string="allegedly" />
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="3" string="who allegedly brandished the weapon" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="allegedly" />
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="4" string="Camarillo" type="NP">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="5" string="brandished the weapon" type="VP">
          <tokens>
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="6" string="Cornett" type="NP">
          <tokens>
            <token id="3" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="7" string="the weapon" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="8" string="fit the description of the man who allegedly brandished the weapon" type="VP">
          <tokens>
            <token id="4" string="fit" />
            <token id="5" string="the" />
            <token id="6" string="description" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="man" />
            <token id="10" string="who" />
            <token id="11" string="allegedly" />
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="9" string="the description" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="description" />
          </tokens>
        </chunking>
        <chunking id="10" string="said Cornett fit the description of the man who allegedly brandished the weapon" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Cornett" />
            <token id="4" string="fit" />
            <token id="5" string="the" />
            <token id="6" string="description" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="man" />
            <token id="10" string="who" />
            <token id="11" string="allegedly" />
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
        <chunking id="11" string="the description of the man who allegedly brandished the weapon" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="description" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="man" />
            <token id="10" string="who" />
            <token id="11" string="allegedly" />
            <token id="12" string="brandished" />
            <token id="13" string="the" />
            <token id="14" string="weapon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Camarillo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">fit</governor>
          <dependent id="3">Cornett</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">fit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">description</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">fit</governor>
          <dependent id="6">description</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">man</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">man</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">description</governor>
          <dependent id="9">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">brandished</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">brandished</governor>
          <dependent id="11">allegedly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">man</governor>
          <dependent id="12">brandished</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">weapon</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">brandished</governor>
          <dependent id="14">weapon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Camarillo" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="2" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>When he searched Cornett&amp;apost;s car, Camarillo said, he found a semiautomatic handgun, several rounds of ammunition and a 12-gauge shotgun.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="searched" lemma="search" stem="search" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="semiautomatic" lemma="semiautomatic" stem="semiautomat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="handgun" lemma="handgun" stem="handgun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="rounds" lemma="round" stem="round" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="ammunition" lemma="ammunition" stem="ammunit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="12-gauge" lemma="12-gauge" stem="12-gaug" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="shotgun" lemma="shotgun" stem="shotgun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (WHADVP (WRB When)) (S (NP (PRP he)) (VP (VBD searched) (NP (NP (NNP Cornett) (POS 's)) (NN car))))) (, ,) (NP (NNP Camarillo)) (VP (VBD said))) (, ,) (NP (PRP he)) (VP (VBD found) (NP (NP (DT a) (JJ semiautomatic) (NN handgun)) (, ,) (NP (NP (JJ several) (NNS rounds)) (PP (IN of) (NP (NN ammunition)))) (CC and) (NP (DT a) (JJ 12-gauge) (NN shotgun)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="several rounds of ammunition" type="NP">
          <tokens>
            <token id="17" string="several" />
            <token id="18" string="rounds" />
            <token id="19" string="of" />
            <token id="20" string="ammunition" />
          </tokens>
        </chunking>
        <chunking id="2" string="ammunition" type="NP">
          <tokens>
            <token id="20" string="ammunition" />
          </tokens>
        </chunking>
        <chunking id="3" string="found a semiautomatic handgun , several rounds of ammunition and a 12-gauge shotgun" type="VP">
          <tokens>
            <token id="12" string="found" />
            <token id="13" string="a" />
            <token id="14" string="semiautomatic" />
            <token id="15" string="handgun" />
            <token id="16" string="," />
            <token id="17" string="several" />
            <token id="18" string="rounds" />
            <token id="19" string="of" />
            <token id="20" string="ammunition" />
            <token id="21" string="and" />
            <token id="22" string="a" />
            <token id="23" string="12-gauge" />
            <token id="24" string="shotgun" />
          </tokens>
        </chunking>
        <chunking id="4" string="searched Cornett 's car" type="VP">
          <tokens>
            <token id="3" string="searched" />
            <token id="4" string="Cornett" />
            <token id="5" string="'s" />
            <token id="6" string="car" />
          </tokens>
        </chunking>
        <chunking id="5" string="Camarillo" type="NP">
          <tokens>
            <token id="8" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="6" string="Cornett 's" type="NP">
          <tokens>
            <token id="4" string="Cornett" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="a 12-gauge shotgun" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="12-gauge" />
            <token id="24" string="shotgun" />
          </tokens>
        </chunking>
        <chunking id="8" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="9" string="a semiautomatic handgun , several rounds of ammunition and a 12-gauge shotgun" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="semiautomatic" />
            <token id="15" string="handgun" />
            <token id="16" string="," />
            <token id="17" string="several" />
            <token id="18" string="rounds" />
            <token id="19" string="of" />
            <token id="20" string="ammunition" />
            <token id="21" string="and" />
            <token id="22" string="a" />
            <token id="23" string="12-gauge" />
            <token id="24" string="shotgun" />
          </tokens>
        </chunking>
        <chunking id="10" string="Cornett 's car" type="NP">
          <tokens>
            <token id="4" string="Cornett" />
            <token id="5" string="'s" />
            <token id="6" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="When he searched Cornett 's car" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="he" />
            <token id="3" string="searched" />
            <token id="4" string="Cornett" />
            <token id="5" string="'s" />
            <token id="6" string="car" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="several rounds" type="NP">
          <tokens>
            <token id="17" string="several" />
            <token id="18" string="rounds" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="15" string="a semiautomatic handgun" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="semiautomatic" />
            <token id="15" string="handgun" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">searched</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">searched</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">said</governor>
          <dependent id="3">searched</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">car</governor>
          <dependent id="4">Cornett</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Cornett</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">searched</governor>
          <dependent id="6">car</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Camarillo</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">found</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">found</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">handgun</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">handgun</governor>
          <dependent id="14">semiautomatic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">found</governor>
          <dependent id="15">handgun</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">rounds</governor>
          <dependent id="17">several</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">handgun</governor>
          <dependent id="18">rounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">ammunition</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">rounds</governor>
          <dependent id="20">ammunition</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">handgun</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">shotgun</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">shotgun</governor>
          <dependent id="23">12-gauge</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">handgun</governor>
          <dependent id="24">shotgun</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Camarillo" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="2" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Camarillo admitted that he later shoved Cornett against a wall at police headquarters because the suspect had struggled and had clenched his fists in a threatening manner.</content>
      <tokens>
        <token id="1" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="shoved" lemma="shove" stem="shove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wall" lemma="wall" stem="wall" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="headquarters" lemma="headquarters" stem="headquart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="struggled" lemma="struggle" stem="struggl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="clenched" lemma="clench" stem="clench" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="fists" lemma="fist" stem="fist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="threatening" lemma="threatening" stem="threaten" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="manner" lemma="manner" stem="manner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Camarillo)) (VP (VP (VBD admitted) (SBAR (IN that) (S (NP (PRP he)) (VP (ADVP (RB later)) (VBD shoved) (NP (NP (NNP Cornett)) (PP (IN against) (NP (DT a) (NN wall)))) (PP (IN at) (NP (NN police) (NN headquarters))) (SBAR (IN because) (S (NP (DT the) (NN suspect)) (VP (VBD had) (VP (VBN struggled))))))))) (CC and) (VP (VBD had) (VP (VBN clenched) (NP (PRP$ his) (NNS fists)) (PP (IN in) (NP (DT a) (JJ threatening) (NN manner)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="admitted that he later shoved Cornett against a wall at police headquarters because the suspect had struggled" type="VP">
          <tokens>
            <token id="2" string="admitted" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="later" />
            <token id="6" string="shoved" />
            <token id="7" string="Cornett" />
            <token id="8" string="against" />
            <token id="9" string="a" />
            <token id="10" string="wall" />
            <token id="11" string="at" />
            <token id="12" string="police" />
            <token id="13" string="headquarters" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="had" />
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="2" string="Camarillo" type="NP">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="3" string="a wall" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="wall" />
          </tokens>
        </chunking>
        <chunking id="4" string="later shoved Cornett against a wall at police headquarters because the suspect had struggled" type="VP">
          <tokens>
            <token id="5" string="later" />
            <token id="6" string="shoved" />
            <token id="7" string="Cornett" />
            <token id="8" string="against" />
            <token id="9" string="a" />
            <token id="10" string="wall" />
            <token id="11" string="at" />
            <token id="12" string="police" />
            <token id="13" string="headquarters" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="had" />
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="5" string="struggled" type="VP">
          <tokens>
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="6" string="clenched his fists in a threatening manner" type="VP">
          <tokens>
            <token id="21" string="clenched" />
            <token id="22" string="his" />
            <token id="23" string="fists" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="threatening" />
            <token id="27" string="manner" />
          </tokens>
        </chunking>
        <chunking id="7" string="Cornett against a wall" type="NP">
          <tokens>
            <token id="7" string="Cornett" />
            <token id="8" string="against" />
            <token id="9" string="a" />
            <token id="10" string="wall" />
          </tokens>
        </chunking>
        <chunking id="8" string="had struggled" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="9" string="police headquarters" type="NP">
          <tokens>
            <token id="12" string="police" />
            <token id="13" string="headquarters" />
          </tokens>
        </chunking>
        <chunking id="10" string="because the suspect had struggled" type="SBAR">
          <tokens>
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="had" />
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="11" string="a threatening manner" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="threatening" />
            <token id="27" string="manner" />
          </tokens>
        </chunking>
        <chunking id="12" string="Cornett" type="NP">
          <tokens>
            <token id="7" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="13" string="admitted that he later shoved Cornett against a wall at police headquarters because the suspect had struggled and had clenched his fists in a threatening manner" type="VP">
          <tokens>
            <token id="2" string="admitted" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="later" />
            <token id="6" string="shoved" />
            <token id="7" string="Cornett" />
            <token id="8" string="against" />
            <token id="9" string="a" />
            <token id="10" string="wall" />
            <token id="11" string="at" />
            <token id="12" string="police" />
            <token id="13" string="headquarters" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="had" />
            <token id="18" string="struggled" />
            <token id="19" string="and" />
            <token id="20" string="had" />
            <token id="21" string="clenched" />
            <token id="22" string="his" />
            <token id="23" string="fists" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="threatening" />
            <token id="27" string="manner" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="had clenched his fists in a threatening manner" type="VP">
          <tokens>
            <token id="20" string="had" />
            <token id="21" string="clenched" />
            <token id="22" string="his" />
            <token id="23" string="fists" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="threatening" />
            <token id="27" string="manner" />
          </tokens>
        </chunking>
        <chunking id="16" string="that he later shoved Cornett against a wall at police headquarters because the suspect had struggled" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="later" />
            <token id="6" string="shoved" />
            <token id="7" string="Cornett" />
            <token id="8" string="against" />
            <token id="9" string="a" />
            <token id="10" string="wall" />
            <token id="11" string="at" />
            <token id="12" string="police" />
            <token id="13" string="headquarters" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="had" />
            <token id="18" string="struggled" />
          </tokens>
        </chunking>
        <chunking id="17" string="the suspect" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="18" string="his fists" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="fists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">admitted</governor>
          <dependent id="1">Camarillo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">shoved</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">shoved</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">shoved</governor>
          <dependent id="5">later</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">admitted</governor>
          <dependent id="6">shoved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">shoved</governor>
          <dependent id="7">Cornett</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">wall</governor>
          <dependent id="8">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">wall</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Cornett</governor>
          <dependent id="10">wall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">headquarters</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">headquarters</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">shoved</governor>
          <dependent id="13">headquarters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">struggled</governor>
          <dependent id="14">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">suspect</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">struggled</governor>
          <dependent id="16">suspect</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">struggled</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">shoved</governor>
          <dependent id="18">struggled</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">admitted</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">clenched</governor>
          <dependent id="20">had</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">admitted</governor>
          <dependent id="21">clenched</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">fists</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">clenched</governor>
          <dependent id="23">fists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">manner</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">manner</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">manner</governor>
          <dependent id="26">threatening</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">clenched</governor>
          <dependent id="27">manner</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Camarillo" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="2" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>But a lawsuit against Camarillo filed May 8, 1989, alleges that while in custody at the police station, Camarillo shoved and punched Cornett in the mouth.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="filed" lemma="file" stem="file" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="custody" lemma="custody" stem="custodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Camarillo" lemma="Camarillo" stem="camarillo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="23" string="shoved" lemma="shove" stem="shove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="punched" lemma="punch" stem="punch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="mouth" lemma="mouth" stem="mouth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT a) (NN lawsuit)) (PP (IN against) (NP (NNP Camarillo)))) (VP (VP (VBD filed) (NP-TMP (NNP May) (CD 8) (, ,) (CD 1989))) (, ,) (VP (VBZ alleges) (SBAR (IN that) (IN while) (S (PP (IN in) (NP (NP (NN custody)) (PP (IN at) (NP (DT the) (NN police) (NN station))))) (, ,) (NP (NNP Camarillo)) (VP (VBD shoved))))) (CC and) (VP (VBD punched) (NP (NP (NNP Cornett)) (PP (IN in) (NP (DT the) (NN mouth)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Camarillo" type="NP">
          <tokens>
            <token id="5" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="2" string="the police station" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="police" />
            <token id="20" string="station" />
          </tokens>
        </chunking>
        <chunking id="3" string="punched Cornett in the mouth" type="VP">
          <tokens>
            <token id="25" string="punched" />
            <token id="26" string="Cornett" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="4" string="Cornett in the mouth" type="NP">
          <tokens>
            <token id="26" string="Cornett" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="5" string="filed May 8 , 1989 , alleges that while in custody at the police station , Camarillo shoved and punched Cornett in the mouth" type="VP">
          <tokens>
            <token id="6" string="filed" />
            <token id="7" string="May" />
            <token id="8" string="8" />
            <token id="9" string="," />
            <token id="10" string="1989" />
            <token id="11" string="," />
            <token id="12" string="alleges" />
            <token id="13" string="that" />
            <token id="14" string="while" />
            <token id="15" string="in" />
            <token id="16" string="custody" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="police" />
            <token id="20" string="station" />
            <token id="21" string="," />
            <token id="22" string="Camarillo" />
            <token id="23" string="shoved" />
            <token id="24" string="and" />
            <token id="25" string="punched" />
            <token id="26" string="Cornett" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="6" string="filed May 8 , 1989" type="VP">
          <tokens>
            <token id="6" string="filed" />
            <token id="7" string="May" />
            <token id="8" string="8" />
            <token id="9" string="," />
            <token id="10" string="1989" />
          </tokens>
        </chunking>
        <chunking id="7" string="custody" type="NP">
          <tokens>
            <token id="16" string="custody" />
          </tokens>
        </chunking>
        <chunking id="8" string="alleges that while in custody at the police station , Camarillo shoved" type="VP">
          <tokens>
            <token id="12" string="alleges" />
            <token id="13" string="that" />
            <token id="14" string="while" />
            <token id="15" string="in" />
            <token id="16" string="custody" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="police" />
            <token id="20" string="station" />
            <token id="21" string="," />
            <token id="22" string="Camarillo" />
            <token id="23" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="9" string="shoved" type="VP">
          <tokens>
            <token id="23" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="10" string="a lawsuit" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lawsuit against Camarillo" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="lawsuit" />
            <token id="4" string="against" />
            <token id="5" string="Camarillo" />
          </tokens>
        </chunking>
        <chunking id="12" string="that while in custody at the police station , Camarillo shoved" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="while" />
            <token id="15" string="in" />
            <token id="16" string="custody" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="police" />
            <token id="20" string="station" />
            <token id="21" string="," />
            <token id="22" string="Camarillo" />
            <token id="23" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="13" string="the mouth" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="14" string="Cornett" type="NP">
          <tokens>
            <token id="26" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="15" string="custody at the police station" type="NP">
          <tokens>
            <token id="16" string="custody" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="police" />
            <token id="20" string="station" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">filed</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">lawsuit</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">filed</governor>
          <dependent id="3">lawsuit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Camarillo</governor>
          <dependent id="4">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">lawsuit</governor>
          <dependent id="5">Camarillo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">filed</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">filed</governor>
          <dependent id="7">May</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">May</governor>
          <dependent id="8">8</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">May</governor>
          <dependent id="10">1989</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">filed</governor>
          <dependent id="12">alleges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">shoved</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">shoved</governor>
          <dependent id="14">while</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">custody</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">shoved</governor>
          <dependent id="16">custody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">station</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">station</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">station</governor>
          <dependent id="19">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">custody</governor>
          <dependent id="20">station</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">shoved</governor>
          <dependent id="22">Camarillo</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">alleges</governor>
          <dependent id="23">shoved</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">filed</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">filed</governor>
          <dependent id="25">punched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">punched</governor>
          <dependent id="26">Cornett</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">mouth</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">mouth</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Cornett</governor>
          <dependent id="29">mouth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Camarillo" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Camarillo" />
          </tokens>
        </entity>
        <entity id="2" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Cornett" />
          </tokens>
        </entity>
        <entity id="3" string="May 8 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="May" />
            <token id="8" string="8" />
            <token id="9" string="," />
            <token id="10" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;He slammed me in the mouth once, twice and a third time,&amp;quot; Cornett said in an interview.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="slammed" lemma="slam" stem="slam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="mouth" lemma="mouth" stem="mouth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="twice" lemma="twice" stem="twice" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="14" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (VBD slammed) (NP (PRP me)) (PP (IN in) (NP (NP (NP (DT the) (NN mouth)) (NP (RB once)) (, ,) (ADVP (RB twice))) (CC and) (NP (DT a) (JJ third) (NN time)))))) (, ,) ('' '') (NP (NNP Cornett)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an interview" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="interview" />
          </tokens>
        </chunking>
        <chunking id="2" string="the mouth once , twice and a third time" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="mouth" />
            <token id="8" string="once" />
            <token id="9" string="," />
            <token id="10" string="twice" />
            <token id="11" string="and" />
            <token id="12" string="a" />
            <token id="13" string="third" />
            <token id="14" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="once" type="NP">
          <tokens>
            <token id="8" string="once" />
          </tokens>
        </chunking>
        <chunking id="4" string="the mouth" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="5" string="me" type="NP">
          <tokens>
            <token id="4" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="said in an interview" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="in" />
            <token id="20" string="an" />
            <token id="21" string="interview" />
          </tokens>
        </chunking>
        <chunking id="7" string="Cornett" type="NP">
          <tokens>
            <token id="17" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="8" string="slammed me in the mouth once , twice and a third time" type="VP">
          <tokens>
            <token id="3" string="slammed" />
            <token id="4" string="me" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="mouth" />
            <token id="8" string="once" />
            <token id="9" string="," />
            <token id="10" string="twice" />
            <token id="11" string="and" />
            <token id="12" string="a" />
            <token id="13" string="third" />
            <token id="14" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="the mouth once , twice" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="mouth" />
            <token id="8" string="once" />
            <token id="9" string="," />
            <token id="10" string="twice" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="11" string="a third time" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="third" />
            <token id="14" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">slammed</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="3">slammed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">slammed</governor>
          <dependent id="4">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">mouth</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">mouth</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">slammed</governor>
          <dependent id="7">mouth</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">mouth</governor>
          <dependent id="8">once</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">mouth</governor>
          <dependent id="10">twice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">mouth</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">time</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">time</governor>
          <dependent id="13">third</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">mouth</governor>
          <dependent id="14">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Cornett</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">interview</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">interview</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="21">interview</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="13" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Cornett, maintaining that he never struggled with the officer, said he suffered a broken tooth and a cut lip during the beating.</content>
      <tokens>
        <token id="1" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="maintaining" lemma="maintain" stem="maintain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="struggled" lemma="struggle" stem="struggl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="broken" lemma="broken" stem="broken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="tooth" lemma="tooth" stem="tooth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="cut" lemma="cut" stem="cut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="lip" lemma="lip" stem="lip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Cornett)) (, ,) (S (VP (VBG maintaining) (SBAR (IN that) (S (NP (PRP he)) (ADVP (RB never)) (VP (VBD struggled) (PP (IN with) (NP (DT the) (NN officer)))))))) (, ,) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD suffered) (NP (NP (DT a) (JJ broken) (NN tooth)) (CC and) (NP (DT a) (NN cut) (NN lip))) (PP (IN during) (NP (DT the) (NN beating))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that he never struggled with the officer" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="never" />
            <token id="7" string="struggled" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="a cut lip" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="cut" />
            <token id="21" string="lip" />
          </tokens>
        </chunking>
        <chunking id="3" string="a broken tooth and a cut lip" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="broken" />
            <token id="17" string="tooth" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="cut" />
            <token id="21" string="lip" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officer" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="a broken tooth" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="broken" />
            <token id="17" string="tooth" />
          </tokens>
        </chunking>
        <chunking id="6" string="said he suffered a broken tooth and a cut lip during the beating" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="he" />
            <token id="14" string="suffered" />
            <token id="15" string="a" />
            <token id="16" string="broken" />
            <token id="17" string="tooth" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="cut" />
            <token id="21" string="lip" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="beating" />
          </tokens>
        </chunking>
        <chunking id="7" string="Cornett" type="NP">
          <tokens>
            <token id="1" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="8" string="the beating" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="beating" />
          </tokens>
        </chunking>
        <chunking id="9" string="he suffered a broken tooth and a cut lip during the beating" type="SBAR">
          <tokens>
            <token id="13" string="he" />
            <token id="14" string="suffered" />
            <token id="15" string="a" />
            <token id="16" string="broken" />
            <token id="17" string="tooth" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="cut" />
            <token id="21" string="lip" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="beating" />
          </tokens>
        </chunking>
        <chunking id="10" string="suffered a broken tooth and a cut lip during the beating" type="VP">
          <tokens>
            <token id="14" string="suffered" />
            <token id="15" string="a" />
            <token id="16" string="broken" />
            <token id="17" string="tooth" />
            <token id="18" string="and" />
            <token id="19" string="a" />
            <token id="20" string="cut" />
            <token id="21" string="lip" />
            <token id="22" string="during" />
            <token id="23" string="the" />
            <token id="24" string="beating" />
          </tokens>
        </chunking>
        <chunking id="11" string="maintaining that he never struggled with the officer" type="VP">
          <tokens>
            <token id="3" string="maintaining" />
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="never" />
            <token id="7" string="struggled" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="struggled with the officer" type="VP">
          <tokens>
            <token id="7" string="struggled" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="1">Cornett</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">said</governor>
          <dependent id="3">maintaining</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">struggled</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">struggled</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">struggled</governor>
          <dependent id="6">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">maintaining</governor>
          <dependent id="7">struggled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">officer</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officer</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struggled</governor>
          <dependent id="10">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">suffered</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="14">suffered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tooth</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">tooth</governor>
          <dependent id="16">broken</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">suffered</governor>
          <dependent id="17">tooth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">tooth</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lip</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">lip</governor>
          <dependent id="20">cut</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">tooth</governor>
          <dependent id="21">lip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">beating</governor>
          <dependent id="22">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">beating</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">suffered</governor>
          <dependent id="24">beating</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Cornett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>The district attorney&amp;apost;s office declined to file charges against Cornett because, Brodie said, there was insufficient evidence to prove that Cornett brandished a gun.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="insufficient" lemma="insufficient" stem="insuffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Cornett" lemma="Cornett" stem="cornett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="brandished" lemma="brandish" stem="brandish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="gun" lemma="gun" stem="gun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VBD declined) (S (VP (TO to) (VP (VB file) (NP (NNS charges)) (PP (IN against) (NP (NNP Cornett))) (SBAR (IN because) (, ,) (S (NP (NNP Brodie)) (VP (VBD said))))))))) (, ,) (NP (EX there)) (VP (VBD was) (NP (JJ insufficient) (NN evidence) (S (VP (TO to) (VP (VB prove) (SBAR (IN that) (S (NP (NNP Cornett)) (VP (VBD brandished) (NP (DT a) (NN gun)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The district attorney 's office" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
            <token id="5" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Cornett brandished a gun" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="Cornett" />
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="3" string="a gun" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="4" string="declined to file charges against Cornett because , Brodie said" type="VP">
          <tokens>
            <token id="6" string="declined" />
            <token id="7" string="to" />
            <token id="8" string="file" />
            <token id="9" string="charges" />
            <token id="10" string="against" />
            <token id="11" string="Cornett" />
            <token id="12" string="because" />
            <token id="13" string="," />
            <token id="14" string="Brodie" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="prove that Cornett brandished a gun" type="VP">
          <tokens>
            <token id="22" string="prove" />
            <token id="23" string="that" />
            <token id="24" string="Cornett" />
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="6" string="The district attorney 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="insufficient evidence to prove that Cornett brandished a gun" type="NP">
          <tokens>
            <token id="19" string="insufficient" />
            <token id="20" string="evidence" />
            <token id="21" string="to" />
            <token id="22" string="prove" />
            <token id="23" string="that" />
            <token id="24" string="Cornett" />
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="8" string="file charges against Cornett because , Brodie said" type="VP">
          <tokens>
            <token id="8" string="file" />
            <token id="9" string="charges" />
            <token id="10" string="against" />
            <token id="11" string="Cornett" />
            <token id="12" string="because" />
            <token id="13" string="," />
            <token id="14" string="Brodie" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="17" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="brandished a gun" type="VP">
          <tokens>
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="11" string="because , Brodie said" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="," />
            <token id="14" string="Brodie" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="charges" type="NP">
          <tokens>
            <token id="9" string="charges" />
          </tokens>
        </chunking>
        <chunking id="13" string="to prove that Cornett brandished a gun" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="prove" />
            <token id="23" string="that" />
            <token id="24" string="Cornett" />
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="14" string="Cornett" type="NP">
          <tokens>
            <token id="11" string="Cornett" />
          </tokens>
        </chunking>
        <chunking id="15" string="was insufficient evidence to prove that Cornett brandished a gun" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="insufficient" />
            <token id="20" string="evidence" />
            <token id="21" string="to" />
            <token id="22" string="prove" />
            <token id="23" string="that" />
            <token id="24" string="Cornett" />
            <token id="25" string="brandished" />
            <token id="26" string="a" />
            <token id="27" string="gun" />
          </tokens>
        </chunking>
        <chunking id="16" string="Brodie" type="NP">
          <tokens>
            <token id="14" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="to file charges against Cornett because , Brodie said" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="file" />
            <token id="9" string="charges" />
            <token id="10" string="against" />
            <token id="11" string="Cornett" />
            <token id="12" string="because" />
            <token id="13" string="," />
            <token id="14" string="Brodie" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">attorney</governor>
          <dependent id="2">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">office</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">attorney</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">declined</governor>
          <dependent id="5">office</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">was</governor>
          <dependent id="6">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">file</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">declined</governor>
          <dependent id="8">file</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">file</governor>
          <dependent id="9">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Cornett</governor>
          <dependent id="10">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">file</governor>
          <dependent id="11">Cornett</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">said</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Brodie</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">file</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="18">was</governor>
          <dependent id="17">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">evidence</governor>
          <dependent id="19">insufficient</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">was</governor>
          <dependent id="20">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">prove</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">evidence</governor>
          <dependent id="22">prove</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">brandished</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">brandished</governor>
          <dependent id="24">Cornett</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">prove</governor>
          <dependent id="25">brandished</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">gun</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">brandished</governor>
          <dependent id="27">gun</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cornett" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Cornett" />
          </tokens>
        </entity>
        <entity id="2" string="Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Brodie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>In a fourth incident, Alejandro Guzman-Flores, 21, accused three Oxnard officers of beating him on his face, causing severe damage to his eyesight.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fourth" lemma="fourth" stem="fourth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Alejandro" lemma="Alejandro" stem="alejandro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Guzman-Flores" lemma="Guzman-Flores" stem="guzman-flor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="13" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="beating" lemma="beat" stem="beat" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="severe" lemma="severe" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="eyesight" lemma="eyesight" stem="eyesight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT a) (JJ fourth) (NN incident))) (, ,) (NP (NP (NNP Alejandro) (NNP Guzman-Flores)) (, ,) (NP (CD 21)) (, ,)) (VP (VBD accused) (NP (NP (CD three) (NNP Oxnard) (NNS officers)) (PP (IN of) (S (VP (VBG beating) (NP (PRP him)) (PP (IN on) (NP (PRP$ his) (NN face))))))) (, ,) (S (VP (VBG causing) (NP (JJ severe) (NN damage)) (PP (TO to) (NP (PRP$ his) (NN eyesight)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="three Oxnard officers of beating him on his face" type="NP">
          <tokens>
            <token id="12" string="three" />
            <token id="13" string="Oxnard" />
            <token id="14" string="officers" />
            <token id="15" string="of" />
            <token id="16" string="beating" />
            <token id="17" string="him" />
            <token id="18" string="on" />
            <token id="19" string="his" />
            <token id="20" string="face" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alejandro Guzman-Flores , 21 ," type="NP">
          <tokens>
            <token id="6" string="Alejandro" />
            <token id="7" string="Guzman-Flores" />
            <token id="8" string="," />
            <token id="9" string="21" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="beating him on his face" type="VP">
          <tokens>
            <token id="16" string="beating" />
            <token id="17" string="him" />
            <token id="18" string="on" />
            <token id="19" string="his" />
            <token id="20" string="face" />
          </tokens>
        </chunking>
        <chunking id="4" string="accused three Oxnard officers of beating him on his face , causing severe damage to his eyesight" type="VP">
          <tokens>
            <token id="11" string="accused" />
            <token id="12" string="three" />
            <token id="13" string="Oxnard" />
            <token id="14" string="officers" />
            <token id="15" string="of" />
            <token id="16" string="beating" />
            <token id="17" string="him" />
            <token id="18" string="on" />
            <token id="19" string="his" />
            <token id="20" string="face" />
            <token id="21" string="," />
            <token id="22" string="causing" />
            <token id="23" string="severe" />
            <token id="24" string="damage" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="eyesight" />
          </tokens>
        </chunking>
        <chunking id="5" string="severe damage" type="NP">
          <tokens>
            <token id="23" string="severe" />
            <token id="24" string="damage" />
          </tokens>
        </chunking>
        <chunking id="6" string="Alejandro Guzman-Flores" type="NP">
          <tokens>
            <token id="6" string="Alejandro" />
            <token id="7" string="Guzman-Flores" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="three Oxnard officers" type="NP">
          <tokens>
            <token id="12" string="three" />
            <token id="13" string="Oxnard" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="causing severe damage to his eyesight" type="VP">
          <tokens>
            <token id="22" string="causing" />
            <token id="23" string="severe" />
            <token id="24" string="damage" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="eyesight" />
          </tokens>
        </chunking>
        <chunking id="10" string="his face" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="face" />
          </tokens>
        </chunking>
        <chunking id="11" string="his eyesight" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="eyesight" />
          </tokens>
        </chunking>
        <chunking id="12" string="a fourth incident" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="fourth" />
            <token id="4" string="incident" />
          </tokens>
        </chunking>
        <chunking id="13" string="21" type="NP">
          <tokens>
            <token id="9" string="21" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">incident</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">incident</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">incident</governor>
          <dependent id="3">fourth</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">accused</governor>
          <dependent id="4">incident</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Guzman-Flores</governor>
          <dependent id="6">Alejandro</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">accused</governor>
          <dependent id="7">Guzman-Flores</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Guzman-Flores</governor>
          <dependent id="9">21</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">accused</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">officers</governor>
          <dependent id="12">three</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officers</governor>
          <dependent id="13">Oxnard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">accused</governor>
          <dependent id="14">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">beating</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">officers</governor>
          <dependent id="16">beating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">beating</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">face</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">face</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">beating</governor>
          <dependent id="20">face</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">accused</governor>
          <dependent id="22">causing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">damage</governor>
          <dependent id="23">severe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">causing</governor>
          <dependent id="24">damage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">eyesight</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">eyesight</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">causing</governor>
          <dependent id="27">eyesight</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="fourth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="fourth" />
          </tokens>
        </entity>
        <entity id="3" string="Alejandro Guzman-Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Alejandro" />
            <token id="7" string="Guzman-Flores" />
          </tokens>
        </entity>
        <entity id="4" string="21" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="21" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>Guzman-Flores said he was working in a motorcycle repair shop on Jan. 27, 1989, when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street.</content>
      <tokens>
        <token id="1" string="Guzman-Flores" lemma="Guzman-Flores" stem="guzman-flor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="motorcycle" lemma="motorcycle" stem="motorcycl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="repair" lemma="repair" stem="repair" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="shop" lemma="shop" stem="shop" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="27" lemma="27" stem="27" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="boss" lemma="boss" stem="boss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="noise" lemma="noise" stem="nois" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="alley" lemma="alley" stem="allei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="shop" lemma="shop" stem="shop" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="1500" lemma="1500" stem="1500" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="35" string="block" lemma="block" stem="block" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="Pine" lemma="Pine" stem="pine" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="39" string="Street" lemma="Street" stem="street" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Guzman-Flores)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG working) (PP (IN in) (NP (DT a) (NN motorcycle) (NN repair) (NN shop))) (PP (IN on) (NP (NP (NNP Jan.) (CD 27) (, ,) (CD 1989)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ his) (NN boss)) (VP (VBD asked) (S (NP (PRP him)) (VP (TO to) (VP (VB investigate) (NP (DT a) (NN noise)) (PP (IN in) (NP (NP (DT the) (NN alley)) (PP (IN behind) (NP (NP (DT the) (NN shop)) (PP (IN in) (NP (NP (DT the) (CD 1500) (NN block)) (PP (IN of) (NP (NNP South) (NNP Pine) (NNP Street)))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="2" string="South Pine Street" type="NP">
          <tokens>
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="3" string="the alley behind the shop in the 1500 block of South Pine Street" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="4" string="the shop in the 1500 block of South Pine Street" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="5" string="a noise" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="noise" />
          </tokens>
        </chunking>
        <chunking id="6" string="working in a motorcycle repair shop on Jan. 27 , 1989 , when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="5" string="working" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="motorcycle" />
            <token id="9" string="repair" />
            <token id="10" string="shop" />
            <token id="11" string="on" />
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
            <token id="16" string="," />
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="7" string="the shop" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="shop" />
          </tokens>
        </chunking>
        <chunking id="8" string="a motorcycle repair shop" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="motorcycle" />
            <token id="9" string="repair" />
            <token id="10" string="shop" />
          </tokens>
        </chunking>
        <chunking id="9" string="when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="SBAR">
          <tokens>
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 1500 block" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
          </tokens>
        </chunking>
        <chunking id="11" string="him" type="NP">
          <tokens>
            <token id="21" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="his boss" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="boss" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 1500 block of South Pine Street" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="14" string="said he was working in a motorcycle repair shop on Jan. 27 , 1989 , when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="was" />
            <token id="5" string="working" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="motorcycle" />
            <token id="9" string="repair" />
            <token id="10" string="shop" />
            <token id="11" string="on" />
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
            <token id="16" string="," />
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="15" string="he was working in a motorcycle repair shop on Jan. 27 , 1989 , when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="was" />
            <token id="5" string="working" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="motorcycle" />
            <token id="9" string="repair" />
            <token id="10" string="shop" />
            <token id="11" string="on" />
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
            <token id="16" string="," />
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="16" string="when" type="WHADVP">
          <tokens>
            <token id="17" string="when" />
          </tokens>
        </chunking>
        <chunking id="17" string="the alley" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="alley" />
          </tokens>
        </chunking>
        <chunking id="18" string="was working in a motorcycle repair shop on Jan. 27 , 1989 , when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="working" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="motorcycle" />
            <token id="9" string="repair" />
            <token id="10" string="shop" />
            <token id="11" string="on" />
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
            <token id="16" string="," />
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jan. 27 , 1989 , when his boss asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="NP">
          <tokens>
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
            <token id="16" string="," />
            <token id="17" string="when" />
            <token id="18" string="his" />
            <token id="19" string="boss" />
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="20" string="asked him to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="20" string="asked" />
            <token id="21" string="him" />
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="21" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="22" string="Jan. 27 , 1989" type="NP">
          <tokens>
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
          </tokens>
        </chunking>
        <chunking id="23" string="to investigate a noise in the alley behind the shop in the 1500 block of South Pine Street" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="investigate" />
            <token id="24" string="a" />
            <token id="25" string="noise" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="alley" />
            <token id="29" string="behind" />
            <token id="30" string="the" />
            <token id="31" string="shop" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="1500" />
            <token id="35" string="block" />
            <token id="36" string="of" />
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </chunking>
        <chunking id="24" string="Guzman-Flores" type="NP">
          <tokens>
            <token id="1" string="Guzman-Flores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Guzman-Flores</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">working</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">working</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">shop</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">shop</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">shop</governor>
          <dependent id="8">motorcycle</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">shop</governor>
          <dependent id="9">repair</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">working</governor>
          <dependent id="10">shop</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Jan.</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">working</governor>
          <dependent id="12">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Jan.</governor>
          <dependent id="13">27</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Jan.</governor>
          <dependent id="15">1989</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">asked</governor>
          <dependent id="17">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">boss</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">asked</governor>
          <dependent id="19">boss</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Jan.</governor>
          <dependent id="20">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">asked</governor>
          <dependent id="21">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">investigate</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">asked</governor>
          <dependent id="23">investigate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">noise</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">investigate</governor>
          <dependent id="25">noise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">alley</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">alley</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">investigate</governor>
          <dependent id="28">alley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">shop</governor>
          <dependent id="29">behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">shop</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">alley</governor>
          <dependent id="31">shop</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">block</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">block</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">block</governor>
          <dependent id="34">1500</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">shop</governor>
          <dependent id="35">block</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Street</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Street</governor>
          <dependent id="37">South</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Street</governor>
          <dependent id="38">Pine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">block</governor>
          <dependent id="39">Street</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="South Pine Street" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="South" />
            <token id="38" string="Pine" />
            <token id="39" string="Street" />
          </tokens>
        </entity>
        <entity id="2" string="1500" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="1500" />
          </tokens>
        </entity>
        <entity id="3" string="Jan. 27 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Jan." />
            <token id="13" string="27" />
            <token id="14" string="," />
            <token id="15" string="1989" />
          </tokens>
        </entity>
        <entity id="4" string="Guzman-Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Guzman-Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>In a suit filed against the city Nov. 14, 1989, the Police Department and officers Jana Younger, Fred Sedillos and James Struck, Guzman-Flores contends that he was grabbed from behind by Younger while in the alley.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Nov." lemma="Nov." stem="nov." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="15" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Jana" lemma="Jana" stem="jana" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Younger" lemma="Younger" stem="younger" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Fred" lemma="Fred" stem="fred" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Sedillos" lemma="Sedillos" stem="sedillo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="Struck" lemma="Struck" stem="struck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Guzman-Flores" lemma="Guzman-Flores" stem="guzman-flor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="contends" lemma="contend" stem="contend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="grabbed" lemma="grab" stem="grab" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="behind" lemma="behind" stem="behind" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Younger" lemma="Younger" stem="younger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="alley" lemma="alley" stem="allei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (NN suit)) (VP (VBN filed) (PP (IN against) (NP (NP (NP (DT the) (NN city)) (NP-TMP (NNP Nov.) (CD 14) (, ,) (CD 1989))) (, ,) (NP (DT the) (NNP Police) (NNP Department) (CC and) (NNS officers) (NNP Jana) (NNP Younger) (, ,) (NNP Fred) (NNP Sedillos) (CC and) (NNP James) (NNP Struck))))))) (, ,) (NP (NNP Guzman-Flores)) (VP (VBZ contends) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (VP (VBN grabbed) (PP (IN from) (ADVP (RB behind))) (PP (IN by) (NP (NNP Younger))) (PP (IN while) (PP (IN in) (NP (DT the) (NN alley))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a suit filed against the city Nov. 14 , 1989 , the Police Department and officers Jana Younger , Fred Sedillos and James Struck" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="suit" />
            <token id="4" string="filed" />
            <token id="5" string="against" />
            <token id="6" string="the" />
            <token id="7" string="city" />
            <token id="8" string="Nov." />
            <token id="9" string="14" />
            <token id="10" string="," />
            <token id="11" string="1989" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
            <token id="16" string="and" />
            <token id="17" string="officers" />
            <token id="18" string="Jana" />
            <token id="19" string="Younger" />
            <token id="20" string="," />
            <token id="21" string="Fred" />
            <token id="22" string="Sedillos" />
            <token id="23" string="and" />
            <token id="24" string="James" />
            <token id="25" string="Struck" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="contends that he was grabbed from behind by Younger while in the alley" type="VP">
          <tokens>
            <token id="28" string="contends" />
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="grabbed" />
            <token id="33" string="from" />
            <token id="34" string="behind" />
            <token id="35" string="by" />
            <token id="36" string="Younger" />
            <token id="37" string="while" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="alley" />
          </tokens>
        </chunking>
        <chunking id="4" string="grabbed from behind by Younger while in the alley" type="VP">
          <tokens>
            <token id="32" string="grabbed" />
            <token id="33" string="from" />
            <token id="34" string="behind" />
            <token id="35" string="by" />
            <token id="36" string="Younger" />
            <token id="37" string="while" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="alley" />
          </tokens>
        </chunking>
        <chunking id="5" string="that he was grabbed from behind by Younger while in the alley" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="grabbed" />
            <token id="33" string="from" />
            <token id="34" string="behind" />
            <token id="35" string="by" />
            <token id="36" string="Younger" />
            <token id="37" string="while" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="alley" />
          </tokens>
        </chunking>
        <chunking id="6" string="filed against the city Nov. 14 , 1989 , the Police Department and officers Jana Younger , Fred Sedillos and James Struck" type="VP">
          <tokens>
            <token id="4" string="filed" />
            <token id="5" string="against" />
            <token id="6" string="the" />
            <token id="7" string="city" />
            <token id="8" string="Nov." />
            <token id="9" string="14" />
            <token id="10" string="," />
            <token id="11" string="1989" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
            <token id="16" string="and" />
            <token id="17" string="officers" />
            <token id="18" string="Jana" />
            <token id="19" string="Younger" />
            <token id="20" string="," />
            <token id="21" string="Fred" />
            <token id="22" string="Sedillos" />
            <token id="23" string="and" />
            <token id="24" string="James" />
            <token id="25" string="Struck" />
          </tokens>
        </chunking>
        <chunking id="7" string="the city Nov. 14 , 1989 , the Police Department and officers Jana Younger , Fred Sedillos and James Struck" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="city" />
            <token id="8" string="Nov." />
            <token id="9" string="14" />
            <token id="10" string="," />
            <token id="11" string="1989" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
            <token id="16" string="and" />
            <token id="17" string="officers" />
            <token id="18" string="Jana" />
            <token id="19" string="Younger" />
            <token id="20" string="," />
            <token id="21" string="Fred" />
            <token id="22" string="Sedillos" />
            <token id="23" string="and" />
            <token id="24" string="James" />
            <token id="25" string="Struck" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Police Department and officers Jana Younger , Fred Sedillos and James Struck" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Police" />
            <token id="15" string="Department" />
            <token id="16" string="and" />
            <token id="17" string="officers" />
            <token id="18" string="Jana" />
            <token id="19" string="Younger" />
            <token id="20" string="," />
            <token id="21" string="Fred" />
            <token id="22" string="Sedillos" />
            <token id="23" string="and" />
            <token id="24" string="James" />
            <token id="25" string="Struck" />
          </tokens>
        </chunking>
        <chunking id="9" string="was grabbed from behind by Younger while in the alley" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="grabbed" />
            <token id="33" string="from" />
            <token id="34" string="behind" />
            <token id="35" string="by" />
            <token id="36" string="Younger" />
            <token id="37" string="while" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="alley" />
          </tokens>
        </chunking>
        <chunking id="10" string="the city Nov. 14 , 1989" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="city" />
            <token id="8" string="Nov." />
            <token id="9" string="14" />
            <token id="10" string="," />
            <token id="11" string="1989" />
          </tokens>
        </chunking>
        <chunking id="11" string="the alley" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="alley" />
          </tokens>
        </chunking>
        <chunking id="12" string="a suit" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="suit" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="30" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="Younger" type="NP">
          <tokens>
            <token id="36" string="Younger" />
          </tokens>
        </chunking>
        <chunking id="15" string="Guzman-Flores" type="NP">
          <tokens>
            <token id="27" string="Guzman-Flores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">suit</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">suit</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">contends</governor>
          <dependent id="3">suit</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">suit</governor>
          <dependent id="4">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">city</governor>
          <dependent id="5">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">city</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">filed</governor>
          <dependent id="7">city</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">city</governor>
          <dependent id="8">Nov.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">Nov.</governor>
          <dependent id="9">14</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">Nov.</governor>
          <dependent id="11">1989</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Department</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Department</governor>
          <dependent id="14">Police</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">city</governor>
          <dependent id="15">Department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Department</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Sedillos</governor>
          <dependent id="17">officers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Sedillos</governor>
          <dependent id="18">Jana</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Sedillos</governor>
          <dependent id="19">Younger</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Sedillos</governor>
          <dependent id="21">Fred</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Department</governor>
          <dependent id="22">Sedillos</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Department</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Struck</governor>
          <dependent id="24">James</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Department</governor>
          <dependent id="25">Struck</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">contends</governor>
          <dependent id="27">Guzman-Flores</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">contends</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">grabbed</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">grabbed</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">grabbed</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">contends</governor>
          <dependent id="32">grabbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">behind</governor>
          <dependent id="33">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">grabbed</governor>
          <dependent id="34">behind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Younger</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">grabbed</governor>
          <dependent id="36">Younger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">alley</governor>
          <dependent id="37">while</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">alley</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">alley</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">grabbed</governor>
          <dependent id="40">alley</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jana Younger" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Jana" />
            <token id="19" string="Younger" />
          </tokens>
        </entity>
        <entity id="2" string="Fred Sedillos" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Fred" />
            <token id="22" string="Sedillos" />
          </tokens>
        </entity>
        <entity id="3" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Police" />
            <token id="15" string="Department" />
          </tokens>
        </entity>
        <entity id="4" string="James Struck" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="James" />
            <token id="25" string="Struck" />
          </tokens>
        </entity>
        <entity id="5" string="Nov. 14 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Nov." />
            <token id="9" string="14" />
            <token id="10" string="," />
            <token id="11" string="1989" />
          </tokens>
        </entity>
        <entity id="6" string="Guzman-Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Guzman-Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>The officer poked him with a baton and questioned him about a car parked nearby, Guzman-Flores said in the suit.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="poked" lemma="poke" stem="poke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="baton" lemma="baton" stem="baton" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="questioned" lemma="question" stem="question" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="parked" lemma="park" stem="park" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="nearby" lemma="nearby" stem="nearbi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Guzman-Flores" lemma="Guzman-Flores" stem="guzman-flor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN officer)) (VP (VP (VBD poked) (NP (PRP him)) (PP (IN with) (NP (DT a) (NN baton)))) (CC and) (VP (VBD questioned) (NP (PRP him)) (PP (IN about) (NP (NP (DT a) (NN car)) (VP (VBD parked) (ADVP (RB nearby)))))))) (, ,) (NP (NNP Guzman-Flores)) (VP (VBD said) (PP (IN in) (NP (DT the) (NN suit)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The officer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="a car parked nearby" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="parked" />
            <token id="15" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="3" string="a car" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="4" string="poked him with a baton and questioned him about a car parked nearby" type="VP">
          <tokens>
            <token id="3" string="poked" />
            <token id="4" string="him" />
            <token id="5" string="with" />
            <token id="6" string="a" />
            <token id="7" string="baton" />
            <token id="8" string="and" />
            <token id="9" string="questioned" />
            <token id="10" string="him" />
            <token id="11" string="about" />
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="parked" />
            <token id="15" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="5" string="questioned him about a car parked nearby" type="VP">
          <tokens>
            <token id="9" string="questioned" />
            <token id="10" string="him" />
            <token id="11" string="about" />
            <token id="12" string="a" />
            <token id="13" string="car" />
            <token id="14" string="parked" />
            <token id="15" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="6" string="the suit" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="suit" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="poked him with a baton" type="VP">
          <tokens>
            <token id="3" string="poked" />
            <token id="4" string="him" />
            <token id="5" string="with" />
            <token id="6" string="a" />
            <token id="7" string="baton" />
          </tokens>
        </chunking>
        <chunking id="9" string="a baton" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="baton" />
          </tokens>
        </chunking>
        <chunking id="10" string="parked nearby" type="VP">
          <tokens>
            <token id="14" string="parked" />
            <token id="15" string="nearby" />
          </tokens>
        </chunking>
        <chunking id="11" string="said in the suit" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="suit" />
          </tokens>
        </chunking>
        <chunking id="12" string="Guzman-Flores" type="NP">
          <tokens>
            <token id="17" string="Guzman-Flores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">officer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">poked</governor>
          <dependent id="2">officer</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="3">poked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">poked</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">baton</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">baton</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">poked</governor>
          <dependent id="7">baton</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">poked</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">poked</governor>
          <dependent id="9">questioned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">questioned</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">car</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">car</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">questioned</governor>
          <dependent id="13">car</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">car</governor>
          <dependent id="14">parked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">parked</governor>
          <dependent id="15">nearby</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Guzman-Flores</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">suit</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">suit</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="21">suit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Guzman-Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Guzman-Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>The Police Department declined to release Flores&amp;apost; arrest report because, police officials said, it contains his criminal history.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="release" lemma="release" stem="releas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="contains" lemma="contain" stem="contain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP Police) (NNP Department)) (VP (VBD declined) (S (VP (TO to) (VP (VB release) (NP (NP (NNP Flores) (POS ')) (NN arrest) (NN report)) (SBAR (IN because) (, ,) (S (NP (NN police) (NNS officials)) (VP (VBD said))))))))) (, ,) (NP (PRP it)) (VP (VBZ contains) (NP (PRP$ his) (JJ criminal) (NN history))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="declined to release Flores ' arrest report because , police officials said" type="VP">
          <tokens>
            <token id="4" string="declined" />
            <token id="5" string="to" />
            <token id="6" string="release" />
            <token id="7" string="Flores" />
            <token id="8" string="'" />
            <token id="9" string="arrest" />
            <token id="10" string="report" />
            <token id="11" string="because" />
            <token id="12" string="," />
            <token id="13" string="police" />
            <token id="14" string="officials" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="2" string="contains his criminal history" type="VP">
          <tokens>
            <token id="18" string="contains" />
            <token id="19" string="his" />
            <token id="20" string="criminal" />
            <token id="21" string="history" />
          </tokens>
        </chunking>
        <chunking id="3" string="Flores ' arrest report" type="NP">
          <tokens>
            <token id="7" string="Flores" />
            <token id="8" string="'" />
            <token id="9" string="arrest" />
            <token id="10" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="to release Flores ' arrest report because , police officials said" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="release" />
            <token id="7" string="Flores" />
            <token id="8" string="'" />
            <token id="9" string="arrest" />
            <token id="10" string="report" />
            <token id="11" string="because" />
            <token id="12" string="," />
            <token id="13" string="police" />
            <token id="14" string="officials" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="because , police officials said" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="," />
            <token id="13" string="police" />
            <token id="14" string="officials" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="police officials" type="NP">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="officials" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="his criminal history" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="criminal" />
            <token id="21" string="history" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Police Department" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Police" />
            <token id="3" string="Department" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="Flores '" type="NP">
          <tokens>
            <token id="7" string="Flores" />
            <token id="8" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="release Flores ' arrest report because , police officials said" type="VP">
          <tokens>
            <token id="6" string="release" />
            <token id="7" string="Flores" />
            <token id="8" string="'" />
            <token id="9" string="arrest" />
            <token id="10" string="report" />
            <token id="11" string="because" />
            <token id="12" string="," />
            <token id="13" string="police" />
            <token id="14" string="officials" />
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Department</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Department</governor>
          <dependent id="2">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">declined</governor>
          <dependent id="3">Department</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">contains</governor>
          <dependent id="4">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">release</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">declined</governor>
          <dependent id="6">release</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">report</governor>
          <dependent id="7">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Flores</governor>
          <dependent id="8">'</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">report</governor>
          <dependent id="9">arrest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">release</governor>
          <dependent id="10">report</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">said</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officials</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">officials</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">release</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">contains</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">contains</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">history</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">history</governor>
          <dependent id="20">criminal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">contains</governor>
          <dependent id="21">history</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Police" />
            <token id="3" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>But Flores&amp;apost; lawyer, Sherrie L. McCracken, said the report states that officers were at the shop responding to a complaint of a man with a gun.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Sherrie" lemma="Sherrie" stem="sherri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="L." lemma="L." stem="l." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="McCracken" lemma="McCracken" stem="mccracken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="states" lemma="state" stem="state" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="shop" lemma="shop" stem="shop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="responding" lemma="respond" stem="respond" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="gun" lemma="gun" stem="gun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NP (NNP Flores) (POS ')) (NN lawyer)) (, ,) (NP (NNP Sherrie) (NNP L.) (NNP McCracken)) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (NN report)) (VP (VBZ states) (SBAR (IN that) (S (NP (NNS officers)) (VP (VBD were) (ADVP (IN at) (NP (DT the) (NN shop))) (VP (VBG responding) (PP (TO to) (NP (NP (DT a) (NN complaint)) (PP (IN of) (NP (NP (DT a) (NN man)) (PP (IN with) (NP (DT a) (NN gun))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were at the shop responding to a complaint of a man with a gun" type="VP">
          <tokens>
            <token id="16" string="were" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="shop" />
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="2" string="the report states that officers were at the shop responding to a complaint of a man with a gun" type="SBAR">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="report" />
            <token id="13" string="states" />
            <token id="14" string="that" />
            <token id="15" string="officers" />
            <token id="16" string="were" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="shop" />
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="3" string="the shop" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="shop" />
          </tokens>
        </chunking>
        <chunking id="4" string="a gun" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="5" string="Flores ' lawyer , Sherrie L. McCracken ," type="NP">
          <tokens>
            <token id="2" string="Flores" />
            <token id="3" string="'" />
            <token id="4" string="lawyer" />
            <token id="5" string="," />
            <token id="6" string="Sherrie" />
            <token id="7" string="L." />
            <token id="8" string="McCracken" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="responding to a complaint of a man with a gun" type="VP">
          <tokens>
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="7" string="Flores '" type="NP">
          <tokens>
            <token id="2" string="Flores" />
            <token id="3" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="a complaint of a man with a gun" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="9" string="a man with a gun" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="10" string="Flores ' lawyer" type="NP">
          <tokens>
            <token id="2" string="Flores" />
            <token id="3" string="'" />
            <token id="4" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="11" string="that officers were at the shop responding to a complaint of a man with a gun" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="officers" />
            <token id="16" string="were" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="shop" />
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="12" string="Sherrie L. McCracken" type="NP">
          <tokens>
            <token id="6" string="Sherrie" />
            <token id="7" string="L." />
            <token id="8" string="McCracken" />
          </tokens>
        </chunking>
        <chunking id="13" string="said the report states that officers were at the shop responding to a complaint of a man with a gun" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="the" />
            <token id="12" string="report" />
            <token id="13" string="states" />
            <token id="14" string="that" />
            <token id="15" string="officers" />
            <token id="16" string="were" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="shop" />
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="14" string="states that officers were at the shop responding to a complaint of a man with a gun" type="VP">
          <tokens>
            <token id="13" string="states" />
            <token id="14" string="that" />
            <token id="15" string="officers" />
            <token id="16" string="were" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="shop" />
            <token id="20" string="responding" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="complaint" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="man" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="gun" />
          </tokens>
        </chunking>
        <chunking id="15" string="the report" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="report" />
          </tokens>
        </chunking>
        <chunking id="16" string="a man" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="man" />
          </tokens>
        </chunking>
        <chunking id="17" string="officers" type="NP">
          <tokens>
            <token id="15" string="officers" />
          </tokens>
        </chunking>
        <chunking id="18" string="a complaint" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="complaint" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">lawyer</governor>
          <dependent id="2">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Flores</governor>
          <dependent id="3">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="4">lawyer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">McCracken</governor>
          <dependent id="6">Sherrie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">McCracken</governor>
          <dependent id="7">L.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">lawyer</governor>
          <dependent id="8">McCracken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">report</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">states</governor>
          <dependent id="12">report</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="13">states</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">responding</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">responding</governor>
          <dependent id="15">officers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">responding</governor>
          <dependent id="16">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">shop</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">shop</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">responding</governor>
          <dependent id="19">shop</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">states</governor>
          <dependent id="20">responding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">complaint</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">complaint</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">responding</governor>
          <dependent id="23">complaint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">man</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">man</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">complaint</governor>
          <dependent id="26">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">gun</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">gun</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">man</governor>
          <dependent id="29">gun</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sherrie L. McCracken" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Sherrie" />
            <token id="7" string="L." />
            <token id="8" string="McCracken" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>McCracken said the officers continued to question Flores in English, but Flores -- a recent immigrant from Mexico who speaks only Spanish -- could not respond.</content>
      <tokens>
        <token id="1" string="McCracken" lemma="McCracken" stem="mccracken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="question" lemma="question" stem="question" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="immigrant" lemma="immigrant" stem="immigr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="speaks" lemma="speak" stem="speak" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Spanish" lemma="spanish" stem="spanish" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="24" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="respond" lemma="respond" stem="respond" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP McCracken)) (VP (VBD said) (SBAR (S (NP (DT the) (NNS officers)) (VP (VBD continued) (S (VP (TO to) (VP (VB question) (NP (NP (NNP Flores)) (PP (IN in) (NP (NNP English)))))))))))) (, ,) (CC but) (S (NP (NP (NNP Flores)) (PRN (: --) (NP (NP (DT a) (JJ recent) (JJ immigrant)) (PP (IN from) (NP (NP (NNP Mexico)) (SBAR (WHNP (WP who)) (S (VP (VBZ speaks) (ADJP (RB only) (JJ Spanish)))))))) (: --))) (VP (MD could) (RB not) (VP (VB respond)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Flores -- a recent immigrant from Mexico who speaks only Spanish --" type="NP">
          <tokens>
            <token id="13" string="Flores" />
            <token id="14" string="--" />
            <token id="15" string="a" />
            <token id="16" string="recent" />
            <token id="17" string="immigrant" />
            <token id="18" string="from" />
            <token id="19" string="Mexico" />
            <token id="20" string="who" />
            <token id="21" string="speaks" />
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
            <token id="24" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="a recent immigrant from Mexico who speaks only Spanish" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="recent" />
            <token id="17" string="immigrant" />
            <token id="18" string="from" />
            <token id="19" string="Mexico" />
            <token id="20" string="who" />
            <token id="21" string="speaks" />
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
          </tokens>
        </chunking>
        <chunking id="3" string="said the officers continued to question Flores in English" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="officers" />
            <token id="5" string="continued" />
            <token id="6" string="to" />
            <token id="7" string="question" />
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="4" string="speaks only Spanish" type="VP">
          <tokens>
            <token id="21" string="speaks" />
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
          </tokens>
        </chunking>
        <chunking id="5" string="only Spanish" type="ADJP">
          <tokens>
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
          </tokens>
        </chunking>
        <chunking id="6" string="English" type="NP">
          <tokens>
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mexico who speaks only Spanish" type="NP">
          <tokens>
            <token id="19" string="Mexico" />
            <token id="20" string="who" />
            <token id="21" string="speaks" />
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
          </tokens>
        </chunking>
        <chunking id="8" string="Flores" type="NP">
          <tokens>
            <token id="8" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="9" string="could not respond" type="VP">
          <tokens>
            <token id="25" string="could" />
            <token id="26" string="not" />
            <token id="27" string="respond" />
          </tokens>
        </chunking>
        <chunking id="10" string="McCracken" type="NP">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </chunking>
        <chunking id="11" string="the officers continued to question Flores in English" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officers" />
            <token id="5" string="continued" />
            <token id="6" string="to" />
            <token id="7" string="question" />
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mexico" type="NP">
          <tokens>
            <token id="19" string="Mexico" />
          </tokens>
        </chunking>
        <chunking id="13" string="the officers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officers" />
          </tokens>
        </chunking>
        <chunking id="14" string="continued to question Flores in English" type="VP">
          <tokens>
            <token id="5" string="continued" />
            <token id="6" string="to" />
            <token id="7" string="question" />
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="15" string="Flores in English" type="NP">
          <tokens>
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="16" string="question Flores in English" type="VP">
          <tokens>
            <token id="7" string="question" />
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
        <chunking id="17" string="a recent immigrant" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="recent" />
            <token id="17" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="18" string="who speaks only Spanish" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="speaks" />
            <token id="22" string="only" />
            <token id="23" string="Spanish" />
          </tokens>
        </chunking>
        <chunking id="19" string="respond" type="VP">
          <tokens>
            <token id="27" string="respond" />
          </tokens>
        </chunking>
        <chunking id="20" string="to question Flores in English" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="question" />
            <token id="8" string="Flores" />
            <token id="9" string="in" />
            <token id="10" string="English" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">McCracken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">officers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">continued</governor>
          <dependent id="4">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">question</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">continued</governor>
          <dependent id="7">question</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">question</governor>
          <dependent id="8">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">English</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Flores</governor>
          <dependent id="10">English</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">respond</governor>
          <dependent id="13">Flores</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">immigrant</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">immigrant</governor>
          <dependent id="16">recent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Flores</governor>
          <dependent id="17">immigrant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Mexico</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">immigrant</governor>
          <dependent id="19">Mexico</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">speaks</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">Mexico</governor>
          <dependent id="21">speaks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">Spanish</governor>
          <dependent id="22">only</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">speaks</governor>
          <dependent id="23">Spanish</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">respond</governor>
          <dependent id="25">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">respond</governor>
          <dependent id="26">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="27">respond</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McCracken" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </entity>
        <entity id="2" string="Mexico" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Mexico" />
          </tokens>
        </entity>
        <entity id="3" string="Spanish" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="23" string="Spanish" />
          </tokens>
        </entity>
        <entity id="4" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="English" />
          </tokens>
        </entity>
        <entity id="5" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Flores was handcuffed and shoved to the ground, causing Sedillos to trip and fall on him, according to the suit.</content>
      <tokens>
        <token id="1" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="handcuffed" lemma="handcuff" stem="handcuf" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="shoved" lemma="shove" stem="shove" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Sedillos" lemma="Sedillos" stem="sedillo" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="fall" lemma="fall" stem="fall" pos="VB" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Flores)) (VP (VBD was) (UCP (ADJP (VBN handcuffed)) (CC and) (VP (VP (VBN shoved) (PP (TO to) (NP (DT the) (NN ground))) (, ,) (S (VP (VBG causing) (NP (NNP Sedillos)) (PP (TO to) (NP (NN trip)))))) (CC and) (VP (VB fall) (PP (IN on) (NP (PRP him)))))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (NN suit))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="trip" type="NP">
          <tokens>
            <token id="13" string="trip" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ground" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="ground" />
          </tokens>
        </chunking>
        <chunking id="3" string="causing Sedillos to trip" type="VP">
          <tokens>
            <token id="10" string="causing" />
            <token id="11" string="Sedillos" />
            <token id="12" string="to" />
            <token id="13" string="trip" />
          </tokens>
        </chunking>
        <chunking id="4" string="the suit" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="suit" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="was handcuffed and shoved to the ground , causing Sedillos to trip and fall on him , according to the suit" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="handcuffed" />
            <token id="4" string="and" />
            <token id="5" string="shoved" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="ground" />
            <token id="9" string="," />
            <token id="10" string="causing" />
            <token id="11" string="Sedillos" />
            <token id="12" string="to" />
            <token id="13" string="trip" />
            <token id="14" string="and" />
            <token id="15" string="fall" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="," />
            <token id="19" string="according" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="suit" />
          </tokens>
        </chunking>
        <chunking id="7" string="handcuffed" type="ADJP">
          <tokens>
            <token id="3" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="8" string="shoved to the ground , causing Sedillos to trip" type="VP">
          <tokens>
            <token id="5" string="shoved" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="ground" />
            <token id="9" string="," />
            <token id="10" string="causing" />
            <token id="11" string="Sedillos" />
            <token id="12" string="to" />
            <token id="13" string="trip" />
          </tokens>
        </chunking>
        <chunking id="9" string="shoved to the ground , causing Sedillos to trip and fall on him" type="VP">
          <tokens>
            <token id="5" string="shoved" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="ground" />
            <token id="9" string="," />
            <token id="10" string="causing" />
            <token id="11" string="Sedillos" />
            <token id="12" string="to" />
            <token id="13" string="trip" />
            <token id="14" string="and" />
            <token id="15" string="fall" />
            <token id="16" string="on" />
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="Flores" type="NP">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="11" string="Sedillos" type="NP">
          <tokens>
            <token id="11" string="Sedillos" />
          </tokens>
        </chunking>
        <chunking id="12" string="fall on him" type="VP">
          <tokens>
            <token id="15" string="fall" />
            <token id="16" string="on" />
            <token id="17" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">handcuffed</governor>
          <dependent id="1">Flores</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">handcuffed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">handcuffed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">handcuffed</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">handcuffed</governor>
          <dependent id="5">shoved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">ground</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">ground</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">shoved</governor>
          <dependent id="8">ground</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">shoved</governor>
          <dependent id="10">causing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">causing</governor>
          <dependent id="11">Sedillos</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">trip</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">causing</governor>
          <dependent id="13">trip</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">shoved</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">shoved</governor>
          <dependent id="15">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">him</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">fall</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">suit</governor>
          <dependent id="19">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="19">according</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">suit</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">handcuffed</governor>
          <dependent id="22">suit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fall" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="fall" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>Sedillos got up and punched and kicked Flores several times while Younger held Flores in a &amp;quot;choke-hold,&amp;quot; the suit alleges.</content>
      <tokens>
        <token id="1" string="Sedillos" lemma="Sedillos" stem="sedillo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="punched" lemma="punch" stem="punch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="kicked" lemma="kick" stem="kick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Younger" lemma="Younger" stem="younger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="choke-hold" lemma="choke-hold" stem="choke-hold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Sedillos)) (VP (VP (VBD got) (ADVP (RB up))) (CC and) (VP (VBD punched) (CC and) (VBD kicked) (NP (NP (NNP Flores) (JJ several) (NNS times)) (SBAR (IN while) (S (NP (NNP Younger)) (VP (VBD held) (NP (NP (NNP Flores)) (PP (IN in) (NP (DT a) (`` ``) (NN choke-hold))))))))))) (, ,) ('' '') (NP (DT the) (NN suit)) (VP (VBZ alleges)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Flores several times while Younger held Flores in a `` choke-hold" type="NP">
          <tokens>
            <token id="8" string="Flores" />
            <token id="9" string="several" />
            <token id="10" string="times" />
            <token id="11" string="while" />
            <token id="12" string="Younger" />
            <token id="13" string="held" />
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` choke-hold" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="3" string="held Flores in a `` choke-hold" type="VP">
          <tokens>
            <token id="13" string="held" />
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="4" string="punched and kicked Flores several times while Younger held Flores in a `` choke-hold" type="VP">
          <tokens>
            <token id="5" string="punched" />
            <token id="6" string="and" />
            <token id="7" string="kicked" />
            <token id="8" string="Flores" />
            <token id="9" string="several" />
            <token id="10" string="times" />
            <token id="11" string="while" />
            <token id="12" string="Younger" />
            <token id="13" string="held" />
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="5" string="Flores in a `` choke-hold" type="NP">
          <tokens>
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sedillos" type="NP">
          <tokens>
            <token id="1" string="Sedillos" />
          </tokens>
        </chunking>
        <chunking id="7" string="Flores" type="NP">
          <tokens>
            <token id="14" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="8" string="while Younger held Flores in a `` choke-hold" type="SBAR">
          <tokens>
            <token id="11" string="while" />
            <token id="12" string="Younger" />
            <token id="13" string="held" />
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="9" string="Flores several times" type="NP">
          <tokens>
            <token id="8" string="Flores" />
            <token id="9" string="several" />
            <token id="10" string="times" />
          </tokens>
        </chunking>
        <chunking id="10" string="the suit" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="suit" />
          </tokens>
        </chunking>
        <chunking id="11" string="alleges" type="VP">
          <tokens>
            <token id="23" string="alleges" />
          </tokens>
        </chunking>
        <chunking id="12" string="got up" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="up" />
          </tokens>
        </chunking>
        <chunking id="13" string="got up and punched and kicked Flores several times while Younger held Flores in a `` choke-hold" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="up" />
            <token id="4" string="and" />
            <token id="5" string="punched" />
            <token id="6" string="and" />
            <token id="7" string="kicked" />
            <token id="8" string="Flores" />
            <token id="9" string="several" />
            <token id="10" string="times" />
            <token id="11" string="while" />
            <token id="12" string="Younger" />
            <token id="13" string="held" />
            <token id="14" string="Flores" />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="14" string="Younger" type="NP">
          <tokens>
            <token id="12" string="Younger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">got</governor>
          <dependent id="1">Sedillos</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">alleges</governor>
          <dependent id="2">got</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">got</governor>
          <dependent id="3">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">got</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">got</governor>
          <dependent id="5">punched</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">punched</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">punched</governor>
          <dependent id="7">kicked</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">times</governor>
          <dependent id="8">Flores</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">times</governor>
          <dependent id="9">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">punched</governor>
          <dependent id="10">times</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">held</governor>
          <dependent id="11">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">held</governor>
          <dependent id="12">Younger</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">times</governor>
          <dependent id="13">held</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">held</governor>
          <dependent id="14">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">choke-hold</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">choke-hold</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Flores</governor>
          <dependent id="18">choke-hold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">suit</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">alleges</governor>
          <dependent id="22">suit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">alleges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sedillos" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Sedillos" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>Flores was arrested on suspicion of resisting arrest and obstructing an officer.</content>
      <tokens>
        <token id="1" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="resisting" lemma="resist" stem="resist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="obstructing" lemma="obstruct" stem="obstruct" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Flores)) (VP (VBD was) (VP (VBN arrested) (PP (IN on) (NP (NP (NN suspicion)) (PP (IN of) (S (VP (VP (VBG resisting) (NP (NN arrest))) (CC and) (VP (VBG obstructing) (NP (DT an) (NN officer)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="resisting arrest" type="VP">
          <tokens>
            <token id="7" string="resisting" />
            <token id="8" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="2" string="was arrested on suspicion of resisting arrest and obstructing an officer" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="arrested" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="resisting" />
            <token id="8" string="arrest" />
            <token id="9" string="and" />
            <token id="10" string="obstructing" />
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="3" string="resisting arrest and obstructing an officer" type="VP">
          <tokens>
            <token id="7" string="resisting" />
            <token id="8" string="arrest" />
            <token id="9" string="and" />
            <token id="10" string="obstructing" />
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="4" string="an officer" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="arrested on suspicion of resisting arrest and obstructing an officer" type="VP">
          <tokens>
            <token id="3" string="arrested" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="resisting" />
            <token id="8" string="arrest" />
            <token id="9" string="and" />
            <token id="10" string="obstructing" />
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="arrest" type="NP">
          <tokens>
            <token id="8" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="7" string="suspicion of resisting arrest and obstructing an officer" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="resisting" />
            <token id="8" string="arrest" />
            <token id="9" string="and" />
            <token id="10" string="obstructing" />
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="suspicion" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="9" string="obstructing an officer" type="VP">
          <tokens>
            <token id="10" string="obstructing" />
            <token id="11" string="an" />
            <token id="12" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="Flores" type="NP">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">arrested</governor>
          <dependent id="1">Flores</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">arrested</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">suspicion</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">arrested</governor>
          <dependent id="5">suspicion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">resisting</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">suspicion</governor>
          <dependent id="7">resisting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">resisting</governor>
          <dependent id="8">arrest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">resisting</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">resisting</governor>
          <dependent id="10">obstructing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">officer</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">obstructing</governor>
          <dependent id="12">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>The district attorney&amp;apost;s office decided to prosecute Flores but later dismissed all charges during Flores&amp;apost; trial because police failed to turn over a recording of a dispatcher&amp;apost;s call requesting that officers investigate the incident at the motorcycle shop, McCracken said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="dismissed" lemma="dismiss" stem="dismiss" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="17" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="recording" lemma="recording" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="dispatcher" lemma="dispatcher" stem="dispatch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="requesting" lemma="request" stem="request" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="investigate" lemma="investigate" stem="investig" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="motorcycle" lemma="motorcycle" stem="motorcycl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="shop" lemma="shop" stem="shop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="McCracken" lemma="McCracken" stem="mccracken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="44" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VP (VBD decided) (S (VP (TO to) (VP (VB prosecute) (NP (NNP Flores)))))) (CC but) (ADVP (RB later)) (VP (VBD dismissed) (NP (DT all) (NNS charges)) (PP (IN during) (NP (NP (NNP Flores) (POS ')) (NN trial))) (SBAR (IN because) (S (NP (NN police)) (VP (VBD failed) (S (VP (TO to) (VP (VB turn) (PRT (RP over)) (NP (NP (DT a) (NN recording)) (PP (IN of) (NP (NP (DT a) (NN dispatcher) (POS 's)) (NN call)))) (S (VP (VBG requesting) (SBAR (IN that) (S (NP (NNS officers)) (VP (VBP investigate) (NP (NP (DT the) (NN incident)) (PP (IN at) (NP (DT the) (NN motorcycle) (NN shop)))))))))))))))))) (, ,) (NP (NNP McCracken)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="2" string="The district attorney 's office" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
            <token id="5" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="the motorcycle shop" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="4" string="prosecute Flores" type="VP">
          <tokens>
            <token id="8" string="prosecute" />
            <token id="9" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="5" string="decided to prosecute Flores but later dismissed all charges during Flores ' trial because police failed to turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="6" string="decided" />
            <token id="7" string="to" />
            <token id="8" string="prosecute" />
            <token id="9" string="Flores" />
            <token id="10" string="but" />
            <token id="11" string="later" />
            <token id="12" string="dismissed" />
            <token id="13" string="all" />
            <token id="14" string="charges" />
            <token id="15" string="during" />
            <token id="16" string="Flores" />
            <token id="17" string="'" />
            <token id="18" string="trial" />
            <token id="19" string="because" />
            <token id="20" string="police" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="6" string="Flores '" type="NP">
          <tokens>
            <token id="16" string="Flores" />
            <token id="17" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="Flores" type="NP">
          <tokens>
            <token id="9" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="8" string="police" type="NP">
          <tokens>
            <token id="20" string="police" />
          </tokens>
        </chunking>
        <chunking id="9" string="decided to prosecute Flores" type="VP">
          <tokens>
            <token id="6" string="decided" />
            <token id="7" string="to" />
            <token id="8" string="prosecute" />
            <token id="9" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="10" string="McCracken" type="NP">
          <tokens>
            <token id="43" string="McCracken" />
          </tokens>
        </chunking>
        <chunking id="11" string="to prosecute Flores" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="prosecute" />
            <token id="9" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="12" string="the incident" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="incident" />
          </tokens>
        </chunking>
        <chunking id="13" string="a recording" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="recording" />
          </tokens>
        </chunking>
        <chunking id="14" string="because police failed to turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="SBAR">
          <tokens>
            <token id="19" string="because" />
            <token id="20" string="police" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="15" string="a dispatcher 's" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="that officers investigate the incident at the motorcycle shop" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="17" string="all charges" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="charges" />
          </tokens>
        </chunking>
        <chunking id="18" string="to turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="19" string="the incident at the motorcycle shop" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="20" string="The district attorney 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="22" string="turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="23" string="failed to turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="24" string="a recording of a dispatcher 's call" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
          </tokens>
        </chunking>
        <chunking id="25" string="dismissed all charges during Flores ' trial because police failed to turn over a recording of a dispatcher 's call requesting that officers investigate the incident at the motorcycle shop" type="VP">
          <tokens>
            <token id="12" string="dismissed" />
            <token id="13" string="all" />
            <token id="14" string="charges" />
            <token id="15" string="during" />
            <token id="16" string="Flores" />
            <token id="17" string="'" />
            <token id="18" string="trial" />
            <token id="19" string="because" />
            <token id="20" string="police" />
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="turn" />
            <token id="24" string="over" />
            <token id="25" string="a" />
            <token id="26" string="recording" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
            <token id="32" string="requesting" />
            <token id="33" string="that" />
            <token id="34" string="officers" />
            <token id="35" string="investigate" />
            <token id="36" string="the" />
            <token id="37" string="incident" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="motorcycle" />
            <token id="41" string="shop" />
          </tokens>
        </chunking>
        <chunking id="26" string="a dispatcher 's call" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="dispatcher" />
            <token id="30" string="'s" />
            <token id="31" string="call" />
          </tokens>
        </chunking>
        <chunking id="27" string="said" type="VP">
          <tokens>
            <token id="44" string="said" />
          </tokens>
        </chunking>
        <chunking id="28" string="Flores ' trial" type="NP">
          <tokens>
            <token id="16" string="Flores" />
            <token id="17" string="'" />
            <token id="18" string="trial" />
          </tokens>
        </chunking>
        <chunking id="29" string="officers" type="NP">
          <tokens>
            <token id="34" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">attorney</governor>
          <dependent id="2">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">office</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">attorney</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">decided</governor>
          <dependent id="5">office</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="44">said</governor>
          <dependent id="6">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">prosecute</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">decided</governor>
          <dependent id="8">prosecute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">prosecute</governor>
          <dependent id="9">Flores</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">decided</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">dismissed</governor>
          <dependent id="11">later</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">decided</governor>
          <dependent id="12">dismissed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">charges</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">dismissed</governor>
          <dependent id="14">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">trial</governor>
          <dependent id="15">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">trial</governor>
          <dependent id="16">Flores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Flores</governor>
          <dependent id="17">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">dismissed</governor>
          <dependent id="18">trial</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">failed</governor>
          <dependent id="19">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">failed</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">dismissed</governor>
          <dependent id="21">failed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">turn</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">failed</governor>
          <dependent id="23">turn</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">turn</governor>
          <dependent id="24">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">recording</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">turn</governor>
          <dependent id="26">recording</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">call</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">dispatcher</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">call</governor>
          <dependent id="29">dispatcher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">dispatcher</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">recording</governor>
          <dependent id="31">call</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">turn</governor>
          <dependent id="32">requesting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">investigate</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">investigate</governor>
          <dependent id="34">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">requesting</governor>
          <dependent id="35">investigate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">incident</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">investigate</governor>
          <dependent id="37">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">shop</governor>
          <dependent id="38">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">shop</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">shop</governor>
          <dependent id="40">motorcycle</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">incident</governor>
          <dependent id="41">shop</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">said</governor>
          <dependent id="43">McCracken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="44">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McCracken" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="McCracken" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>McCracken said Flores never struggled with the officers until after he was placed in the choke-hold.</content>
      <tokens>
        <token id="1" string="McCracken" lemma="McCracken" stem="mccracken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="struggled" lemma="struggle" stem="struggl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="placed" lemma="place" stem="place" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="choke-hold" lemma="choke-hold" stem="choke-hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP McCracken)) (VP (VBD said) (SBAR (S (NP (NNP Flores)) (ADVP (RB never)) (VP (VBD struggled) (PP (IN with) (NP (DT the) (NNS officers))) (SBAR (IN until) (IN after) (S (NP (PRP he)) (VP (VBD was) (VP (VBN placed) (PP (IN in) (NP (DT the) (NN choke-hold))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="McCracken" type="NP">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </chunking>
        <chunking id="2" string="was placed in the choke-hold" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="3" string="Flores never struggled with the officers until after he was placed in the choke-hold" type="SBAR">
          <tokens>
            <token id="3" string="Flores" />
            <token id="4" string="never" />
            <token id="5" string="struggled" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="officers" />
            <token id="9" string="until" />
            <token id="10" string="after" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="4" string="until after he was placed in the choke-hold" type="SBAR">
          <tokens>
            <token id="9" string="until" />
            <token id="10" string="after" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="5" string="the officers" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="officers" />
          </tokens>
        </chunking>
        <chunking id="6" string="placed in the choke-hold" type="VP">
          <tokens>
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="7" string="the choke-hold" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="said Flores never struggled with the officers until after he was placed in the choke-hold" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Flores" />
            <token id="4" string="never" />
            <token id="5" string="struggled" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="officers" />
            <token id="9" string="until" />
            <token id="10" string="after" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
        <chunking id="10" string="Flores" type="NP">
          <tokens>
            <token id="3" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="11" string="struggled with the officers until after he was placed in the choke-hold" type="VP">
          <tokens>
            <token id="5" string="struggled" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="officers" />
            <token id="9" string="until" />
            <token id="10" string="after" />
            <token id="11" string="he" />
            <token id="12" string="was" />
            <token id="13" string="placed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="choke-hold" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">McCracken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">struggled</governor>
          <dependent id="3">Flores</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">struggled</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">struggled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">officers</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">officers</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">struggled</governor>
          <dependent id="8">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">placed</governor>
          <dependent id="9">until</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">placed</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">placed</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">placed</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">struggled</governor>
          <dependent id="13">placed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">choke-hold</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">choke-hold</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">placed</governor>
          <dependent id="16">choke-hold</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McCracken" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </entity>
        <entity id="2" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>McCracken said Flores was beaten so severely that he suffered a detached retina and might lose partial sight in one eye.</content>
      <tokens>
        <token id="1" string="McCracken" lemma="McCracken" stem="mccracken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Flores" lemma="Flores" stem="flore" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="severely" lemma="severely" stem="sever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="detached" lemma="detach" stem="detach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="retina" lemma="retina" stem="retina" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="partial" lemma="partial" stem="partial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="sight" lemma="sight" stem="sight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="eye" lemma="eye" stem="ey" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP McCracken)) (VP (VBD said) (SBAR (S (NP (NNP Flores)) (VP (VBD was) (VP (VBN beaten) (ADVP (ADVP (RB so) (RB severely)) (SBAR (IN that) (S (NP (PRP he)) (VP (VP (VBD suffered) (NP (DT a) (VBN detached) (NN retina))) (CC and) (VP (MD might) (VP (VB lose) (NP (JJ partial) (NN sight)) (PP (IN in) (NP (CD one) (NN eye)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Flores was beaten so severely that he suffered a detached retina and might lose partial sight in one eye" type="SBAR">
          <tokens>
            <token id="3" string="Flores" />
            <token id="4" string="was" />
            <token id="5" string="beaten" />
            <token id="6" string="so" />
            <token id="7" string="severely" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="2" string="beaten so severely that he suffered a detached retina and might lose partial sight in one eye" type="VP">
          <tokens>
            <token id="5" string="beaten" />
            <token id="6" string="so" />
            <token id="7" string="severely" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="3" string="a detached retina" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Flores was beaten so severely that he suffered a detached retina and might lose partial sight in one eye" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Flores" />
            <token id="4" string="was" />
            <token id="5" string="beaten" />
            <token id="6" string="so" />
            <token id="7" string="severely" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="5" string="Flores" type="NP">
          <tokens>
            <token id="3" string="Flores" />
          </tokens>
        </chunking>
        <chunking id="6" string="suffered a detached retina and might lose partial sight in one eye" type="VP">
          <tokens>
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="7" string="lose partial sight in one eye" type="VP">
          <tokens>
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="8" string="McCracken" type="NP">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </chunking>
        <chunking id="9" string="partial sight" type="NP">
          <tokens>
            <token id="17" string="partial" />
            <token id="18" string="sight" />
          </tokens>
        </chunking>
        <chunking id="10" string="was beaten so severely that he suffered a detached retina and might lose partial sight in one eye" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="beaten" />
            <token id="6" string="so" />
            <token id="7" string="severely" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="might lose partial sight in one eye" type="VP">
          <tokens>
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="13" string="that he suffered a detached retina and might lose partial sight in one eye" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
            <token id="14" string="and" />
            <token id="15" string="might" />
            <token id="16" string="lose" />
            <token id="17" string="partial" />
            <token id="18" string="sight" />
            <token id="19" string="in" />
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="14" string="one eye" type="NP">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="eye" />
          </tokens>
        </chunking>
        <chunking id="15" string="suffered a detached retina" type="VP">
          <tokens>
            <token id="10" string="suffered" />
            <token id="11" string="a" />
            <token id="12" string="detached" />
            <token id="13" string="retina" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">McCracken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">beaten</governor>
          <dependent id="3">Flores</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">beaten</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">beaten</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">severely</governor>
          <dependent id="6">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">beaten</governor>
          <dependent id="7">severely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">suffered</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">suffered</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">severely</governor>
          <dependent id="10">suffered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">retina</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">retina</governor>
          <dependent id="12">detached</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">suffered</governor>
          <dependent id="13">retina</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">suffered</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">lose</governor>
          <dependent id="15">might</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">suffered</governor>
          <dependent id="16">lose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">sight</governor>
          <dependent id="17">partial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">lose</governor>
          <dependent id="18">sight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">eye</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">eye</governor>
          <dependent id="20">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">lose</governor>
          <dependent id="21">eye</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="McCracken" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="McCracken" />
          </tokens>
        </entity>
        <entity id="3" string="Flores" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Flores" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>&amp;quot;They essentially beat the hell out of him for nothing,&amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="essentially" lemma="essentially" stem="essenti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hell" lemma="hell" stem="hell" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP They)) (ADVP (RB essentially)) (VP (VBD beat) (NP (NP (DT the) (NN hell)) (ADVP (IN out)) (PP (IN of) (NP (PRP him)))) (PP (IN for) (NP (NN nothing))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the hell" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="hell" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing" type="NP">
          <tokens>
            <token id="11" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="4" string="beat the hell out of him for nothing" type="VP">
          <tokens>
            <token id="4" string="beat" />
            <token id="5" string="the" />
            <token id="6" string="hell" />
            <token id="7" string="out" />
            <token id="8" string="of" />
            <token id="9" string="him" />
            <token id="10" string="for" />
            <token id="11" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="5" string="the hell out of him" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="hell" />
            <token id="7" string="out" />
            <token id="8" string="of" />
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">beat</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">beat</governor>
          <dependent id="3">essentially</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="4">beat</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">hell</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">beat</governor>
          <dependent id="6">hell</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">hell</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">him</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">hell</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">nothing</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">beat</governor>
          <dependent id="11">nothing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>In another incident, Luis C. Luna, 50, alleges in a complaint filed with the city on June 27, 1989, that he was beaten by three officers near a restaurant in Port Hueneme.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Luis" lemma="Luis" stem="lui" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="C." lemma="C." stem="c." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="27" lemma="27" stem="27" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="31" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="restaurant" lemma="restaurant" stem="restaur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Port" lemma="Port" stem="port" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="37" string="Hueneme" lemma="Hueneme" stem="huenem" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT another) (NN incident))) (, ,) (NP (NP (NNP Luis) (NNP C.) (NNP Luna)) (, ,) (NP (CD 50)) (, ,)) (VP (VBZ alleges) (PP (IN in) (NP (NP (DT a) (NN complaint)) (VP (VBN filed) (PP (IN with) (NP (NP (DT the) (NN city)) (PP (IN on) (NP (NNP June) (CD 27) (, ,) (CD 1989) (, ,))))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (VP (VBN beaten) (PP (IN by) (NP (NP (CD three) (NNS officers)) (PP (IN near) (NP (NP (DT a) (NN restaurant)) (PP (IN in) (NP (NNP Port) (NNP Hueneme))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="filed with the city on June 27 , 1989 , that he was beaten by three officers near a restaurant in Port Hueneme" type="VP">
          <tokens>
            <token id="15" string="filed" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="city" />
            <token id="19" string="on" />
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
            <token id="24" string="," />
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="was" />
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="2" string="Luis C. Luna , 50 ," type="NP">
          <tokens>
            <token id="5" string="Luis" />
            <token id="6" string="C." />
            <token id="7" string="Luna" />
            <token id="8" string="," />
            <token id="9" string="50" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the city" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="city" />
          </tokens>
        </chunking>
        <chunking id="4" string="another incident" type="NP">
          <tokens>
            <token id="2" string="another" />
            <token id="3" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="three officers" type="NP">
          <tokens>
            <token id="30" string="three" />
            <token id="31" string="officers" />
          </tokens>
        </chunking>
        <chunking id="6" string="the city on June 27 , 1989 ," type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="city" />
            <token id="19" string="on" />
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="that he was beaten by three officers near a restaurant in Port Hueneme" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="was" />
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="8" string="beaten by three officers near a restaurant in Port Hueneme" type="VP">
          <tokens>
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="9" string="alleges in a complaint filed with the city on June 27 , 1989 , that he was beaten by three officers near a restaurant in Port Hueneme" type="VP">
          <tokens>
            <token id="11" string="alleges" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="complaint" />
            <token id="15" string="filed" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="city" />
            <token id="19" string="on" />
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
            <token id="24" string="," />
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="was" />
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="10" string="three officers near a restaurant in Port Hueneme" type="NP">
          <tokens>
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="11" string="Luis C. Luna" type="NP">
          <tokens>
            <token id="5" string="Luis" />
            <token id="6" string="C." />
            <token id="7" string="Luna" />
          </tokens>
        </chunking>
        <chunking id="12" string="a restaurant in Port Hueneme" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="13" string="was beaten by three officers near a restaurant in Port Hueneme" type="VP">
          <tokens>
            <token id="27" string="was" />
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="14" string="Port Hueneme" type="NP">
          <tokens>
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="15" string="a complaint filed with the city on June 27 , 1989 , that he was beaten by three officers near a restaurant in Port Hueneme" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="complaint" />
            <token id="15" string="filed" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="city" />
            <token id="19" string="on" />
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
            <token id="24" string="," />
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="was" />
            <token id="28" string="beaten" />
            <token id="29" string="by" />
            <token id="30" string="three" />
            <token id="31" string="officers" />
            <token id="32" string="near" />
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
            <token id="35" string="in" />
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="16" string="50" type="NP">
          <tokens>
            <token id="9" string="50" />
          </tokens>
        </chunking>
        <chunking id="17" string="a restaurant" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="a complaint" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="20" string="June 27 , 1989 ," type="NP">
          <tokens>
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
            <token id="24" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">incident</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">incident</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">alleges</governor>
          <dependent id="3">incident</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Luna</governor>
          <dependent id="5">Luis</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Luna</governor>
          <dependent id="6">C.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">alleges</governor>
          <dependent id="7">Luna</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Luna</governor>
          <dependent id="9">50</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">alleges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">complaint</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">complaint</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">alleges</governor>
          <dependent id="14">complaint</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">complaint</governor>
          <dependent id="15">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">city</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">city</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">filed</governor>
          <dependent id="18">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">June</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">city</governor>
          <dependent id="20">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">June</governor>
          <dependent id="21">27</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">June</governor>
          <dependent id="23">1989</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">beaten</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">beaten</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">beaten</governor>
          <dependent id="27">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">filed</governor>
          <dependent id="28">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">officers</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">officers</governor>
          <dependent id="30">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">beaten</governor>
          <dependent id="31">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">restaurant</governor>
          <dependent id="32">near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">restaurant</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">officers</governor>
          <dependent id="34">restaurant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Hueneme</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Hueneme</governor>
          <dependent id="36">Port</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">restaurant</governor>
          <dependent id="37">Hueneme</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Port Hueneme" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Port" />
            <token id="37" string="Hueneme" />
          </tokens>
        </entity>
        <entity id="2" string="June 27 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="June" />
            <token id="21" string="27" />
            <token id="22" string="," />
            <token id="23" string="1989" />
          </tokens>
        </entity>
        <entity id="3" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="50" />
          </tokens>
        </entity>
        <entity id="4" string="Luis C. Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Luis" />
            <token id="6" string="C." />
            <token id="7" string="Luna" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="30" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>Luna said in an interview that he, his wife and several friends were leaving the restaurant on July 16, 1988, when an Oxnard police car pulled up in front of the group.</content>
      <tokens>
        <token id="1" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="leaving" lemma="leave" stem="leav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="restaurant" lemma="restaurant" stem="restaur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="Oxnard" lemma="Oxnard" stem="oxnard" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="27" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="pulled" lemma="pull" stem="pull" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Luna)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview))) (SBAR (IN that) (S (NP (NP (PRP he)) (, ,) (NP (PRP$ his) (NN wife)) (CC and) (NP (JJ several) (NNS friends))) (VP (VBD were) (VP (VBG leaving) (NP (DT the) (NN restaurant)) (PP (IN on) (NP (NNP July) (CD 16) (, ,) (CD 1988))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (DT an) (NNP Oxnard) (NN police) (NN car)) (VP (VBD pulled) (PRT (RP up)) (PP (IN in) (NP (NP (NN front)) (PP (IN of) (NP (DT the) (NN group))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he , his wife and several friends" type="NP">
          <tokens>
            <token id="7" string="he" />
            <token id="8" string="," />
            <token id="9" string="his" />
            <token id="10" string="wife" />
            <token id="11" string="and" />
            <token id="12" string="several" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="2" string="the group" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="3" string="several friends" type="NP">
          <tokens>
            <token id="12" string="several" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="4" string="July 16 , 1988" type="NP">
          <tokens>
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
          </tokens>
        </chunking>
        <chunking id="5" string="when an Oxnard police car pulled up in front of the group" type="SBAR">
          <tokens>
            <token id="24" string="when" />
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="6" string="the restaurant" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="restaurant" />
          </tokens>
        </chunking>
        <chunking id="7" string="were leaving the restaurant on July 16 , 1988 , when an Oxnard police car pulled up in front of the group" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="leaving" />
            <token id="16" string="the" />
            <token id="17" string="restaurant" />
            <token id="18" string="on" />
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
            <token id="23" string="," />
            <token id="24" string="when" />
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="24" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="an Oxnard police car" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="front of the group" type="NP">
          <tokens>
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="11" string="an interview" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="interview" />
          </tokens>
        </chunking>
        <chunking id="12" string="leaving the restaurant on July 16 , 1988 , when an Oxnard police car pulled up in front of the group" type="VP">
          <tokens>
            <token id="15" string="leaving" />
            <token id="16" string="the" />
            <token id="17" string="restaurant" />
            <token id="18" string="on" />
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
            <token id="23" string="," />
            <token id="24" string="when" />
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="13" string="that he , his wife and several friends were leaving the restaurant on July 16 , 1988 , when an Oxnard police car pulled up in front of the group" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="he" />
            <token id="8" string="," />
            <token id="9" string="his" />
            <token id="10" string="wife" />
            <token id="11" string="and" />
            <token id="12" string="several" />
            <token id="13" string="friends" />
            <token id="14" string="were" />
            <token id="15" string="leaving" />
            <token id="16" string="the" />
            <token id="17" string="restaurant" />
            <token id="18" string="on" />
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
            <token id="23" string="," />
            <token id="24" string="when" />
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="14" string="said in an interview that he , his wife and several friends were leaving the restaurant on July 16 , 1988 , when an Oxnard police car pulled up in front of the group" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="in" />
            <token id="4" string="an" />
            <token id="5" string="interview" />
            <token id="6" string="that" />
            <token id="7" string="he" />
            <token id="8" string="," />
            <token id="9" string="his" />
            <token id="10" string="wife" />
            <token id="11" string="and" />
            <token id="12" string="several" />
            <token id="13" string="friends" />
            <token id="14" string="were" />
            <token id="15" string="leaving" />
            <token id="16" string="the" />
            <token id="17" string="restaurant" />
            <token id="18" string="on" />
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
            <token id="23" string="," />
            <token id="24" string="when" />
            <token id="25" string="an" />
            <token id="26" string="Oxnard" />
            <token id="27" string="police" />
            <token id="28" string="car" />
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="15" string="front" type="NP">
          <tokens>
            <token id="32" string="front" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="his wife" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="wife" />
          </tokens>
        </chunking>
        <chunking id="18" string="Luna" type="NP">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </chunking>
        <chunking id="19" string="pulled up in front of the group" type="VP">
          <tokens>
            <token id="29" string="pulled" />
            <token id="30" string="up" />
            <token id="31" string="in" />
            <token id="32" string="front" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Luna</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">interview</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">interview</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">said</governor>
          <dependent id="5">interview</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">leaving</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">leaving</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">wife</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">he</governor>
          <dependent id="10">wife</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">he</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">friends</governor>
          <dependent id="12">several</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">he</governor>
          <dependent id="13">friends</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">leaving</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="15">leaving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">restaurant</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">leaving</governor>
          <dependent id="17">restaurant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">July</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">leaving</governor>
          <dependent id="19">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">July</governor>
          <dependent id="20">16</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">July</governor>
          <dependent id="22">1988</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">pulled</governor>
          <dependent id="24">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">car</governor>
          <dependent id="25">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">car</governor>
          <dependent id="26">Oxnard</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">car</governor>
          <dependent id="27">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">pulled</governor>
          <dependent id="28">car</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">leaving</governor>
          <dependent id="29">pulled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="29">pulled</governor>
          <dependent id="30">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">group</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="31">in</governor>
          <dependent id="32">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="31">in</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">group</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">pulled</governor>
          <dependent id="35">group</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxnard" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Oxnard" />
          </tokens>
        </entity>
        <entity id="2" string="July 16 , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="July" />
            <token id="20" string="16" />
            <token id="21" string="," />
            <token id="22" string="1988" />
          </tokens>
        </entity>
        <entity id="3" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>Luna, a public works inspector for the city of Port Hueneme, said he walked up to the police car and asked Officer Peter Ruggiero &amp;quot;in a kidding manner&amp;quot; what he was doing in Port Hueneme.</content>
      <tokens>
        <token id="1" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="inspector" lemma="inspector" stem="inspector" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Port" lemma="Port" stem="port" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="Hueneme" lemma="Hueneme" stem="huenem" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="walked" lemma="walk" stem="walk" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="Ruggiero" lemma="Ruggiero" stem="ruggiero" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="kidding" lemma="kidding" stem="kid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="manner" lemma="manner" stem="manner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Port" lemma="Port" stem="port" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="39" string="Hueneme" lemma="Hueneme" stem="huenem" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Luna)) (, ,) (NP (NP (DT a) (JJ public) (NNS works) (NN inspector)) (PP (IN for) (NP (NP (DT the) (NN city)) (PP (IN of) (NP (NNP Port) (NNP Hueneme)))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VP (VBD walked) (PRT (RP up)) (PP (TO to) (NP (DT the) (NN police) (NN car)))) (CC and) (VP (VBD asked) (NP (NP (NNP Officer) (NNP Peter) (NNP Ruggiero)) (`` ``) (PP (IN in) (NP (DT a) (JJ kidding) (NN manner)))) ('' '') (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBD was) (VP (VBG doing) (PP (IN in) (NP (NNP Port) (NNP Hueneme)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city of Port Hueneme" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="of" />
            <token id="11" string="Port" />
            <token id="12" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="Officer Peter Ruggiero" type="NP">
          <tokens>
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="4" string="what he was doing in Port Hueneme" type="SBAR">
          <tokens>
            <token id="33" string="what" />
            <token id="34" string="he" />
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="5" string="doing in Port Hueneme" type="VP">
          <tokens>
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="6" string="Officer Peter Ruggiero `` in a kidding manner" type="NP">
          <tokens>
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
            <token id="27" string="&quot;" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
          </tokens>
        </chunking>
        <chunking id="7" string="a kidding manner" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
          </tokens>
        </chunking>
        <chunking id="8" string="a public works inspector for the city of Port Hueneme" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="public" />
            <token id="5" string="works" />
            <token id="6" string="inspector" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="of" />
            <token id="11" string="Port" />
            <token id="12" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="9" string="Luna , a public works inspector for the city of Port Hueneme ," type="NP">
          <tokens>
            <token id="1" string="Luna" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="public" />
            <token id="5" string="works" />
            <token id="6" string="inspector" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="of" />
            <token id="11" string="Port" />
            <token id="12" string="Hueneme" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the police car" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="asked Officer Peter Ruggiero `` in a kidding manner '' what he was doing in Port Hueneme" type="VP">
          <tokens>
            <token id="23" string="asked" />
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
            <token id="27" string="&quot;" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
            <token id="32" string="&quot;" />
            <token id="33" string="what" />
            <token id="34" string="he" />
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="12" string="a public works inspector" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="public" />
            <token id="5" string="works" />
            <token id="6" string="inspector" />
          </tokens>
        </chunking>
        <chunking id="13" string="Port Hueneme" type="NP">
          <tokens>
            <token id="11" string="Port" />
            <token id="12" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="14" string="walked up to the police car" type="VP">
          <tokens>
            <token id="16" string="walked" />
            <token id="17" string="up" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
        <chunking id="15" string="he walked up to the police car and asked Officer Peter Ruggiero `` in a kidding manner '' what he was doing in Port Hueneme" type="SBAR">
          <tokens>
            <token id="15" string="he" />
            <token id="16" string="walked" />
            <token id="17" string="up" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="asked" />
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
            <token id="27" string="&quot;" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
            <token id="32" string="&quot;" />
            <token id="33" string="what" />
            <token id="34" string="he" />
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="16" string="was doing in Port Hueneme" type="VP">
          <tokens>
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="17" string="said he walked up to the police car and asked Officer Peter Ruggiero `` in a kidding manner '' what he was doing in Port Hueneme" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="walked" />
            <token id="17" string="up" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="asked" />
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
            <token id="27" string="&quot;" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
            <token id="32" string="&quot;" />
            <token id="33" string="what" />
            <token id="34" string="he" />
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="walked up to the police car and asked Officer Peter Ruggiero `` in a kidding manner '' what he was doing in Port Hueneme" type="VP">
          <tokens>
            <token id="16" string="walked" />
            <token id="17" string="up" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="asked" />
            <token id="24" string="Officer" />
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
            <token id="27" string="&quot;" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="kidding" />
            <token id="31" string="manner" />
            <token id="32" string="&quot;" />
            <token id="33" string="what" />
            <token id="34" string="he" />
            <token id="35" string="was" />
            <token id="36" string="doing" />
            <token id="37" string="in" />
            <token id="38" string="Port" />
            <token id="39" string="Hueneme" />
          </tokens>
        </chunking>
        <chunking id="20" string="Luna" type="NP">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="1">Luna</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">inspector</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">inspector</governor>
          <dependent id="4">public</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">inspector</governor>
          <dependent id="5">works</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Luna</governor>
          <dependent id="6">inspector</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">city</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">city</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">inspector</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Hueneme</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Hueneme</governor>
          <dependent id="11">Port</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">city</governor>
          <dependent id="12">Hueneme</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">walked</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="16">walked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">walked</governor>
          <dependent id="17">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">car</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">car</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">car</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">walked</governor>
          <dependent id="21">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">walked</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">walked</governor>
          <dependent id="23">asked</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Ruggiero</governor>
          <dependent id="24">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Ruggiero</governor>
          <dependent id="25">Peter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">asked</governor>
          <dependent id="26">Ruggiero</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">manner</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">manner</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">manner</governor>
          <dependent id="30">kidding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Ruggiero</governor>
          <dependent id="31">manner</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">doing</governor>
          <dependent id="33">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">doing</governor>
          <dependent id="34">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">doing</governor>
          <dependent id="35">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">asked</governor>
          <dependent id="36">doing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Hueneme</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Hueneme</governor>
          <dependent id="38">Port</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">doing</governor>
          <dependent id="39">Hueneme</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Port Hueneme" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Port" />
            <token id="12" string="Hueneme" />
          </tokens>
        </entity>
        <entity id="2" string="Peter Ruggiero" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Peter" />
            <token id="26" string="Ruggiero" />
          </tokens>
        </entity>
        <entity id="3" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>&amp;quot;The officer jumped out and started pushing me back against the pillar in front of the building, using his baton on my throat,&amp;quot; Luna said in the complaint.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="jumped" lemma="jump" stem="jump" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="pushing" lemma="push" stem="push" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="pillar" lemma="pillar" stem="pillar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="building" lemma="building" stem="build" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="baton" lemma="baton" stem="baton" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="throat" lemma="throat" stem="throat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN officer)) (VP (VP (VBD jumped) (PRT (RP out))) (CC and) (VP (VBD started) (S (VP (VBG pushing) (NP (PRP me)) (PRT (RP back)) (PP (IN against) (NP (NP (DT the) (NN pillar)) (PP (IN in) (NP (NP (NN front)) (PP (IN of) (NP (DT the) (NN building)))))))))) (, ,) (S (VP (VBG using) (NP (PRP$ his) (NN baton)) (PP (IN on) (NP (PRP$ my) (NN throat))))))) (, ,) ('' '') (NP (NNP Luna)) (VP (VBD said) (PP (IN in) (NP (DT the) (NN complaint)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="using his baton on my throat" type="VP">
          <tokens>
            <token id="20" string="using" />
            <token id="21" string="his" />
            <token id="22" string="baton" />
            <token id="23" string="on" />
            <token id="24" string="my" />
            <token id="25" string="throat" />
          </tokens>
        </chunking>
        <chunking id="2" string="front of the building" type="NP">
          <tokens>
            <token id="15" string="front" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="building" />
          </tokens>
        </chunking>
        <chunking id="3" string="his baton" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="baton" />
          </tokens>
        </chunking>
        <chunking id="4" string="jumped out and started pushing me back against the pillar in front of the building , using his baton on my throat" type="VP">
          <tokens>
            <token id="4" string="jumped" />
            <token id="5" string="out" />
            <token id="6" string="and" />
            <token id="7" string="started" />
            <token id="8" string="pushing" />
            <token id="9" string="me" />
            <token id="10" string="back" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="pillar" />
            <token id="14" string="in" />
            <token id="15" string="front" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="building" />
            <token id="19" string="," />
            <token id="20" string="using" />
            <token id="21" string="his" />
            <token id="22" string="baton" />
            <token id="23" string="on" />
            <token id="24" string="my" />
            <token id="25" string="throat" />
          </tokens>
        </chunking>
        <chunking id="5" string="the complaint" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="6" string="the building" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="building" />
          </tokens>
        </chunking>
        <chunking id="7" string="my throat" type="NP">
          <tokens>
            <token id="24" string="my" />
            <token id="25" string="throat" />
          </tokens>
        </chunking>
        <chunking id="8" string="jumped out" type="VP">
          <tokens>
            <token id="4" string="jumped" />
            <token id="5" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="started pushing me back against the pillar in front of the building" type="VP">
          <tokens>
            <token id="7" string="started" />
            <token id="8" string="pushing" />
            <token id="9" string="me" />
            <token id="10" string="back" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="pillar" />
            <token id="14" string="in" />
            <token id="15" string="front" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="building" />
          </tokens>
        </chunking>
        <chunking id="10" string="The officer" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="officer" />
          </tokens>
        </chunking>
        <chunking id="11" string="the pillar" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="pillar" />
          </tokens>
        </chunking>
        <chunking id="12" string="pushing me back against the pillar in front of the building" type="VP">
          <tokens>
            <token id="8" string="pushing" />
            <token id="9" string="me" />
            <token id="10" string="back" />
            <token id="11" string="against" />
            <token id="12" string="the" />
            <token id="13" string="pillar" />
            <token id="14" string="in" />
            <token id="15" string="front" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="building" />
          </tokens>
        </chunking>
        <chunking id="13" string="the pillar in front of the building" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="pillar" />
            <token id="14" string="in" />
            <token id="15" string="front" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="building" />
          </tokens>
        </chunking>
        <chunking id="14" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="15" string="front" type="NP">
          <tokens>
            <token id="15" string="front" />
          </tokens>
        </chunking>
        <chunking id="16" string="said in the complaint" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="17" string="Luna" type="NP">
          <tokens>
            <token id="28" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officer</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">jumped</governor>
          <dependent id="3">officer</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="4">jumped</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">jumped</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">jumped</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">jumped</governor>
          <dependent id="7">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">started</governor>
          <dependent id="8">pushing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">pushing</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">pushing</governor>
          <dependent id="10">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">pillar</governor>
          <dependent id="11">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">pillar</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">pushing</governor>
          <dependent id="13">pillar</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">building</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">in</governor>
          <dependent id="15">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">in</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">building</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">pillar</governor>
          <dependent id="18">building</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">jumped</governor>
          <dependent id="20">using</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">baton</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">using</governor>
          <dependent id="22">baton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">throat</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">throat</governor>
          <dependent id="24">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">using</governor>
          <dependent id="25">throat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">Luna</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">complaint</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">complaint</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">said</governor>
          <dependent id="32">complaint</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>When he asked the officer why he was being shoved, Ruggiero told him that he was under arrest, according to the complaint.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="shoved" lemma="shove" stem="shove" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ruggiero" lemma="Ruggiero" stem="ruggiero" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP he)) (VP (VBD asked) (NP (DT the) (NN officer)) (SBAR (WHADVP (WRB why)) (S (NP (PRP he)) (VP (VBD was) (VP (VBG being) (VP (VBN shoved))))))))) (, ,) (NP (NNP Ruggiero)) (VP (VBD told) (NP (PRP him)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (PP (IN under) (NP (NN arrest))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (NN complaint)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ruggiero" type="NP">
          <tokens>
            <token id="12" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="2" string="arrest" type="NP">
          <tokens>
            <token id="19" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="3" string="why" type="WHADVP">
          <tokens>
            <token id="6" string="why" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officer" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the complaint" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="7" string="that he was under arrest , according to the complaint" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="was" />
            <token id="18" string="under" />
            <token id="19" string="arrest" />
            <token id="20" string="," />
            <token id="21" string="according" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="8" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="9" string="was being shoved" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="being" />
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="10" string="why he was being shoved" type="SBAR">
          <tokens>
            <token id="6" string="why" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="being" />
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="11" string="shoved" type="VP">
          <tokens>
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="12" string="being shoved" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="13" string="told him that he was under arrest , according to the complaint" type="VP">
          <tokens>
            <token id="13" string="told" />
            <token id="14" string="him" />
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="was" />
            <token id="18" string="under" />
            <token id="19" string="arrest" />
            <token id="20" string="," />
            <token id="21" string="according" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="14" string="was under arrest , according to the complaint" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="under" />
            <token id="19" string="arrest" />
            <token id="20" string="," />
            <token id="21" string="according" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="asked the officer why he was being shoved" type="VP">
          <tokens>
            <token id="3" string="asked" />
            <token id="4" string="the" />
            <token id="5" string="officer" />
            <token id="6" string="why" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="being" />
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
        <chunking id="17" string="When he asked the officer why he was being shoved" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="he" />
            <token id="3" string="asked" />
            <token id="4" string="the" />
            <token id="5" string="officer" />
            <token id="6" string="why" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="being" />
            <token id="10" string="shoved" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">asked</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">asked</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">told</governor>
          <dependent id="3">asked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">officer</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">asked</governor>
          <dependent id="5">officer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">shoved</governor>
          <dependent id="6">why</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">shoved</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">shoved</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">shoved</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">asked</governor>
          <dependent id="10">shoved</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">told</governor>
          <dependent id="12">Ruggiero</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">told</governor>
          <dependent id="14">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">arrest</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">arrest</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">arrest</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">arrest</governor>
          <dependent id="18">under</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">told</governor>
          <dependent id="19">arrest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">complaint</governor>
          <dependent id="21">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">according</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">complaint</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">arrest</governor>
          <dependent id="24">complaint</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ruggiero" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ruggiero" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>Officers Steven Vendt and Humberto Jimenez were called to assist Ruggiero, the complaint said.</content>
      <tokens>
        <token id="1" string="Officers" lemma="officer" stem="officer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Steven" lemma="Steven" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Vendt" lemma="Vendt" stem="vendt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Humberto" lemma="Humberto" stem="humberto" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Jimenez" lemma="Jimenez" stem="jimenez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assist" lemma="assist" stem="assist" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Ruggiero" lemma="Ruggiero" stem="ruggiero" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Officers) (NNP Steven) (NNP Vendt) (CC and) (NNP Humberto) (NNP Jimenez)) (VP (VBD were) (VP (VBN called) (S (VP (TO to) (VP (VB assist) (NP (NNP Ruggiero)))))))) (, ,) (NP (DT the) (NN complaint)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were called to assist Ruggiero" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="called" />
            <token id="9" string="to" />
            <token id="10" string="assist" />
            <token id="11" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ruggiero" type="NP">
          <tokens>
            <token id="11" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="3" string="Officers Steven Vendt and Humberto Jimenez" type="NP">
          <tokens>
            <token id="1" string="Officers" />
            <token id="2" string="Steven" />
            <token id="3" string="Vendt" />
            <token id="4" string="and" />
            <token id="5" string="Humberto" />
            <token id="6" string="Jimenez" />
          </tokens>
        </chunking>
        <chunking id="4" string="to assist Ruggiero" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="assist" />
            <token id="11" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="5" string="assist Ruggiero" type="VP">
          <tokens>
            <token id="10" string="assist" />
            <token id="11" string="Ruggiero" />
          </tokens>
        </chunking>
        <chunking id="6" string="the complaint" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="called to assist Ruggiero" type="VP">
          <tokens>
            <token id="8" string="called" />
            <token id="9" string="to" />
            <token id="10" string="assist" />
            <token id="11" string="Ruggiero" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Vendt</governor>
          <dependent id="1">Officers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Vendt</governor>
          <dependent id="2">Steven</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">called</governor>
          <dependent id="3">Vendt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Vendt</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Jimenez</governor>
          <dependent id="5">Humberto</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Vendt</governor>
          <dependent id="6">Jimenez</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">called</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="8">called</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">assist</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">called</governor>
          <dependent id="10">assist</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">assist</governor>
          <dependent id="11">Ruggiero</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">complaint</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">complaint</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Steven Vendt" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Steven" />
            <token id="3" string="Vendt" />
          </tokens>
        </entity>
        <entity id="2" string="Humberto Jimenez" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Humberto" />
            <token id="6" string="Jimenez" />
          </tokens>
        </entity>
        <entity id="3" string="Ruggiero" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ruggiero" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>&amp;quot;They used forcible brutality by hitting me with the baton on my elbow, knees and back, forcing me to drop down on the sidewalk with my face slammed against the pavement,&amp;quot; Luna said in the complaint.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="forcible" lemma="forcible" stem="forcibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hitting" lemma="hit" stem="hit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="baton" lemma="baton" stem="baton" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="elbow" lemma="elbow" stem="elbow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="knees" lemma="knee" stem="knee" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="forcing" lemma="force" stem="forc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="drop" lemma="drop" stem="drop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="sidewalk" lemma="sidewalk" stem="sidewalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="slammed" lemma="slam" stem="slam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="pavement" lemma="pavement" stem="pavement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP They)) (VP (VBD used) (NP (JJ forcible) (NN brutality)) (PP (IN by) (S (VP (VBG hitting) (NP (PRP me)) (PP (IN with) (S (NP (NP (DT the) (NN baton)) (PP (IN on) (NP (PRP$ my) (NN elbow))) (, ,) (UCP (NP (NNS knees)) (CC and) (ADVP (RB back))) (, ,)) (VP (VBG forcing) (S (NP (PRP me)) (VP (TO to) (VP (VB drop) (PRT (RP down)) (PP (IN on) (NP (DT the) (NN sidewalk))) (SBAR (IN with) (S (NP (PRP$ my) (NN face)) (VP (VBD slammed) (PP (IN against) (NP (DT the) (NN pavement))))))))))))))))) (, ,) ('' '') (NP (NNP Luna)) (VP (VBD said) (PP (IN in) (NP (DT the) (NN complaint)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the baton on my elbow , knees and back ," type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="baton" />
            <token id="12" string="on" />
            <token id="13" string="my" />
            <token id="14" string="elbow" />
            <token id="15" string="," />
            <token id="16" string="knees" />
            <token id="17" string="and" />
            <token id="18" string="back" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="forcible brutality" type="NP">
          <tokens>
            <token id="4" string="forcible" />
            <token id="5" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="my elbow" type="NP">
          <tokens>
            <token id="13" string="my" />
            <token id="14" string="elbow" />
          </tokens>
        </chunking>
        <chunking id="5" string="the sidewalk" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
          </tokens>
        </chunking>
        <chunking id="6" string="the pavement" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="7" string="to drop down on the sidewalk with my face slammed against the pavement" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="drop" />
            <token id="24" string="down" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="8" string="used forcible brutality by hitting me with the baton on my elbow , knees and back , forcing me to drop down on the sidewalk with my face slammed against the pavement" type="VP">
          <tokens>
            <token id="3" string="used" />
            <token id="4" string="forcible" />
            <token id="5" string="brutality" />
            <token id="6" string="by" />
            <token id="7" string="hitting" />
            <token id="8" string="me" />
            <token id="9" string="with" />
            <token id="10" string="the" />
            <token id="11" string="baton" />
            <token id="12" string="on" />
            <token id="13" string="my" />
            <token id="14" string="elbow" />
            <token id="15" string="," />
            <token id="16" string="knees" />
            <token id="17" string="and" />
            <token id="18" string="back" />
            <token id="19" string="," />
            <token id="20" string="forcing" />
            <token id="21" string="me" />
            <token id="22" string="to" />
            <token id="23" string="drop" />
            <token id="24" string="down" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="9" string="my face" type="NP">
          <tokens>
            <token id="29" string="my" />
            <token id="30" string="face" />
          </tokens>
        </chunking>
        <chunking id="10" string="forcing me to drop down on the sidewalk with my face slammed against the pavement" type="VP">
          <tokens>
            <token id="20" string="forcing" />
            <token id="21" string="me" />
            <token id="22" string="to" />
            <token id="23" string="drop" />
            <token id="24" string="down" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="11" string="the complaint" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="12" string="hitting me with the baton on my elbow , knees and back , forcing me to drop down on the sidewalk with my face slammed against the pavement" type="VP">
          <tokens>
            <token id="7" string="hitting" />
            <token id="8" string="me" />
            <token id="9" string="with" />
            <token id="10" string="the" />
            <token id="11" string="baton" />
            <token id="12" string="on" />
            <token id="13" string="my" />
            <token id="14" string="elbow" />
            <token id="15" string="," />
            <token id="16" string="knees" />
            <token id="17" string="and" />
            <token id="18" string="back" />
            <token id="19" string="," />
            <token id="20" string="forcing" />
            <token id="21" string="me" />
            <token id="22" string="to" />
            <token id="23" string="drop" />
            <token id="24" string="down" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="13" string="with my face slammed against the pavement" type="SBAR">
          <tokens>
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="14" string="drop down on the sidewalk with my face slammed against the pavement" type="VP">
          <tokens>
            <token id="23" string="drop" />
            <token id="24" string="down" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="sidewalk" />
            <token id="28" string="with" />
            <token id="29" string="my" />
            <token id="30" string="face" />
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="15" string="slammed against the pavement" type="VP">
          <tokens>
            <token id="31" string="slammed" />
            <token id="32" string="against" />
            <token id="33" string="the" />
            <token id="34" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="16" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="17" string="knees" type="NP">
          <tokens>
            <token id="16" string="knees" />
          </tokens>
        </chunking>
        <chunking id="18" string="the baton" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="baton" />
          </tokens>
        </chunking>
        <chunking id="19" string="said in the complaint" type="VP">
          <tokens>
            <token id="38" string="said" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="20" string="Luna" type="NP">
          <tokens>
            <token id="37" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">used</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="38">said</governor>
          <dependent id="3">used</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">brutality</governor>
          <dependent id="4">forcible</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">used</governor>
          <dependent id="5">brutality</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">hitting</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">used</governor>
          <dependent id="7">hitting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">hitting</governor>
          <dependent id="8">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">forcing</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">baton</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">forcing</governor>
          <dependent id="11">baton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">elbow</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">elbow</governor>
          <dependent id="13">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">baton</governor>
          <dependent id="14">elbow</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">baton</governor>
          <dependent id="16">knees</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">knees</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">knees</governor>
          <dependent id="18">back</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">hitting</governor>
          <dependent id="20">forcing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">forcing</governor>
          <dependent id="21">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">drop</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">forcing</governor>
          <dependent id="23">drop</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">drop</governor>
          <dependent id="24">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">sidewalk</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">sidewalk</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">drop</governor>
          <dependent id="27">sidewalk</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">slammed</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">face</governor>
          <dependent id="29">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">slammed</governor>
          <dependent id="30">face</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">drop</governor>
          <dependent id="31">slammed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">pavement</governor>
          <dependent id="32">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">pavement</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">slammed</governor>
          <dependent id="34">pavement</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">said</governor>
          <dependent id="37">Luna</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">complaint</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">complaint</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">said</governor>
          <dependent id="41">complaint</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>Luna was arrested on suspicion of disorderly conduct under the influence of drugs.</content>
      <tokens>
        <token id="1" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="disorderly" lemma="disorderly" stem="disorderli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="conduct" lemma="conduct" stem="conduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Luna)) (VP (VBD was) (VP (VBN arrested) (PP (IN on) (NP (NP (NN suspicion)) (PP (IN of) (NP (JJ disorderly) (NN conduct))))) (PP (IN under) (NP (NP (DT the) (NN influence)) (PP (IN of) (NP (NNS drugs))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suspicion of disorderly conduct" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disorderly" />
            <token id="8" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="2" string="the influence of drugs" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="influence" />
            <token id="12" string="of" />
            <token id="13" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="13" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="arrested on suspicion of disorderly conduct under the influence of drugs" type="VP">
          <tokens>
            <token id="3" string="arrested" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disorderly" />
            <token id="8" string="conduct" />
            <token id="9" string="under" />
            <token id="10" string="the" />
            <token id="11" string="influence" />
            <token id="12" string="of" />
            <token id="13" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="suspicion" type="NP">
          <tokens>
            <token id="5" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="6" string="the influence" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="influence" />
          </tokens>
        </chunking>
        <chunking id="7" string="disorderly conduct" type="NP">
          <tokens>
            <token id="7" string="disorderly" />
            <token id="8" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="8" string="was arrested on suspicion of disorderly conduct under the influence of drugs" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="arrested" />
            <token id="4" string="on" />
            <token id="5" string="suspicion" />
            <token id="6" string="of" />
            <token id="7" string="disorderly" />
            <token id="8" string="conduct" />
            <token id="9" string="under" />
            <token id="10" string="the" />
            <token id="11" string="influence" />
            <token id="12" string="of" />
            <token id="13" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="Luna" type="NP">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">arrested</governor>
          <dependent id="1">Luna</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">arrested</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">suspicion</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">arrested</governor>
          <dependent id="5">suspicion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">conduct</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">conduct</governor>
          <dependent id="7">disorderly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">suspicion</governor>
          <dependent id="8">conduct</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">influence</governor>
          <dependent id="9">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">influence</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">arrested</governor>
          <dependent id="11">influence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">drugs</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">influence</governor>
          <dependent id="13">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>The district attorney&amp;apost;s office decided to prosecute Luna, but in September, 1988 -- before his trial began -- all charges against him were withdrawn for lack of evidence, Brodie said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="prosecute" lemma="prosecute" stem="prosecut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="withdrawn" lemma="withdraw" stem="withdrawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Brodie" lemma="Brodie" stem="brodi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN district) (NN attorney) (POS 's)) (NN office)) (VP (VBD decided) (S (VP (TO to) (VP (VB prosecute) (NP (NNP Luna))))))) (, ,) (CC but) (S (PP (IN in) (NP (NP (NP (NNP September)) (, ,) (NP (CD 1988)) (PRN (: --) (SBAR (IN before) (S (NP (PRP$ his) (NN trial)) (VP (VBD began)))) (: --))) (SBAR (S (NP (NP (DT all) (NNS charges)) (PP (IN against) (NP (PRP him)))) (VP (VBD were) (VP (VBN withdrawn) (PP (IN for) (NP (NP (NN lack)) (PP (IN of) (NP (NN evidence))))))))))) (, ,) (NP (NNP Brodie)) (VP (VBD said))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="decided to prosecute Luna" type="VP">
          <tokens>
            <token id="6" string="decided" />
            <token id="7" string="to" />
            <token id="8" string="prosecute" />
            <token id="9" string="Luna" />
          </tokens>
        </chunking>
        <chunking id="2" string="began" type="VP">
          <tokens>
            <token id="20" string="began" />
          </tokens>
        </chunking>
        <chunking id="3" string="lack of evidence" type="NP">
          <tokens>
            <token id="29" string="lack" />
            <token id="30" string="of" />
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="The district attorney 's office" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
            <token id="5" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="September" type="NP">
          <tokens>
            <token id="13" string="September" />
          </tokens>
        </chunking>
        <chunking id="6" string="before his trial began" type="SBAR">
          <tokens>
            <token id="17" string="before" />
            <token id="18" string="his" />
            <token id="19" string="trial" />
            <token id="20" string="began" />
          </tokens>
        </chunking>
        <chunking id="7" string="evidence" type="NP">
          <tokens>
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="8" string="to prosecute Luna" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="prosecute" />
            <token id="9" string="Luna" />
          </tokens>
        </chunking>
        <chunking id="9" string="prosecute Luna" type="VP">
          <tokens>
            <token id="8" string="prosecute" />
            <token id="9" string="Luna" />
          </tokens>
        </chunking>
        <chunking id="10" string="all charges against him" type="NP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="charges" />
            <token id="24" string="against" />
            <token id="25" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="all charges" type="NP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="charges" />
          </tokens>
        </chunking>
        <chunking id="12" string="him" type="NP">
          <tokens>
            <token id="25" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="The district attorney 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="lack" type="NP">
          <tokens>
            <token id="29" string="lack" />
          </tokens>
        </chunking>
        <chunking id="15" string="September , 1988 -- before his trial began -- all charges against him were withdrawn for lack of evidence" type="NP">
          <tokens>
            <token id="13" string="September" />
            <token id="14" string="," />
            <token id="15" string="1988" />
            <token id="16" string="--" />
            <token id="17" string="before" />
            <token id="18" string="his" />
            <token id="19" string="trial" />
            <token id="20" string="began" />
            <token id="21" string="--" />
            <token id="22" string="all" />
            <token id="23" string="charges" />
            <token id="24" string="against" />
            <token id="25" string="him" />
            <token id="26" string="were" />
            <token id="27" string="withdrawn" />
            <token id="28" string="for" />
            <token id="29" string="lack" />
            <token id="30" string="of" />
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="16" string="his trial" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="trial" />
          </tokens>
        </chunking>
        <chunking id="17" string="1988" type="NP">
          <tokens>
            <token id="15" string="1988" />
          </tokens>
        </chunking>
        <chunking id="18" string="all charges against him were withdrawn for lack of evidence" type="SBAR">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="charges" />
            <token id="24" string="against" />
            <token id="25" string="him" />
            <token id="26" string="were" />
            <token id="27" string="withdrawn" />
            <token id="28" string="for" />
            <token id="29" string="lack" />
            <token id="30" string="of" />
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="19" string="withdrawn for lack of evidence" type="VP">
          <tokens>
            <token id="27" string="withdrawn" />
            <token id="28" string="for" />
            <token id="29" string="lack" />
            <token id="30" string="of" />
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="20" string="Brodie" type="NP">
          <tokens>
            <token id="33" string="Brodie" />
          </tokens>
        </chunking>
        <chunking id="21" string="September , 1988 -- before his trial began --" type="NP">
          <tokens>
            <token id="13" string="September" />
            <token id="14" string="," />
            <token id="15" string="1988" />
            <token id="16" string="--" />
            <token id="17" string="before" />
            <token id="18" string="his" />
            <token id="19" string="trial" />
            <token id="20" string="began" />
            <token id="21" string="--" />
          </tokens>
        </chunking>
        <chunking id="22" string="were withdrawn for lack of evidence" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="withdrawn" />
            <token id="28" string="for" />
            <token id="29" string="lack" />
            <token id="30" string="of" />
            <token id="31" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="23" string="said" type="VP">
          <tokens>
            <token id="34" string="said" />
          </tokens>
        </chunking>
        <chunking id="24" string="Luna" type="NP">
          <tokens>
            <token id="9" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">attorney</governor>
          <dependent id="2">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">office</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">attorney</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">decided</governor>
          <dependent id="5">office</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">prosecute</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">decided</governor>
          <dependent id="8">prosecute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">prosecute</governor>
          <dependent id="9">Luna</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">decided</governor>
          <dependent id="11">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">September</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">said</governor>
          <dependent id="13">September</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">September</governor>
          <dependent id="15">1988</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">began</governor>
          <dependent id="17">before</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">trial</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">began</governor>
          <dependent id="19">trial</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">September</governor>
          <dependent id="20">began</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">charges</governor>
          <dependent id="22">all</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">withdrawn</governor>
          <dependent id="23">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">him</governor>
          <dependent id="24">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">charges</governor>
          <dependent id="25">him</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">withdrawn</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">September</governor>
          <dependent id="27">withdrawn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">lack</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">withdrawn</governor>
          <dependent id="29">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">evidence</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">lack</governor>
          <dependent id="31">evidence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">said</governor>
          <dependent id="33">Brodie</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">decided</governor>
          <dependent id="34">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="September , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="September" />
            <token id="14" string="," />
            <token id="15" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Brodie" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Brodie" />
          </tokens>
        </entity>
        <entity id="3" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Owens ordered the department&amp;apost;s internal affairs division to investigate Luna&amp;apost;s complaint.</content>
      <tokens>
        <token id="1" string="Owens" lemma="Owens" stem="owen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="ordered" lemma="order" stem="order" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="internal" lemma="internal" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="affairs" lemma="affair" stem="affair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="division" lemma="division" stem="divis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Owens)) (VP (VBD ordered) (S (NP (NP (DT the) (NN department) (POS 's)) (JJ internal) (NNS affairs) (NN division)) (VP (TO to) (VP (VB investigate) (NP (NP (NNP Luna) (POS 's)) (NN complaint)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Owens" type="NP">
          <tokens>
            <token id="1" string="Owens" />
          </tokens>
        </chunking>
        <chunking id="2" string="Luna 's" type="NP">
          <tokens>
            <token id="11" string="Luna" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="to investigate Luna 's complaint" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="investigate" />
            <token id="11" string="Luna" />
            <token id="12" string="'s" />
            <token id="13" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="4" string="ordered the department 's internal affairs division to investigate Luna 's complaint" type="VP">
          <tokens>
            <token id="2" string="ordered" />
            <token id="3" string="the" />
            <token id="4" string="department" />
            <token id="5" string="'s" />
            <token id="6" string="internal" />
            <token id="7" string="affairs" />
            <token id="8" string="division" />
            <token id="9" string="to" />
            <token id="10" string="investigate" />
            <token id="11" string="Luna" />
            <token id="12" string="'s" />
            <token id="13" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="5" string="investigate Luna 's complaint" type="VP">
          <tokens>
            <token id="10" string="investigate" />
            <token id="11" string="Luna" />
            <token id="12" string="'s" />
            <token id="13" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="6" string="Luna 's complaint" type="NP">
          <tokens>
            <token id="11" string="Luna" />
            <token id="12" string="'s" />
            <token id="13" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="7" string="the department 's" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="department" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="the department 's internal affairs division" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="department" />
            <token id="5" string="'s" />
            <token id="6" string="internal" />
            <token id="7" string="affairs" />
            <token id="8" string="division" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">ordered</governor>
          <dependent id="1">Owens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">ordered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">department</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">division</governor>
          <dependent id="4">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">department</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">division</governor>
          <dependent id="6">internal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">division</governor>
          <dependent id="7">affairs</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">ordered</governor>
          <dependent id="8">division</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">investigate</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">ordered</governor>
          <dependent id="10">investigate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">complaint</governor>
          <dependent id="11">Luna</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Luna</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">investigate</governor>
          <dependent id="13">complaint</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Owens" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Owens" />
          </tokens>
        </entity>
        <entity id="2" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>But Luna said the Police Department later sent him a letter saying the investigation revealed no wrongdoing on the officers&amp;apost; parts.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="sent" lemma="send" stem="sent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="revealed" lemma="reveal" stem="reveal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wrongdoing" lemma="wrongdoing" stem="wrongdo" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Luna)) (VP (VBD said) (SBAR (S (NP (DT the) (NNP Police) (NNP Department)) (ADVP (RB later)) (VP (VBD sent) (NP (PRP him)) (NP (NP (DT a) (NN letter)) (VP (VBG saying) (SBAR (S (NP (DT the) (NN investigation)) (VP (VBD revealed) (NP (DT no) (NN wrongdoing)) (PP (IN on) (NP (NP (DT the) (NNS officers) (POS ')) (NNS parts)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sent him a letter saying the investigation revealed no wrongdoing on the officers ' parts" type="VP">
          <tokens>
            <token id="8" string="sent" />
            <token id="9" string="him" />
            <token id="10" string="a" />
            <token id="11" string="letter" />
            <token id="12" string="saying" />
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="2" string="a letter saying the investigation revealed no wrongdoing on the officers ' parts" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="letter" />
            <token id="12" string="saying" />
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="3" string="no wrongdoing" type="NP">
          <tokens>
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="a letter" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="letter" />
          </tokens>
        </chunking>
        <chunking id="6" string="the officers '" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the Police Department later sent him a letter saying the investigation revealed no wrongdoing on the officers ' parts" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Department" />
            <token id="7" string="later" />
            <token id="8" string="sent" />
            <token id="9" string="him" />
            <token id="10" string="a" />
            <token id="11" string="letter" />
            <token id="12" string="saying" />
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="8" string="the investigation revealed no wrongdoing on the officers ' parts" type="SBAR">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="9" string="the investigation" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="10" string="revealed no wrongdoing on the officers ' parts" type="VP">
          <tokens>
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Police Department later sent him a letter saying the investigation revealed no wrongdoing on the officers ' parts" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Department" />
            <token id="7" string="later" />
            <token id="8" string="sent" />
            <token id="9" string="him" />
            <token id="10" string="a" />
            <token id="11" string="letter" />
            <token id="12" string="saying" />
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="12" string="saying the investigation revealed no wrongdoing on the officers ' parts" type="VP">
          <tokens>
            <token id="12" string="saying" />
            <token id="13" string="the" />
            <token id="14" string="investigation" />
            <token id="15" string="revealed" />
            <token id="16" string="no" />
            <token id="17" string="wrongdoing" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="13" string="the officers ' parts" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="officers" />
            <token id="21" string="'" />
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Police Department" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Department" />
          </tokens>
        </chunking>
        <chunking id="15" string="Luna" type="NP">
          <tokens>
            <token id="2" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Luna</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Department</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Department</governor>
          <dependent id="5">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">sent</governor>
          <dependent id="6">Department</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">sent</governor>
          <dependent id="7">later</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="8">sent</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="8">sent</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">letter</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">sent</governor>
          <dependent id="11">letter</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">letter</governor>
          <dependent id="12">saying</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">investigation</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">revealed</governor>
          <dependent id="14">investigation</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">saying</governor>
          <dependent id="15">revealed</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">wrongdoing</governor>
          <dependent id="16">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">revealed</governor>
          <dependent id="17">wrongdoing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">parts</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">officers</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">parts</governor>
          <dependent id="20">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">officers</governor>
          <dependent id="21">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">revealed</governor>
          <dependent id="22">parts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Police" />
            <token id="6" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Luna had asked the city for $50,000 for medical expenses and to compensate for &amp;quot;humiliation suffered in public.&amp;quot;</content>
      <tokens>
        <token id="1" string="Luna" lemma="Luna" stem="luna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="expenses" lemma="expense" stem="expens" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="compensate" lemma="compensate" stem="compens" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="humiliation" lemma="humiliation" stem="humili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Luna)) (VP (VBD had) (VP (VBN asked) (NP (NP (DT the) (NN city)) (PP (IN for) (NP (NP ($ $) (CD 50,000)) (PP (IN for) (NP (JJ medical) (NNS expenses))))))))) (CC and) (S (S (VP (TO to) (VP (VB compensate) (PP (IN for) (`` ``) (NP (NN humiliation)))))) (VP (VBD suffered) (PP (IN in) (NP (NN public))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="$ 50,000" type="NP">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="50,000" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="to compensate for `` humiliation" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="compensate" />
            <token id="15" string="for" />
            <token id="16" string="&quot;" />
            <token id="17" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="4" string="compensate for `` humiliation" type="VP">
          <tokens>
            <token id="14" string="compensate" />
            <token id="15" string="for" />
            <token id="16" string="&quot;" />
            <token id="17" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="5" string="suffered in public" type="VP">
          <tokens>
            <token id="18" string="suffered" />
            <token id="19" string="in" />
            <token id="20" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="public" type="NP">
          <tokens>
            <token id="20" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="had asked the city for $ 50,000 for medical expenses" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="asked" />
            <token id="4" string="the" />
            <token id="5" string="city" />
            <token id="6" string="for" />
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="for" />
            <token id="10" string="medical" />
            <token id="11" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="8" string="asked the city for $ 50,000 for medical expenses" type="VP">
          <tokens>
            <token id="3" string="asked" />
            <token id="4" string="the" />
            <token id="5" string="city" />
            <token id="6" string="for" />
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="for" />
            <token id="10" string="medical" />
            <token id="11" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="9" string="$ 50,000 for medical expenses" type="NP">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="for" />
            <token id="10" string="medical" />
            <token id="11" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="10" string="the city for $ 50,000 for medical expenses" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="city" />
            <token id="6" string="for" />
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="for" />
            <token id="10" string="medical" />
            <token id="11" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="11" string="medical expenses" type="NP">
          <tokens>
            <token id="10" string="medical" />
            <token id="11" string="expenses" />
          </tokens>
        </chunking>
        <chunking id="12" string="humiliation" type="NP">
          <tokens>
            <token id="17" string="humiliation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Luna" type="NP">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">asked</governor>
          <dependent id="1">Luna</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">asked</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">asked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">city</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">asked</governor>
          <dependent id="5">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">50,000</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">50,000</governor>
          <dependent id="7">$</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">city</governor>
          <dependent id="8">50,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">expenses</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">expenses</governor>
          <dependent id="10">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">50,000</governor>
          <dependent id="11">expenses</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">asked</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">compensate</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="18">suffered</governor>
          <dependent id="14">compensate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">humiliation</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">compensate</governor>
          <dependent id="17">humiliation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">asked</governor>
          <dependent id="18">suffered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">public</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">suffered</governor>
          <dependent id="20">public</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 50,000" type="MONEY" score="0.0">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="50,000" />
          </tokens>
        </entity>
        <entity id="2" string="Luna" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Luna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>He failed, however, to submit the claim for damages during the statutory six-month period after the incident and was barred by law from filing a lawsuit.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="submit" lemma="submit" stem="submit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="claim" lemma="claim" stem="claim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="statutory" lemma="statutory" stem="statutori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="six-month" lemma="six-month" stem="six-month" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="barred" lemma="bar" stem="bar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="filing" lemma="file" stem="file" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD failed) (, ,) (ADVP (RB however)) (, ,) (S (VP (TO to) (VP (VP (VB submit) (NP (NP (DT the) (NN claim)) (PP (IN for) (NP (NNS damages)))) (PP (IN during) (NP (DT the) (JJ statutory) (JJ six-month) (NN period))) (PP (IN after) (NP (DT the) (NN incident)))) (CC and) (VP (VBD was) (VP (VBN barred) (PP (IN by) (NP (NN law))) (PP (IN from) (S (VP (VBG filing) (NP (DT a) (NN lawsuit))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="submit the claim for damages during the statutory six-month period after the incident" type="VP">
          <tokens>
            <token id="7" string="submit" />
            <token id="8" string="the" />
            <token id="9" string="claim" />
            <token id="10" string="for" />
            <token id="11" string="damages" />
            <token id="12" string="during" />
            <token id="13" string="the" />
            <token id="14" string="statutory" />
            <token id="15" string="six-month" />
            <token id="16" string="period" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="incident" />
          </tokens>
        </chunking>
        <chunking id="2" string="law" type="NP">
          <tokens>
            <token id="24" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="damages" type="NP">
          <tokens>
            <token id="11" string="damages" />
          </tokens>
        </chunking>
        <chunking id="4" string="the claim for damages" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="claim" />
            <token id="10" string="for" />
            <token id="11" string="damages" />
          </tokens>
        </chunking>
        <chunking id="5" string="to submit the claim for damages during the statutory six-month period after the incident and was barred by law from filing a lawsuit" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="submit" />
            <token id="8" string="the" />
            <token id="9" string="claim" />
            <token id="10" string="for" />
            <token id="11" string="damages" />
            <token id="12" string="during" />
            <token id="13" string="the" />
            <token id="14" string="statutory" />
            <token id="15" string="six-month" />
            <token id="16" string="period" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="incident" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="barred" />
            <token id="23" string="by" />
            <token id="24" string="law" />
            <token id="25" string="from" />
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="6" string="submit the claim for damages during the statutory six-month period after the incident and was barred by law from filing a lawsuit" type="VP">
          <tokens>
            <token id="7" string="submit" />
            <token id="8" string="the" />
            <token id="9" string="claim" />
            <token id="10" string="for" />
            <token id="11" string="damages" />
            <token id="12" string="during" />
            <token id="13" string="the" />
            <token id="14" string="statutory" />
            <token id="15" string="six-month" />
            <token id="16" string="period" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="incident" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="barred" />
            <token id="23" string="by" />
            <token id="24" string="law" />
            <token id="25" string="from" />
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="7" string="was barred by law from filing a lawsuit" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="barred" />
            <token id="23" string="by" />
            <token id="24" string="law" />
            <token id="25" string="from" />
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="8" string="a lawsuit" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="9" string="the statutory six-month period" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="statutory" />
            <token id="15" string="six-month" />
            <token id="16" string="period" />
          </tokens>
        </chunking>
        <chunking id="10" string="filing a lawsuit" type="VP">
          <tokens>
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="11" string="barred by law from filing a lawsuit" type="VP">
          <tokens>
            <token id="22" string="barred" />
            <token id="23" string="by" />
            <token id="24" string="law" />
            <token id="25" string="from" />
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="12" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="13" string="the claim" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="claim" />
          </tokens>
        </chunking>
        <chunking id="14" string="the incident" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="incident" />
          </tokens>
        </chunking>
        <chunking id="15" string="failed , however , to submit the claim for damages during the statutory six-month period after the incident and was barred by law from filing a lawsuit" type="VP">
          <tokens>
            <token id="2" string="failed" />
            <token id="3" string="," />
            <token id="4" string="however" />
            <token id="5" string="," />
            <token id="6" string="to" />
            <token id="7" string="submit" />
            <token id="8" string="the" />
            <token id="9" string="claim" />
            <token id="10" string="for" />
            <token id="11" string="damages" />
            <token id="12" string="during" />
            <token id="13" string="the" />
            <token id="14" string="statutory" />
            <token id="15" string="six-month" />
            <token id="16" string="period" />
            <token id="17" string="after" />
            <token id="18" string="the" />
            <token id="19" string="incident" />
            <token id="20" string="and" />
            <token id="21" string="was" />
            <token id="22" string="barred" />
            <token id="23" string="by" />
            <token id="24" string="law" />
            <token id="25" string="from" />
            <token id="26" string="filing" />
            <token id="27" string="a" />
            <token id="28" string="lawsuit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">failed</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">failed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">failed</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">submit</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">failed</governor>
          <dependent id="7">submit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">claim</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">submit</governor>
          <dependent id="9">claim</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">damages</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">claim</governor>
          <dependent id="11">damages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">period</governor>
          <dependent id="12">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">period</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">period</governor>
          <dependent id="14">statutory</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">period</governor>
          <dependent id="15">six-month</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">submit</governor>
          <dependent id="16">period</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">incident</governor>
          <dependent id="17">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">incident</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">submit</governor>
          <dependent id="19">incident</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">submit</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">barred</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">submit</governor>
          <dependent id="22">barred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">law</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">barred</governor>
          <dependent id="24">law</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">filing</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">barred</governor>
          <dependent id="26">filing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">lawsuit</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">filing</governor>
          <dependent id="28">lawsuit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six-month" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="six-month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="15" string="four" id_sentence="1" />
      <mentions>
        <mention ids_tokens="17" string="it" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17" string="the Ventura County district attorney 's office in four separate incidents" id_sentence="1" />
      <mentions>
        <mention ids_tokens="9-13" string="the district attorney's office" id_sentence="2" />
        <mention ids_tokens="8-9" string="the office" id_sentence="8" />
        <mention ids_tokens="11-12" string="his office" id_sentence="9" />
        <mention ids_tokens="1-5" string="The district attorney's office" id_sentence="11" />
        <mention ids_tokens="16-20" string="the district attorney's office" id_sentence="21" />
        <mention ids_tokens="2-6" string="the district attorney's office" id_sentence="33" />
        <mention ids_tokens="1-5" string="The district attorney's office" id_sentence="45" />
        <mention ids_tokens="1-5" string="The district attorney's office" id_sentence="56" />
        <mention ids_tokens="1-5" string="The district attorney's office" id_sentence="68" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="the Ventura County district attorney 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="9-12" string="the district attorney's" id_sentence="2" />
        <mention ids_tokens="22-25" string="the district attorney's" id_sentence="10" />
        <mention ids_tokens="1-4" string="The district attorney's" id_sentence="11" />
        <mention ids_tokens="10-13" string="the district attorney's" id_sentence="14" />
        <mention ids_tokens="16-19" string="the district attorney's" id_sentence="21" />
        <mention ids_tokens="2-5" string="the district attorney's" id_sentence="33" />
        <mention ids_tokens="1-4" string="The district attorney's" id_sentence="45" />
        <mention ids_tokens="1-4" string="The district attorney's" id_sentence="56" />
        <mention ids_tokens="1-4" string="The district attorney's" id_sentence="68" />
        <mention ids_tokens="18" string="his" id_sentence="68" />
        <mention ids_tokens="25" string="him" id_sentence="68" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="17-18" string="the suspects" id_sentence="8" />
      <mentions>
        <mention ids_tokens="22-43" string="suspects who contended that they were victims of police brutality while being arrested for various offenses by Oxnard officers , records show" id_sentence="1" />
        <mention ids_tokens="6" string="our" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="the Oxnard officers" id_sentence="13" />
      <mentions>
        <mention ids_tokens="39-40" string="Oxnard officers" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="1" string="Police" id_sentence="32" />
      <mentions>
        <mention ids_tokens="43-44" string="Oxnard police" id_sentence="2" />
        <mention ids_tokens="24-25" string="Oxnard police" id_sentence="8" />
        <mention ids_tokens="20" string="she" id_sentence="11" />
        <mention ids_tokens="17" string="she" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="3-4" string="Anthony Flores" id_sentence="3" />
      <mentions>
        <mention ids_tokens="5" string="Flores" id_sentence="19" />
        <mention ids_tokens="1" string="Flores" id_sentence="20" />
        <mention ids_tokens="3" string="his" id_sentence="20" />
        <mention ids_tokens="4" string="Flores" id_sentence="21" />
        <mention ids_tokens="27-35" string="Flores on the five misdemeanor counts of resisting arrest" id_sentence="21" />
        <mention ids_tokens="7-8" string="Flores'" id_sentence="50" />
        <mention ids_tokens="19" string="his" id_sentence="50" />
        <mention ids_tokens="2-3" string="Flores'" id_sentence="51" />
        <mention ids_tokens="1" string="Flores" id_sentence="53" />
        <mention ids_tokens="17" string="him" id_sentence="53" />
        <mention ids_tokens="8" string="Flores" id_sentence="54" />
        <mention ids_tokens="14-18" string="Flores in a &quot; choke-hold" id_sentence="54" />
        <mention ids_tokens="1" string="Flores" id_sentence="55" />
        <mention ids_tokens="9" string="Flores" id_sentence="56" />
        <mention ids_tokens="16-17" string="Flores'" id_sentence="56" />
        <mention ids_tokens="3" string="Flores" id_sentence="57" />
        <mention ids_tokens="11" string="he" id_sentence="57" />
        <mention ids_tokens="3" string="Flores" id_sentence="58" />
        <mention ids_tokens="9" string="he" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="29-30-31-32-33-34-35" string="the five misdemeanor counts of resisting arrest" id_sentence="21" />
      <mentions>
        <mention ids_tokens="11-16" string="five misdemeanor counts of resisting arrest" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="three of the five incidents" id_sentence="4" />
      <mentions>
        <mention ids_tokens="12" string="three" id_sentence="46" />
        <mention ids_tokens="30" string="three" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="19-20" string="the department" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3-5" string="the department's" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="6-7" string="unspecified damages" id_sentence="5" />
      <mentions>
        <mention ids_tokens="11" string="damages" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="10-11" string="medical expenses" id_sentence="71" />
      <mentions>
        <mention ids_tokens="9-12" string="medical and legal expenses" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="8-9" string="an investigation" id_sentence="6" />
      <mentions>
        <mention ids_tokens="13-14" string="the investigation" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17" string="the Police Department 's internal affairs division" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3-8" string="the department's internal affairs division" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="11-12-13-14" string="the Police Department 's" id_sentence="6" />
      <mentions>
        <mention ids_tokens="14-15" string="Police Department" id_sentence="48" />
        <mention ids_tokens="1-3" string="The Police Department" id_sentence="50" />
        <mention ids_tokens="17" string="it" id_sentence="50" />
        <mention ids_tokens="4-6" string="the Police Department" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Deputy Dist ." id_sentence="7" />
      <mentions>
        <mention ids_tokens="23-24" string="Deputy Dist" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="2-3" string="Edward Brodie" id_sentence="8" />
      <mentions>
        <mention ids_tokens="8" string="Brodie" id_sentence="9" />
        <mention ids_tokens="11" string="Brodie" id_sentence="32" />
        <mention ids_tokens="27" string="Brodie" id_sentence="33" />
        <mention ids_tokens="14" string="Brodie" id_sentence="45" />
        <mention ids_tokens="33" string="Brodie" id_sentence="68" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="the most appropriate charges" id_sentence="22" />
      <mentions>
        <mention ids_tokens="28-29" string="the charges" id_sentence="9" />
        <mention ids_tokens="9" string="charges" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="30-31-32-33-34-35-36" string="a suspect who is accused by police" id_sentence="10" />
      <mentions>
        <mention ids_tokens="15-16" string="the suspect" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Assistant Police Chief William Kady" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="14" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="18" string="he" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="The latest incident involving an accusation of police brutality" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="18" />
        <mention ids_tokens="10-11" string="the incident" id_sentence="24" />
        <mention ids_tokens="18-19" string="the incident" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="4-5" string="four officers" id_sentence="18" />
      <mentions>
        <mention ids_tokens="30-31" string="the officers" id_sentence="20" />
        <mention ids_tokens="33" string="them" id_sentence="20" />
        <mention ids_tokens="3-4" string="the officers" id_sentence="52" />
        <mention ids_tokens="7-8" string="the officers" id_sentence="57" />
        <mention ids_tokens="2" string="They" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="A police report" id_sentence="19" />
      <mentions>
        <mention ids_tokens="13-15" string="the police report" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="9-10" string="an officer" id_sentence="21" />
      <mentions>
        <mention ids_tokens="9-10" string="the officer" id_sentence="44" />
        <mention ids_tokens="1-2" string="The officer" id_sentence="49" />
        <mention ids_tokens="4" string="him" id_sentence="49" />
        <mention ids_tokens="10" string="him" id_sentence="49" />
        <mention ids_tokens="2-3" string="The officer" id_sentence="63" />
        <mention ids_tokens="21" string="his" id_sentence="63" />
        <mention ids_tokens="2" string="he" id_sentence="64" />
        <mention ids_tokens="4-5" string="the officer" id_sentence="64" />
        <mention ids_tokens="7" string="he" id_sentence="64" />
        <mention ids_tokens="14" string="him" id_sentence="64" />
        <mention ids_tokens="16" string="he" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="22-23-24" string="two weeks later" id_sentence="21" />
      <mentions>
        <mention ids_tokens="18-19" string="two weeks" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Atty. Donald Gran" id_sentence="23" />
      <mentions>
        <mention ids_tokens="4" string="my" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="Police Chief Robert Owens" id_sentence="24" />
      <mentions>
        <mention ids_tokens="1" string="Owens" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="7-8-9" string="Sergio E. Gonzalez" id_sentence="25" />
      <mentions>
        <mention ids_tokens="8" string="Gonzalez" id_sentence="26" />
        <mention ids_tokens="10" string="he" id_sentence="26" />
        <mention ids_tokens="1" string="Gonzalez" id_sentence="27" />
        <mention ids_tokens="13" string="he" id_sentence="27" />
        <mention ids_tokens="22" string="his" id_sentence="27" />
        <mention ids_tokens="8" string="Gonzalez" id_sentence="28" />
        <mention ids_tokens="5" string="Gonzalez" id_sentence="30" />
        <mention ids_tokens="13" string="Gonzalez" id_sentence="31" />
        <mention ids_tokens="16" string="Gonzalez" id_sentence="31" />
        <mention ids_tokens="20" string="Gonzalez" id_sentence="33" />
        <mention ids_tokens="3" string="Gonzalez" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="a police dog" id_sentence="25" />
      <mentions>
        <mention ids_tokens="17-18" string="the dog" id_sentence="26" />
        <mention ids_tokens="20" string="him" id_sentence="26" />
        <mention ids_tokens="23" string="him" id_sentence="26" />
        <mention ids_tokens="10-11" string="the dog" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Edward M. Fox" id_sentence="28" />
      <mentions>
        <mention ids_tokens="1" string="Fox" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="44" type="PROPER">
      <referenced ids_tokens="9-10" string="Michael Cole" id_sentence="29" />
      <mentions>
        <mention ids_tokens="1-2" string="Cole's" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10" string="a police report filed by Officer Michael Cole" id_sentence="29" />
      <mentions>
        <mention ids_tokens="1-3" string="Cole's report" id_sentence="30" />
        <mention ids_tokens="1-2" string="The report" id_sentence="31" />
        <mention ids_tokens="4-5" string="the report" id_sentence="38" />
        <mention ids_tokens="11-12" string="the report" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21-22-23" string="a parking lot outside the Oxnard Moose Lodge" id_sentence="29" />
      <mentions>
        <mention ids_tokens="10-12" string="the parking lot" id_sentence="30" />
        <mention ids_tokens="18-20" string="the parking lot" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="29-30-31-32-33" string="an altercation between several men" id_sentence="29" />
      <mentions>
        <mention ids_tokens="24-25" string="the altercation" id_sentence="33" />
        <mention ids_tokens="3-4" string="the altercation" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="6-7-8" string="Louis M. Cornett" id_sentence="35" />
      <mentions>
        <mention ids_tokens="1" string="Cornett" id_sentence="36" />
        <mention ids_tokens="7" string="he" id_sentence="36" />
        <mention ids_tokens="10" string="Cornett" id_sentence="37" />
        <mention ids_tokens="9" string="Cornett" id_sentence="38" />
        <mention ids_tokens="3" string="Cornett" id_sentence="39" />
        <mention ids_tokens="4-5" string="Cornett's" id_sentence="40" />
        <mention ids_tokens="17" string="Cornett" id_sentence="43" />
        <mention ids_tokens="1" string="Cornett" id_sentence="44" />
        <mention ids_tokens="5" string="he" id_sentence="44" />
        <mention ids_tokens="13" string="he" id_sentence="44" />
        <mention ids_tokens="11" string="Cornett" id_sentence="45" />
        <mention ids_tokens="24" string="Cornett" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="50" type="NOMINAL">
      <referenced ids_tokens="29-30-31" string="Oxnard police headquarters" id_sentence="35" />
      <mentions>
        <mention ids_tokens="12-13" string="police headquarters" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="51" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Officer Robert Camarillo" id_sentence="37" />
      <mentions>
        <mention ids_tokens="1" string="Camarillo" id_sentence="38" />
        <mention ids_tokens="7" string="he" id_sentence="38" />
        <mention ids_tokens="1" string="Camarillo" id_sentence="39" />
        <mention ids_tokens="2" string="he" id_sentence="40" />
        <mention ids_tokens="8" string="Camarillo" id_sentence="40" />
        <mention ids_tokens="11" string="he" id_sentence="40" />
        <mention ids_tokens="1" string="Camarillo" id_sentence="41" />
        <mention ids_tokens="4" string="he" id_sentence="41" />
        <mention ids_tokens="22" string="his" id_sentence="41" />
        <mention ids_tokens="5" string="Camarillo" id_sentence="42" />
        <mention ids_tokens="22" string="Camarillo" id_sentence="42" />
        <mention ids_tokens="2" string="He" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="52" type="NOMINAL">
      <referenced ids_tokens="24-25" string="a weapon" id_sentence="37" />
      <mentions>
        <mention ids_tokens="13-14" string="the weapon" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="28-29" string="the mouth" id_sentence="42" />
      <mentions>
        <mention ids_tokens="6-10" string="the mouth once , twice" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="57" type="PROPER">
      <referenced ids_tokens="6-7" string="Alejandro Guzman-Flores" id_sentence="46" />
      <mentions>
        <mention ids_tokens="1" string="Guzman-Flores" id_sentence="47" />
        <mention ids_tokens="3" string="he" id_sentence="47" />
        <mention ids_tokens="18" string="his" id_sentence="47" />
        <mention ids_tokens="27" string="Guzman-Flores" id_sentence="48" />
        <mention ids_tokens="17" string="Guzman-Flores" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="58" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20" string="three Oxnard officers of beating him on his face" id_sentence="46" />
      <mentions>
        <mention ids_tokens="15" string="officers" id_sentence="51" />
        <mention ids_tokens="34" string="officers" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="19-20" string="his face" id_sentence="46" />
      <mentions>
        <mention ids_tokens="29-30" string="my face" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="60" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10" string="a motorcycle repair shop" id_sentence="47" />
      <mentions>
        <mention ids_tokens="18-19" string="the shop" id_sentence="51" />
        <mention ids_tokens="39-41" string="the motorcycle shop" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="62" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32-33-34-35-36-37-38-39" string="the alley behind the shop in the 1500 block of South Pine Street" id_sentence="47" />
      <mentions>
        <mention ids_tokens="39-40" string="the alley" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="63" type="PROPER">
      <referenced ids_tokens="18-19" string="Jana Younger" id_sentence="48" />
      <mentions>
        <mention ids_tokens="12" string="Younger" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="64" type="PROPER">
      <referenced ids_tokens="21-22" string="Fred Sedillos" id_sentence="48" />
      <mentions>
        <mention ids_tokens="11" string="Sedillos" id_sentence="53" />
        <mention ids_tokens="1" string="Sedillos" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="66" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25" string="a suit filed against the city Nov. 14 , 1989 , the Police Department and officers Jana Younger , Fred Sedillos and James Struck" id_sentence="48" />
      <mentions>
        <mention ids_tokens="20-21" string="the suit" id_sentence="49" />
        <mention ids_tokens="21-22" string="the suit" id_sentence="53" />
        <mention ids_tokens="21-22" string="the suit" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="67" type="NOMINAL">
      <referenced ids_tokens="6-7" string="a baton" id_sentence="49" />
      <mentions>
        <mention ids_tokens="21-22" string="his baton" id_sentence="63" />
      </mentions>
    </coreference>
    <coreference id="68" type="PROPER">
      <referenced ids_tokens="6-7-8" string="Sherrie L. McCracken" id_sentence="51" />
      <mentions>
        <mention ids_tokens="1" string="McCracken" id_sentence="52" />
        <mention ids_tokens="43" string="McCracken" id_sentence="56" />
        <mention ids_tokens="1" string="McCracken" id_sentence="57" />
        <mention ids_tokens="1" string="McCracken" id_sentence="58" />
        <mention ids_tokens="9" string="him" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="69" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="a &quot; choke-hold" id_sentence="54" />
      <mentions>
        <mention ids_tokens="15-16" string="the choke-hold" id_sentence="57" />
        <mention ids_tokens="14" string="she" id_sentence="59" />
      </mentions>
    </coreference>
    <coreference id="70" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="Flores ' trial" id_sentence="56" />
      <mentions>
        <mention ids_tokens="18-19" string="his trial" id_sentence="68" />
      </mentions>
    </coreference>
    <coreference id="71" type="PROPER">
      <referenced ids_tokens="5-6-7" string="Luis C. Luna" id_sentence="60" />
      <mentions>
        <mention ids_tokens="1" string="Luna" id_sentence="61" />
        <mention ids_tokens="7" string="he" id_sentence="61" />
        <mention ids_tokens="9" string="his" id_sentence="61" />
        <mention ids_tokens="1-12" string="Luna , a public works inspector for the city of Port Hueneme" id_sentence="62" />
        <mention ids_tokens="1" string="Luna" id_sentence="62" />
        <mention ids_tokens="3-12" string="a public works inspector for the city of Port Hueneme" id_sentence="62" />
        <mention ids_tokens="15" string="he" id_sentence="62" />
        <mention ids_tokens="34" string="he" id_sentence="62" />
        <mention ids_tokens="28" string="Luna" id_sentence="63" />
        <mention ids_tokens="37" string="Luna" id_sentence="66" />
        <mention ids_tokens="1" string="Luna" id_sentence="67" />
        <mention ids_tokens="9" string="Luna" id_sentence="68" />
        <mention ids_tokens="11-12" string="Luna's" id_sentence="69" />
        <mention ids_tokens="2" string="Luna" id_sentence="70" />
        <mention ids_tokens="9" string="him" id_sentence="70" />
        <mention ids_tokens="1" string="Luna" id_sentence="71" />
        <mention ids_tokens="1" string="He" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="73" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37" string="a complaint filed with the city on June 27 , 1989 , that he was beaten by three officers near a restaurant in Port Hueneme" id_sentence="60" />
      <mentions>
        <mention ids_tokens="31-32" string="the complaint" id_sentence="63" />
        <mention ids_tokens="23-24" string="the complaint" id_sentence="64" />
        <mention ids_tokens="13-14" string="the complaint" id_sentence="65" />
        <mention ids_tokens="40-41" string="the complaint" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="74" type="NOMINAL">
      <referenced ids_tokens="30-31-32-33-34-35-36-37" string="three officers near a restaurant in Port Hueneme" id_sentence="60" />
      <mentions>
        <mention ids_tokens="19-21" string="the officers'" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="75" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37" string="a restaurant in Port Hueneme" id_sentence="60" />
      <mentions>
        <mention ids_tokens="16-17" string="the restaurant" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="76" type="NOMINAL">
      <referenced ids_tokens="25-26-27-28" string="an Oxnard police car" id_sentence="61" />
      <mentions>
        <mention ids_tokens="19-21" string="the police car" id_sentence="62" />
      </mentions>
    </coreference>
    <coreference id="77" type="PROPER">
      <referenced ids_tokens="24-25-26-27-28-29-30-31" string="Officer Peter Ruggiero &quot; in a kidding manner" id_sentence="62" />
      <mentions>
        <mention ids_tokens="12" string="Ruggiero" id_sentence="64" />
        <mention ids_tokens="11" string="Ruggiero" id_sentence="65" />
      </mentions>
    </coreference>
    <coreference id="79" type="LIST">
      <referenced ids_tokens="1-2-3-4-5-6" string="Officers Steven Vendt and Humberto Jimenez" id_sentence="65" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="66" />
      </mentions>
    </coreference>
  </coreferences>
</document>
