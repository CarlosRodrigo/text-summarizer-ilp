<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06311092">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Robert Maxwell, the flamboyant billionaire who built a global publishing empire, was found dead Tuesday in waters off the Canary Islands, where he had been vacationing on his yacht Authorities said Maxwell, 68, who earlier this year had bought the New York Daily News, vanished overnight from the 180-foot Lady Ghislaine.</content>
      <tokens>
        <token id="1" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="flamboyant" lemma="flamboyant" stem="flamboy" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="billionaire" lemma="billionaire" stem="billionair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="built" lemma="build" stem="built" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="global" lemma="global" stem="global" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="empire" lemma="empire" stem="empir" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="waters" lemma="water" stem="water" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Canary" lemma="Canary" stem="canari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Islands" lemma="Islands" stem="island" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="vacationing" lemma="vacation" stem="vacat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="yacht" lemma="yacht" stem="yacht" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="68" lemma="68" stem="68" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="41" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="42" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="43" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="44" string="bought" lemma="buy" stem="bought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="47" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="48" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="49" string="News" lemma="News" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="50" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="vanished" lemma="vanish" stem="vanish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="overnight" lemma="overnight" stem="overnight" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="53" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="180-foot" lemma="180-foot" stem="180-foot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="Lady" lemma="lady" stem="ladi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="Ghislaine" lemma="Ghislaine" stem="ghislain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="58" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NNP Robert) (NNP Maxwell)) (, ,) (NP (NP (DT the) (JJ flamboyant) (NN billionaire)) (SBAR (WHNP (WP who)) (S (VP (VBD built) (NP (DT a) (JJ global) (NN publishing) (NN empire)))))) (, ,)) (VP (VBD was) (VP (VBN found) (NP-TMP (JJ dead) (NNP Tuesday)) (PP (IN in) (NP (NNS waters))) (PP (IN off) (NP (NP (DT the) (NNP Canary) (NNPS Islands)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP he)) (VP (VBD had) (VP (VBN been) (NP (NP (VBG vacationing)) (PP (IN on) (NP (PRP$ his) (NN yacht) (NNS Authorities))))))))))))) (VP (VBD said) (SBAR (S (NP (NP (NNP Maxwell)) (, ,) (NP (CD 68)) (, ,) (SBAR (WHNP (WP who)) (S (NP-TMP (RBR earlier) (DT this) (NN year)) (VP (VBD had) (VP (VBN bought) (NP (DT the) (NNP New) (NNP York) (NNP Daily) (NNP News)))))) (, ,)) (VP (VBD vanished) (ADVP (RB overnight)) (PP (IN from) (NP (DT the) (JJ 180-foot) (NN Lady))))))) (NP (NNP Ghislaine)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Maxwell , 68 , who earlier this year had bought the New York Daily News ," type="NP">
          <tokens>
            <token id="35" string="Maxwell" />
            <token id="36" string="," />
            <token id="37" string="68" />
            <token id="38" string="," />
            <token id="39" string="who" />
            <token id="40" string="earlier" />
            <token id="41" string="this" />
            <token id="42" string="year" />
            <token id="43" string="had" />
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
            <token id="50" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="his yacht Authorities" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="3" string="vanished overnight from the 180-foot Lady" type="VP">
          <tokens>
            <token id="51" string="vanished" />
            <token id="52" string="overnight" />
            <token id="53" string="from" />
            <token id="54" string="the" />
            <token id="55" string="180-foot" />
            <token id="56" string="Lady" />
          </tokens>
        </chunking>
        <chunking id="4" string="waters" type="NP">
          <tokens>
            <token id="19" string="waters" />
          </tokens>
        </chunking>
        <chunking id="5" string="said Maxwell , 68 , who earlier this year had bought the New York Daily News , vanished overnight from the 180-foot Lady" type="VP">
          <tokens>
            <token id="34" string="said" />
            <token id="35" string="Maxwell" />
            <token id="36" string="," />
            <token id="37" string="68" />
            <token id="38" string="," />
            <token id="39" string="who" />
            <token id="40" string="earlier" />
            <token id="41" string="this" />
            <token id="42" string="year" />
            <token id="43" string="had" />
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
            <token id="50" string="," />
            <token id="51" string="vanished" />
            <token id="52" string="overnight" />
            <token id="53" string="from" />
            <token id="54" string="the" />
            <token id="55" string="180-foot" />
            <token id="56" string="Lady" />
          </tokens>
        </chunking>
        <chunking id="6" string="found dead Tuesday in waters off the Canary Islands , where he had been vacationing on his yacht Authorities" type="VP">
          <tokens>
            <token id="15" string="found" />
            <token id="16" string="dead" />
            <token id="17" string="Tuesday" />
            <token id="18" string="in" />
            <token id="19" string="waters" />
            <token id="20" string="off" />
            <token id="21" string="the" />
            <token id="22" string="Canary" />
            <token id="23" string="Islands" />
            <token id="24" string="," />
            <token id="25" string="where" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="7" string="been vacationing on his yacht Authorities" type="VP">
          <tokens>
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="8" string="had bought the New York Daily News" type="VP">
          <tokens>
            <token id="43" string="had" />
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
          </tokens>
        </chunking>
        <chunking id="9" string="had been vacationing on his yacht Authorities" type="VP">
          <tokens>
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="10" string="vacationing" type="NP">
          <tokens>
            <token id="29" string="vacationing" />
          </tokens>
        </chunking>
        <chunking id="11" string="Maxwell , 68 , who earlier this year had bought the New York Daily News , vanished overnight from the 180-foot Lady" type="SBAR">
          <tokens>
            <token id="35" string="Maxwell" />
            <token id="36" string="," />
            <token id="37" string="68" />
            <token id="38" string="," />
            <token id="39" string="who" />
            <token id="40" string="earlier" />
            <token id="41" string="this" />
            <token id="42" string="year" />
            <token id="43" string="had" />
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
            <token id="50" string="," />
            <token id="51" string="vanished" />
            <token id="52" string="overnight" />
            <token id="53" string="from" />
            <token id="54" string="the" />
            <token id="55" string="180-foot" />
            <token id="56" string="Lady" />
          </tokens>
        </chunking>
        <chunking id="12" string="who earlier this year had bought the New York Daily News" type="SBAR">
          <tokens>
            <token id="39" string="who" />
            <token id="40" string="earlier" />
            <token id="41" string="this" />
            <token id="42" string="year" />
            <token id="43" string="had" />
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
          </tokens>
        </chunking>
        <chunking id="13" string="the flamboyant billionaire who built a global publishing empire" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="flamboyant" />
            <token id="6" string="billionaire" />
            <token id="7" string="who" />
            <token id="8" string="built" />
            <token id="9" string="a" />
            <token id="10" string="global" />
            <token id="11" string="publishing" />
            <token id="12" string="empire" />
          </tokens>
        </chunking>
        <chunking id="14" string="bought the New York Daily News" type="VP">
          <tokens>
            <token id="44" string="bought" />
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="vacationing on his yacht Authorities" type="NP">
          <tokens>
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="17" string="built a global publishing empire" type="VP">
          <tokens>
            <token id="8" string="built" />
            <token id="9" string="a" />
            <token id="10" string="global" />
            <token id="11" string="publishing" />
            <token id="12" string="empire" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Canary Islands" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Canary" />
            <token id="23" string="Islands" />
          </tokens>
        </chunking>
        <chunking id="19" string="Ghislaine" type="NP">
          <tokens>
            <token id="57" string="Ghislaine" />
          </tokens>
        </chunking>
        <chunking id="20" string="was found dead Tuesday in waters off the Canary Islands , where he had been vacationing on his yacht Authorities" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="found" />
            <token id="16" string="dead" />
            <token id="17" string="Tuesday" />
            <token id="18" string="in" />
            <token id="19" string="waters" />
            <token id="20" string="off" />
            <token id="21" string="the" />
            <token id="22" string="Canary" />
            <token id="23" string="Islands" />
            <token id="24" string="," />
            <token id="25" string="where" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="21" string="the New York Daily News" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
          </tokens>
        </chunking>
        <chunking id="22" string="68" type="NP">
          <tokens>
            <token id="37" string="68" />
          </tokens>
        </chunking>
        <chunking id="23" string="Maxwell" type="NP">
          <tokens>
            <token id="35" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="24" string="where he had been vacationing on his yacht Authorities" type="SBAR">
          <tokens>
            <token id="25" string="where" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="25" string="who built a global publishing empire" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="built" />
            <token id="9" string="a" />
            <token id="10" string="global" />
            <token id="11" string="publishing" />
            <token id="12" string="empire" />
          </tokens>
        </chunking>
        <chunking id="26" string="Robert Maxwell" type="NP">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="27" string="where" type="WHADVP">
          <tokens>
            <token id="25" string="where" />
          </tokens>
        </chunking>
        <chunking id="28" string="the 180-foot Lady" type="NP">
          <tokens>
            <token id="54" string="the" />
            <token id="55" string="180-foot" />
            <token id="56" string="Lady" />
          </tokens>
        </chunking>
        <chunking id="29" string="the Canary Islands , where he had been vacationing on his yacht Authorities" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Canary" />
            <token id="23" string="Islands" />
            <token id="24" string="," />
            <token id="25" string="where" />
            <token id="26" string="he" />
            <token id="27" string="had" />
            <token id="28" string="been" />
            <token id="29" string="vacationing" />
            <token id="30" string="on" />
            <token id="31" string="his" />
            <token id="32" string="yacht" />
            <token id="33" string="Authorities" />
          </tokens>
        </chunking>
        <chunking id="30" string="the flamboyant billionaire" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="flamboyant" />
            <token id="6" string="billionaire" />
          </tokens>
        </chunking>
        <chunking id="31" string="Robert Maxwell , the flamboyant billionaire who built a global publishing empire ," type="NP">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Maxwell" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="flamboyant" />
            <token id="6" string="billionaire" />
            <token id="7" string="who" />
            <token id="8" string="built" />
            <token id="9" string="a" />
            <token id="10" string="global" />
            <token id="11" string="publishing" />
            <token id="12" string="empire" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="32" string="a global publishing empire" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="global" />
            <token id="11" string="publishing" />
            <token id="12" string="empire" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Maxwell</governor>
          <dependent id="1">Robert</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">found</governor>
          <dependent id="2">Maxwell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">billionaire</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">billionaire</governor>
          <dependent id="5">flamboyant</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Maxwell</governor>
          <dependent id="6">billionaire</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">built</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">billionaire</governor>
          <dependent id="8">built</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">empire</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">empire</governor>
          <dependent id="10">global</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">empire</governor>
          <dependent id="11">publishing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">built</governor>
          <dependent id="12">empire</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">found</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">said</governor>
          <dependent id="15">found</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Tuesday</governor>
          <dependent id="16">dead</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="15">found</governor>
          <dependent id="17">Tuesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">waters</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">found</governor>
          <dependent id="19">waters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Islands</governor>
          <dependent id="20">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Islands</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Islands</governor>
          <dependent id="22">Canary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">found</governor>
          <dependent id="23">Islands</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">vacationing</governor>
          <dependent id="25">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">vacationing</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">vacationing</governor>
          <dependent id="27">had</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">vacationing</governor>
          <dependent id="28">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">Islands</governor>
          <dependent id="29">vacationing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Authorities</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">Authorities</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Authorities</governor>
          <dependent id="32">yacht</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">vacationing</governor>
          <dependent id="33">Authorities</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="34">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="51">vanished</governor>
          <dependent id="35">Maxwell</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Maxwell</governor>
          <dependent id="37">68</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">bought</governor>
          <dependent id="39">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">year</governor>
          <dependent id="40">earlier</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">year</governor>
          <dependent id="41">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="44">bought</governor>
          <dependent id="42">year</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="44">bought</governor>
          <dependent id="43">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">Maxwell</governor>
          <dependent id="44">bought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">News</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">News</governor>
          <dependent id="46">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">News</governor>
          <dependent id="47">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">News</governor>
          <dependent id="48">Daily</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="44">bought</governor>
          <dependent id="49">News</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="34">said</governor>
          <dependent id="51">vanished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="51">vanished</governor>
          <dependent id="52">overnight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="56">Lady</governor>
          <dependent id="53">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="56">Lady</governor>
          <dependent id="54">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="56">Lady</governor>
          <dependent id="55">180-foot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">vanished</governor>
          <dependent id="56">Lady</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">said</governor>
          <dependent id="57">Ghislaine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York Daily News" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="46" string="New" />
            <token id="47" string="York" />
            <token id="48" string="Daily" />
            <token id="49" string="News" />
          </tokens>
        </entity>
        <entity id="2" string="Canary Islands" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Canary" />
            <token id="23" string="Islands" />
          </tokens>
        </entity>
        <entity id="3" string="68" type="NUMBER" score="0.0">
          <tokens>
            <token id="37" string="68" />
          </tokens>
        </entity>
        <entity id="4" string="earlier this year" type="DATE" score="0.0">
          <tokens>
            <token id="40" string="earlier" />
            <token id="41" string="this" />
            <token id="42" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="overnight" type="TIME" score="0.0">
          <tokens>
            <token id="52" string="overnight" />
          </tokens>
        </entity>
        <entity id="6" string="Robert Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="7" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="8" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="9" string="Ghislaine" type="PERSON" score="0.0">
          <tokens>
            <token id="57" string="Ghislaine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>His unclothed body was found several hours later.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="unclothed" lemma="unclothed" stem="uncloth" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ His) (JJ unclothed) (NN body)) (VP (VBD was) (VP (VBN found) (NP (JJ several) (NNS hours)) (ADVP (RB later)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="His unclothed body" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="unclothed" />
            <token id="3" string="body" />
          </tokens>
        </chunking>
        <chunking id="2" string="several hours" type="NP">
          <tokens>
            <token id="6" string="several" />
            <token id="7" string="hours" />
          </tokens>
        </chunking>
        <chunking id="3" string="was found several hours later" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="found" />
            <token id="6" string="several" />
            <token id="7" string="hours" />
            <token id="8" string="later" />
          </tokens>
        </chunking>
        <chunking id="4" string="found several hours later" type="VP">
          <tokens>
            <token id="5" string="found" />
            <token id="6" string="several" />
            <token id="7" string="hours" />
            <token id="8" string="later" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">body</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">body</governor>
          <dependent id="2">unclothed</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">found</governor>
          <dependent id="3">body</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">found</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">found</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">hours</governor>
          <dependent id="6">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">found</governor>
          <dependent id="7">hours</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">found</governor>
          <dependent id="8">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="several hours later" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="several" />
            <token id="7" string="hours" />
            <token id="8" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Maxwell&amp;apost;s death ended the reign of a contentious media baron who battled unions, barked out orders in eight languages and bullied editors as he built a $2 billion media conglomerate &amp;quot;He was larger than life . . . the Citizen Kane of his time,&amp;quot; said British Conservative Party lawmaker Anthony Beaumont-Dark, referring to Orson Welles&amp;apost; classic movie about a publishing baron, presumed to have been William Randolph Hearst.</content>
      <tokens>
        <token id="1" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reign" lemma="reign" stem="reign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="contentious" lemma="contentious" stem="contenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="baron" lemma="baron" stem="baron" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="battled" lemma="battle" stem="battl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="unions" lemma="union" stem="union" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="barked" lemma="bark" stem="bark" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="orders" lemma="order" stem="order" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="languages" lemma="language" stem="languag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="bullied" lemma="bully" stem="bulli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="editors" lemma="editor" stem="editor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="built" lemma="build" stem="built" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="30" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="31" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="32" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="conglomerate" lemma="conglomerate" stem="conglomer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="larger" lemma="larger" stem="larger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Citizen" lemma="Citizen" stem="citizen" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="Kane" lemma="Kane" stem="kane" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="British" lemma="British" stem="british" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="51" string="Conservative" lemma="Conservative" stem="conserv" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="52" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="53" string="lawmaker" lemma="lawmaker" stem="lawmak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="Anthony" lemma="Anthony" stem="anthoni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="55" string="Beaumont-Dark" lemma="Beaumont-Dark" stem="beaumont-dark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="56" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="referring" lemma="refer" stem="refer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="Orson" lemma="Orson" stem="orson" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="60" string="Welles" lemma="Welles" stem="well" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="61" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="classic" lemma="classic" stem="classic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="67" string="baron" lemma="baron" stem="baron" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="presumed" lemma="presume" stem="presum" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="72" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="74" string="Randolph" lemma="Randolph" stem="randolph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="75" string="Hearst" lemma="Hearst" stem="hearst" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="76" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NNP Maxwell) (POS 's)) (NN death)) (VP (VBD ended) (NP (NP (DT the) (NN reign)) (PP (IN of) (NP (NP (DT a) (JJ contentious) (NNS media) (NN baron)) (SBAR (WHNP (WP who)) (S (VP (VP (VBD battled) (NP (NNS unions))) (, ,) (VP (VBD barked) (PRT (RP out)) (NP (NP (NNS orders)) (PP (IN in) (NP (CD eight) (NNS languages))))) (CC and) (VP (VBD bullied) (NP (NNS editors)) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD built) (NP (NP (NP (DT a) (ADJP (QP ($ $) (CD 2) (CD billion))) (NNS media) (NN conglomerate)) (SBAR (`` ``) (S (NP (PRP He)) (VP (VBD was) (ADJP (JJR larger)) (PP (IN than) (NP (NN life))))))) (: ...) (NP (NP (DT the) (NNP Citizen) (NNP Kane)) (PP (IN of) (NP (PRP$ his) (NN time))))))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP British) (NNP Conservative) (NNP Party) (NN lawmaker) (NNP Anthony) (NNP Beaumont-Dark)) (, ,) (S (VP (VBG referring) (PP (TO to) (NP (NP (NP (NNP Orson) (NNP Welles) (POS ')) (JJ classic) (NN movie)) (PP (IN about) (NP (DT a) (NN publishing) (NN baron))) (, ,) (VP (VBN presumed) (S (VP (TO to) (VP (VB have) (VP (VBN been) (NP (NNP William) (NNP Randolph) (NNP Hearst))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a $ 2 billion media conglomerate `` He was larger than life" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="been William Randolph Hearst" type="VP">
          <tokens>
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="3" string="who battled unions , barked out orders in eight languages and bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="battled" />
            <token id="14" string="unions" />
            <token id="15" string="," />
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
            <token id="22" string="and" />
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="unions" type="NP">
          <tokens>
            <token id="14" string="unions" />
          </tokens>
        </chunking>
        <chunking id="5" string="built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="VP">
          <tokens>
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="presumed to have been William Randolph Hearst" type="VP">
          <tokens>
            <token id="69" string="presumed" />
            <token id="70" string="to" />
            <token id="71" string="have" />
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="7" string="ended the reign of a contentious media baron who battled unions , barked out orders in eight languages and bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="VP">
          <tokens>
            <token id="4" string="ended" />
            <token id="5" string="the" />
            <token id="6" string="reign" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="contentious" />
            <token id="10" string="media" />
            <token id="11" string="baron" />
            <token id="12" string="who" />
            <token id="13" string="battled" />
            <token id="14" string="unions" />
            <token id="15" string="," />
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
            <token id="22" string="and" />
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="VP">
          <tokens>
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="Maxwell 's" type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="the reign" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="reign" />
          </tokens>
        </chunking>
        <chunking id="11" string="eight languages" type="NP">
          <tokens>
            <token id="20" string="eight" />
            <token id="21" string="languages" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` He was larger than life" type="SBAR">
          <tokens>
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
          </tokens>
        </chunking>
        <chunking id="13" string="referring to Orson Welles ' classic movie about a publishing baron , presumed to have been William Randolph Hearst" type="VP">
          <tokens>
            <token id="57" string="referring" />
            <token id="58" string="to" />
            <token id="59" string="Orson" />
            <token id="60" string="Welles" />
            <token id="61" string="'" />
            <token id="62" string="classic" />
            <token id="63" string="movie" />
            <token id="64" string="about" />
            <token id="65" string="a" />
            <token id="66" string="publishing" />
            <token id="67" string="baron" />
            <token id="68" string="," />
            <token id="69" string="presumed" />
            <token id="70" string="to" />
            <token id="71" string="have" />
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="14" string="$ 2 billion" type="ADJP">
          <tokens>
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
          </tokens>
        </chunking>
        <chunking id="15" string="a publishing baron" type="NP">
          <tokens>
            <token id="65" string="a" />
            <token id="66" string="publishing" />
            <token id="67" string="baron" />
          </tokens>
        </chunking>
        <chunking id="16" string="orders" type="NP">
          <tokens>
            <token id="18" string="orders" />
          </tokens>
        </chunking>
        <chunking id="17" string="battled unions" type="VP">
          <tokens>
            <token id="13" string="battled" />
            <token id="14" string="unions" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="barked out orders in eight languages" type="VP">
          <tokens>
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
          </tokens>
        </chunking>
        <chunking id="20" string="larger" type="ADJP">
          <tokens>
            <token id="37" string="larger" />
          </tokens>
        </chunking>
        <chunking id="21" string="orders in eight languages" type="NP">
          <tokens>
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
          </tokens>
        </chunking>
        <chunking id="22" string="a contentious media baron" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="contentious" />
            <token id="10" string="media" />
            <token id="11" string="baron" />
          </tokens>
        </chunking>
        <chunking id="23" string="Orson Welles ' classic movie" type="NP">
          <tokens>
            <token id="59" string="Orson" />
            <token id="60" string="Welles" />
            <token id="61" string="'" />
            <token id="62" string="classic" />
            <token id="63" string="movie" />
          </tokens>
        </chunking>
        <chunking id="24" string="the Citizen Kane of his time" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="25" string="his time" type="NP">
          <tokens>
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="26" string="British Conservative Party lawmaker Anthony Beaumont-Dark" type="NP">
          <tokens>
            <token id="50" string="British" />
            <token id="51" string="Conservative" />
            <token id="52" string="Party" />
            <token id="53" string="lawmaker" />
            <token id="54" string="Anthony" />
            <token id="55" string="Beaumont-Dark" />
          </tokens>
        </chunking>
        <chunking id="27" string="a $ 2 billion media conglomerate" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
          </tokens>
        </chunking>
        <chunking id="28" string="life" type="NP">
          <tokens>
            <token id="39" string="life" />
          </tokens>
        </chunking>
        <chunking id="29" string="a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="30" string="have been William Randolph Hearst" type="VP">
          <tokens>
            <token id="71" string="have" />
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="31" string="Maxwell 's death" type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
            <token id="3" string="death" />
          </tokens>
        </chunking>
        <chunking id="32" string="as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="SBAR">
          <tokens>
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="33" string="the Citizen Kane" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
          </tokens>
        </chunking>
        <chunking id="34" string="Orson Welles ' classic movie about a publishing baron , presumed to have been William Randolph Hearst" type="NP">
          <tokens>
            <token id="59" string="Orson" />
            <token id="60" string="Welles" />
            <token id="61" string="'" />
            <token id="62" string="classic" />
            <token id="63" string="movie" />
            <token id="64" string="about" />
            <token id="65" string="a" />
            <token id="66" string="publishing" />
            <token id="67" string="baron" />
            <token id="68" string="," />
            <token id="69" string="presumed" />
            <token id="70" string="to" />
            <token id="71" string="have" />
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="35" string="the reign of a contentious media baron who battled unions , barked out orders in eight languages and bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="reign" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="contentious" />
            <token id="10" string="media" />
            <token id="11" string="baron" />
            <token id="12" string="who" />
            <token id="13" string="battled" />
            <token id="14" string="unions" />
            <token id="15" string="," />
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
            <token id="22" string="and" />
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="36" string="Orson Welles '" type="NP">
          <tokens>
            <token id="59" string="Orson" />
            <token id="60" string="Welles" />
            <token id="61" string="'" />
          </tokens>
        </chunking>
        <chunking id="37" string="to have been William Randolph Hearst" type="VP">
          <tokens>
            <token id="70" string="to" />
            <token id="71" string="have" />
            <token id="72" string="been" />
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="38" string="William Randolph Hearst" type="NP">
          <tokens>
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </chunking>
        <chunking id="39" string="a contentious media baron who battled unions , barked out orders in eight languages and bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="contentious" />
            <token id="10" string="media" />
            <token id="11" string="baron" />
            <token id="12" string="who" />
            <token id="13" string="battled" />
            <token id="14" string="unions" />
            <token id="15" string="," />
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
            <token id="22" string="and" />
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="40" string="He" type="NP">
          <tokens>
            <token id="35" string="He" />
          </tokens>
        </chunking>
        <chunking id="41" string="battled unions , barked out orders in eight languages and bullied editors as he built a $ 2 billion media conglomerate `` He was larger than life ... the Citizen Kane of his time" type="VP">
          <tokens>
            <token id="13" string="battled" />
            <token id="14" string="unions" />
            <token id="15" string="," />
            <token id="16" string="barked" />
            <token id="17" string="out" />
            <token id="18" string="orders" />
            <token id="19" string="in" />
            <token id="20" string="eight" />
            <token id="21" string="languages" />
            <token id="22" string="and" />
            <token id="23" string="bullied" />
            <token id="24" string="editors" />
            <token id="25" string="as" />
            <token id="26" string="he" />
            <token id="27" string="built" />
            <token id="28" string="a" />
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
            <token id="32" string="media" />
            <token id="33" string="conglomerate" />
            <token id="34" string="&quot;" />
            <token id="35" string="He" />
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
            <token id="40" string=". . ." />
            <token id="41" string="the" />
            <token id="42" string="Citizen" />
            <token id="43" string="Kane" />
            <token id="44" string="of" />
            <token id="45" string="his" />
            <token id="46" string="time" />
          </tokens>
        </chunking>
        <chunking id="42" string="editors" type="NP">
          <tokens>
            <token id="24" string="editors" />
          </tokens>
        </chunking>
        <chunking id="43" string="was larger than life" type="VP">
          <tokens>
            <token id="36" string="was" />
            <token id="37" string="larger" />
            <token id="38" string="than" />
            <token id="39" string="life" />
          </tokens>
        </chunking>
        <chunking id="44" string="said" type="VP">
          <tokens>
            <token id="49" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">death</governor>
          <dependent id="1">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Maxwell</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">ended</governor>
          <dependent id="3">death</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="49">said</governor>
          <dependent id="4">ended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">reign</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">ended</governor>
          <dependent id="6">reign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">baron</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">baron</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">baron</governor>
          <dependent id="9">contentious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">baron</governor>
          <dependent id="10">media</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">reign</governor>
          <dependent id="11">baron</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">battled</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">baron</governor>
          <dependent id="13">battled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">battled</governor>
          <dependent id="14">unions</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">battled</governor>
          <dependent id="16">barked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">barked</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">barked</governor>
          <dependent id="18">orders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">languages</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">languages</governor>
          <dependent id="20">eight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">orders</governor>
          <dependent id="21">languages</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">battled</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">battled</governor>
          <dependent id="23">bullied</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">bullied</governor>
          <dependent id="24">editors</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">built</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">built</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">bullied</governor>
          <dependent id="27">built</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">conglomerate</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">conglomerate</governor>
          <dependent id="29">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">billion</governor>
          <dependent id="30">2</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">$</governor>
          <dependent id="31">billion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">conglomerate</governor>
          <dependent id="32">media</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">built</governor>
          <dependent id="33">conglomerate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">larger</governor>
          <dependent id="35">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="37">larger</governor>
          <dependent id="36">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">conglomerate</governor>
          <dependent id="37">larger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">life</governor>
          <dependent id="38">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">larger</governor>
          <dependent id="39">life</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">Kane</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Kane</governor>
          <dependent id="42">Citizen</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">conglomerate</governor>
          <dependent id="43">Kane</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">time</governor>
          <dependent id="44">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">time</governor>
          <dependent id="45">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">Kane</governor>
          <dependent id="46">time</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="49">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Beaumont-Dark</governor>
          <dependent id="50">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Beaumont-Dark</governor>
          <dependent id="51">Conservative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Beaumont-Dark</governor>
          <dependent id="52">Party</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Beaumont-Dark</governor>
          <dependent id="53">lawmaker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">Beaumont-Dark</governor>
          <dependent id="54">Anthony</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="49">said</governor>
          <dependent id="55">Beaumont-Dark</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="49">said</governor>
          <dependent id="57">referring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">movie</governor>
          <dependent id="58">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="60">Welles</governor>
          <dependent id="59">Orson</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="63">movie</governor>
          <dependent id="60">Welles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="60">Welles</governor>
          <dependent id="61">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="63">movie</governor>
          <dependent id="62">classic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="57">referring</governor>
          <dependent id="63">movie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="67">baron</governor>
          <dependent id="64">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="67">baron</governor>
          <dependent id="65">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">baron</governor>
          <dependent id="66">publishing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="63">movie</governor>
          <dependent id="67">baron</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="63">movie</governor>
          <dependent id="69">presumed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="75">Hearst</governor>
          <dependent id="70">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="75">Hearst</governor>
          <dependent id="71">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="75">Hearst</governor>
          <dependent id="72">been</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="75">Hearst</governor>
          <dependent id="73">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="75">Hearst</governor>
          <dependent id="74">Randolph</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="69">presumed</governor>
          <dependent id="75">Hearst</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 2 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="29" string="$" />
            <token id="30" string="2" />
            <token id="31" string="billion" />
          </tokens>
        </entity>
        <entity id="2" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="3" string="William Randolph Hearst" type="PERSON" score="0.0">
          <tokens>
            <token id="73" string="William" />
            <token id="74" string="Randolph" />
            <token id="75" string="Hearst" />
          </tokens>
        </entity>
        <entity id="4" string="Anthony Beaumont-Dark" type="PERSON" score="0.0">
          <tokens>
            <token id="54" string="Anthony" />
            <token id="55" string="Beaumont-Dark" />
          </tokens>
        </entity>
        <entity id="5" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="eight" />
          </tokens>
        </entity>
        <entity id="6" string="British Conservative Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="50" string="British" />
            <token id="51" string="Conservative" />
            <token id="52" string="Party" />
          </tokens>
        </entity>
        <entity id="7" string="Kane" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Kane" />
          </tokens>
        </entity>
        <entity id="8" string="Orson Welles" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="59" string="Orson" />
            <token id="60" string="Welles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>&amp;quot;If you wrote a film about his life, it would be rejected as unrealistic.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="rejected" lemma="reject" stem="reject" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="unrealistic" lemma="unrealistic" stem="unrealist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP you)) (VP (VBD wrote) (NP (DT a) (NN film)) (PP (IN about) (NP (PRP$ his) (NN life)))))) (, ,) (NP (PRP it)) (VP (MD would) (VP (VB be) (VP (VBN rejected) (PP (IN as) (ADJP (JJ unrealistic)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="wrote a film about his life" type="VP">
          <tokens>
            <token id="4" string="wrote" />
            <token id="5" string="a" />
            <token id="6" string="film" />
            <token id="7" string="about" />
            <token id="8" string="his" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="his life" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="would be rejected as unrealistic" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="rejected" />
            <token id="15" string="as" />
            <token id="16" string="unrealistic" />
          </tokens>
        </chunking>
        <chunking id="4" string="unrealistic" type="ADJP">
          <tokens>
            <token id="16" string="unrealistic" />
          </tokens>
        </chunking>
        <chunking id="5" string="rejected as unrealistic" type="VP">
          <tokens>
            <token id="14" string="rejected" />
            <token id="15" string="as" />
            <token id="16" string="unrealistic" />
          </tokens>
        </chunking>
        <chunking id="6" string="If you wrote a film about his life" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="wrote" />
            <token id="5" string="a" />
            <token id="6" string="film" />
            <token id="7" string="about" />
            <token id="8" string="his" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="a film" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="film" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="be rejected as unrealistic" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="rejected" />
            <token id="15" string="as" />
            <token id="16" string="unrealistic" />
          </tokens>
        </chunking>
        <chunking id="10" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">wrote</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">wrote</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">rejected</governor>
          <dependent id="4">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">film</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">wrote</governor>
          <dependent id="6">film</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">life</governor>
          <dependent id="7">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">life</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">wrote</governor>
          <dependent id="9">life</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">rejected</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">rejected</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">rejected</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">rejected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">unrealistic</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">rejected</governor>
          <dependent id="16">unrealistic</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>; A labor union leader once said Maxwell &amp;quot;could charm the birds out of the trees.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="labor" lemma="labor" stem="labor" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="4" string="union" lemma="union" stem="union" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="charm" lemma="charm" stem="charm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="birds" lemma="bird" stem="bird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="trees" lemma="tree" stem="tree" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (DT A) (NN labor) (NN union) (NN leader)) (ADVP (RB once)) (VP (VBD said) (SBAR (S (NP (NNP Maxwell)) (`` ``) (VP (MD could) (VP (NN charm) (NP (DT the) (NNS birds)) (ADVP (IN out) (PP (IN of) (NP (DT the) (NNS trees))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the trees" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="trees" />
          </tokens>
        </chunking>
        <chunking id="2" string="A labor union leader" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="labor" />
            <token id="4" string="union" />
            <token id="5" string="leader" />
          </tokens>
        </chunking>
        <chunking id="3" string="Maxwell `` could charm the birds out of the trees" type="SBAR">
          <tokens>
            <token id="8" string="Maxwell" />
            <token id="9" string="&quot;" />
            <token id="10" string="could" />
            <token id="11" string="charm" />
            <token id="12" string="the" />
            <token id="13" string="birds" />
            <token id="14" string="out" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="trees" />
          </tokens>
        </chunking>
        <chunking id="4" string="charm the birds out of the trees" type="VP">
          <tokens>
            <token id="11" string="charm" />
            <token id="12" string="the" />
            <token id="13" string="birds" />
            <token id="14" string="out" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="trees" />
          </tokens>
        </chunking>
        <chunking id="5" string="said Maxwell `` could charm the birds out of the trees" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="Maxwell" />
            <token id="9" string="&quot;" />
            <token id="10" string="could" />
            <token id="11" string="charm" />
            <token id="12" string="the" />
            <token id="13" string="birds" />
            <token id="14" string="out" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="trees" />
          </tokens>
        </chunking>
        <chunking id="6" string="Maxwell" type="NP">
          <tokens>
            <token id="8" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="7" string="the birds" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="birds" />
          </tokens>
        </chunking>
        <chunking id="8" string="could charm the birds out of the trees" type="VP">
          <tokens>
            <token id="10" string="could" />
            <token id="11" string="charm" />
            <token id="12" string="the" />
            <token id="13" string="birds" />
            <token id="14" string="out" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="trees" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">leader</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">leader</governor>
          <dependent id="3">labor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">leader</governor>
          <dependent id="4">union</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="5">leader</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">said</governor>
          <dependent id="6">once</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">charm</governor>
          <dependent id="8">Maxwell</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">charm</governor>
          <dependent id="10">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">charm</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">birds</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">charm</governor>
          <dependent id="13">birds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">trees</governor>
          <dependent id="14">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">out</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">trees</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">charm</governor>
          <dependent id="17">trees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="labor" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="3" string="labor" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="once" />
          </tokens>
        </entity>
        <entity id="3" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Maxwell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>And then shoot them.&amp;quot;</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="shoot" lemma="shoot" stem="shoot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (RB then)) (VP (VB shoot) (NP (PRP them))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="shoot them" type="VP">
          <tokens>
            <token id="3" string="shoot" />
            <token id="4" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="4" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">shoot</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">shoot</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">shoot</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">shoot</governor>
          <dependent id="4">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>; The Czechoslovak-born Maxwell, who escaped the Holocaust and emigrated to Britain in 1940, personally ran his publishing empire, often making minute-to-minute decisions.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Czechoslovak-born" lemma="czechoslovak-born" stem="czechoslovak-born" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="escaped" lemma="escape" stem="escap" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Holocaust" lemma="Holocaust" stem="holocaust" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="emigrated" lemma="emigrate" stem="emigr" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="1940" lemma="1940" stem="1940" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="personally" lemma="personally" stem="person" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="empire" lemma="empire" stem="empir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="minute-to-minute" lemma="minute-to-minute" stem="minute-to-minut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (DT The) (JJ Czechoslovak-born) (NNP Maxwell)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBD escaped) (NP (DT the) (NNP Holocaust))) (CC and) (VP (VBD emigrated) (PP (TO to) (NP (NNP Britain))) (PP (IN in) (NP (CD 1940))))))) (, ,)) (VP (ADVP (RB personally)) (VBD ran) (NP (PRP$ his) (NN publishing) (NN empire)) (, ,) (S (VP (ADVP (RB often)) (VBG making) (NP (JJ minute-to-minute) (NNS decisions))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="escaped the Holocaust and emigrated to Britain in 1940" type="VP">
          <tokens>
            <token id="7" string="escaped" />
            <token id="8" string="the" />
            <token id="9" string="Holocaust" />
            <token id="10" string="and" />
            <token id="11" string="emigrated" />
            <token id="12" string="to" />
            <token id="13" string="Britain" />
            <token id="14" string="in" />
            <token id="15" string="1940" />
          </tokens>
        </chunking>
        <chunking id="2" string="escaped the Holocaust" type="VP">
          <tokens>
            <token id="7" string="escaped" />
            <token id="8" string="the" />
            <token id="9" string="Holocaust" />
          </tokens>
        </chunking>
        <chunking id="3" string="minute-to-minute decisions" type="NP">
          <tokens>
            <token id="25" string="minute-to-minute" />
            <token id="26" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="4" string="emigrated to Britain in 1940" type="VP">
          <tokens>
            <token id="11" string="emigrated" />
            <token id="12" string="to" />
            <token id="13" string="Britain" />
            <token id="14" string="in" />
            <token id="15" string="1940" />
          </tokens>
        </chunking>
        <chunking id="5" string="personally ran his publishing empire , often making minute-to-minute decisions" type="VP">
          <tokens>
            <token id="17" string="personally" />
            <token id="18" string="ran" />
            <token id="19" string="his" />
            <token id="20" string="publishing" />
            <token id="21" string="empire" />
            <token id="22" string="," />
            <token id="23" string="often" />
            <token id="24" string="making" />
            <token id="25" string="minute-to-minute" />
            <token id="26" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="13" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Czechoslovak-born Maxwell" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="Czechoslovak-born" />
            <token id="4" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="8" string="his publishing empire" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="publishing" />
            <token id="21" string="empire" />
          </tokens>
        </chunking>
        <chunking id="9" string="who escaped the Holocaust and emigrated to Britain in 1940" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="escaped" />
            <token id="8" string="the" />
            <token id="9" string="Holocaust" />
            <token id="10" string="and" />
            <token id="11" string="emigrated" />
            <token id="12" string="to" />
            <token id="13" string="Britain" />
            <token id="14" string="in" />
            <token id="15" string="1940" />
          </tokens>
        </chunking>
        <chunking id="10" string="1940" type="NP">
          <tokens>
            <token id="15" string="1940" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Czechoslovak-born Maxwell , who escaped the Holocaust and emigrated to Britain in 1940 ," type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="Czechoslovak-born" />
            <token id="4" string="Maxwell" />
            <token id="5" string="," />
            <token id="6" string="who" />
            <token id="7" string="escaped" />
            <token id="8" string="the" />
            <token id="9" string="Holocaust" />
            <token id="10" string="and" />
            <token id="11" string="emigrated" />
            <token id="12" string="to" />
            <token id="13" string="Britain" />
            <token id="14" string="in" />
            <token id="15" string="1940" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="the Holocaust" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Holocaust" />
          </tokens>
        </chunking>
        <chunking id="13" string="often making minute-to-minute decisions" type="VP">
          <tokens>
            <token id="23" string="often" />
            <token id="24" string="making" />
            <token id="25" string="minute-to-minute" />
            <token id="26" string="decisions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">Maxwell</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Maxwell</governor>
          <dependent id="3">Czechoslovak-born</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">ran</governor>
          <dependent id="4">Maxwell</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">escaped</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">Maxwell</governor>
          <dependent id="7">escaped</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Holocaust</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">escaped</governor>
          <dependent id="9">Holocaust</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">escaped</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">escaped</governor>
          <dependent id="11">emigrated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Britain</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">emigrated</governor>
          <dependent id="13">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">1940</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">emigrated</governor>
          <dependent id="15">1940</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">ran</governor>
          <dependent id="17">personally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">ran</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">empire</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">empire</governor>
          <dependent id="20">publishing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">ran</governor>
          <dependent id="21">empire</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">making</governor>
          <dependent id="23">often</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">ran</governor>
          <dependent id="24">making</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">decisions</governor>
          <dependent id="25">minute-to-minute</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">making</governor>
          <dependent id="26">decisions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1940" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1940" />
          </tokens>
        </entity>
        <entity id="2" string="Czechoslovak-born" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Czechoslovak-born" />
          </tokens>
        </entity>
        <entity id="3" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="4" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Maxwell&amp;apost;s sons, Kevin, 32, and Ian, 35, took over running the businesses Tuesday &amp;quot;What normal people consider pressure was meat and drink to Robert Maxwell,&amp;quot; said Charles Wilson, editorial director of Maxwell&amp;apost;s Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News, one of the nation&amp;apost;s largest metropolitan papers Among Maxwell&amp;apost;s assets were the Macmillan publishing house in New York, Britain&amp;apost;s No. 2 paper, the Daily Mirror, The Daily Record, and The European and British Printing &amp;amp;amp; Communications Corp., Britain&amp;apost;s largest printing company On the steps of Mirror Group Newspapers in London, Ian Maxwell told reporters the moment was tragic not only for his family but also for Maxwell&amp;apost;s thousands of employees.</content>
      <tokens>
        <token id="1" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="sons" lemma="son" stem="son" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Kevin" lemma="Kevin" stem="kevin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="32" lemma="32" stem="32" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ian" lemma="Ian" stem="ian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="businesses" lemma="business" stem="busi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="normal" lemma="normal" stem="normal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="consider" lemma="consider" stem="consid" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="pressure" lemma="pressure" stem="pressur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="drink" lemma="drink" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="editorial" lemma="editorial" stem="editori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="43" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="44" string="Mirror" lemma="Mirror" stem="mirror" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="45" string="Group" lemma="Group" stem="group" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="46" string="Newspapers" lemma="Newspapers" stem="newspap" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="47" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="49" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="immediate" lemma="immediate" stem="immedi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="54" string="financial" lemma="financial" stem="financi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="circles" lemma="circle" stem="circl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="58" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="59" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="61" string="debt-laden" lemma="debt-laden" stem="debt-laden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="empire" lemma="empire" stem="empir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="66" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="67" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="68" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="69" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="70" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="71" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="72" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="73" string="News" lemma="News" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="74" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="75" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="76" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="77" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="78" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="79" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="80" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="81" string="metropolitan" lemma="metropolitan" stem="metropolitan" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="82" string="papers" lemma="papers" stem="paper" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="83" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="84" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="85" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="86" string="assets" lemma="asset" stem="asset" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="87" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="88" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="89" string="Macmillan" lemma="Macmillan" stem="macmillan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="90" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="91" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="92" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="93" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="94" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="95" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="96" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="97" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="98" string="No." lemma="no." stem="no." pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="99" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="100" string="paper" lemma="paper" stem="paper" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="101" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="102" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="103" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="104" string="Mirror" lemma="Mirror" stem="mirror" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="105" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="106" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="107" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="108" string="Record" lemma="Record" stem="record" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="109" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="110" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="111" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="112" string="European" lemma="european" stem="european" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="113" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="114" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="115" string="Printing" lemma="Printing" stem="print" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="116" string="&amp;amp;" lemma="&amp;" stem="&amp;amp;" pos="CC" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="117" string="Communications" lemma="Communications" stem="commun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="118" string="Corp." lemma="Corp." stem="corp." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="119" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="120" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="121" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="122" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="123" string="printing" lemma="print" stem="print" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="124" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="125" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="126" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="127" string="steps" lemma="step" stem="step" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="128" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="129" string="Mirror" lemma="Mirror" stem="mirror" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="130" string="Group" lemma="Group" stem="group" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="131" string="Newspapers" lemma="Newspapers" stem="newspap" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="132" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="133" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="134" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="135" string="Ian" lemma="Ian" stem="ian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="136" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="137" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="138" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="139" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="140" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="141" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="142" string="tragic" lemma="tragic" stem="tragic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="143" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="144" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="145" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="146" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="147" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="148" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="149" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="150" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="151" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="152" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="153" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="154" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="155" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="156" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (NP (NP (NP (NNP Maxwell) (POS 's)) (NNS sons)) (, ,) (NP (NP (NNP Kevin)) (, ,) (NP (CD 32)) (, ,)) (CC and) (NP (NNP Ian))) (, ,) (NP (CD 35)) (, ,)) (VP (VBD took) (PRT (RP over)) (S (VP (VBG running) (NP (DT the) (NNS businesses)))) (NP-TMP (NNP Tuesday)) (SBAR (`` ``) (S (SBAR (WHNP (WP What)) (S (NP (JJ normal) (NNS people)) (VP (VBP consider) (SBAR (SINV (S (NP (NN pressure)) (VP (VBD was) (NP (NP (NN meat) (CC and) (NN drink)) (PP (TO to) (NP (NNP Robert) (NNP Maxwell)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Charles) (NNP Wilson)) (, ,) (NP (NP (NN editorial) (NN director)) (PP (IN of) (NP (NP (NNP Maxwell) (POS 's)) (NNP Mirror) (NNP Group) (NNP Newspapers))) (SBAR (S (NP (PRP$ His) (NN death)) (VP (VBD prompted) (NP (JJ immediate) (NN concern)) (PP (IN in) (NP (JJ British) (JJ financial) (NNS circles))) (PP (PP (IN about) (NP (NP (DT the) (NN future)) (PP (IN of) (NP (PRP$ his) (JJ debt-laden) (NN empire))))) (CC and) (PP (IN in) (NP (NP (NNP New) (NNP York)) (PP (IN about) (NP (NP (DT the) (NN future)) (PP (IN of) (NP (DT the) (NNP Daily) (NNP News)))))))))))))))))) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NN nation) (POS 's)) (JJS largest) (JJ metropolitan) (NNS papers)))) (PP (IN Among) (NP (NP (NNP Maxwell) (POS 's)) (NNS assets))) (VP (VBD were) (NP (NP (DT the) (NNP Macmillan) (NN publishing) (NN house)) (PP (IN in) (NP (NP (NNP New) (NNP York)) (, ,) (NP (NP (NNP Britain) (POS 's)) (NN No.) (CD 2) (NN paper)) (, ,) (NP (DT the) (NNP Daily) (NNP Mirror)) (, ,) (NP (DT The) (NNP Daily) (NNP Record)) (, ,) (CC and) (NP (DT The) (JJ European)))))))))) (CC and) (S (NP (NP (JJ British) (NNP Printing) (CC &amp;) (NNP Communications) (NNP Corp.)) (, ,) (NP (NP (NNP Britain) (POS 's)) (JJS largest))) (VP (VBG printing) (NP (NN company)))) (PP (IN On) (NP (NP (DT the) (NNS steps)) (PP (IN of) (NP (NP (NNP Mirror) (NNP Group) (NNP Newspapers)) (PP (IN in) (NP (NNP London)))))))) (, ,) (NP (NNP Ian) (NNP Maxwell)) (VP (VBD told) (NP (NP (NNS reporters)) (SBAR (S (NP (DT the) (NN moment)) (VP (VBD was) (ADJP (JJ tragic)) (PP (CONJP (RB not) (RB only)) (PP (IN for) (NP (PRP$ his) (NN family))) (CC but) (PP (ADVP (RB also)) (IN for) (NP (NP (NP (NNP Maxwell) (POS 's)) (NNS thousands)) (PP (IN of) (NP (NNS employees))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="editorial director" type="NP">
          <tokens>
            <token id="39" string="editorial" />
            <token id="40" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="Maxwell 's assets" type="NP">
          <tokens>
            <token id="84" string="Maxwell" />
            <token id="85" string="'s" />
            <token id="86" string="assets" />
          </tokens>
        </chunking>
        <chunking id="3" string="The European" type="NP">
          <tokens>
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="4" string="35" type="NP">
          <tokens>
            <token id="12" string="35" />
          </tokens>
        </chunking>
        <chunking id="5" string="normal people" type="NP">
          <tokens>
            <token id="22" string="normal" />
            <token id="23" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="one" type="NP">
          <tokens>
            <token id="75" string="one" />
          </tokens>
        </chunking>
        <chunking id="7" string="the future of his debt-laden empire" type="NP">
          <tokens>
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
          </tokens>
        </chunking>
        <chunking id="8" string="pressure" type="NP">
          <tokens>
            <token id="25" string="pressure" />
          </tokens>
        </chunking>
        <chunking id="9" string="His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="SBAR">
          <tokens>
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="10" string="the moment was tragic not only for his family but also for Maxwell 's thousands of employees" type="SBAR">
          <tokens>
            <token id="139" string="the" />
            <token id="140" string="moment" />
            <token id="141" string="was" />
            <token id="142" string="tragic" />
            <token id="143" string="not" />
            <token id="144" string="only" />
            <token id="145" string="for" />
            <token id="146" string="his" />
            <token id="147" string="family" />
            <token id="148" string="but" />
            <token id="149" string="also" />
            <token id="150" string="for" />
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
            <token id="154" string="of" />
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="11" string="Maxwell 's sons , Kevin , 32 , and Ian" type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
            <token id="3" string="sons" />
            <token id="4" string="," />
            <token id="5" string="Kevin" />
            <token id="6" string="," />
            <token id="7" string="32" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="Ian" />
          </tokens>
        </chunking>
        <chunking id="12" string="Maxwell 's" type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mirror Group Newspapers" type="NP">
          <tokens>
            <token id="129" string="Mirror" />
            <token id="130" string="Group" />
            <token id="131" string="Newspapers" />
          </tokens>
        </chunking>
        <chunking id="14" string="the future" type="NP">
          <tokens>
            <token id="57" string="the" />
            <token id="58" string="future" />
          </tokens>
        </chunking>
        <chunking id="15" string="Britain 's largest" type="NP">
          <tokens>
            <token id="120" string="Britain" />
            <token id="121" string="'s" />
            <token id="122" string="largest" />
          </tokens>
        </chunking>
        <chunking id="16" string="pressure was meat and drink to Robert Maxwell , '' said Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="SBAR">
          <tokens>
            <token id="25" string="pressure" />
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="said" />
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="17" string="running the businesses" type="VP">
          <tokens>
            <token id="16" string="running" />
            <token id="17" string="the" />
            <token id="18" string="businesses" />
          </tokens>
        </chunking>
        <chunking id="18" string="employees" type="NP">
          <tokens>
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="19" string="The Daily Record" type="NP">
          <tokens>
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
          </tokens>
        </chunking>
        <chunking id="20" string="the steps" type="NP">
          <tokens>
            <token id="126" string="the" />
            <token id="127" string="steps" />
          </tokens>
        </chunking>
        <chunking id="21" string="reporters" type="NP">
          <tokens>
            <token id="138" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="22" string="took over running the businesses Tuesday `` What normal people consider pressure was meat and drink to Robert Maxwell , '' said Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News , one of the nation 's largest metropolitan papers Among Maxwell 's assets were the Macmillan publishing house in New York , Britain 's No. 2 paper , the Daily Mirror , The Daily Record , and The European" type="VP">
          <tokens>
            <token id="14" string="took" />
            <token id="15" string="over" />
            <token id="16" string="running" />
            <token id="17" string="the" />
            <token id="18" string="businesses" />
            <token id="19" string="Tuesday" />
            <token id="20" string="&quot;" />
            <token id="21" string="What" />
            <token id="22" string="normal" />
            <token id="23" string="people" />
            <token id="24" string="consider" />
            <token id="25" string="pressure" />
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="said" />
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
            <token id="74" string="," />
            <token id="75" string="one" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="nation" />
            <token id="79" string="'s" />
            <token id="80" string="largest" />
            <token id="81" string="metropolitan" />
            <token id="82" string="papers" />
            <token id="83" string="Among" />
            <token id="84" string="Maxwell" />
            <token id="85" string="'s" />
            <token id="86" string="assets" />
            <token id="87" string="were" />
            <token id="88" string="the" />
            <token id="89" string="Macmillan" />
            <token id="90" string="publishing" />
            <token id="91" string="house" />
            <token id="92" string="in" />
            <token id="93" string="New" />
            <token id="94" string="York" />
            <token id="95" string="," />
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
            <token id="101" string="," />
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
            <token id="105" string="," />
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
            <token id="109" string="," />
            <token id="110" string="and" />
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="23" string="Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="NP">
          <tokens>
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="24" string="the future of the Daily News" type="NP">
          <tokens>
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="25" string="editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="NP">
          <tokens>
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="26" string="Maxwell 's sons" type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
            <token id="3" string="sons" />
          </tokens>
        </chunking>
        <chunking id="27" string="New York about the future of the Daily News" type="NP">
          <tokens>
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="28" string="the nation 's" type="NP">
          <tokens>
            <token id="77" string="the" />
            <token id="78" string="nation" />
            <token id="79" string="'s" />
          </tokens>
        </chunking>
        <chunking id="29" string="the moment" type="NP">
          <tokens>
            <token id="139" string="the" />
            <token id="140" string="moment" />
          </tokens>
        </chunking>
        <chunking id="30" string="Charles Wilson" type="NP">
          <tokens>
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
          </tokens>
        </chunking>
        <chunking id="31" string="the nation 's largest metropolitan papers" type="NP">
          <tokens>
            <token id="77" string="the" />
            <token id="78" string="nation" />
            <token id="79" string="'s" />
            <token id="80" string="largest" />
            <token id="81" string="metropolitan" />
            <token id="82" string="papers" />
          </tokens>
        </chunking>
        <chunking id="32" string="consider pressure was meat and drink to Robert Maxwell , '' said Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="VP">
          <tokens>
            <token id="24" string="consider" />
            <token id="25" string="pressure" />
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="said" />
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="33" string="meat and drink" type="NP">
          <tokens>
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
          </tokens>
        </chunking>
        <chunking id="34" string="His death" type="NP">
          <tokens>
            <token id="47" string="His" />
            <token id="48" string="death" />
          </tokens>
        </chunking>
        <chunking id="35" string="Robert Maxwell" type="NP">
          <tokens>
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="36" string="What normal people consider pressure was meat and drink to Robert Maxwell , '' said Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="SBAR">
          <tokens>
            <token id="21" string="What" />
            <token id="22" string="normal" />
            <token id="23" string="people" />
            <token id="24" string="consider" />
            <token id="25" string="pressure" />
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="said" />
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="37" string="company" type="NP">
          <tokens>
            <token id="124" string="company" />
          </tokens>
        </chunking>
        <chunking id="38" string="tragic" type="ADJP">
          <tokens>
            <token id="142" string="tragic" />
          </tokens>
        </chunking>
        <chunking id="39" string="said" type="VP">
          <tokens>
            <token id="35" string="said" />
          </tokens>
        </chunking>
        <chunking id="40" string="his family" type="NP">
          <tokens>
            <token id="146" string="his" />
            <token id="147" string="family" />
          </tokens>
        </chunking>
        <chunking id="41" string="New York" type="NP">
          <tokens>
            <token id="65" string="New" />
            <token id="66" string="York" />
          </tokens>
        </chunking>
        <chunking id="42" string="the businesses" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="businesses" />
          </tokens>
        </chunking>
        <chunking id="43" string="was meat and drink to Robert Maxwell" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="44" string="the Macmillan publishing house" type="NP">
          <tokens>
            <token id="88" string="the" />
            <token id="89" string="Macmillan" />
            <token id="90" string="publishing" />
            <token id="91" string="house" />
          </tokens>
        </chunking>
        <chunking id="45" string="New York , Britain 's No. 2 paper , the Daily Mirror , The Daily Record , and The European" type="NP">
          <tokens>
            <token id="93" string="New" />
            <token id="94" string="York" />
            <token id="95" string="," />
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
            <token id="101" string="," />
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
            <token id="105" string="," />
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
            <token id="109" string="," />
            <token id="110" string="and" />
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="46" string="Kevin" type="NP">
          <tokens>
            <token id="5" string="Kevin" />
          </tokens>
        </chunking>
        <chunking id="47" string="immediate concern" type="NP">
          <tokens>
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
          </tokens>
        </chunking>
        <chunking id="48" string="British financial circles" type="NP">
          <tokens>
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
          </tokens>
        </chunking>
        <chunking id="49" string="Ian" type="NP">
          <tokens>
            <token id="10" string="Ian" />
          </tokens>
        </chunking>
        <chunking id="50" string="Maxwell 's thousands" type="NP">
          <tokens>
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="51" string="Britain 's" type="NP">
          <tokens>
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
          </tokens>
        </chunking>
        <chunking id="52" string="London" type="NP">
          <tokens>
            <token id="133" string="London" />
          </tokens>
        </chunking>
        <chunking id="53" string="the steps of Mirror Group Newspapers in London" type="NP">
          <tokens>
            <token id="126" string="the" />
            <token id="127" string="steps" />
            <token id="128" string="of" />
            <token id="129" string="Mirror" />
            <token id="130" string="Group" />
            <token id="131" string="Newspapers" />
            <token id="132" string="in" />
            <token id="133" string="London" />
          </tokens>
        </chunking>
        <chunking id="54" string="the Daily News" type="NP">
          <tokens>
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="55" string="the Daily Mirror" type="NP">
          <tokens>
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
          </tokens>
        </chunking>
        <chunking id="56" string="told reporters the moment was tragic not only for his family but also for Maxwell 's thousands of employees" type="VP">
          <tokens>
            <token id="137" string="told" />
            <token id="138" string="reporters" />
            <token id="139" string="the" />
            <token id="140" string="moment" />
            <token id="141" string="was" />
            <token id="142" string="tragic" />
            <token id="143" string="not" />
            <token id="144" string="only" />
            <token id="145" string="for" />
            <token id="146" string="his" />
            <token id="147" string="family" />
            <token id="148" string="but" />
            <token id="149" string="also" />
            <token id="150" string="for" />
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
            <token id="154" string="of" />
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="57" string="his debt-laden empire" type="NP">
          <tokens>
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
          </tokens>
        </chunking>
        <chunking id="58" string="Mirror Group Newspapers in London" type="NP">
          <tokens>
            <token id="129" string="Mirror" />
            <token id="130" string="Group" />
            <token id="131" string="Newspapers" />
            <token id="132" string="in" />
            <token id="133" string="London" />
          </tokens>
        </chunking>
        <chunking id="59" string="prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News" type="VP">
          <tokens>
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </chunking>
        <chunking id="60" string="British Printing &amp; Communications Corp. , Britain 's largest" type="NP">
          <tokens>
            <token id="114" string="British" />
            <token id="115" string="Printing" />
            <token id="116" string="&amp;amp;" />
            <token id="117" string="Communications" />
            <token id="118" string="Corp." />
            <token id="119" string="," />
            <token id="120" string="Britain" />
            <token id="121" string="'s" />
            <token id="122" string="largest" />
          </tokens>
        </chunking>
        <chunking id="61" string="British Printing &amp; Communications Corp." type="NP">
          <tokens>
            <token id="114" string="British" />
            <token id="115" string="Printing" />
            <token id="116" string="&amp;amp;" />
            <token id="117" string="Communications" />
            <token id="118" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="62" string="reporters the moment was tragic not only for his family but also for Maxwell 's thousands of employees" type="NP">
          <tokens>
            <token id="138" string="reporters" />
            <token id="139" string="the" />
            <token id="140" string="moment" />
            <token id="141" string="was" />
            <token id="142" string="tragic" />
            <token id="143" string="not" />
            <token id="144" string="only" />
            <token id="145" string="for" />
            <token id="146" string="his" />
            <token id="147" string="family" />
            <token id="148" string="but" />
            <token id="149" string="also" />
            <token id="150" string="for" />
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
            <token id="154" string="of" />
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="63" string="Maxwell 's Mirror Group Newspapers" type="NP">
          <tokens>
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
          </tokens>
        </chunking>
        <chunking id="64" string="was tragic not only for his family but also for Maxwell 's thousands of employees" type="VP">
          <tokens>
            <token id="141" string="was" />
            <token id="142" string="tragic" />
            <token id="143" string="not" />
            <token id="144" string="only" />
            <token id="145" string="for" />
            <token id="146" string="his" />
            <token id="147" string="family" />
            <token id="148" string="but" />
            <token id="149" string="also" />
            <token id="150" string="for" />
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
            <token id="154" string="of" />
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="65" string="printing company" type="VP">
          <tokens>
            <token id="123" string="printing" />
            <token id="124" string="company" />
          </tokens>
        </chunking>
        <chunking id="66" string="one of the nation 's largest metropolitan papers" type="NP">
          <tokens>
            <token id="75" string="one" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="nation" />
            <token id="79" string="'s" />
            <token id="80" string="largest" />
            <token id="81" string="metropolitan" />
            <token id="82" string="papers" />
          </tokens>
        </chunking>
        <chunking id="67" string="Maxwell 's thousands of employees" type="NP">
          <tokens>
            <token id="151" string="Maxwell" />
            <token id="152" string="'s" />
            <token id="153" string="thousands" />
            <token id="154" string="of" />
            <token id="155" string="employees" />
          </tokens>
        </chunking>
        <chunking id="68" string="the Macmillan publishing house in New York , Britain 's No. 2 paper , the Daily Mirror , The Daily Record , and The European" type="NP">
          <tokens>
            <token id="88" string="the" />
            <token id="89" string="Macmillan" />
            <token id="90" string="publishing" />
            <token id="91" string="house" />
            <token id="92" string="in" />
            <token id="93" string="New" />
            <token id="94" string="York" />
            <token id="95" string="," />
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
            <token id="101" string="," />
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
            <token id="105" string="," />
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
            <token id="109" string="," />
            <token id="110" string="and" />
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="69" string="`` What normal people consider pressure was meat and drink to Robert Maxwell , '' said Charles Wilson , editorial director of Maxwell 's Mirror Group Newspapers His death prompted immediate concern in British financial circles about the future of his debt-laden empire and in New York about the future of the Daily News , one of the nation 's largest metropolitan papers Among Maxwell 's assets were the Macmillan publishing house in New York , Britain 's No. 2 paper , the Daily Mirror , The Daily Record , and The European" type="SBAR">
          <tokens>
            <token id="20" string="&quot;" />
            <token id="21" string="What" />
            <token id="22" string="normal" />
            <token id="23" string="people" />
            <token id="24" string="consider" />
            <token id="25" string="pressure" />
            <token id="26" string="was" />
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="said" />
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
            <token id="38" string="," />
            <token id="39" string="editorial" />
            <token id="40" string="director" />
            <token id="41" string="of" />
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
            <token id="47" string="His" />
            <token id="48" string="death" />
            <token id="49" string="prompted" />
            <token id="50" string="immediate" />
            <token id="51" string="concern" />
            <token id="52" string="in" />
            <token id="53" string="British" />
            <token id="54" string="financial" />
            <token id="55" string="circles" />
            <token id="56" string="about" />
            <token id="57" string="the" />
            <token id="58" string="future" />
            <token id="59" string="of" />
            <token id="60" string="his" />
            <token id="61" string="debt-laden" />
            <token id="62" string="empire" />
            <token id="63" string="and" />
            <token id="64" string="in" />
            <token id="65" string="New" />
            <token id="66" string="York" />
            <token id="67" string="about" />
            <token id="68" string="the" />
            <token id="69" string="future" />
            <token id="70" string="of" />
            <token id="71" string="the" />
            <token id="72" string="Daily" />
            <token id="73" string="News" />
            <token id="74" string="," />
            <token id="75" string="one" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="nation" />
            <token id="79" string="'s" />
            <token id="80" string="largest" />
            <token id="81" string="metropolitan" />
            <token id="82" string="papers" />
            <token id="83" string="Among" />
            <token id="84" string="Maxwell" />
            <token id="85" string="'s" />
            <token id="86" string="assets" />
            <token id="87" string="were" />
            <token id="88" string="the" />
            <token id="89" string="Macmillan" />
            <token id="90" string="publishing" />
            <token id="91" string="house" />
            <token id="92" string="in" />
            <token id="93" string="New" />
            <token id="94" string="York" />
            <token id="95" string="," />
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
            <token id="101" string="," />
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
            <token id="105" string="," />
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
            <token id="109" string="," />
            <token id="110" string="and" />
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="70" string="meat and drink to Robert Maxwell" type="NP">
          <tokens>
            <token id="27" string="meat" />
            <token id="28" string="and" />
            <token id="29" string="drink" />
            <token id="30" string="to" />
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="71" string="Kevin , 32 ," type="NP">
          <tokens>
            <token id="5" string="Kevin" />
            <token id="6" string="," />
            <token id="7" string="32" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="72" string="Ian Maxwell" type="NP">
          <tokens>
            <token id="135" string="Ian" />
            <token id="136" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="73" string="were the Macmillan publishing house in New York , Britain 's No. 2 paper , the Daily Mirror , The Daily Record , and The European" type="VP">
          <tokens>
            <token id="87" string="were" />
            <token id="88" string="the" />
            <token id="89" string="Macmillan" />
            <token id="90" string="publishing" />
            <token id="91" string="house" />
            <token id="92" string="in" />
            <token id="93" string="New" />
            <token id="94" string="York" />
            <token id="95" string="," />
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
            <token id="101" string="," />
            <token id="102" string="the" />
            <token id="103" string="Daily" />
            <token id="104" string="Mirror" />
            <token id="105" string="," />
            <token id="106" string="The" />
            <token id="107" string="Daily" />
            <token id="108" string="Record" />
            <token id="109" string="," />
            <token id="110" string="and" />
            <token id="111" string="The" />
            <token id="112" string="European" />
          </tokens>
        </chunking>
        <chunking id="74" string="Britain 's No. 2 paper" type="NP">
          <tokens>
            <token id="96" string="Britain" />
            <token id="97" string="'s" />
            <token id="98" string="No." />
            <token id="99" string="2" />
            <token id="100" string="paper" />
          </tokens>
        </chunking>
        <chunking id="75" string="Maxwell 's sons , Kevin , 32 , and Ian , 35 ," type="NP">
          <tokens>
            <token id="1" string="Maxwell" />
            <token id="2" string="'s" />
            <token id="3" string="sons" />
            <token id="4" string="," />
            <token id="5" string="Kevin" />
            <token id="6" string="," />
            <token id="7" string="32" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="Ian" />
            <token id="11" string="," />
            <token id="12" string="35" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="76" string="32" type="NP">
          <tokens>
            <token id="7" string="32" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">sons</governor>
          <dependent id="1">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Maxwell</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">took</governor>
          <dependent id="3">sons</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">sons</governor>
          <dependent id="5">Kevin</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Kevin</governor>
          <dependent id="7">32</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">sons</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">sons</governor>
          <dependent id="10">Ian</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">sons</governor>
          <dependent id="12">35</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="137">told</governor>
          <dependent id="14">took</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">took</governor>
          <dependent id="15">over</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">took</governor>
          <dependent id="16">running</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">businesses</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">running</governor>
          <dependent id="18">businesses</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">took</governor>
          <dependent id="19">Tuesday</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">consider</governor>
          <dependent id="21">What</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">people</governor>
          <dependent id="22">normal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">consider</governor>
          <dependent id="23">people</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="91">house</governor>
          <dependent id="24">consider</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">meat</governor>
          <dependent id="25">pressure</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">meat</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">said</governor>
          <dependent id="27">meat</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">meat</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">meat</governor>
          <dependent id="29">drink</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Maxwell</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Maxwell</governor>
          <dependent id="31">Robert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">meat</governor>
          <dependent id="32">Maxwell</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">consider</governor>
          <dependent id="35">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Wilson</governor>
          <dependent id="36">Charles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">said</governor>
          <dependent id="37">Wilson</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">director</governor>
          <dependent id="39">editorial</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">Wilson</governor>
          <dependent id="40">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Newspapers</governor>
          <dependent id="41">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">Newspapers</governor>
          <dependent id="42">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">Maxwell</governor>
          <dependent id="43">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">Newspapers</governor>
          <dependent id="44">Mirror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">Newspapers</governor>
          <dependent id="45">Group</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">director</governor>
          <dependent id="46">Newspapers</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="48">death</governor>
          <dependent id="47">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="49">prompted</governor>
          <dependent id="48">death</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="40">director</governor>
          <dependent id="49">prompted</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="49">prompted</governor>
          <dependent id="49">prompted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">concern</governor>
          <dependent id="50">immediate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="49">prompted</governor>
          <dependent id="51">concern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">circles</governor>
          <dependent id="52">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="55">circles</governor>
          <dependent id="53">British</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="55">circles</governor>
          <dependent id="54">financial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">prompted</governor>
          <dependent id="55">circles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="58">future</governor>
          <dependent id="56">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="58">future</governor>
          <dependent id="57">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">prompted</governor>
          <dependent id="58">future</dependent>
        </dependency>
        <dependency type="case">
          <governor id="62">empire</governor>
          <dependent id="59">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="62">empire</governor>
          <dependent id="60">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="62">empire</governor>
          <dependent id="61">debt-laden</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="58">future</governor>
          <dependent id="62">empire</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="49">prompted</governor>
          <dependent id="63">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="66">York</governor>
          <dependent id="64">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="66">York</governor>
          <dependent id="65">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">prompted</governor>
          <dependent id="66">York</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">future</governor>
          <dependent id="67">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="69">future</governor>
          <dependent id="68">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="66">York</governor>
          <dependent id="69">future</dependent>
        </dependency>
        <dependency type="case">
          <governor id="73">News</governor>
          <dependent id="70">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="73">News</governor>
          <dependent id="71">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="73">News</governor>
          <dependent id="72">Daily</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="69">future</governor>
          <dependent id="73">News</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="91">house</governor>
          <dependent id="75">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="82">papers</governor>
          <dependent id="76">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="78">nation</governor>
          <dependent id="77">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="82">papers</governor>
          <dependent id="78">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="78">nation</governor>
          <dependent id="79">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="82">papers</governor>
          <dependent id="80">largest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="82">papers</governor>
          <dependent id="81">metropolitan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="75">one</governor>
          <dependent id="82">papers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="86">assets</governor>
          <dependent id="83">Among</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="86">assets</governor>
          <dependent id="84">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="84">Maxwell</governor>
          <dependent id="85">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="91">house</governor>
          <dependent id="86">assets</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="91">house</governor>
          <dependent id="87">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="91">house</governor>
          <dependent id="88">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="91">house</governor>
          <dependent id="89">Macmillan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="91">house</governor>
          <dependent id="90">publishing</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">took</governor>
          <dependent id="91">house</dependent>
        </dependency>
        <dependency type="case">
          <governor id="94">York</governor>
          <dependent id="92">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="94">York</governor>
          <dependent id="93">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="91">house</governor>
          <dependent id="94">York</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="100">paper</governor>
          <dependent id="96">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="96">Britain</governor>
          <dependent id="97">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="100">paper</governor>
          <dependent id="98">No.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="100">paper</governor>
          <dependent id="99">2</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="94">York</governor>
          <dependent id="100">paper</dependent>
        </dependency>
        <dependency type="det">
          <governor id="104">Mirror</governor>
          <dependent id="102">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="104">Mirror</governor>
          <dependent id="103">Daily</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="94">York</governor>
          <dependent id="104">Mirror</dependent>
        </dependency>
        <dependency type="det">
          <governor id="108">Record</governor>
          <dependent id="106">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="108">Record</governor>
          <dependent id="107">Daily</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="94">York</governor>
          <dependent id="108">Record</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="94">York</governor>
          <dependent id="110">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="112">European</governor>
          <dependent id="111">The</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="94">York</governor>
          <dependent id="112">European</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">took</governor>
          <dependent id="113">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="115">Printing</governor>
          <dependent id="114">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="123">printing</governor>
          <dependent id="115">Printing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="115">Printing</governor>
          <dependent id="116">&amp;</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="118">Corp.</governor>
          <dependent id="117">Communications</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="115">Printing</governor>
          <dependent id="118">Corp.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="115">Printing</governor>
          <dependent id="120">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="120">Britain</governor>
          <dependent id="121">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="120">Britain</governor>
          <dependent id="122">largest</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">took</governor>
          <dependent id="123">printing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="123">printing</governor>
          <dependent id="124">company</dependent>
        </dependency>
        <dependency type="case">
          <governor id="127">steps</governor>
          <dependent id="125">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="127">steps</governor>
          <dependent id="126">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">took</governor>
          <dependent id="127">steps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="131">Newspapers</governor>
          <dependent id="128">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="131">Newspapers</governor>
          <dependent id="129">Mirror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="131">Newspapers</governor>
          <dependent id="130">Group</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="127">steps</governor>
          <dependent id="131">Newspapers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="133">London</governor>
          <dependent id="132">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="131">Newspapers</governor>
          <dependent id="133">London</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="136">Maxwell</governor>
          <dependent id="135">Ian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="137">told</governor>
          <dependent id="136">Maxwell</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="137">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="137">told</governor>
          <dependent id="138">reporters</dependent>
        </dependency>
        <dependency type="det">
          <governor id="140">moment</governor>
          <dependent id="139">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="142">tragic</governor>
          <dependent id="140">moment</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="142">tragic</governor>
          <dependent id="141">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="138">reporters</governor>
          <dependent id="142">tragic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="142">tragic</governor>
          <dependent id="142">tragic</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="144">only</governor>
          <dependent id="143">not</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="147">family</governor>
          <dependent id="144">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="147">family</governor>
          <dependent id="145">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="147">family</governor>
          <dependent id="146">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="142">tragic</governor>
          <dependent id="147">family</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="142">tragic</governor>
          <dependent id="148">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="153">thousands</governor>
          <dependent id="149">also</dependent>
        </dependency>
        <dependency type="case">
          <governor id="153">thousands</governor>
          <dependent id="150">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="153">thousands</governor>
          <dependent id="151">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="151">Maxwell</governor>
          <dependent id="152">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="142">tragic</governor>
          <dependent id="153">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="155">employees</governor>
          <dependent id="154">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="153">thousands</governor>
          <dependent id="155">employees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="65" string="New" />
            <token id="66" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="35" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="35" />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="53" string="British" />
          </tokens>
        </entity>
        <entity id="4" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="75" string="one" />
          </tokens>
        </entity>
        <entity id="5" string="Maxwell 's Mirror Group Newspapers" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="42" string="Maxwell" />
            <token id="43" string="'s" />
            <token id="44" string="Mirror" />
            <token id="45" string="Group" />
            <token id="46" string="Newspapers" />
          </tokens>
        </entity>
        <entity id="6" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="7" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="96" string="Britain" />
          </tokens>
        </entity>
        <entity id="8" string="European" type="MISC" score="0.0">
          <tokens>
            <token id="112" string="European" />
          </tokens>
        </entity>
        <entity id="9" string="On the steps of Mirror Group Newspapers" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="125" string="On" />
            <token id="126" string="the" />
            <token id="127" string="steps" />
            <token id="128" string="of" />
            <token id="129" string="Mirror" />
            <token id="130" string="Group" />
            <token id="131" string="Newspapers" />
          </tokens>
        </entity>
        <entity id="10" string="Kevin" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Kevin" />
          </tokens>
        </entity>
        <entity id="11" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="99" string="2" />
          </tokens>
        </entity>
        <entity id="12" string="Daily" type="SET" score="0.0">
          <tokens>
            <token id="103" string="Daily" />
          </tokens>
        </entity>
        <entity id="13" string="Ian" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ian" />
          </tokens>
        </entity>
        <entity id="14" string="Charles Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Charles" />
            <token id="37" string="Wilson" />
          </tokens>
        </entity>
        <entity id="15" string="Daily News" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="72" string="Daily" />
            <token id="73" string="News" />
          </tokens>
        </entity>
        <entity id="16" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="133" string="London" />
          </tokens>
        </entity>
        <entity id="17" string="Ian Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="135" string="Ian" />
            <token id="136" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="18" string="Robert Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Robert" />
            <token id="32" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="19" string="the future" type="DATE" score="0.0">
          <tokens>
            <token id="57" string="the" />
            <token id="58" string="future" />
          </tokens>
        </entity>
        <entity id="20" string="British Printing &amp;amp; Communications Corp." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="114" string="British" />
            <token id="115" string="Printing" />
            <token id="116" string="&amp;amp;" />
            <token id="117" string="Communications" />
            <token id="118" string="Corp." />
          </tokens>
        </entity>
        <entity id="21" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="22" string="Macmillan" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="89" string="Macmillan" />
          </tokens>
        </entity>
        <entity id="23" string="32" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="32" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;This paper has lost its publisher and its chairman and its savior.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="paper" lemma="paper" stem="paper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="savior" lemma="savior" stem="savior" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT This) (NN paper)) (VP (VBZ has) (VP (VBN lost) (NP (NP (PRP$ its) (NN publisher)) (CC and) (NP (NP (PRP$ its) (NN chairman)) (CC and) (NP (PRP$ its) (NN savior)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="has lost its publisher and its chairman and its savior" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="lost" />
            <token id="6" string="its" />
            <token id="7" string="publisher" />
            <token id="8" string="and" />
            <token id="9" string="its" />
            <token id="10" string="chairman" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="savior" />
          </tokens>
        </chunking>
        <chunking id="2" string="its chairman and its savior" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="chairman" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="savior" />
          </tokens>
        </chunking>
        <chunking id="3" string="its savior" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="savior" />
          </tokens>
        </chunking>
        <chunking id="4" string="lost its publisher and its chairman and its savior" type="VP">
          <tokens>
            <token id="5" string="lost" />
            <token id="6" string="its" />
            <token id="7" string="publisher" />
            <token id="8" string="and" />
            <token id="9" string="its" />
            <token id="10" string="chairman" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="savior" />
          </tokens>
        </chunking>
        <chunking id="5" string="its chairman" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="6" string="its publisher and its chairman and its savior" type="NP">
          <tokens>
            <token id="6" string="its" />
            <token id="7" string="publisher" />
            <token id="8" string="and" />
            <token id="9" string="its" />
            <token id="10" string="chairman" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="savior" />
          </tokens>
        </chunking>
        <chunking id="7" string="This paper" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="paper" />
          </tokens>
        </chunking>
        <chunking id="8" string="its publisher" type="NP">
          <tokens>
            <token id="6" string="its" />
            <token id="7" string="publisher" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">paper</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">lost</governor>
          <dependent id="3">paper</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">lost</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">publisher</governor>
          <dependent id="6">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">lost</governor>
          <dependent id="7">publisher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">publisher</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">chairman</governor>
          <dependent id="9">its</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">publisher</governor>
          <dependent id="10">chairman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">chairman</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">savior</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">chairman</governor>
          <dependent id="13">savior</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>; British Prime Minister John Major called Maxwell &amp;quot;a great character who will be missed.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="British" lemma="British" stem="british" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="Prime" lemma="Prime" stem="prime" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Minister" lemma="Minister" stem="minist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="5" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="missed" lemma="miss" stem="miss" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NNP British) (NNP Prime) (NNP Minister) (NNP John) (NNP Major)) (VP (VBD called) (NP (NP (NNP Maxwell)) (FRAG (`` ``) (NP (NP (DT a) (JJ great) (NN character)) (SBAR (WHNP (WP who)) (S (VP (MD will) (VP (VB be) (VP (VBN missed))))))) (. .) ('' '')))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Maxwell `` a great character who will be missed . ''" type="NP">
          <tokens>
            <token id="8" string="Maxwell" />
            <token id="9" string="&quot;" />
            <token id="10" string="a" />
            <token id="11" string="great" />
            <token id="12" string="character" />
            <token id="13" string="who" />
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="missed" />
            <token id="17" string="." />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="a great character who will be missed" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="great" />
            <token id="12" string="character" />
            <token id="13" string="who" />
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="missed" />
          </tokens>
        </chunking>
        <chunking id="3" string="who will be missed" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="missed" />
          </tokens>
        </chunking>
        <chunking id="4" string="a great character" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="great" />
            <token id="12" string="character" />
          </tokens>
        </chunking>
        <chunking id="5" string="called Maxwell `` a great character who will be missed . ''" type="VP">
          <tokens>
            <token id="7" string="called" />
            <token id="8" string="Maxwell" />
            <token id="9" string="&quot;" />
            <token id="10" string="a" />
            <token id="11" string="great" />
            <token id="12" string="character" />
            <token id="13" string="who" />
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="missed" />
            <token id="17" string="." />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="missed" type="VP">
          <tokens>
            <token id="16" string="missed" />
          </tokens>
        </chunking>
        <chunking id="7" string="Maxwell" type="NP">
          <tokens>
            <token id="8" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be missed" type="VP">
          <tokens>
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="missed" />
          </tokens>
        </chunking>
        <chunking id="9" string="be missed" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="missed" />
          </tokens>
        </chunking>
        <chunking id="10" string="British Prime Minister John Major" type="NP">
          <tokens>
            <token id="2" string="British" />
            <token id="3" string="Prime" />
            <token id="4" string="Minister" />
            <token id="5" string="John" />
            <token id="6" string="Major" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="6">Major</governor>
          <dependent id="2">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Major</governor>
          <dependent id="3">Prime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Major</governor>
          <dependent id="4">Minister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Major</governor>
          <dependent id="5">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">called</governor>
          <dependent id="6">Major</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">called</governor>
          <dependent id="8">Maxwell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">character</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">character</governor>
          <dependent id="11">great</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Maxwell</governor>
          <dependent id="12">character</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">missed</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">missed</governor>
          <dependent id="14">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">missed</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">character</governor>
          <dependent id="16">missed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="John" />
            <token id="6" string="Major" />
          </tokens>
        </entity>
        <entity id="3" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="4" string="Minister" type="TITLE" score="0.0">
          <tokens>
            <token id="4" string="Minister" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>; &amp;quot;Maxwell was a passionate friend of Israel, and we are sorry about this heavy tragedy,&amp;quot; Israeli Prime Minister Yitzhak Shamir said.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="passionate" lemma="passionate" stem="passion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Israel" lemma="Israel" stem="israel" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sorry" lemma="sorry" stem="sorri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="heavy" lemma="heavy" stem="heavi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="tragedy" lemma="tragedy" stem="tragedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Israeli" lemma="israeli" stem="israeli" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="Prime" lemma="Prime" stem="prime" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Minister" lemma="Minister" stem="minist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="24" string="Yitzhak" lemma="Yitzhak" stem="yitzhak" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Shamir" lemma="Shamir" stem="shamir" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (S (NP (NNP Maxwell)) (VP (VBD was) (NP (NP (DT a) (JJ passionate) (NN friend)) (PP (IN of) (NP (NNP Israel)))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP are) (ADJP (JJ sorry) (PP (IN about) (NP (DT this) (JJ heavy) (NN tragedy))))))) (, ,) ('' '') (NP (JJ Israeli) (NNP Prime) (NNP Minister) (NNP Yitzhak) (NNP Shamir)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a passionate friend" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="passionate" />
            <token id="7" string="friend" />
          </tokens>
        </chunking>
        <chunking id="2" string="Israel" type="NP">
          <tokens>
            <token id="9" string="Israel" />
          </tokens>
        </chunking>
        <chunking id="3" string="are sorry about this heavy tragedy" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="sorry" />
            <token id="15" string="about" />
            <token id="16" string="this" />
            <token id="17" string="heavy" />
            <token id="18" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="4" string="this heavy tragedy" type="NP">
          <tokens>
            <token id="16" string="this" />
            <token id="17" string="heavy" />
            <token id="18" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="5" string="Maxwell" type="NP">
          <tokens>
            <token id="3" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="6" string="a passionate friend of Israel" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="passionate" />
            <token id="7" string="friend" />
            <token id="8" string="of" />
            <token id="9" string="Israel" />
          </tokens>
        </chunking>
        <chunking id="7" string="was a passionate friend of Israel" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="a" />
            <token id="6" string="passionate" />
            <token id="7" string="friend" />
            <token id="8" string="of" />
            <token id="9" string="Israel" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="12" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="sorry about this heavy tragedy" type="ADJP">
          <tokens>
            <token id="14" string="sorry" />
            <token id="15" string="about" />
            <token id="16" string="this" />
            <token id="17" string="heavy" />
            <token id="18" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="Israeli Prime Minister Yitzhak Shamir" type="NP">
          <tokens>
            <token id="21" string="Israeli" />
            <token id="22" string="Prime" />
            <token id="23" string="Minister" />
            <token id="24" string="Yitzhak" />
            <token id="25" string="Shamir" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">friend</governor>
          <dependent id="3">Maxwell</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">friend</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">friend</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">friend</governor>
          <dependent id="6">passionate</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="7">friend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Israel</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">friend</governor>
          <dependent id="9">Israel</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">friend</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">sorry</governor>
          <dependent id="12">we</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">sorry</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">friend</governor>
          <dependent id="14">sorry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">tragedy</governor>
          <dependent id="15">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">tragedy</governor>
          <dependent id="16">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">tragedy</governor>
          <dependent id="17">heavy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">sorry</governor>
          <dependent id="18">tragedy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">Shamir</governor>
          <dependent id="21">Israeli</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Shamir</governor>
          <dependent id="22">Prime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Shamir</governor>
          <dependent id="23">Minister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Shamir</governor>
          <dependent id="24">Yitzhak</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">Shamir</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Israeli" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="Israeli" />
          </tokens>
        </entity>
        <entity id="2" string="Israel" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Israel" />
          </tokens>
        </entity>
        <entity id="3" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="4" string="Yitzhak Shamir" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Yitzhak" />
            <token id="25" string="Shamir" />
          </tokens>
        </entity>
        <entity id="5" string="Minister" type="TITLE" score="0.0">
          <tokens>
            <token id="23" string="Minister" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;God bless his memory.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="bless" lemma="bless" stem="bless" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="memory" lemma="memory" stem="memori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP God)) (VP (VB bless) (NP (PRP$ his) (NN memory))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="bless his memory" type="VP">
          <tokens>
            <token id="3" string="bless" />
            <token id="4" string="his" />
            <token id="5" string="memory" />
          </tokens>
        </chunking>
        <chunking id="2" string="his memory" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="memory" />
          </tokens>
        </chunking>
        <chunking id="3" string="God" type="NP">
          <tokens>
            <token id="2" string="God" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">bless</governor>
          <dependent id="2">God</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">bless</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">memory</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">bless</governor>
          <dependent id="5">memory</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>; His body was found 20 miles northwest of Grand Canary Island after an extensive air-and-sea search, officials at the rescue center in Madrid said.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="northwest" lemma="northwest" stem="northwest" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Grand" lemma="Grand" stem="grand" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Canary" lemma="Canary" stem="canari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Island" lemma="Island" stem="island" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="extensive" lemma="extensive" stem="extens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="air-and-sea" lemma="air-and-sea" stem="air-and-sea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="search" lemma="search" stem="search" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="rescue" lemma="rescue" stem="rescu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Madrid" lemma="Madrid" stem="madrid" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (PRP$ His) (NN body)) (VP (VBD was) (VP (VBN found) (PP (ADVP (NP (CD 20) (NNS miles)) (RB northwest)) (IN of) (NP (NNP Grand) (NNP Canary) (NNP Island))) (SBAR (IN after) (S (NP (NP (DT an) (JJ extensive) (NN air-and-sea) (NN search)) (, ,) (NP (NP (NNS officials)) (PP (IN at) (NP (NP (DT the) (NN rescue) (NN center)) (PP (IN in) (NP (NNP Madrid))))))) (VP (VBD said)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="found 20 miles northwest of Grand Canary Island after an extensive air-and-sea search , officials at the rescue center in Madrid said" type="VP">
          <tokens>
            <token id="5" string="found" />
            <token id="6" string="20" />
            <token id="7" string="miles" />
            <token id="8" string="northwest" />
            <token id="9" string="of" />
            <token id="10" string="Grand" />
            <token id="11" string="Canary" />
            <token id="12" string="Island" />
            <token id="13" string="after" />
            <token id="14" string="an" />
            <token id="15" string="extensive" />
            <token id="16" string="air-and-sea" />
            <token id="17" string="search" />
            <token id="18" string="," />
            <token id="19" string="officials" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="2" string="Grand Canary Island" type="NP">
          <tokens>
            <token id="10" string="Grand" />
            <token id="11" string="Canary" />
            <token id="12" string="Island" />
          </tokens>
        </chunking>
        <chunking id="3" string="20 miles" type="NP">
          <tokens>
            <token id="6" string="20" />
            <token id="7" string="miles" />
          </tokens>
        </chunking>
        <chunking id="4" string="was found 20 miles northwest of Grand Canary Island after an extensive air-and-sea search , officials at the rescue center in Madrid said" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="found" />
            <token id="6" string="20" />
            <token id="7" string="miles" />
            <token id="8" string="northwest" />
            <token id="9" string="of" />
            <token id="10" string="Grand" />
            <token id="11" string="Canary" />
            <token id="12" string="Island" />
            <token id="13" string="after" />
            <token id="14" string="an" />
            <token id="15" string="extensive" />
            <token id="16" string="air-and-sea" />
            <token id="17" string="search" />
            <token id="18" string="," />
            <token id="19" string="officials" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="officials at the rescue center in Madrid" type="NP">
          <tokens>
            <token id="19" string="officials" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
          </tokens>
        </chunking>
        <chunking id="6" string="the rescue center in Madrid" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
          </tokens>
        </chunking>
        <chunking id="7" string="an extensive air-and-sea search , officials at the rescue center in Madrid" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="extensive" />
            <token id="16" string="air-and-sea" />
            <token id="17" string="search" />
            <token id="18" string="," />
            <token id="19" string="officials" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
          </tokens>
        </chunking>
        <chunking id="8" string="officials" type="NP">
          <tokens>
            <token id="19" string="officials" />
          </tokens>
        </chunking>
        <chunking id="9" string="Madrid" type="NP">
          <tokens>
            <token id="25" string="Madrid" />
          </tokens>
        </chunking>
        <chunking id="10" string="an extensive air-and-sea search" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="extensive" />
            <token id="16" string="air-and-sea" />
            <token id="17" string="search" />
          </tokens>
        </chunking>
        <chunking id="11" string="after an extensive air-and-sea search , officials at the rescue center in Madrid said" type="SBAR">
          <tokens>
            <token id="13" string="after" />
            <token id="14" string="an" />
            <token id="15" string="extensive" />
            <token id="16" string="air-and-sea" />
            <token id="17" string="search" />
            <token id="18" string="," />
            <token id="19" string="officials" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
            <token id="24" string="in" />
            <token id="25" string="Madrid" />
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="the rescue center" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="rescue" />
            <token id="23" string="center" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="His body" type="NP">
          <tokens>
            <token id="2" string="His" />
            <token id="3" string="body" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">body</governor>
          <dependent id="2">His</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">found</governor>
          <dependent id="3">body</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">found</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">found</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">miles</governor>
          <dependent id="6">20</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="8">northwest</governor>
          <dependent id="7">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">Island</governor>
          <dependent id="8">northwest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Island</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Island</governor>
          <dependent id="10">Grand</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Island</governor>
          <dependent id="11">Canary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">found</governor>
          <dependent id="12">Island</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">said</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">search</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">search</governor>
          <dependent id="15">extensive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">search</governor>
          <dependent id="16">air-and-sea</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="17">search</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">search</governor>
          <dependent id="19">officials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">center</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">center</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">center</governor>
          <dependent id="22">rescue</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">officials</governor>
          <dependent id="23">center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Madrid</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">center</governor>
          <dependent id="25">Madrid</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">found</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Grand Canary Island" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Grand" />
            <token id="11" string="Canary" />
            <token id="12" string="Island" />
          </tokens>
        </entity>
        <entity id="2" string="Madrid" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Madrid" />
          </tokens>
        </entity>
        <entity id="3" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>The body was taken by helicopter to the Gando air base on Grand Canary Island, where it was identified by Maxwell&amp;apost;s wife of more than 40 years, Elizabeth, and their son, Phillip.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="helicopter" lemma="helicopter" stem="helicopt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Gando" lemma="Gando" stem="gando" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="base" lemma="base" stem="base" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Grand" lemma="Grand" stem="grand" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="Canary" lemma="Canary" stem="canari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="15" string="Island" lemma="Island" stem="island" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="identified" lemma="identify" stem="identifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="27" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="28" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="29" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="Phillip" lemma="Phillip" stem="phillip" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN body)) (VP (VBD was) (VP (VBN taken) (PP (IN by) (NP (NN helicopter))) (PP (TO to) (NP (NP (DT the) (NNP Gando) (NN air) (NN base)) (PP (IN on) (NP (NP (NNP Grand) (NNP Canary) (NNP Island)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBD was) (VP (VBN identified) (PP (IN by) (NP (NP (NP (NP (NNP Maxwell) (POS 's)) (NN wife)) (PP (IN of) (NP (NP (QP (JJR more) (IN than) (CD 40)) (NNS years)) (, ,) (NP (NNP Elizabeth)) (, ,)))) (CC and) (NP (NP (PRP$ their) (NN son)) (, ,) (NP (NNP Phillip))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="VP">
          <tokens>
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="2" string="Grand Canary Island" type="NP">
          <tokens>
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
          </tokens>
        </chunking>
        <chunking id="3" string="The body" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="body" />
          </tokens>
        </chunking>
        <chunking id="4" string="taken by helicopter to the Gando air base on Grand Canary Island , where it was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="VP">
          <tokens>
            <token id="4" string="taken" />
            <token id="5" string="by" />
            <token id="6" string="helicopter" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Gando" />
            <token id="10" string="air" />
            <token id="11" string="base" />
            <token id="12" string="on" />
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
            <token id="16" string="," />
            <token id="17" string="where" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="5" string="more than 40 years" type="NP">
          <tokens>
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="Grand Canary Island , where it was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="NP">
          <tokens>
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
            <token id="16" string="," />
            <token id="17" string="where" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Elizabeth" type="NP">
          <tokens>
            <token id="31" string="Elizabeth" />
          </tokens>
        </chunking>
        <chunking id="9" string="Maxwell 's" type="NP">
          <tokens>
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="their son , Phillip" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="11" string="more than 40 years , Elizabeth ," type="NP">
          <tokens>
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="13" string="Phillip" type="NP">
          <tokens>
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="14" string="was taken by helicopter to the Gando air base on Grand Canary Island , where it was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="taken" />
            <token id="5" string="by" />
            <token id="6" string="helicopter" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Gando" />
            <token id="10" string="air" />
            <token id="11" string="base" />
            <token id="12" string="on" />
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
            <token id="16" string="," />
            <token id="17" string="where" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="15" string="helicopter" type="NP">
          <tokens>
            <token id="6" string="helicopter" />
          </tokens>
        </chunking>
        <chunking id="16" string="Maxwell 's wife of more than 40 years , Elizabeth ," type="NP">
          <tokens>
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="Maxwell 's wife" type="NP">
          <tokens>
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
          </tokens>
        </chunking>
        <chunking id="18" string="where" type="WHADVP">
          <tokens>
            <token id="17" string="where" />
          </tokens>
        </chunking>
        <chunking id="19" string="where it was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="SBAR">
          <tokens>
            <token id="17" string="where" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Gando air base on Grand Canary Island , where it was identified by Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Gando" />
            <token id="10" string="air" />
            <token id="11" string="base" />
            <token id="12" string="on" />
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
            <token id="16" string="," />
            <token id="17" string="where" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="identified" />
            <token id="21" string="by" />
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
        <chunking id="21" string="their son" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="son" />
          </tokens>
        </chunking>
        <chunking id="22" string="the Gando air base" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Gando" />
            <token id="10" string="air" />
            <token id="11" string="base" />
          </tokens>
        </chunking>
        <chunking id="23" string="Maxwell 's wife of more than 40 years , Elizabeth , and their son , Phillip" type="NP">
          <tokens>
            <token id="22" string="Maxwell" />
            <token id="23" string="'s" />
            <token id="24" string="wife" />
            <token id="25" string="of" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
            <token id="30" string="," />
            <token id="31" string="Elizabeth" />
            <token id="32" string="," />
            <token id="33" string="and" />
            <token id="34" string="their" />
            <token id="35" string="son" />
            <token id="36" string="," />
            <token id="37" string="Phillip" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">body</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">taken</governor>
          <dependent id="2">body</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">taken</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">helicopter</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">taken</governor>
          <dependent id="6">helicopter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">base</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">base</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">base</governor>
          <dependent id="9">Gando</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">base</governor>
          <dependent id="10">air</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">taken</governor>
          <dependent id="11">base</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Island</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Island</governor>
          <dependent id="13">Grand</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Island</governor>
          <dependent id="14">Canary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">base</governor>
          <dependent id="15">Island</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">identified</governor>
          <dependent id="17">where</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">identified</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">identified</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Island</governor>
          <dependent id="20">identified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">wife</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">wife</governor>
          <dependent id="22">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Maxwell</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">identified</governor>
          <dependent id="24">wife</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">years</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">40</governor>
          <dependent id="26">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">more</governor>
          <dependent id="27">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">years</governor>
          <dependent id="28">40</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">wife</governor>
          <dependent id="29">years</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">years</governor>
          <dependent id="31">Elizabeth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">wife</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">son</governor>
          <dependent id="34">their</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">wife</governor>
          <dependent id="35">son</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">son</governor>
          <dependent id="37">Phillip</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Grand Canary Island" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Grand" />
            <token id="14" string="Canary" />
            <token id="15" string="Island" />
          </tokens>
        </entity>
        <entity id="2" string="Phillip" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Phillip" />
          </tokens>
        </entity>
        <entity id="3" string="Gando" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Gando" />
          </tokens>
        </entity>
        <entity id="4" string="more than 40 years" type="DURATION" score="0.0">
          <tokens>
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="40" />
            <token id="29" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Maxwell" />
          </tokens>
        </entity>
        <entity id="6" string="Elizabeth" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Elizabeth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>An autopsy is planned for today, and the cause of death is officially still unknown Details of Maxwell&amp;apost;s death are sketchy.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="autopsy" lemma="autopsy" stem="autopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="planned" lemma="plan" stem="plan" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="officially" lemma="officially" stem="offici" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="unknown" lemma="unknown" stem="unknown" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Details" lemma="detail" stem="detail" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="sketchy" lemma="sketchy" stem="sketchi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT An) (NN autopsy)) (VP (VBZ is) (VP (VBN planned) (PP (IN for) (NP (NN today)))))) (, ,) (CC and) (S (NP (NP (DT the) (NN cause)) (PP (IN of) (NP (NN death)))) (VP (VBZ is) (ADVP (RB officially)) (ADVP (RB still)) (SBAR (S (NP (NP (JJ unknown) (NNS Details)) (PP (IN of) (NP (NP (NNP Maxwell) (POS 's)) (NN death)))) (VP (VBP are) (ADJP (JJ sketchy))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is planned for today" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="planned" />
            <token id="5" string="for" />
            <token id="6" string="today" />
          </tokens>
        </chunking>
        <chunking id="2" string="death" type="NP">
          <tokens>
            <token id="12" string="death" />
          </tokens>
        </chunking>
        <chunking id="3" string="sketchy" type="ADJP">
          <tokens>
            <token id="23" string="sketchy" />
          </tokens>
        </chunking>
        <chunking id="4" string="are sketchy" type="VP">
          <tokens>
            <token id="22" string="are" />
            <token id="23" string="sketchy" />
          </tokens>
        </chunking>
        <chunking id="5" string="Maxwell 's" type="NP">
          <tokens>
            <token id="19" string="Maxwell" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the cause of death" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="cause" />
            <token id="11" string="of" />
            <token id="12" string="death" />
          </tokens>
        </chunking>
        <chunking id="7" string="Maxwell 's death" type="NP">
          <tokens>
            <token id="19" string="Maxwell" />
            <token id="20" string="'s" />
            <token id="21" string="death" />
          </tokens>
        </chunking>
        <chunking id="8" string="unknown Details of Maxwell 's death are sketchy" type="SBAR">
          <tokens>
            <token id="16" string="unknown" />
            <token id="17" string="Details" />
            <token id="18" string="of" />
            <token id="19" string="Maxwell" />
            <token id="20" string="'s" />
            <token id="21" string="death" />
            <token id="22" string="are" />
            <token id="23" string="sketchy" />
          </tokens>
        </chunking>
        <chunking id="9" string="unknown Details" type="NP">
          <tokens>
            <token id="16" string="unknown" />
            <token id="17" string="Details" />
          </tokens>
        </chunking>
        <chunking id="10" string="the cause" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="cause" />
          </tokens>
        </chunking>
        <chunking id="11" string="unknown Details of Maxwell 's death" type="NP">
          <tokens>
            <token id="16" string="unknown" />
            <token id="17" string="Details" />
            <token id="18" string="of" />
            <token id="19" string="Maxwell" />
            <token id="20" string="'s" />
            <token id="21" string="death" />
          </tokens>
        </chunking>
        <chunking id="12" string="today" type="NP">
          <tokens>
            <token id="6" string="today" />
          </tokens>
        </chunking>
        <chunking id="13" string="is officially still unknown Details of Maxwell 's death are sketchy" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="officially" />
            <token id="15" string="still" />
            <token id="16" string="unknown" />
            <token id="17" string="Details" />
            <token id="18" string="of" />
            <token id="19" string="Maxwell" />
            <token id="20" string="'s" />
            <token id="21" string="death" />
            <token id="22" string="are" />
            <token id="23" string="sketchy" />
          </tokens>
        </chunking>
        <chunking id="14" string="planned for today" type="VP">
          <tokens>
            <token id="4" string="planned" />
            <token id="5" string="for" />
            <token id="6" string="today" />
          </tokens>
        </chunking>
        <chunking id="15" string="An autopsy" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="autopsy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">autopsy</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">planned</governor>
          <dependent id="2">autopsy</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">planned</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">planned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">today</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">planned</governor>
          <dependent id="6">today</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">planned</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">cause</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">is</governor>
          <dependent id="10">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">death</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">cause</governor>
          <dependent id="12">death</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">planned</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">is</governor>
          <dependent id="14">officially</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">is</governor>
          <dependent id="15">still</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Details</governor>
          <dependent id="16">unknown</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">sketchy</governor>
          <dependent id="17">Details</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">death</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">death</governor>
          <dependent id="19">Maxwell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Maxwell</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">Details</governor>
          <dependent id="21">death</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">sketchy</governor>
          <dependent id="22">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">is</governor>
          <dependent id="23">sketchy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Maxwell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>He was last seen alive on the deck of his yacht at 4:45 a.m. EST, Daily News spokesman John Campi said.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="alive" lemma="alive" stem="aliv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="deck" lemma="deck" stem="deck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="yacht" lemma="yacht" stem="yacht" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="4:45" lemma="4:45" stem="4:45" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="14" string="a.m." lemma="a.m." stem="a.m." pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="15" string="EST" lemma="est" stem="est" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="18" string="News" lemma="News" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="19" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Campi" lemma="Campi" stem="campi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBD was) (ADVP (JJ last)) (VP (VBN seen) (ADJP (JJ alive) (PP (IN on) (NP (NP (DT the) (NN deck)) (PP (IN of) (NP (PRP$ his) (NN yacht)))))) (PP (IN at) (NP (CD 4:45) (NN a.m.) (NN EST)))))) (, ,) (NP (NNP Daily) (NNP News) (NN spokesman) (NNP John) (NNP Campi)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="4:45 a.m. EST" type="NP">
          <tokens>
            <token id="13" string="4:45" />
            <token id="14" string="a.m." />
            <token id="15" string="EST" />
          </tokens>
        </chunking>
        <chunking id="2" string="seen alive on the deck of his yacht at 4:45 a.m. EST" type="VP">
          <tokens>
            <token id="4" string="seen" />
            <token id="5" string="alive" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="deck" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="yacht" />
            <token id="12" string="at" />
            <token id="13" string="4:45" />
            <token id="14" string="a.m." />
            <token id="15" string="EST" />
          </tokens>
        </chunking>
        <chunking id="3" string="alive on the deck of his yacht" type="ADJP">
          <tokens>
            <token id="5" string="alive" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="deck" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="yacht" />
          </tokens>
        </chunking>
        <chunking id="4" string="the deck of his yacht" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="deck" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="yacht" />
          </tokens>
        </chunking>
        <chunking id="5" string="was last seen alive on the deck of his yacht at 4:45 a.m. EST" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="last" />
            <token id="4" string="seen" />
            <token id="5" string="alive" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="deck" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="yacht" />
            <token id="12" string="at" />
            <token id="13" string="4:45" />
            <token id="14" string="a.m." />
            <token id="15" string="EST" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="the deck" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="deck" />
          </tokens>
        </chunking>
        <chunking id="8" string="Daily News spokesman John Campi" type="NP">
          <tokens>
            <token id="17" string="Daily" />
            <token id="18" string="News" />
            <token id="19" string="spokesman" />
            <token id="20" string="John" />
            <token id="21" string="Campi" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="his yacht" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="yacht" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">seen</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">seen</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">seen</governor>
          <dependent id="3">last</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="4">seen</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">seen</governor>
          <dependent id="5">alive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">deck</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">deck</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">alive</governor>
          <dependent id="8">deck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">yacht</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">yacht</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">deck</governor>
          <dependent id="11">yacht</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">EST</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">EST</governor>
          <dependent id="13">4:45</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">EST</governor>
          <dependent id="14">a.m.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">seen</governor>
          <dependent id="15">EST</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Campi</governor>
          <dependent id="17">Daily</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Campi</governor>
          <dependent id="18">News</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Campi</governor>
          <dependent id="19">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Campi</governor>
          <dependent id="20">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">Campi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="4:45 a.m. EST" type="TIME" score="0.0">
          <tokens>
            <token id="13" string="4:45" />
            <token id="14" string="a.m." />
            <token id="15" string="EST" />
          </tokens>
        </entity>
        <entity id="2" string="John Campi" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Campi" />
          </tokens>
        </entity>
        <entity id="3" string="Daily News" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Daily" />
            <token id="18" string="News" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>At 11 a.m., a business call arrived from New York, and the crew discovered that Maxwell was not aboard.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="3" string="a.m." lemma="a.m." stem="a.m." pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="arrived" lemma="arrive" stem="arriv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="discovered" lemma="discover" stem="discov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="aboard" lemma="aboard" stem="aboard" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (CD 11) (RB a.m.))) (, ,) (S (NP (DT a) (NN business) (NN call)) (VP (VBD arrived) (PP (IN from) (NP (NNP New) (NNP York))))) (, ,) (CC and) (S (NP (DT the) (NN crew)) (VP (VBD discovered) (SBAR (IN that) (S (NP (NNP Maxwell)) (VP (VBD was) (RB not) (ADVP (IN aboard))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="11 a.m." type="NP">
          <tokens>
            <token id="2" string="11" />
            <token id="3" string="a.m." />
          </tokens>
        </chunking>
        <chunking id="3" string="discovered that Maxwell was not aboard" type="VP">
          <tokens>
            <token id="16" string="discovered" />
            <token id="17" string="that" />
            <token id="18" string="Maxwell" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="aboard" />
          </tokens>
        </chunking>
        <chunking id="4" string="was not aboard" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="aboard" />
          </tokens>
        </chunking>
        <chunking id="5" string="a business call" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="business" />
            <token id="7" string="call" />
          </tokens>
        </chunking>
        <chunking id="6" string="the crew" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="crew" />
          </tokens>
        </chunking>
        <chunking id="7" string="Maxwell" type="NP">
          <tokens>
            <token id="18" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Maxwell was not aboard" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="Maxwell" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="aboard" />
          </tokens>
        </chunking>
        <chunking id="9" string="arrived from New York" type="VP">
          <tokens>
            <token id="8" string="arrived" />
            <token id="9" string="from" />
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">11</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">arrived</governor>
          <dependent id="2">11</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">11</governor>
          <dependent id="3">a.m.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">call</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">call</governor>
          <dependent id="6">business</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">arrived</governor>
          <dependent id="7">call</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">arrived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">York</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">York</governor>
          <dependent id="10">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">arrived</governor>
          <dependent id="11">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">arrived</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">crew</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">discovered</governor>
          <dependent id="15">crew</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">arrived</governor>
          <dependent id="16">discovered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">was</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">was</governor>
          <dependent id="18">Maxwell</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">discovered</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">was</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">was</governor>
          <dependent id="21">aboard</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="11 a.m." type="TIME" score="0.0">
          <tokens>
            <token id="2" string="11" />
            <token id="3" string="a.m." />
          </tokens>
        </entity>
        <entity id="3" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Maxwell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Campi said Capt. Gus Rankin then radioed a distress call.</content>
      <tokens>
        <token id="1" string="Campi" lemma="Campi" stem="campi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Capt." lemma="Capt." stem="capt." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Gus" lemma="Gus" stem="gu" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Rankin" lemma="Rankin" stem="rankin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="radioed" lemma="radio" stem="radio" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="distress" lemma="distress" stem="distress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Campi)) (VP (VBD said) (SBAR (S (NP (NNP Capt.) (NNP Gus) (NNP Rankin)) (ADVP (RB then)) (VP (VBD radioed) (NP (DT a) (NN distress) (NN call)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Capt. Gus Rankin then radioed a distress call" type="SBAR">
          <tokens>
            <token id="3" string="Capt." />
            <token id="4" string="Gus" />
            <token id="5" string="Rankin" />
            <token id="6" string="then" />
            <token id="7" string="radioed" />
            <token id="8" string="a" />
            <token id="9" string="distress" />
            <token id="10" string="call" />
          </tokens>
        </chunking>
        <chunking id="2" string="radioed a distress call" type="VP">
          <tokens>
            <token id="7" string="radioed" />
            <token id="8" string="a" />
            <token id="9" string="distress" />
            <token id="10" string="call" />
          </tokens>
        </chunking>
        <chunking id="3" string="a distress call" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="distress" />
            <token id="10" string="call" />
          </tokens>
        </chunking>
        <chunking id="4" string="Campi" type="NP">
          <tokens>
            <token id="1" string="Campi" />
          </tokens>
        </chunking>
        <chunking id="5" string="Capt. Gus Rankin" type="NP">
          <tokens>
            <token id="3" string="Capt." />
            <token id="4" string="Gus" />
            <token id="5" string="Rankin" />
          </tokens>
        </chunking>
        <chunking id="6" string="said Capt. Gus Rankin then radioed a distress call" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Capt." />
            <token id="4" string="Gus" />
            <token id="5" string="Rankin" />
            <token id="6" string="then" />
            <token id="7" string="radioed" />
            <token id="8" string="a" />
            <token id="9" string="distress" />
            <token id="10" string="call" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Campi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Rankin</governor>
          <dependent id="3">Capt.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Rankin</governor>
          <dependent id="4">Gus</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">radioed</governor>
          <dependent id="5">Rankin</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">radioed</governor>
          <dependent id="6">then</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">radioed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">call</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">call</governor>
          <dependent id="9">distress</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">radioed</governor>
          <dependent id="10">call</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gus Rankin" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Gus" />
            <token id="5" string="Rankin" />
          </tokens>
        </entity>
        <entity id="2" string="Campi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Campi" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The body was found several hours later Wilson said there had been no suggestion of foul play.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="suggestion" lemma="suggestion" stem="suggest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="foul" lemma="foul" stem="foul" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="play" lemma="play" stem="plai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN body)) (VP (VBD was) (VP (VBN found) (NP (JJ several) (NNS hours)) (ADVP (RB later))))) (NP (NNP Wilson)) (VP (VBD said) (SBAR (S (NP (EX there)) (VP (VBD had) (VP (VBN been) (NP (NP (DT no) (NN suggestion)) (PP (IN of) (NP (JJ foul) (NN play))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said there had been no suggestion of foul play" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="there" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
            <token id="15" string="of" />
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="2" string="several hours" type="NP">
          <tokens>
            <token id="5" string="several" />
            <token id="6" string="hours" />
          </tokens>
        </chunking>
        <chunking id="3" string="The body" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="body" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wilson" type="NP">
          <tokens>
            <token id="8" string="Wilson" />
          </tokens>
        </chunking>
        <chunking id="5" string="had been no suggestion of foul play" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
            <token id="15" string="of" />
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="6" string="been no suggestion of foul play" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
            <token id="15" string="of" />
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="7" string="there had been no suggestion of foul play" type="SBAR">
          <tokens>
            <token id="10" string="there" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
            <token id="15" string="of" />
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="8" string="no suggestion of foul play" type="NP">
          <tokens>
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
            <token id="15" string="of" />
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="9" string="no suggestion" type="NP">
          <tokens>
            <token id="13" string="no" />
            <token id="14" string="suggestion" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="foul play" type="NP">
          <tokens>
            <token id="16" string="foul" />
            <token id="17" string="play" />
          </tokens>
        </chunking>
        <chunking id="12" string="was found several hours later" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="found" />
            <token id="5" string="several" />
            <token id="6" string="hours" />
            <token id="7" string="later" />
          </tokens>
        </chunking>
        <chunking id="13" string="found several hours later" type="VP">
          <tokens>
            <token id="4" string="found" />
            <token id="5" string="several" />
            <token id="6" string="hours" />
            <token id="7" string="later" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">body</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">found</governor>
          <dependent id="2">body</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">found</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">said</governor>
          <dependent id="4">found</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">hours</governor>
          <dependent id="5">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">found</governor>
          <dependent id="6">hours</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">found</governor>
          <dependent id="7">later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Wilson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="14">suggestion</governor>
          <dependent id="10">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">suggestion</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">suggestion</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">suggestion</governor>
          <dependent id="13">no</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">suggestion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">play</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">play</governor>
          <dependent id="16">foul</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">suggestion</governor>
          <dependent id="17">play</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Wilson" />
          </tokens>
        </entity>
        <entity id="2" string="several hours later" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="several" />
            <token id="6" string="hours" />
            <token id="7" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;We can only assume that Mr. Maxwell slipped and fell overboard,&amp;quot; he said His mysterious death came as Maxwell was embroiled in an international controversy, something common in a life that had the improbable, extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service Maxwell had denied the accusations.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="assume" lemma="assume" stem="assum" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="slipped" lemma="slip" stem="slip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="fell" lemma="fall" stem="fell" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="overboard" lemma="overboard" stem="overboard" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="mysterious" lemma="mysterious" stem="mysteri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="embroiled" lemma="embroil" stem="embroil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="improbable" lemma="improbable" stem="improb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="extravagant" lemma="extravagant" stem="extravag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="mysterious" lemma="mysterious" stem="mysteri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="47" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="49" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="Seymour" lemma="Seymour" stem="seymour" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="59" string="Hersh" lemma="Hersh" stem="hersh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="60" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="ties" lemma="tie" stem="ti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="Israeli" lemma="israeli" stem="israeli" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="67" string="secret" lemma="secret" stem="secret" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="69" string="Maxwell" lemma="Maxwell" stem="maxwel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="70" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="denied" lemma="deny" stem="deni" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="72" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="accusations" lemma="accusation" stem="accus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="74" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (MD can) (ADVP (RB only)) (VP (VB assume) (SBAR (IN that) (S (NP (NNP Mr.) (NNP Maxwell)) (VP (VP (VBD slipped)) (CC and) (VP (VBD fell) (ADVP (RB overboard))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said) (SBAR (S (NP (PRP$ His) (JJ mysterious) (NN death)) (VP (VBD came) (SBAR (S (SBAR (IN as) (S (NP (NNP Maxwell)) (VP (VBD was) (VP (VBN embroiled) (PP (IN in) (NP (DT an) (JJ international) (NN controversy))))))) (, ,) (NP-TMP (NP (NN something)) (SBAR (S (NP (ADJP (JJ common) (PP (IN in) (NP (NP (DT a) (NN life)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (NP (NP (DT the) (ADJP (JJ improbable)) (, ,) (ADJP (JJ extravagant) (CC and) (RB sometimes)) (JJ mysterious) (NN character)) (PP (IN of) (NP (JJ British) (NN fiction)))))))))) (NNP Maxwell)) (VP (VBD had) (ADVP (RB just)) (VP (VBN been) (VP (VBN accused) (PP (IN in) (NP (DT a) (NN book))) (PP (IN by) (NP (NP (NN reporter) (NNP Seymour) (NNP Hersh)) (PP (IN of) (S (VP (VBG having) (NP (JJ close) (NNS ties)) (PP (TO to) (NP (DT the) (JJ Israeli) (JJ secret) (NN service)))))))))))))) (NP (NNP Maxwell)) (VP (VBD had) (VP (VBN denied) (NP (DT the) (NNS accusations)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a life" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="extravagant and sometimes" type="ADJP">
          <tokens>
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
          </tokens>
        </chunking>
        <chunking id="3" string="as Maxwell was embroiled in an international controversy" type="SBAR">
          <tokens>
            <token id="21" string="as" />
            <token id="22" string="Maxwell" />
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="4" string="fell overboard" type="VP">
          <tokens>
            <token id="11" string="fell" />
            <token id="12" string="overboard" />
          </tokens>
        </chunking>
        <chunking id="5" string="His mysterious death" type="NP">
          <tokens>
            <token id="17" string="His" />
            <token id="18" string="mysterious" />
            <token id="19" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="having close ties to the Israeli secret service" type="VP">
          <tokens>
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="7" string="can only assume that Mr. Maxwell slipped and fell overboard" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="only" />
            <token id="5" string="assume" />
            <token id="6" string="that" />
            <token id="7" string="Mr." />
            <token id="8" string="Maxwell" />
            <token id="9" string="slipped" />
            <token id="10" string="and" />
            <token id="11" string="fell" />
            <token id="12" string="overboard" />
          </tokens>
        </chunking>
        <chunking id="8" string="the accusations" type="NP">
          <tokens>
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="9" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="10" string="embroiled in an international controversy" type="VP">
          <tokens>
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="11" string="something" type="NP">
          <tokens>
            <token id="30" string="something" />
          </tokens>
        </chunking>
        <chunking id="12" string="close ties" type="NP">
          <tokens>
            <token id="62" string="close" />
            <token id="63" string="ties" />
          </tokens>
        </chunking>
        <chunking id="13" string="was embroiled in an international controversy" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="14" string="slipped and fell overboard" type="VP">
          <tokens>
            <token id="9" string="slipped" />
            <token id="10" string="and" />
            <token id="11" string="fell" />
            <token id="12" string="overboard" />
          </tokens>
        </chunking>
        <chunking id="15" string="a book" type="NP">
          <tokens>
            <token id="54" string="a" />
            <token id="55" string="book" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mr. Maxwell" type="NP">
          <tokens>
            <token id="7" string="Mr." />
            <token id="8" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="17" string="a life that had the improbable , extravagant and sometimes mysterious character of British fiction" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="18" string="as Maxwell was embroiled in an international controversy , something common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service Maxwell had denied the accusations" type="SBAR">
          <tokens>
            <token id="21" string="as" />
            <token id="22" string="Maxwell" />
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
            <token id="29" string="," />
            <token id="30" string="something" />
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
            <token id="69" string="Maxwell" />
            <token id="70" string="had" />
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="19" string="assume that Mr. Maxwell slipped and fell overboard" type="VP">
          <tokens>
            <token id="5" string="assume" />
            <token id="6" string="that" />
            <token id="7" string="Mr." />
            <token id="8" string="Maxwell" />
            <token id="9" string="slipped" />
            <token id="10" string="and" />
            <token id="11" string="fell" />
            <token id="12" string="overboard" />
          </tokens>
        </chunking>
        <chunking id="20" string="had the improbable , extravagant and sometimes mysterious character of British fiction" type="VP">
          <tokens>
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="21" string="the improbable , extravagant and sometimes mysterious character of British fiction" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="22" string="slipped" type="VP">
          <tokens>
            <token id="9" string="slipped" />
          </tokens>
        </chunking>
        <chunking id="23" string="had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service" type="VP">
          <tokens>
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="24" string="reporter Seymour Hersh" type="NP">
          <tokens>
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
          </tokens>
        </chunking>
        <chunking id="25" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="26" string="the improbable , extravagant and sometimes mysterious character" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
          </tokens>
        </chunking>
        <chunking id="27" string="an international controversy" type="NP">
          <tokens>
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="28" string="denied the accusations" type="VP">
          <tokens>
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="29" string="accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service" type="VP">
          <tokens>
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="30" string="that Mr. Maxwell slipped and fell overboard" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="Mr." />
            <token id="8" string="Maxwell" />
            <token id="9" string="slipped" />
            <token id="10" string="and" />
            <token id="11" string="fell" />
            <token id="12" string="overboard" />
          </tokens>
        </chunking>
        <chunking id="31" string="came as Maxwell was embroiled in an international controversy , something common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service Maxwell had denied the accusations" type="VP">
          <tokens>
            <token id="20" string="came" />
            <token id="21" string="as" />
            <token id="22" string="Maxwell" />
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
            <token id="29" string="," />
            <token id="30" string="something" />
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
            <token id="69" string="Maxwell" />
            <token id="70" string="had" />
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="32" string="that had the improbable , extravagant and sometimes mysterious character of British fiction" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="33" string="Maxwell" type="NP">
          <tokens>
            <token id="22" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="34" string="common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell" type="NP">
          <tokens>
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
          </tokens>
        </chunking>
        <chunking id="35" string="common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction" type="ADJP">
          <tokens>
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="36" string="had denied the accusations" type="VP">
          <tokens>
            <token id="70" string="had" />
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="37" string="the Israeli secret service" type="NP">
          <tokens>
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="38" string="His mysterious death came as Maxwell was embroiled in an international controversy , something common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service Maxwell had denied the accusations" type="SBAR">
          <tokens>
            <token id="17" string="His" />
            <token id="18" string="mysterious" />
            <token id="19" string="death" />
            <token id="20" string="came" />
            <token id="21" string="as" />
            <token id="22" string="Maxwell" />
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
            <token id="29" string="," />
            <token id="30" string="something" />
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
            <token id="69" string="Maxwell" />
            <token id="70" string="had" />
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="39" string="British fiction" type="NP">
          <tokens>
            <token id="46" string="British" />
            <token id="47" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="40" string="reporter Seymour Hersh of having close ties to the Israeli secret service" type="NP">
          <tokens>
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="41" string="improbable" type="ADJP">
          <tokens>
            <token id="38" string="improbable" />
          </tokens>
        </chunking>
        <chunking id="42" string="been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service" type="VP">
          <tokens>
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
        <chunking id="43" string="said His mysterious death came as Maxwell was embroiled in an international controversy , something common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service Maxwell had denied the accusations" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="His" />
            <token id="18" string="mysterious" />
            <token id="19" string="death" />
            <token id="20" string="came" />
            <token id="21" string="as" />
            <token id="22" string="Maxwell" />
            <token id="23" string="was" />
            <token id="24" string="embroiled" />
            <token id="25" string="in" />
            <token id="26" string="an" />
            <token id="27" string="international" />
            <token id="28" string="controversy" />
            <token id="29" string="," />
            <token id="30" string="something" />
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
            <token id="69" string="Maxwell" />
            <token id="70" string="had" />
            <token id="71" string="denied" />
            <token id="72" string="the" />
            <token id="73" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="44" string="common in a life that had the improbable , extravagant and sometimes mysterious character of British fiction Maxwell had just been accused in a book by reporter Seymour Hersh of having close ties to the Israeli secret service" type="SBAR">
          <tokens>
            <token id="31" string="common" />
            <token id="32" string="in" />
            <token id="33" string="a" />
            <token id="34" string="life" />
            <token id="35" string="that" />
            <token id="36" string="had" />
            <token id="37" string="the" />
            <token id="38" string="improbable" />
            <token id="39" string="," />
            <token id="40" string="extravagant" />
            <token id="41" string="and" />
            <token id="42" string="sometimes" />
            <token id="43" string="mysterious" />
            <token id="44" string="character" />
            <token id="45" string="of" />
            <token id="46" string="British" />
            <token id="47" string="fiction" />
            <token id="48" string="Maxwell" />
            <token id="49" string="had" />
            <token id="50" string="just" />
            <token id="51" string="been" />
            <token id="52" string="accused" />
            <token id="53" string="in" />
            <token id="54" string="a" />
            <token id="55" string="book" />
            <token id="56" string="by" />
            <token id="57" string="reporter" />
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
            <token id="60" string="of" />
            <token id="61" string="having" />
            <token id="62" string="close" />
            <token id="63" string="ties" />
            <token id="64" string="to" />
            <token id="65" string="the" />
            <token id="66" string="Israeli" />
            <token id="67" string="secret" />
            <token id="68" string="service" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">assume</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">assume</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">assume</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">assume</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">slipped</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Maxwell</governor>
          <dependent id="7">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">slipped</governor>
          <dependent id="8">Maxwell</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">assume</governor>
          <dependent id="9">slipped</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">slipped</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">slipped</governor>
          <dependent id="11">fell</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">fell</governor>
          <dependent id="12">overboard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">death</governor>
          <dependent id="17">His</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">death</governor>
          <dependent id="18">mysterious</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">came</governor>
          <dependent id="19">death</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="20">came</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">embroiled</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">embroiled</governor>
          <dependent id="22">Maxwell</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">embroiled</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="71">denied</governor>
          <dependent id="24">embroiled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">controversy</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">controversy</governor>
          <dependent id="26">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">controversy</governor>
          <dependent id="27">international</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">embroiled</governor>
          <dependent id="28">controversy</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="71">denied</governor>
          <dependent id="30">something</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">Maxwell</governor>
          <dependent id="31">common</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">life</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">life</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">common</governor>
          <dependent id="34">life</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">had</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="34">life</governor>
          <dependent id="36">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">character</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">character</governor>
          <dependent id="38">improbable</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">character</governor>
          <dependent id="40">extravagant</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="40">extravagant</governor>
          <dependent id="41">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">extravagant</governor>
          <dependent id="42">sometimes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">character</governor>
          <dependent id="43">mysterious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">had</governor>
          <dependent id="44">character</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">fiction</governor>
          <dependent id="45">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">fiction</governor>
          <dependent id="46">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">character</governor>
          <dependent id="47">fiction</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="52">accused</governor>
          <dependent id="48">Maxwell</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="52">accused</governor>
          <dependent id="49">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="52">accused</governor>
          <dependent id="50">just</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="52">accused</governor>
          <dependent id="51">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="30">something</governor>
          <dependent id="52">accused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">book</governor>
          <dependent id="53">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="55">book</governor>
          <dependent id="54">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="52">accused</governor>
          <dependent id="55">book</dependent>
        </dependency>
        <dependency type="case">
          <governor id="59">Hersh</governor>
          <dependent id="56">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">Hersh</governor>
          <dependent id="57">reporter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">Hersh</governor>
          <dependent id="58">Seymour</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="52">accused</governor>
          <dependent id="59">Hersh</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="61">having</governor>
          <dependent id="60">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="59">Hersh</governor>
          <dependent id="61">having</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="63">ties</governor>
          <dependent id="62">close</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="61">having</governor>
          <dependent id="63">ties</dependent>
        </dependency>
        <dependency type="case">
          <governor id="68">service</governor>
          <dependent id="64">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="68">service</governor>
          <dependent id="65">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="68">service</governor>
          <dependent id="66">Israeli</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="68">service</governor>
          <dependent id="67">secret</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="61">having</governor>
          <dependent id="68">service</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="71">denied</governor>
          <dependent id="69">Maxwell</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="71">denied</governor>
          <dependent id="70">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">came</governor>
          <dependent id="71">denied</dependent>
        </dependency>
        <dependency type="det">
          <governor id="73">accusations</governor>
          <dependent id="72">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="71">denied</governor>
          <dependent id="73">accusations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Israeli" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="66" string="Israeli" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="46" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Seymour Hersh" type="PERSON" score="0.0">
          <tokens>
            <token id="58" string="Seymour" />
            <token id="59" string="Hersh" />
          </tokens>
        </entity>
        <entity id="4" string="Maxwell" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Maxwell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="46-47-48-49" string="New York Daily News" id_sentence="1" />
      <mentions>
        <mention ids_tokens="71-73" string="the Daily News" id_sentence="8" />
        <mention ids_tokens="72-73" string="Daily News" id_sentence="8" />
        <mention ids_tokens="17-18" string="Daily News" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="57" string="Ghislaine" id_sentence="1" />
      <mentions>
        <mention ids_tokens="45" string="his" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="2-3-4" string="The Czechoslovak-born Maxwell" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1-12" string="Robert Maxwell , the flamboyant billionaire who built a global publishing empire" id_sentence="1" />
        <mention ids_tokens="1-2" string="Robert Maxwell" id_sentence="1" />
        <mention ids_tokens="4-12" string="the flamboyant billionaire who built a global publishing empire" id_sentence="1" />
        <mention ids_tokens="26" string="he" id_sentence="1" />
        <mention ids_tokens="31" string="his" id_sentence="1" />
        <mention ids_tokens="35-49" string="Maxwell , 68 , who earlier this year had bought the New York Daily News" id_sentence="1" />
        <mention ids_tokens="35" string="Maxwell" id_sentence="1" />
        <mention ids_tokens="1" string="His" id_sentence="2" />
        <mention ids_tokens="1-2" string="Maxwell's" id_sentence="3" />
        <mention ids_tokens="26" string="he" id_sentence="3" />
        <mention ids_tokens="35" string="He" id_sentence="3" />
        <mention ids_tokens="8" string="his" id_sentence="4" />
        <mention ids_tokens="8" string="Maxwell" id_sentence="5" />
        <mention ids_tokens="1-2" string="Maxwell's" id_sentence="8" />
        <mention ids_tokens="10" string="Ian" id_sentence="8" />
        <mention ids_tokens="31-32" string="Robert Maxwell" id_sentence="8" />
        <mention ids_tokens="47" string="His" id_sentence="8" />
        <mention ids_tokens="60" string="his" id_sentence="8" />
        <mention ids_tokens="84-85" string="Maxwell's" id_sentence="8" />
        <mention ids_tokens="135-136" string="Ian Maxwell" id_sentence="8" />
        <mention ids_tokens="146" string="his" id_sentence="8" />
        <mention ids_tokens="151-152" string="Maxwell's" id_sentence="8" />
        <mention ids_tokens="3" string="Maxwell" id_sentence="11" />
        <mention ids_tokens="5-9" string="a passionate friend of Israel" id_sentence="11" />
        <mention ids_tokens="22-23" string="Maxwell's" id_sentence="14" />
        <mention ids_tokens="19-20" string="Maxwell's" id_sentence="15" />
        <mention ids_tokens="1" string="He" id_sentence="16" />
        <mention ids_tokens="10" string="his" id_sentence="16" />
        <mention ids_tokens="18" string="Maxwell" id_sentence="17" />
        <mention ids_tokens="7-8" string="Mr. Maxwell" id_sentence="20" />
        <mention ids_tokens="15" string="he" id_sentence="20" />
        <mention ids_tokens="17" string="His" id_sentence="20" />
        <mention ids_tokens="22" string="Maxwell" id_sentence="20" />
        <mention ids_tokens="69" string="Maxwell" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="a global publishing empire" id_sentence="1" />
      <mentions>
        <mention ids_tokens="19-21" string="his publishing empire" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="16-17" string="dead Tuesday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="19" string="Tuesday" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="His unclothed body" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2-3" string="His body" id_sentence="13" />
        <mention ids_tokens="1-2" string="The body" id_sentence="14" />
        <mention ids_tokens="18" string="it" id_sentence="14" />
        <mention ids_tokens="1-2" string="The body" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Maxwell 's death" id_sentence="3" />
      <mentions>
        <mention ids_tokens="47-48" string="His death" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="13" string="Britain" id_sentence="7" />
      <mentions>
        <mention ids_tokens="96-97" string="Britain's" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="36-37" string="Charles Wilson" id_sentence="8" />
      <mentions>
        <mention ids_tokens="8" string="Wilson" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="65-66-67-68-69-70-71-72-73" string="New York about the future of the Daily News" id_sentence="8" />
      <mentions>
        <mention ids_tokens="10-11" string="New York" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="96-97-98-99-100" string="Britain 's No. 2 paper" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2-3" string="This paper" id_sentence="9" />
        <mention ids_tokens="6" string="its" id_sentence="9" />
        <mention ids_tokens="9" string="its" id_sentence="9" />
        <mention ids_tokens="12" string="its" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="15" type="LIST">
      <referenced ids_tokens="6-7-8-9-10-11-12-13" string="its publisher and its chairman and its savior" id_sentence="9" />
      <mentions>
        <mention ids_tokens="12" string="we" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="2" string="God" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2" string="His" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Grand Canary Island" id_sentence="13" />
      <mentions>
        <mention ids_tokens="13-37" string="Grand Canary Island , where it was identified by Maxwell's wife of more than 40 years , Elizabeth , and their son , Phillip" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24-25" string="officials at the rescue center in Madrid" id_sentence="13" />
      <mentions>
        <mention ids_tokens="34" string="their" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21" string="Daily News spokesman John Campi" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1" string="Campi" id_sentence="18" />
      </mentions>
    </coreference>
  </coreferences>
</document>
