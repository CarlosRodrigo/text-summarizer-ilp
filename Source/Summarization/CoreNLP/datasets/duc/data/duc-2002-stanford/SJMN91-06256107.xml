<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06256107">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Frustrated Democrats on the Senate Judiciary Committee say Supreme Court nominee Clarence Thomas is an evasive witness, but no groundswell of opposition to his confirmation seems to be emerging Several senators were openly skeptical Wednesday over Thomas&amp;apost; insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion.</content>
      <tokens>
        <token id="1" string="Frustrated" lemma="frustrated" stem="frustrat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Democrats" lemma="democrat" stem="democrat" pos="NNS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Judiciary" lemma="Judiciary" stem="judiciari" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="evasive" lemma="evasive" stem="evas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="groundswell" lemma="groundswell" stem="groundswel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="emerging" lemma="emerge" stem="emerg" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="skeptical" lemma="skeptical" stem="skeptic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="37" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="39" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="insistence" lemma="insistence" stem="insist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="48" string="1973" lemma="1973" stem="1973" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="49" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="50" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="51" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="52" string="legalizing" lemma="legalize" stem="legal" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="53" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (JJ Frustrated) (NNS Democrats)) (PP (IN on) (NP (DT the) (NNP Senate) (NNP Judiciary) (NNP Committee)))) (VP (VBP say) (SBAR (S (NP (NNP Supreme) (NNP Court) (NN nominee) (NNP Clarence) (NNP Thomas)) (VP (VBZ is) (NP (DT an) (JJ evasive) (NN witness))))))) (, ,) (CC but) (S (NP (NP (DT no) (NN groundswell)) (PP (IN of) (NP (NP (NN opposition)) (PP (TO to) (NP (PRP$ his) (NN confirmation)))))) (VP (VBZ seems) (S (VP (TO to) (VP (VB be) (VP (VBG emerging) (SBAR (S (NP (JJ Several) (NNS senators)) (VP (VBD were) (ADVP (RB openly)) (ADJP (JJ skeptical) (NP-TMP (NNP Wednesday)) (PP (IN over) (NP (NP (NNP Thomas) (POS ')) (NN insistence)))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ has) (NP (NP (DT no) (NN opinion)) (PP (IN on) (NP (NP (DT the) (CD 1973) (NNP Supreme) (NNP Court) (NN decision)) (VP (VBG legalizing) (NP (NN abortion)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is an evasive witness" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="an" />
            <token id="16" string="evasive" />
            <token id="17" string="witness" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 1973 Supreme Court decision legalizing abortion" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="3" string="legalizing abortion" type="VP">
          <tokens>
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="4" string="his confirmation" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="5" string="say Supreme Court nominee Clarence Thomas is an evasive witness" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="nominee" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="is" />
            <token id="15" string="an" />
            <token id="16" string="evasive" />
            <token id="17" string="witness" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas '" type="NP">
          <tokens>
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="an evasive witness" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="evasive" />
            <token id="17" string="witness" />
          </tokens>
        </chunking>
        <chunking id="8" string="be emerging Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="29" string="be" />
            <token id="30" string="emerging" />
            <token id="31" string="Several" />
            <token id="32" string="senators" />
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Senate" />
            <token id="6" string="Judiciary" />
            <token id="7" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="10" string="skeptical Wednesday over Thomas ' insistence" type="ADJP">
          <tokens>
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
          </tokens>
        </chunking>
        <chunking id="11" string="the 1973 Supreme Court decision" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
          </tokens>
        </chunking>
        <chunking id="12" string="seems to be emerging Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="27" string="seems" />
            <token id="28" string="to" />
            <token id="29" string="be" />
            <token id="30" string="emerging" />
            <token id="31" string="Several" />
            <token id="32" string="senators" />
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="13" string="no opinion" type="NP">
          <tokens>
            <token id="44" string="no" />
            <token id="45" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="14" string="Frustrated Democrats" type="NP">
          <tokens>
            <token id="1" string="Frustrated" />
            <token id="2" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="15" string="Supreme Court nominee Clarence Thomas" type="NP">
          <tokens>
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="nominee" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="16" string="that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="SBAR">
          <tokens>
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="17" string="Supreme Court nominee Clarence Thomas is an evasive witness" type="SBAR">
          <tokens>
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="nominee" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="is" />
            <token id="15" string="an" />
            <token id="16" string="evasive" />
            <token id="17" string="witness" />
          </tokens>
        </chunking>
        <chunking id="18" string="were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="42" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="Frustrated Democrats on the Senate Judiciary Committee" type="NP">
          <tokens>
            <token id="1" string="Frustrated" />
            <token id="2" string="Democrats" />
            <token id="3" string="on" />
            <token id="4" string="the" />
            <token id="5" string="Senate" />
            <token id="6" string="Judiciary" />
            <token id="7" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="21" string="emerging Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="30" string="emerging" />
            <token id="31" string="Several" />
            <token id="32" string="senators" />
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="22" string="to be emerging Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="be" />
            <token id="30" string="emerging" />
            <token id="31" string="Several" />
            <token id="32" string="senators" />
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="23" string="Several senators were openly skeptical Wednesday over Thomas ' insistence that he has no opinion on the 1973 Supreme Court decision legalizing abortion" type="SBAR">
          <tokens>
            <token id="31" string="Several" />
            <token id="32" string="senators" />
            <token id="33" string="were" />
            <token id="34" string="openly" />
            <token id="35" string="skeptical" />
            <token id="36" string="Wednesday" />
            <token id="37" string="over" />
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
            <token id="41" string="that" />
            <token id="42" string="he" />
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="24" string="no groundswell" type="NP">
          <tokens>
            <token id="20" string="no" />
            <token id="21" string="groundswell" />
          </tokens>
        </chunking>
        <chunking id="25" string="no groundswell of opposition to his confirmation" type="NP">
          <tokens>
            <token id="20" string="no" />
            <token id="21" string="groundswell" />
            <token id="22" string="of" />
            <token id="23" string="opposition" />
            <token id="24" string="to" />
            <token id="25" string="his" />
            <token id="26" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="26" string="no opinion on the 1973 Supreme Court decision legalizing abortion" type="NP">
          <tokens>
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="27" string="abortion" type="NP">
          <tokens>
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="28" string="has no opinion on the 1973 Supreme Court decision legalizing abortion" type="VP">
          <tokens>
            <token id="43" string="has" />
            <token id="44" string="no" />
            <token id="45" string="opinion" />
            <token id="46" string="on" />
            <token id="47" string="the" />
            <token id="48" string="1973" />
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
            <token id="51" string="decision" />
            <token id="52" string="legalizing" />
            <token id="53" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="29" string="Several senators" type="NP">
          <tokens>
            <token id="31" string="Several" />
            <token id="32" string="senators" />
          </tokens>
        </chunking>
        <chunking id="30" string="opposition" type="NP">
          <tokens>
            <token id="23" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="31" string="opposition to his confirmation" type="NP">
          <tokens>
            <token id="23" string="opposition" />
            <token id="24" string="to" />
            <token id="25" string="his" />
            <token id="26" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="32" string="Thomas ' insistence" type="NP">
          <tokens>
            <token id="38" string="Thomas" />
            <token id="39" string="'" />
            <token id="40" string="insistence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">Democrats</governor>
          <dependent id="1">Frustrated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">say</governor>
          <dependent id="2">Democrats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Committee</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Committee</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Committee</governor>
          <dependent id="5">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Committee</governor>
          <dependent id="6">Judiciary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Democrats</governor>
          <dependent id="7">Committee</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Thomas</governor>
          <dependent id="9">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Thomas</governor>
          <dependent id="10">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Thomas</governor>
          <dependent id="11">nominee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Thomas</governor>
          <dependent id="12">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">witness</governor>
          <dependent id="13">Thomas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">witness</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">witness</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">witness</governor>
          <dependent id="16">evasive</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">say</governor>
          <dependent id="17">witness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">say</governor>
          <dependent id="19">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">groundswell</governor>
          <dependent id="20">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">seems</governor>
          <dependent id="21">groundswell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">opposition</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">groundswell</governor>
          <dependent id="23">opposition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">confirmation</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">confirmation</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">opposition</governor>
          <dependent id="26">confirmation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">say</governor>
          <dependent id="27">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">emerging</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">emerging</governor>
          <dependent id="29">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">seems</governor>
          <dependent id="30">emerging</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">senators</governor>
          <dependent id="31">Several</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">skeptical</governor>
          <dependent id="32">senators</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">skeptical</governor>
          <dependent id="33">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">skeptical</governor>
          <dependent id="34">openly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">emerging</governor>
          <dependent id="35">skeptical</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="35">skeptical</governor>
          <dependent id="36">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">insistence</governor>
          <dependent id="37">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">insistence</governor>
          <dependent id="38">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Thomas</governor>
          <dependent id="39">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">skeptical</governor>
          <dependent id="40">insistence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">has</governor>
          <dependent id="41">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">has</governor>
          <dependent id="42">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">skeptical</governor>
          <dependent id="43">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="45">opinion</governor>
          <dependent id="44">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">has</governor>
          <dependent id="45">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">decision</governor>
          <dependent id="46">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">decision</governor>
          <dependent id="47">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="51">decision</governor>
          <dependent id="48">1973</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">decision</governor>
          <dependent id="49">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">decision</governor>
          <dependent id="50">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">opinion</governor>
          <dependent id="51">decision</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="51">decision</governor>
          <dependent id="52">legalizing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="52">legalizing</governor>
          <dependent id="53">abortion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="49" string="Supreme" />
            <token id="50" string="Court" />
          </tokens>
        </entity>
        <entity id="3" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="36" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="4" string="1973" type="DATE" score="0.0">
          <tokens>
            <token id="48" string="1973" />
          </tokens>
        </entity>
        <entity id="5" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Thomas" />
          </tokens>
        </entity>
        <entity id="6" string="Senate Judiciary Committee say Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Senate" />
            <token id="6" string="Judiciary" />
            <token id="7" string="Committee" />
            <token id="8" string="say" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
          </tokens>
        </entity>
        <entity id="7" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>If that&amp;apost;s so, said Sen. Paul Simon, D-Ill., &amp;quot;he&amp;apost;s the only person gathered in the room who does not have an opinion.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="D-Ill." lemma="D-Ill." stem="d-ill." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="gathered" lemma="gather" stem="gather" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT that)) (VP (VBZ 's) (ADVP (RB so))))) (PRN (, ,) (SINV (VP (VBD said)) (NP (NP (NNP Sen.) (NNP Paul) (NNP Simon)) (, ,) (NP (NNP D-Ill.)))) (, ,)) (`` ``) (NP (PRP he)) (VP (VBZ 's) (NP (NP (DT the) (JJ only) (NN person)) (VP (VBN gathered) (PP (IN in) (NP (NP (DT the) (NN room)) (SBAR (WHNP (WP who)) (S (VP (VBZ does) (RB not) (VP (VB have) (NP (DT an) (NN opinion))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s the only person gathered in the room who does not have an opinion" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="the" />
            <token id="17" string="only" />
            <token id="18" string="person" />
            <token id="19" string="gathered" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="room" />
            <token id="23" string="who" />
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="2" string="an opinion" type="NP">
          <tokens>
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="3" string="the only person" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="only" />
            <token id="18" string="person" />
          </tokens>
        </chunking>
        <chunking id="4" string="gathered in the room who does not have an opinion" type="VP">
          <tokens>
            <token id="19" string="gathered" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="room" />
            <token id="23" string="who" />
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="5" string="the room who does not have an opinion" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="room" />
            <token id="23" string="who" />
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="6" string="D-Ill." type="NP">
          <tokens>
            <token id="11" string="D-Ill." />
          </tokens>
        </chunking>
        <chunking id="7" string="the room" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="room" />
          </tokens>
        </chunking>
        <chunking id="8" string="have an opinion" type="VP">
          <tokens>
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="9" string="If that 's so" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="that" />
            <token id="3" string="'s" />
            <token id="4" string="so" />
          </tokens>
        </chunking>
        <chunking id="10" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="11" string="the only person gathered in the room who does not have an opinion" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="only" />
            <token id="18" string="person" />
            <token id="19" string="gathered" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="room" />
            <token id="23" string="who" />
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="12" string="who does not have an opinion" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s so" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="so" />
          </tokens>
        </chunking>
        <chunking id="14" string="Sen. Paul Simon" type="NP">
          <tokens>
            <token id="7" string="Sen." />
            <token id="8" string="Paul" />
            <token id="9" string="Simon" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sen. Paul Simon , D-Ill." type="NP">
          <tokens>
            <token id="7" string="Sen." />
            <token id="8" string="Paul" />
            <token id="9" string="Simon" />
            <token id="10" string="," />
            <token id="11" string="D-Ill." />
          </tokens>
        </chunking>
        <chunking id="16" string="does not have an opinion" type="VP">
          <tokens>
            <token id="24" string="does" />
            <token id="25" string="not" />
            <token id="26" string="have" />
            <token id="27" string="an" />
            <token id="28" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="6" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">'s</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">'s</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">person</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">'s</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="18">person</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Simon</governor>
          <dependent id="7">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Simon</governor>
          <dependent id="8">Paul</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="9">Simon</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Simon</governor>
          <dependent id="11">D-Ill.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">person</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">person</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">person</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">person</governor>
          <dependent id="17">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">person</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">person</governor>
          <dependent id="19">gathered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">room</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">room</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">gathered</governor>
          <dependent id="22">room</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">have</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">have</governor>
          <dependent id="24">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">have</governor>
          <dependent id="25">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">room</governor>
          <dependent id="26">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">opinion</governor>
          <dependent id="27">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">have</governor>
          <dependent id="28">opinion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Paul Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Paul" />
            <token id="9" string="Simon" />
          </tokens>
        </entity>
        <entity id="2" string="D-Ill." type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="D-Ill." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>; Sen. Herb Kohl, D-Wis., added, &amp;quot;I&amp;apost;m concerned about his candor, his willingness to be forthcoming.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Herb" lemma="Herb" stem="herb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="D-Wis." lemma="D-Wis." stem="d-wis." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="concerned" lemma="concerned" stem="concern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="candor" lemma="candor" stem="candor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="willingness" lemma="willingness" stem="willing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="forthcoming" lemma="forthcoming" stem="forthcom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NNP Sen.) (NNP Herb) (NNP Kohl)) (, ,) (NP (NNP D-Wis.))) (, ,) (PRN (S (VP (VBD added)))) (, ,) (`` ``) (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ concerned) (PP (IN about) (NP (NP (PRP$ his) (NN candor)) (, ,) (NP (PRP$ his) (NN willingness) (S (VP (TO to) (VP (VB be) (ADJP (JJ forthcoming)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="his candor , his willingness to be forthcoming" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="candor" />
            <token id="17" string="," />
            <token id="18" string="his" />
            <token id="19" string="willingness" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="3" string="be forthcoming" type="VP">
          <tokens>
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sen. Herb Kohl , D-Wis." type="NP">
          <tokens>
            <token id="2" string="Sen." />
            <token id="3" string="Herb" />
            <token id="4" string="Kohl" />
            <token id="5" string="," />
            <token id="6" string="D-Wis." />
          </tokens>
        </chunking>
        <chunking id="5" string="his candor" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="candor" />
          </tokens>
        </chunking>
        <chunking id="6" string="'m concerned about his candor , his willingness to be forthcoming" type="VP">
          <tokens>
            <token id="12" string="'m" />
            <token id="13" string="concerned" />
            <token id="14" string="about" />
            <token id="15" string="his" />
            <token id="16" string="candor" />
            <token id="17" string="," />
            <token id="18" string="his" />
            <token id="19" string="willingness" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be forthcoming" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="8" string="D-Wis." type="NP">
          <tokens>
            <token id="6" string="D-Wis." />
          </tokens>
        </chunking>
        <chunking id="9" string="added" type="VP">
          <tokens>
            <token id="8" string="added" />
          </tokens>
        </chunking>
        <chunking id="10" string="his willingness to be forthcoming" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="willingness" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="11" string="concerned about his candor , his willingness to be forthcoming" type="ADJP">
          <tokens>
            <token id="13" string="concerned" />
            <token id="14" string="about" />
            <token id="15" string="his" />
            <token id="16" string="candor" />
            <token id="17" string="," />
            <token id="18" string="his" />
            <token id="19" string="willingness" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="12" string="forthcoming" type="ADJP">
          <tokens>
            <token id="22" string="forthcoming" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sen. Herb Kohl" type="NP">
          <tokens>
            <token id="2" string="Sen." />
            <token id="3" string="Herb" />
            <token id="4" string="Kohl" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Kohl</governor>
          <dependent id="2">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Kohl</governor>
          <dependent id="3">Herb</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">concerned</governor>
          <dependent id="4">Kohl</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Kohl</governor>
          <dependent id="6">D-Wis.</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">concerned</governor>
          <dependent id="8">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">concerned</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">concerned</governor>
          <dependent id="12">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">concerned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">candor</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">candor</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">concerned</governor>
          <dependent id="16">candor</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">willingness</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">candor</governor>
          <dependent id="19">willingness</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">forthcoming</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">forthcoming</governor>
          <dependent id="21">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">willingness</governor>
          <dependent id="22">forthcoming</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Herb Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Herb" />
            <token id="4" string="Kohl" />
          </tokens>
        </entity>
        <entity id="2" string="D-Wis." type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="D-Wis." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Kohl was today&amp;apost;s leadoff questioner as the hearings entered their third day Two pivotal members of the 14-member committee -- Howell Heflin, D-Ala., and Arlen Specter, R-Pa.</content>
      <tokens>
        <token id="1" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="leadoff" lemma="leadoff" stem="leadoff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="questioner" lemma="questioner" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="entered" lemma="enter" stem="enter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="15" string="pivotal" lemma="pivotal" stem="pivot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="14-member" lemma="14-member" stem="14-member" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Howell" lemma="Howell" stem="howel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Heflin" lemma="Heflin" stem="heflin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="D-Ala." lemma="D-Ala." stem="d-ala." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Arlen" lemma="Arlen" stem="arlen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="Specter" lemma="Specter" stem="specter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="R-Pa" lemma="R-Pa" stem="r-pa" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNP Kohl)) (VP (VBD was) (NP (NP (NN today) (POS 's)) (NN leadoff) (NN questioner)) (PP (IN as) (NP (DT the) (NNS hearings))))) (VP (VBD entered) (NP (PRP$ their) (JJ third) (NN day))) (NP (NP (NP (CD Two) (JJ pivotal) (NNS members)) (PP (IN of) (NP (DT the) (JJ 14-member) (NN committee)))) (: --) (NP (NP (NNP Howell) (NNP Heflin)) (, ,) (NP (NNP D-Ala.))) (, ,) (CC and) (NP (NP (NNP Arlen) (NNP Specter)) (, ,) (NP (NNP R-Pa)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="entered their third day" type="VP">
          <tokens>
            <token id="10" string="entered" />
            <token id="11" string="their" />
            <token id="12" string="third" />
            <token id="13" string="day" />
          </tokens>
        </chunking>
        <chunking id="2" string="their third day" type="NP">
          <tokens>
            <token id="11" string="their" />
            <token id="12" string="third" />
            <token id="13" string="day" />
          </tokens>
        </chunking>
        <chunking id="3" string="D-Ala." type="NP">
          <tokens>
            <token id="25" string="D-Ala." />
          </tokens>
        </chunking>
        <chunking id="4" string="Arlen Specter , R-Pa" type="NP">
          <tokens>
            <token id="28" string="Arlen" />
            <token id="29" string="Specter" />
            <token id="30" string="," />
            <token id="31" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="5" string="Kohl" type="NP">
          <tokens>
            <token id="1" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="6" string="today 's" type="NP">
          <tokens>
            <token id="3" string="today" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 14-member committee" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="14-member" />
            <token id="20" string="committee" />
          </tokens>
        </chunking>
        <chunking id="8" string="Arlen Specter" type="NP">
          <tokens>
            <token id="28" string="Arlen" />
            <token id="29" string="Specter" />
          </tokens>
        </chunking>
        <chunking id="9" string="R-Pa" type="NP">
          <tokens>
            <token id="31" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="10" string="was today 's leadoff questioner as the hearings" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="today" />
            <token id="4" string="'s" />
            <token id="5" string="leadoff" />
            <token id="6" string="questioner" />
            <token id="7" string="as" />
            <token id="8" string="the" />
            <token id="9" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="11" string="the hearings" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="12" string="Two pivotal members of the 14-member committee -- Howell Heflin , D-Ala. , and Arlen Specter , R-Pa" type="NP">
          <tokens>
            <token id="14" string="Two" />
            <token id="15" string="pivotal" />
            <token id="16" string="members" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="14-member" />
            <token id="20" string="committee" />
            <token id="21" string="--" />
            <token id="22" string="Howell" />
            <token id="23" string="Heflin" />
            <token id="24" string="," />
            <token id="25" string="D-Ala." />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Arlen" />
            <token id="29" string="Specter" />
            <token id="30" string="," />
            <token id="31" string="R-Pa" />
          </tokens>
        </chunking>
        <chunking id="13" string="Two pivotal members" type="NP">
          <tokens>
            <token id="14" string="Two" />
            <token id="15" string="pivotal" />
            <token id="16" string="members" />
          </tokens>
        </chunking>
        <chunking id="14" string="Howell Heflin , D-Ala." type="NP">
          <tokens>
            <token id="22" string="Howell" />
            <token id="23" string="Heflin" />
            <token id="24" string="," />
            <token id="25" string="D-Ala." />
          </tokens>
        </chunking>
        <chunking id="15" string="today 's leadoff questioner" type="NP">
          <tokens>
            <token id="3" string="today" />
            <token id="4" string="'s" />
            <token id="5" string="leadoff" />
            <token id="6" string="questioner" />
          </tokens>
        </chunking>
        <chunking id="16" string="Howell Heflin" type="NP">
          <tokens>
            <token id="22" string="Howell" />
            <token id="23" string="Heflin" />
          </tokens>
        </chunking>
        <chunking id="17" string="Two pivotal members of the 14-member committee" type="NP">
          <tokens>
            <token id="14" string="Two" />
            <token id="15" string="pivotal" />
            <token id="16" string="members" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="14-member" />
            <token id="20" string="committee" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">questioner</governor>
          <dependent id="1">Kohl</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">questioner</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">questioner</governor>
          <dependent id="3">today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">today</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">questioner</governor>
          <dependent id="5">leadoff</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">entered</governor>
          <dependent id="6">questioner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">hearings</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">hearings</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">questioner</governor>
          <dependent id="9">hearings</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">entered</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">day</governor>
          <dependent id="11">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">day</governor>
          <dependent id="12">third</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">entered</governor>
          <dependent id="13">day</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">members</governor>
          <dependent id="14">Two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">members</governor>
          <dependent id="15">pivotal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">entered</governor>
          <dependent id="16">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">committee</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">committee</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">committee</governor>
          <dependent id="19">14-member</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">members</governor>
          <dependent id="20">committee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Heflin</governor>
          <dependent id="22">Howell</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">members</governor>
          <dependent id="23">Heflin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Heflin</governor>
          <dependent id="25">D-Ala.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">members</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Specter</governor>
          <dependent id="28">Arlen</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">members</governor>
          <dependent id="29">Specter</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">Specter</governor>
          <dependent id="31">R-Pa</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="D-Ala." type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="D-Ala." />
          </tokens>
        </entity>
        <entity id="2" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kohl" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="today" />
          </tokens>
        </entity>
        <entity id="4" string="third day" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="third" />
            <token id="13" string="day" />
          </tokens>
        </entity>
        <entity id="5" string="Howell Heflin" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Howell" />
            <token id="23" string="Heflin" />
          </tokens>
        </entity>
        <entity id="6" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="Two" />
          </tokens>
        </entity>
        <entity id="7" string="Arlen Specter" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Arlen" />
            <token id="29" string="Specter" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>-- also voiced concern about Thomas&amp;apost; answers.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="voiced" lemma="voice" stem="voic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="7" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (: --) (VP (ADVP (RB also)) (VBD voiced) (NP (NN concern)) (PP (IN about) (NP (NP (NNP Thomas) (POS ')) (NNS answers)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="concern" type="NP">
          <tokens>
            <token id="4" string="concern" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' answers" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="also voiced concern about Thomas ' answers" type="VP">
          <tokens>
            <token id="2" string="also" />
            <token id="3" string="voiced" />
            <token id="4" string="concern" />
            <token id="5" string="about" />
            <token id="6" string="Thomas" />
            <token id="7" string="'" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">voiced</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">voiced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">voiced</governor>
          <dependent id="4">concern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">answers</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">answers</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Thomas</governor>
          <dependent id="7">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">voiced</governor>
          <dependent id="8">answers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>But the panel&amp;apost;s traditional third swing vote, Dennis DeConcini, D-Ariz., said Thomas was doing well Heflin cited the &amp;quot;appearance of a confirmation conversion&amp;quot; and said it may raise questions of Thomas&amp;apost; &amp;quot;integrity and temperament.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="7" string="swing" lemma="swing" stem="swing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dennis" lemma="Dennis" stem="denni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="DeConcini" lemma="DeConcini" stem="deconcini" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="D-Ariz." lemma="D-Ariz." stem="d-ariz." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Heflin" lemma="Heflin" stem="heflin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="cited" lemma="cite" stem="cite" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="conversion" lemma="conversion" stem="convers" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="raise" lemma="raise" stem="rais" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="integrity" lemma="integrity" stem="integr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="temperament" lemma="temperament" stem="tempera" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NP (DT the) (NN panel) (POS 's)) (JJ traditional) (JJ third) (NN swing) (NN vote)) (, ,) (NP (NNP Dennis) (NNP DeConcini)) (, ,) (NP (NNP D-Ariz.)) (, ,)) (VP (VBD said) (SBAR (S (NP (NNP Thomas)) (VP (VBD was) (VP (VBG doing) (S (ADVP (RB well)) (NP (NNP Heflin)) (VP (VP (VBD cited) (NP (NP (DT the) (`` ``) (NN appearance)) (PP (IN of) (NP (DT a) (NN confirmation) (NN conversion))))) ('' '') (CC and) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (MD may) (VP (VB raise) (NP (NP (NNS questions)) (PP (IN of) (NP (NP (NNP Thomas) (POS ')) (`` ``) (NP (NN integrity) (CC and) (NN temperament))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas ' `` integrity and temperament" type="NP">
          <tokens>
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="2" string="it may raise questions of Thomas ' `` integrity and temperament" type="SBAR">
          <tokens>
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="3" string="may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="the `` appearance" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas '" type="NP">
          <tokens>
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="32" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="9" string="Thomas was doing well Heflin cited the `` appearance of a confirmation conversion '' and said it may raise questions of Thomas ' `` integrity and temperament" type="SBAR">
          <tokens>
            <token id="16" string="Thomas" />
            <token id="17" string="was" />
            <token id="18" string="doing" />
            <token id="19" string="well" />
            <token id="20" string="Heflin" />
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dennis DeConcini" type="NP">
          <tokens>
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
          </tokens>
        </chunking>
        <chunking id="11" string="the panel 's traditional third swing vote , Dennis DeConcini , D-Ariz. ," type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
            <token id="5" string="traditional" />
            <token id="6" string="third" />
            <token id="7" string="swing" />
            <token id="8" string="vote" />
            <token id="9" string="," />
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
            <token id="12" string="," />
            <token id="13" string="D-Ariz." />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="the panel 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="was doing well Heflin cited the `` appearance of a confirmation conversion '' and said it may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="doing" />
            <token id="19" string="well" />
            <token id="20" string="Heflin" />
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="14" string="questions of Thomas ' `` integrity and temperament" type="NP">
          <tokens>
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="15" string="cited the `` appearance of a confirmation conversion" type="VP">
          <tokens>
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
          </tokens>
        </chunking>
        <chunking id="16" string="doing well Heflin cited the `` appearance of a confirmation conversion '' and said it may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="18" string="doing" />
            <token id="19" string="well" />
            <token id="20" string="Heflin" />
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="17" string="the panel 's traditional third swing vote" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="panel" />
            <token id="4" string="'s" />
            <token id="5" string="traditional" />
            <token id="6" string="third" />
            <token id="7" string="swing" />
            <token id="8" string="vote" />
          </tokens>
        </chunking>
        <chunking id="18" string="the `` appearance of a confirmation conversion" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
          </tokens>
        </chunking>
        <chunking id="19" string="cited the `` appearance of a confirmation conversion '' and said it may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="20" string="questions" type="NP">
          <tokens>
            <token id="35" string="questions" />
          </tokens>
        </chunking>
        <chunking id="21" string="said it may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="22" string="said Thomas was doing well Heflin cited the `` appearance of a confirmation conversion '' and said it may raise questions of Thomas ' `` integrity and temperament" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="Thomas" />
            <token id="17" string="was" />
            <token id="18" string="doing" />
            <token id="19" string="well" />
            <token id="20" string="Heflin" />
            <token id="21" string="cited" />
            <token id="22" string="the" />
            <token id="23" string="&quot;" />
            <token id="24" string="appearance" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="said" />
            <token id="32" string="it" />
            <token id="33" string="may" />
            <token id="34" string="raise" />
            <token id="35" string="questions" />
            <token id="36" string="of" />
            <token id="37" string="Thomas" />
            <token id="38" string="'" />
            <token id="39" string="&quot;" />
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="23" string="integrity and temperament" type="NP">
          <tokens>
            <token id="40" string="integrity" />
            <token id="41" string="and" />
            <token id="42" string="temperament" />
          </tokens>
        </chunking>
        <chunking id="24" string="a confirmation conversion" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="confirmation" />
            <token id="28" string="conversion" />
          </tokens>
        </chunking>
        <chunking id="25" string="D-Ariz." type="NP">
          <tokens>
            <token id="13" string="D-Ariz." />
          </tokens>
        </chunking>
        <chunking id="26" string="Heflin" type="NP">
          <tokens>
            <token id="20" string="Heflin" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">panel</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">vote</governor>
          <dependent id="3">panel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">panel</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">vote</governor>
          <dependent id="5">traditional</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">vote</governor>
          <dependent id="6">third</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">vote</governor>
          <dependent id="7">swing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="8">vote</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">DeConcini</governor>
          <dependent id="10">Dennis</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">vote</governor>
          <dependent id="11">DeConcini</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">vote</governor>
          <dependent id="13">D-Ariz.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">doing</governor>
          <dependent id="16">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">doing</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="18">doing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">cited</governor>
          <dependent id="19">well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">cited</governor>
          <dependent id="20">Heflin</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">doing</governor>
          <dependent id="21">cited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">appearance</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">cited</governor>
          <dependent id="24">appearance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">conversion</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">conversion</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">conversion</governor>
          <dependent id="27">confirmation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">appearance</governor>
          <dependent id="28">conversion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">cited</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">cited</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">raise</governor>
          <dependent id="32">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">raise</governor>
          <dependent id="33">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="34">raise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">raise</governor>
          <dependent id="35">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Thomas</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">questions</governor>
          <dependent id="37">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Thomas</governor>
          <dependent id="38">'</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">Thomas</governor>
          <dependent id="40">integrity</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="40">integrity</governor>
          <dependent id="41">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="40">integrity</governor>
          <dependent id="42">temperament</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dennis DeConcini" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Dennis" />
            <token id="11" string="DeConcini" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="D-Ariz." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="D-Ariz." />
          </tokens>
        </entity>
        <entity id="5" string="Heflin" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Heflin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>; But Heflin added, &amp;quot;I am not at this time of any firm opinion one way or the other&amp;quot; on whether Thomas should be confirmed And Simon said Thomas&amp;apost; performance thus far &amp;quot;has neither helped him nor hurt him.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Heflin" lemma="Heflin" stem="heflin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="firm" lemma="firm" stem="firm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="thus" lemma="thus" stem="thu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="neither" lemma="neither" stem="neither" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="hurt" lemma="hurt" stem="hurt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (CC But) (NP (NNP Heflin)) (VP (VP (VP (VBD added) (, ,) (`` ``) (S (NP (PRP I)) (VP (VBP am) (RB not) (PP (IN at) (NP (NP (DT this) (NN time)) (PP (IN of) (NP (NP (NP (DT any) (JJ firm) (NN opinion)) (NP (CD one) (NN way))) (CC or) (NP (DT the) (JJ other)))))))) ('' '')) (PP (IN on) (SBAR (IN whether) (S (S (NP (NNP Thomas)) (VP (MD should) (VP (VB be) (VP (VBN confirmed))))) (CC And) (S (NP (NNP Simon)) (VP (VBD said) (SBAR (S (NP (NP (NP (NNP Thomas) (POS ')) (NN performance)) (ADVP (RB thus) (RB far))) (`` ``) (VP (VBZ has) (ADVP (DT neither)) (VP (VBD helped) (NP (PRP him)))))))))))) (CC nor) (VP (VB hurt) (NP (PRP him)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="25" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas '" type="NP">
          <tokens>
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="am not at this time of any firm opinion one way or the other" type="VP">
          <tokens>
            <token id="8" string="am" />
            <token id="9" string="not" />
            <token id="10" string="at" />
            <token id="11" string="this" />
            <token id="12" string="time" />
            <token id="13" string="of" />
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas ' performance thus far" type="NP">
          <tokens>
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
          </tokens>
        </chunking>
        <chunking id="5" string="has neither helped him" type="VP">
          <tokens>
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="this time" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="whether Thomas should be confirmed And Simon said Thomas ' performance thus far `` has neither helped him" type="SBAR">
          <tokens>
            <token id="24" string="whether" />
            <token id="25" string="Thomas" />
            <token id="26" string="should" />
            <token id="27" string="be" />
            <token id="28" string="confirmed" />
            <token id="29" string="And" />
            <token id="30" string="Simon" />
            <token id="31" string="said" />
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
            <token id="37" string="&quot;" />
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="helped him" type="VP">
          <tokens>
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="added , `` I am not at this time of any firm opinion one way or the other ''" type="VP">
          <tokens>
            <token id="4" string="added" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
            <token id="8" string="am" />
            <token id="9" string="not" />
            <token id="10" string="at" />
            <token id="11" string="this" />
            <token id="12" string="time" />
            <token id="13" string="of" />
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="added , `` I am not at this time of any firm opinion one way or the other '' on whether Thomas should be confirmed And Simon said Thomas ' performance thus far `` has neither helped him nor hurt him" type="VP">
          <tokens>
            <token id="4" string="added" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
            <token id="8" string="am" />
            <token id="9" string="not" />
            <token id="10" string="at" />
            <token id="11" string="this" />
            <token id="12" string="time" />
            <token id="13" string="of" />
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="&quot;" />
            <token id="23" string="on" />
            <token id="24" string="whether" />
            <token id="25" string="Thomas" />
            <token id="26" string="should" />
            <token id="27" string="be" />
            <token id="28" string="confirmed" />
            <token id="29" string="And" />
            <token id="30" string="Simon" />
            <token id="31" string="said" />
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
            <token id="37" string="&quot;" />
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
            <token id="42" string="nor" />
            <token id="43" string="hurt" />
            <token id="44" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="be confirmed" type="VP">
          <tokens>
            <token id="27" string="be" />
            <token id="28" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="12" string="should be confirmed" type="VP">
          <tokens>
            <token id="26" string="should" />
            <token id="27" string="be" />
            <token id="28" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="13" string="said Thomas ' performance thus far `` has neither helped him" type="VP">
          <tokens>
            <token id="31" string="said" />
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
            <token id="37" string="&quot;" />
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="15" string="him" type="NP">
          <tokens>
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="confirmed" type="VP">
          <tokens>
            <token id="28" string="confirmed" />
          </tokens>
        </chunking>
        <chunking id="17" string="this time of any firm opinion one way or the other" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="time" />
            <token id="13" string="of" />
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
          </tokens>
        </chunking>
        <chunking id="18" string="any firm opinion" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="19" string="Thomas ' performance thus far `` has neither helped him" type="SBAR">
          <tokens>
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
            <token id="37" string="&quot;" />
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="20" string="hurt him" type="VP">
          <tokens>
            <token id="43" string="hurt" />
            <token id="44" string="him" />
          </tokens>
        </chunking>
        <chunking id="21" string="any firm opinion one way or the other" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
          </tokens>
        </chunking>
        <chunking id="22" string="Simon" type="NP">
          <tokens>
            <token id="30" string="Simon" />
          </tokens>
        </chunking>
        <chunking id="23" string="added , `` I am not at this time of any firm opinion one way or the other '' on whether Thomas should be confirmed And Simon said Thomas ' performance thus far `` has neither helped him" type="VP">
          <tokens>
            <token id="4" string="added" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
            <token id="8" string="am" />
            <token id="9" string="not" />
            <token id="10" string="at" />
            <token id="11" string="this" />
            <token id="12" string="time" />
            <token id="13" string="of" />
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
            <token id="19" string="or" />
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="&quot;" />
            <token id="23" string="on" />
            <token id="24" string="whether" />
            <token id="25" string="Thomas" />
            <token id="26" string="should" />
            <token id="27" string="be" />
            <token id="28" string="confirmed" />
            <token id="29" string="And" />
            <token id="30" string="Simon" />
            <token id="31" string="said" />
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
            <token id="35" string="thus" />
            <token id="36" string="far" />
            <token id="37" string="&quot;" />
            <token id="38" string="has" />
            <token id="39" string="neither" />
            <token id="40" string="helped" />
            <token id="41" string="him" />
          </tokens>
        </chunking>
        <chunking id="24" string="Thomas ' performance" type="NP">
          <tokens>
            <token id="32" string="Thomas" />
            <token id="33" string="'" />
            <token id="34" string="performance" />
          </tokens>
        </chunking>
        <chunking id="25" string="Heflin" type="NP">
          <tokens>
            <token id="3" string="Heflin" />
          </tokens>
        </chunking>
        <chunking id="26" string="one way" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="way" />
          </tokens>
        </chunking>
        <chunking id="27" string="any firm opinion one way" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="firm" />
            <token id="16" string="opinion" />
            <token id="17" string="one" />
            <token id="18" string="way" />
          </tokens>
        </chunking>
        <chunking id="28" string="the other" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="other" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">added</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">added</governor>
          <dependent id="3">Heflin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">time</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">time</governor>
          <dependent id="8">am</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">time</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">time</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">time</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">added</governor>
          <dependent id="12">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">opinion</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">opinion</governor>
          <dependent id="14">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">opinion</governor>
          <dependent id="15">firm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">time</governor>
          <dependent id="16">opinion</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">way</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">opinion</governor>
          <dependent id="18">way</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">opinion</governor>
          <dependent id="19">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">other</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">opinion</governor>
          <dependent id="21">other</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">confirmed</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">confirmed</governor>
          <dependent id="24">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">confirmed</governor>
          <dependent id="25">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">confirmed</governor>
          <dependent id="26">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">confirmed</governor>
          <dependent id="27">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">added</governor>
          <dependent id="28">confirmed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">confirmed</governor>
          <dependent id="29">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="30">Simon</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">confirmed</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">performance</governor>
          <dependent id="32">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Thomas</governor>
          <dependent id="33">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">helped</governor>
          <dependent id="34">performance</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">far</governor>
          <dependent id="35">thus</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">performance</governor>
          <dependent id="36">far</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">helped</governor>
          <dependent id="38">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">helped</governor>
          <dependent id="39">neither</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="40">helped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">helped</governor>
          <dependent id="41">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">added</governor>
          <dependent id="42">nor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">added</governor>
          <dependent id="43">hurt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">hurt</governor>
          <dependent id="44">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Simon" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Heflin" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Heflin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>; Specter blamed fellow committee members more than Thomas in concluding, &amp;quot;We really haven&amp;apost;t moved very far in the process.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Specter" lemma="Specter" stem="specter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="blamed" lemma="blame" stem="blame" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="fellow" lemma="fellow" stem="fellow" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="concluding" lemma="conclude" stem="conclud" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="moved" lemma="move" stem="move" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (NNP Specter)) (VP (VBD blamed) (NP (JJ fellow) (NN committee) (NNS members)) (ADVP (ADVP (RBR more)) (SBAR (IN than) (NP (NP (NNP Thomas)) (PP (IN in) (S (VP (VBG concluding) (, ,) (`` ``) (S (NP (PRP We)) (ADVP (RB really)) (VP (VBP have) (RB n't) (VP (VBN moved) (ADVP (RB very) (RB far)) (PP (IN in) (NP (DT the) (NN process)))))))))) (. .) ('' '')))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="moved very far in the process" type="VP">
          <tokens>
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
          </tokens>
        </chunking>
        <chunking id="2" string="have n't moved very far in the process" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="n't" />
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
          </tokens>
        </chunking>
        <chunking id="3" string="blamed fellow committee members more than Thomas in concluding , `` We really have n't moved very far in the process . ''" type="VP">
          <tokens>
            <token id="3" string="blamed" />
            <token id="4" string="fellow" />
            <token id="5" string="committee" />
            <token id="6" string="members" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="Thomas" />
            <token id="10" string="in" />
            <token id="11" string="concluding" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="We" />
            <token id="15" string="really" />
            <token id="16" string="have" />
            <token id="17" string="n't" />
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
            <token id="24" string="." />
            <token id="25" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas in concluding , `` We really have n't moved very far in the process" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
            <token id="10" string="in" />
            <token id="11" string="concluding" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="We" />
            <token id="15" string="really" />
            <token id="16" string="have" />
            <token id="17" string="n't" />
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
          </tokens>
        </chunking>
        <chunking id="5" string="concluding , `` We really have n't moved very far in the process" type="VP">
          <tokens>
            <token id="11" string="concluding" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="We" />
            <token id="15" string="really" />
            <token id="16" string="have" />
            <token id="17" string="n't" />
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
          </tokens>
        </chunking>
        <chunking id="6" string="the process" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="Specter" type="NP">
          <tokens>
            <token id="2" string="Specter" />
          </tokens>
        </chunking>
        <chunking id="8" string="than Thomas in concluding , `` We really have n't moved very far in the process . ''" type="SBAR">
          <tokens>
            <token id="8" string="than" />
            <token id="9" string="Thomas" />
            <token id="10" string="in" />
            <token id="11" string="concluding" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="We" />
            <token id="15" string="really" />
            <token id="16" string="have" />
            <token id="17" string="n't" />
            <token id="18" string="moved" />
            <token id="19" string="very" />
            <token id="20" string="far" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="process" />
            <token id="24" string="." />
            <token id="25" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="9" string="Thomas" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="10" string="fellow committee members" type="NP">
          <tokens>
            <token id="4" string="fellow" />
            <token id="5" string="committee" />
            <token id="6" string="members" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="14" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">blamed</governor>
          <dependent id="2">Specter</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">blamed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">members</governor>
          <dependent id="4">fellow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">members</governor>
          <dependent id="5">committee</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">blamed</governor>
          <dependent id="6">members</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">blamed</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">more</governor>
          <dependent id="8">than</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">than</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">concluding</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">Thomas</governor>
          <dependent id="11">concluding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">moved</governor>
          <dependent id="14">We</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">moved</governor>
          <dependent id="15">really</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">moved</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">moved</governor>
          <dependent id="17">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">concluding</governor>
          <dependent id="18">moved</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">far</governor>
          <dependent id="19">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">moved</governor>
          <dependent id="20">far</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">process</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">process</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">moved</governor>
          <dependent id="23">process</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Specter" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Specter" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>; Thomas, a black federal appeals judge, was picked by President Bush to replace the retiring Thurgood Marshall, the high court&amp;apost;s only black justice DeConcini said he thought the conservative Thomas &amp;quot;handled the privacy questions very well&amp;quot; without taking a stand on abortion.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="appeals" lemma="appeal" stem="appeal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="picked" lemma="pick" stem="pick" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="14" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="replace" lemma="replace" stem="replac" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="retiring" lemma="retire" stem="retir" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Thurgood" lemma="Thurgood" stem="thurgood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Marshall" lemma="Marshall" stem="marshal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="DeConcini" lemma="DeConcini" stem="deconcini" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="true" />
        <token id="35" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="36" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="handled" lemma="handle" stem="handl" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NP (NNP Thomas)) (, ,) (NP (DT a) (JJ black) (JJ federal) (NNS appeals) (NN judge)) (, ,)) (VP (VBD was) (VP (VBN picked) (PP (IN by) (NP (NNP President) (NNP Bush))) (S (VP (TO to) (VP (VB replace) (NP (NP (DT the) (VBG retiring)) (SBAR (S (NP (NP (NNP Thurgood) (NNP Marshall)) (, ,) (NP (NP (NP (DT the) (JJ high) (NN court) (POS 's)) (JJ only) (JJ black) (NN justice)) (NP (NNP DeConcini)))) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD thought) (SBAR (S (NP (DT the) (JJ conservative) (NNP Thomas)) (`` ``) (VP (VBD handled) (NP (DT the) (NN privacy) (NNS questions)) (ADVP (RB very) (RB well))) ('' ''))))))))))))) (PP (IN without) (S (VP (VBG taking) (NP (DT a) (NN stand)) (PP (IN on) (NP (NN abortion))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="handled the privacy questions very well" type="VP">
          <tokens>
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
          </tokens>
        </chunking>
        <chunking id="2" string="the high court 's" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="the privacy questions" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="the high court 's only black justice DeConcini" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
          </tokens>
        </chunking>
        <chunking id="6" string="President Bush" type="NP">
          <tokens>
            <token id="13" string="President" />
            <token id="14" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="7" string="said he thought the conservative Thomas `` handled the privacy questions very well ''" type="VP">
          <tokens>
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thurgood Marshall" type="NP">
          <tokens>
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
          </tokens>
        </chunking>
        <chunking id="9" string="the high court 's only black justice" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="10" string="a black federal appeals judge" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="black" />
            <token id="6" string="federal" />
            <token id="7" string="appeals" />
            <token id="8" string="judge" />
          </tokens>
        </chunking>
        <chunking id="11" string="DeConcini" type="NP">
          <tokens>
            <token id="29" string="DeConcini" />
          </tokens>
        </chunking>
        <chunking id="12" string="thought the conservative Thomas `` handled the privacy questions very well ''" type="VP">
          <tokens>
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="a stand" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="stand" />
          </tokens>
        </chunking>
        <chunking id="14" string="he thought the conservative Thomas `` handled the privacy questions very well ''" type="SBAR">
          <tokens>
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="15" string="the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well ''" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="retiring" />
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="16" string="Thomas , a black federal appeals judge ," type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="black" />
            <token id="6" string="federal" />
            <token id="7" string="appeals" />
            <token id="8" string="judge" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="taking a stand on abortion" type="VP">
          <tokens>
            <token id="45" string="taking" />
            <token id="46" string="a" />
            <token id="47" string="stand" />
            <token id="48" string="on" />
            <token id="49" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="31" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="picked by President Bush to replace the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well '' without taking a stand on abortion" type="VP">
          <tokens>
            <token id="11" string="picked" />
            <token id="12" string="by" />
            <token id="13" string="President" />
            <token id="14" string="Bush" />
            <token id="15" string="to" />
            <token id="16" string="replace" />
            <token id="17" string="the" />
            <token id="18" string="retiring" />
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
            <token id="44" string="without" />
            <token id="45" string="taking" />
            <token id="46" string="a" />
            <token id="47" string="stand" />
            <token id="48" string="on" />
            <token id="49" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="20" string="the conservative Thomas" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="21" string="the conservative Thomas `` handled the privacy questions very well ''" type="SBAR">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="22" string="Thurgood Marshall , the high court 's only black justice DeConcini" type="NP">
          <tokens>
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
          </tokens>
        </chunking>
        <chunking id="23" string="Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well ''" type="SBAR">
          <tokens>
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="24" string="abortion" type="NP">
          <tokens>
            <token id="49" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="25" string="to replace the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well ''" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="replace" />
            <token id="17" string="the" />
            <token id="18" string="retiring" />
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="26" string="was picked by President Bush to replace the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well '' without taking a stand on abortion" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="picked" />
            <token id="12" string="by" />
            <token id="13" string="President" />
            <token id="14" string="Bush" />
            <token id="15" string="to" />
            <token id="16" string="replace" />
            <token id="17" string="the" />
            <token id="18" string="retiring" />
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
            <token id="44" string="without" />
            <token id="45" string="taking" />
            <token id="46" string="a" />
            <token id="47" string="stand" />
            <token id="48" string="on" />
            <token id="49" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="27" string="replace the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas `` handled the privacy questions very well ''" type="VP">
          <tokens>
            <token id="16" string="replace" />
            <token id="17" string="the" />
            <token id="18" string="retiring" />
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="high" />
            <token id="24" string="court" />
            <token id="25" string="'s" />
            <token id="26" string="only" />
            <token id="27" string="black" />
            <token id="28" string="justice" />
            <token id="29" string="DeConcini" />
            <token id="30" string="said" />
            <token id="31" string="he" />
            <token id="32" string="thought" />
            <token id="33" string="the" />
            <token id="34" string="conservative" />
            <token id="35" string="Thomas" />
            <token id="36" string="&quot;" />
            <token id="37" string="handled" />
            <token id="38" string="the" />
            <token id="39" string="privacy" />
            <token id="40" string="questions" />
            <token id="41" string="very" />
            <token id="42" string="well" />
            <token id="43" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="28" string="the retiring" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="retiring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="11">picked</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">judge</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">judge</governor>
          <dependent id="5">black</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">judge</governor>
          <dependent id="6">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">judge</governor>
          <dependent id="7">appeals</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Thomas</governor>
          <dependent id="8">judge</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">picked</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">picked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Bush</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bush</governor>
          <dependent id="13">President</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">picked</governor>
          <dependent id="14">Bush</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">replace</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">picked</governor>
          <dependent id="16">replace</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">replace</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">the</governor>
          <dependent id="18">retiring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Marshall</governor>
          <dependent id="19">Thurgood</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="20">Marshall</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">court</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">court</governor>
          <dependent id="23">high</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">justice</governor>
          <dependent id="24">court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">court</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">justice</governor>
          <dependent id="26">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">justice</governor>
          <dependent id="27">black</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">Marshall</governor>
          <dependent id="28">justice</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">justice</governor>
          <dependent id="29">DeConcini</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">the</governor>
          <dependent id="30">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">thought</governor>
          <dependent id="31">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="32">thought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Thomas</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Thomas</governor>
          <dependent id="34">conservative</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">handled</governor>
          <dependent id="35">Thomas</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">thought</governor>
          <dependent id="37">handled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">questions</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">questions</governor>
          <dependent id="39">privacy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">handled</governor>
          <dependent id="40">questions</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">well</governor>
          <dependent id="41">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">handled</governor>
          <dependent id="42">well</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">taking</governor>
          <dependent id="44">without</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">picked</governor>
          <dependent id="45">taking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">stand</governor>
          <dependent id="46">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">taking</governor>
          <dependent id="47">stand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">abortion</governor>
          <dependent id="48">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">taking</governor>
          <dependent id="49">abortion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="34" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Bush" />
          </tokens>
        </entity>
        <entity id="4" string="Thurgood Marshall" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Thurgood" />
            <token id="20" string="Marshall" />
          </tokens>
        </entity>
        <entity id="5" string="DeConcini" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="DeConcini" />
          </tokens>
        </entity>
        <entity id="6" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>&amp;quot;I don&amp;apost;t see how you could ask him to do anything more.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB see) (SBAR (WHADVP (WRB how)) (S (NP (PRP you)) (VP (MD could) (VP (VB ask) (S (NP (PRP him)) (VP (TO to) (VP (VB do) (NP (NN anything) (JJR more))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="ask him to do anything more" type="VP">
          <tokens>
            <token id="9" string="ask" />
            <token id="10" string="him" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="2" string="to do anything more" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="3" string="see how you could ask him to do anything more" type="VP">
          <tokens>
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="you" />
            <token id="8" string="could" />
            <token id="9" string="ask" />
            <token id="10" string="him" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="could ask him to do anything more" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="ask" />
            <token id="10" string="him" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="do n't see how you could ask him to do anything more" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="you" />
            <token id="8" string="could" />
            <token id="9" string="ask" />
            <token id="10" string="him" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="8" string="anything more" type="NP">
          <tokens>
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="9" string="do anything more" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="10" string="how you could ask him to do anything more" type="SBAR">
          <tokens>
            <token id="6" string="how" />
            <token id="7" string="you" />
            <token id="8" string="could" />
            <token id="9" string="ask" />
            <token id="10" string="him" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="anything" />
            <token id="14" string="more" />
          </tokens>
        </chunking>
        <chunking id="11" string="how" type="WHADVP">
          <tokens>
            <token id="6" string="how" />
          </tokens>
        </chunking>
        <chunking id="12" string="you" type="NP">
          <tokens>
            <token id="7" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">see</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">see</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">see</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">see</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">ask</governor>
          <dependent id="6">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">ask</governor>
          <dependent id="7">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">ask</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">see</governor>
          <dependent id="9">ask</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">ask</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">do</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">ask</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">more</governor>
          <dependent id="13">anything</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">do</governor>
          <dependent id="14">more</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>; Thomas expanded earlier testimony by saying Wednesday that he believed the right of marital privacy was &amp;quot;fundamental&amp;quot; -- a status that accords it the fullest judicial protection from government intrusion But he repeatedly refused to state his views on the 1973 abortion decision based on women&amp;apost;s right of privacy.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="expanded" lemma="expand" stem="expand" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="earlier" lemma="earlier" stem="earlier" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="believed" lemma="believe" stem="believ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="marital" lemma="marital" stem="marit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fundamental" lemma="fundamental" stem="fundament" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="accords" lemma="accord" stem="accord" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="fullest" lemma="fullest" stem="fullest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="judicial" lemma="judicial" stem="judici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="protection" lemma="protection" stem="protect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="intrusion" lemma="intrusion" stem="intrus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="repeatedly" lemma="repeatedly" stem="repeatedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="state" lemma="state" stem="state" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="44" string="1973" lemma="1973" stem="1973" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="45" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="46" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="47" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="50" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="51" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="52" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NNP Thomas)) (VP (VBD expanded) (NP (JJR earlier) (NN testimony)) (PP (IN by) (S (VP (VP (VBG saying) (NP-TMP (NNP Wednesday)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD believed) (SBAR (S (NP (NP (DT the) (NN right)) (PP (IN of) (NP (JJ marital) (NN privacy)))) (VP (VBD was) (`` ``) (ADJP (JJ fundamental)) ('' '')))))))) (PRN (: --) (S (NP (NP (NP (DT a) (NN status)) (SBAR (WHNP (WDT that)))) (NP (NNS accords))) (NP (PRP it))))))) (PP (NP (DT the) (JJS fullest) (JJ judicial) (NN protection)) (IN from) (NP (NN government) (NN intrusion))))) (CC But) (S (NP (PRP he)) (ADVP (RB repeatedly)) (VP (VBD refused) (S (VP (TO to) (VP (VB state) (NP (PRP$ his) (NNS views)) (PP (IN on) (NP (DT the) (CD 1973) (NN abortion) (NN decision))) (PP (VBN based) (PP (IN on) (NP (NP (NP (NNS women) (POS 's)) (NN right)) (PP (IN of) (NP (NN privacy))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="accords" type="NP">
          <tokens>
            <token id="25" string="accords" />
          </tokens>
        </chunking>
        <chunking id="2" string="government intrusion" type="NP">
          <tokens>
            <token id="32" string="government" />
            <token id="33" string="intrusion" />
          </tokens>
        </chunking>
        <chunking id="3" string="a status that accords" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="status" />
            <token id="24" string="that" />
            <token id="25" string="accords" />
          </tokens>
        </chunking>
        <chunking id="4" string="was `` fundamental ''" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="women 's right of privacy" type="NP">
          <tokens>
            <token id="49" string="women" />
            <token id="50" string="'s" />
            <token id="51" string="right" />
            <token id="52" string="of" />
            <token id="53" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="saying Wednesday that he believed the right of marital privacy was `` fundamental '' -- a status that accords it" type="VP">
          <tokens>
            <token id="7" string="saying" />
            <token id="8" string="Wednesday" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="believed" />
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
            <token id="21" string="--" />
            <token id="22" string="a" />
            <token id="23" string="status" />
            <token id="24" string="that" />
            <token id="25" string="accords" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="the fullest judicial protection" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="fullest" />
            <token id="29" string="judicial" />
            <token id="30" string="protection" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="refused to state his views on the 1973 abortion decision based on women 's right of privacy" type="VP">
          <tokens>
            <token id="37" string="refused" />
            <token id="38" string="to" />
            <token id="39" string="state" />
            <token id="40" string="his" />
            <token id="41" string="views" />
            <token id="42" string="on" />
            <token id="43" string="the" />
            <token id="44" string="1973" />
            <token id="45" string="abortion" />
            <token id="46" string="decision" />
            <token id="47" string="based" />
            <token id="48" string="on" />
            <token id="49" string="women" />
            <token id="50" string="'s" />
            <token id="51" string="right" />
            <token id="52" string="of" />
            <token id="53" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="11" string="the right of marital privacy was `` fundamental ''" type="SBAR">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="12" string="state his views on the 1973 abortion decision based on women 's right of privacy" type="VP">
          <tokens>
            <token id="39" string="state" />
            <token id="40" string="his" />
            <token id="41" string="views" />
            <token id="42" string="on" />
            <token id="43" string="the" />
            <token id="44" string="1973" />
            <token id="45" string="abortion" />
            <token id="46" string="decision" />
            <token id="47" string="based" />
            <token id="48" string="on" />
            <token id="49" string="women" />
            <token id="50" string="'s" />
            <token id="51" string="right" />
            <token id="52" string="of" />
            <token id="53" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="13" string="a status" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="status" />
          </tokens>
        </chunking>
        <chunking id="14" string="women 's right" type="NP">
          <tokens>
            <token id="49" string="women" />
            <token id="50" string="'s" />
            <token id="51" string="right" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="expanded earlier testimony by saying Wednesday that he believed the right of marital privacy was `` fundamental '' -- a status that accords it the fullest judicial protection from government intrusion" type="VP">
          <tokens>
            <token id="3" string="expanded" />
            <token id="4" string="earlier" />
            <token id="5" string="testimony" />
            <token id="6" string="by" />
            <token id="7" string="saying" />
            <token id="8" string="Wednesday" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="believed" />
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
            <token id="21" string="--" />
            <token id="22" string="a" />
            <token id="23" string="status" />
            <token id="24" string="that" />
            <token id="25" string="accords" />
            <token id="26" string="it" />
            <token id="27" string="the" />
            <token id="28" string="fullest" />
            <token id="29" string="judicial" />
            <token id="30" string="protection" />
            <token id="31" string="from" />
            <token id="32" string="government" />
            <token id="33" string="intrusion" />
          </tokens>
        </chunking>
        <chunking id="17" string="the right of marital privacy" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="18" string="marital privacy" type="NP">
          <tokens>
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="19" string="earlier testimony" type="NP">
          <tokens>
            <token id="4" string="earlier" />
            <token id="5" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="20" string="his views" type="NP">
          <tokens>
            <token id="40" string="his" />
            <token id="41" string="views" />
          </tokens>
        </chunking>
        <chunking id="21" string="to state his views on the 1973 abortion decision based on women 's right of privacy" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="state" />
            <token id="40" string="his" />
            <token id="41" string="views" />
            <token id="42" string="on" />
            <token id="43" string="the" />
            <token id="44" string="1973" />
            <token id="45" string="abortion" />
            <token id="46" string="decision" />
            <token id="47" string="based" />
            <token id="48" string="on" />
            <token id="49" string="women" />
            <token id="50" string="'s" />
            <token id="51" string="right" />
            <token id="52" string="of" />
            <token id="53" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="22" string="that he believed the right of marital privacy was `` fundamental ''" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="believed" />
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="23" string="privacy" type="NP">
          <tokens>
            <token id="53" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="24" string="believed the right of marital privacy was `` fundamental ''" type="VP">
          <tokens>
            <token id="11" string="believed" />
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="25" string="the right" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="right" />
          </tokens>
        </chunking>
        <chunking id="26" string="fundamental" type="ADJP">
          <tokens>
            <token id="19" string="fundamental" />
          </tokens>
        </chunking>
        <chunking id="27" string="women 's" type="NP">
          <tokens>
            <token id="49" string="women" />
            <token id="50" string="'s" />
          </tokens>
        </chunking>
        <chunking id="28" string="the 1973 abortion decision" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="1973" />
            <token id="45" string="abortion" />
            <token id="46" string="decision" />
          </tokens>
        </chunking>
        <chunking id="29" string="that" type="SBAR">
          <tokens>
            <token id="24" string="that" />
          </tokens>
        </chunking>
        <chunking id="30" string="saying Wednesday that he believed the right of marital privacy was `` fundamental ''" type="VP">
          <tokens>
            <token id="7" string="saying" />
            <token id="8" string="Wednesday" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="believed" />
            <token id="12" string="the" />
            <token id="13" string="right" />
            <token id="14" string="of" />
            <token id="15" string="marital" />
            <token id="16" string="privacy" />
            <token id="17" string="was" />
            <token id="18" string="&quot;" />
            <token id="19" string="fundamental" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="31" string="a status that" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="status" />
            <token id="24" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">expanded</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">expanded</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">testimony</governor>
          <dependent id="4">earlier</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">expanded</governor>
          <dependent id="5">testimony</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">saying</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">expanded</governor>
          <dependent id="7">saying</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">saying</governor>
          <dependent id="8">Wednesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">believed</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">believed</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">saying</governor>
          <dependent id="11">believed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">right</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">fundamental</governor>
          <dependent id="13">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">privacy</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">privacy</governor>
          <dependent id="15">marital</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">right</governor>
          <dependent id="16">privacy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">fundamental</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">believed</governor>
          <dependent id="19">fundamental</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">status</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">it</governor>
          <dependent id="23">status</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">status</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">status</governor>
          <dependent id="25">accords</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">saying</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">protection</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">protection</governor>
          <dependent id="28">fullest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">protection</governor>
          <dependent id="29">judicial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">expanded</governor>
          <dependent id="30">protection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">protection</governor>
          <dependent id="31">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">intrusion</governor>
          <dependent id="32">government</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">protection</governor>
          <dependent id="33">intrusion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">expanded</governor>
          <dependent id="34">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">refused</governor>
          <dependent id="35">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">refused</governor>
          <dependent id="36">repeatedly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">expanded</governor>
          <dependent id="37">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">state</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">refused</governor>
          <dependent id="39">state</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">views</governor>
          <dependent id="40">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">state</governor>
          <dependent id="41">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">decision</governor>
          <dependent id="42">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">decision</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="46">decision</governor>
          <dependent id="44">1973</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">decision</governor>
          <dependent id="45">abortion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">state</governor>
          <dependent id="46">decision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">right</governor>
          <dependent id="47">based</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="47">based</governor>
          <dependent id="48">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="51">right</governor>
          <dependent id="49">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">women</governor>
          <dependent id="50">'s</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="39">state</governor>
          <dependent id="51">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">privacy</governor>
          <dependent id="52">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">right</governor>
          <dependent id="53">privacy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="2" string="1973" type="DATE" score="0.0">
          <tokens>
            <token id="44" string="1973" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="13" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>To give such an answer, he said, &amp;quot;would undermine my ability to sit in an impartial way on such an important case.&amp;quot;</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="undermine" lemma="undermine" stem="undermin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="ability" lemma="ability" stem="abil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sit" lemma="sit" stem="sit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="impartial" lemma="impartial" stem="imparti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB give) (NP (PDT such) (DT an) (NN answer))))) (PRN (, ,) (S (NP (PRP he)) (VP (VBD said))) (, ,)) (`` ``) (VP (MD would) (VP (VB undermine) (NP (PRP$ my) (NN ability) (S (VP (TO to) (VP (VB sit) (PP (IN in) (NP (NP (DT an) (JJ impartial) (NN way)) (PP (IN on) (NP (PDT such) (DT an) (JJ important) (NN case))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="sit in an impartial way on such an important case" type="VP">
          <tokens>
            <token id="16" string="sit" />
            <token id="17" string="in" />
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="To give such an answer" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="give" />
            <token id="3" string="such" />
            <token id="4" string="an" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
        <chunking id="3" string="undermine my ability to sit in an impartial way on such an important case" type="VP">
          <tokens>
            <token id="12" string="undermine" />
            <token id="13" string="my" />
            <token id="14" string="ability" />
            <token id="15" string="to" />
            <token id="16" string="sit" />
            <token id="17" string="in" />
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="an impartial way on such an important case" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="give such an answer" type="VP">
          <tokens>
            <token id="2" string="give" />
            <token id="3" string="such" />
            <token id="4" string="an" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
        <chunking id="6" string="my ability to sit in an impartial way on such an important case" type="NP">
          <tokens>
            <token id="13" string="my" />
            <token id="14" string="ability" />
            <token id="15" string="to" />
            <token id="16" string="sit" />
            <token id="17" string="in" />
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="would undermine my ability to sit in an impartial way on such an important case" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="undermine" />
            <token id="13" string="my" />
            <token id="14" string="ability" />
            <token id="15" string="to" />
            <token id="16" string="sit" />
            <token id="17" string="in" />
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="such an answer" type="NP">
          <tokens>
            <token id="3" string="such" />
            <token id="4" string="an" />
            <token id="5" string="answer" />
          </tokens>
        </chunking>
        <chunking id="9" string="an impartial way" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="to sit in an impartial way on such an important case" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="sit" />
            <token id="17" string="in" />
            <token id="18" string="an" />
            <token id="19" string="impartial" />
            <token id="20" string="way" />
            <token id="21" string="on" />
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="such an important case" type="NP">
          <tokens>
            <token id="22" string="such" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">give</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="12">undermine</governor>
          <dependent id="2">give</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="5">answer</governor>
          <dependent id="3">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">answer</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">give</governor>
          <dependent id="5">answer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="12">undermine</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">undermine</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">undermine</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">ability</governor>
          <dependent id="13">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">undermine</governor>
          <dependent id="14">ability</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">sit</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">ability</governor>
          <dependent id="16">sit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">way</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">way</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">way</governor>
          <dependent id="19">impartial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">sit</governor>
          <dependent id="20">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">case</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="25">case</governor>
          <dependent id="22">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">case</governor>
          <dependent id="23">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">case</governor>
          <dependent id="24">important</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">way</governor>
          <dependent id="25">case</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>; Thomas, who sat alone at the witness table with no notes or reference materials, also claimed a lack of familiarity with the subject matter when asked about some of his former speeches and articles That moved committee Chairman Joseph Biden, D-Del., to give Thomas a stack of the judge&amp;apost;s past speeches so the nominee could &amp;quot;help me understand them&amp;quot; during future questioning Thomas, testifying calmly but warily, did offer fuller comment on another hot issue before the high court: prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer, Thomas said, &amp;quot;Any policy of exclusion should be considered inappropriate.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="sat" lemma="sit" stem="sat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="table" lemma="table" stem="tabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="notes" lemma="note" stem="note" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="reference" lemma="reference" stem="refer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="materials" lemma="material" stem="materi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="familiarity" lemma="familiarity" stem="familiar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="subject" lemma="subject" stem="subject" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="speeches" lemma="speech" stem="speech" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="That" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="Chairman" lemma="Chairman" stem="chairman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="Joseph" lemma="Joseph" stem="joseph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="D-Del." lemma="D-Del." stem="d-del." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="50" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="stack" lemma="stack" stem="stack" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="54" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="55" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="56" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="57" string="speeches" lemma="speech" stem="speech" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="65" string="understand" lemma="understand" stem="understand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="67" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="68" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="future" lemma="future" stem="futur" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="70" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="72" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="73" string="testifying" lemma="testify" stem="testifi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="74" string="calmly" lemma="calmly" stem="calmli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="75" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="76" string="warily" lemma="warily" stem="warili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="77" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="78" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="79" string="offer" lemma="offer" stem="offer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="80" string="fuller" lemma="fuller" stem="fuller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="81" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="82" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="83" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="84" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="85" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="86" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="87" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="88" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="89" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="90" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="91" string="prayer" lemma="prayer" stem="prayer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="92" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="93" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="94" string="schools" lemma="school" stem="school" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="95" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="96" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="97" string="discussed" lemma="discuss" stem="discuss" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="98" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="99" string="feelings" lemma="feeling" stem="feel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="100" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="101" string="ago" lemma="ago" stem="ago" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="102" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="103" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="104" string="Jewish" lemma="jewish" stem="jewish" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="105" string="elementary" lemma="elementary" stem="elementari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="106" string="schoolboy" lemma="schoolboy" stem="schoolboi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="107" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="108" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="109" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="110" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="111" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="112" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="113" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="114" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="115" string="classmates" lemma="classmate" stem="classmat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="116" string="recited" lemma="recite" stem="recit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="117" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="118" string="prayer" lemma="prayer" stem="prayer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="119" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="120" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="121" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="122" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="123" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="124" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="125" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="126" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="127" string="exclusion" lemma="exclusion" stem="exclus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="128" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="129" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="130" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="131" string="inappropriate" lemma="inappropriate" stem="inappropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="132" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="133" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NP (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD sat) (ADVP (RB alone)) (PP (IN at) (NP (DT the) (NN witness) (NN table))) (PP (IN with) (NP (DT no) (NNS notes) (CC or) (NN reference) (NNS materials)))))))) (, ,) (VP (ADVP (RB also)) (VBD claimed) (NP (NP (DT a) (NN lack)) (PP (IN of) (NP (NN familiarity)))) (PP (IN with) (NP (DT the) (JJ subject) (NN matter))) (SBAR (WHADVP (WRB when)) (S (VP (VBN asked) (PP (IN about) (NP (NP (DT some)) (PP (IN of) (NP (PRP$ his) (JJ former) (NNS speeches) (CC and) (NNS articles))) (SBAR (WHNP (WDT That)) (S (VP (VBD moved) (S (NP (NP (NN committee) (NNP Chairman) (NNP Joseph) (NNP Biden)) (, ,) (NP (NNP D-Del.)) (, ,)) (VP (TO to) (VP (VB give) (NP (NNP Thomas)) (NP (DT a) (NP (VP (VB stack) (PP (IN of) (NP (NP (DT the) (NN judge) (POS 's)) (JJ past) (NNS speeches))) (SBAR (IN so) (S (NP (DT the) (NN nominee)) (VP (MD could) (`` ``) (VP (VB help) (S (NP (PRP me)) (VP (VB understand) (NP (PRP them)) ('' '') (PP (IN during) (NP (NP (JJ future)) (VP (VBG questioning) (NP (NP (NNP Thomas)) (, ,) (VP (VBG testifying) (ADVP (RB calmly)))) (FRAG (CC but) (ADVP (RB warily)) (, ,) (VP (VBD did) (NP (NN offer)) (NP (JJR fuller) (NN comment)) (PP (IN on) (NP (DT another) (JJ hot) (NN issue))))))))))))))) (PP (IN before) (NP (DT the) (JJ high) (NN court)))) (: :) (NP (NP (NN prayer)) (PP (IN in) (NP (JJ public) (NNS schools))) (SBAR (S (SBAR (IN After) (S (NP (NNP Simon)) (VP (VBD discussed) (NP (NP (DT the) (NNS feelings)) (PP (ADVP (NP (NNS decades)) (IN ago)) (IN of) (NP (NP (DT a) (JJ Jewish) (JJ elementary) (NN schoolboy)) (SBAR (WHNP (WP who)) (S (VP (VBD left) (NP (DT the) (NN room)) (NP-TMP (DT each) (NN day)) (SBAR (IN while) (S (NP (PRP$ his) (NNS classmates)) (VP (VBD recited) (NP (DT a) (NN prayer)))))))))))))) (, ,) (NP (NNP Thomas)) (VP (VBD said) (, ,) (`` ``) (S (NP (NP (DT Any) (NN policy)) (PP (IN of) (NP (NN exclusion)))) (VP (MD should) (VP (VB be) (VP (VBN considered) (S (ADJP (JJ inappropriate)))))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="who sat alone at the witness table with no notes or reference materials" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="sat" />
            <token id="6" string="alone" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="witness" />
            <token id="10" string="table" />
            <token id="11" string="with" />
            <token id="12" string="no" />
            <token id="13" string="notes" />
            <token id="14" string="or" />
            <token id="15" string="reference" />
            <token id="16" string="materials" />
          </tokens>
        </chunking>
        <chunking id="2" string="did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="a prayer" type="NP">
          <tokens>
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="5" string="the high court" type="NP">
          <tokens>
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
          </tokens>
        </chunking>
        <chunking id="6" string="be considered inappropriate" type="VP">
          <tokens>
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="7" string="public schools" type="NP">
          <tokens>
            <token id="93" string="public" />
            <token id="94" string="schools" />
          </tokens>
        </chunking>
        <chunking id="8" string="That moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="SBAR">
          <tokens>
            <token id="38" string="That" />
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="66" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="NP">
          <tokens>
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="11" string="a Jewish elementary schoolboy" type="NP">
          <tokens>
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
          </tokens>
        </chunking>
        <chunking id="12" string="sat alone at the witness table with no notes or reference materials" type="VP">
          <tokens>
            <token id="5" string="sat" />
            <token id="6" string="alone" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="witness" />
            <token id="10" string="table" />
            <token id="11" string="with" />
            <token id="12" string="no" />
            <token id="13" string="notes" />
            <token id="14" string="or" />
            <token id="15" string="reference" />
            <token id="16" string="materials" />
          </tokens>
        </chunking>
        <chunking id="13" string="D-Del." type="NP">
          <tokens>
            <token id="45" string="D-Del." />
          </tokens>
        </chunking>
        <chunking id="14" string="questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="15" string="prayer" type="NP">
          <tokens>
            <token id="91" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="16" string="Any policy" type="NP">
          <tokens>
            <token id="124" string="Any" />
            <token id="125" string="policy" />
          </tokens>
        </chunking>
        <chunking id="17" string="some of his former speeches and articles That moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="NP">
          <tokens>
            <token id="31" string="some" />
            <token id="32" string="of" />
            <token id="33" string="his" />
            <token id="34" string="former" />
            <token id="35" string="speeches" />
            <token id="36" string="and" />
            <token id="37" string="articles" />
            <token id="38" string="That" />
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="18" string="prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="NP">
          <tokens>
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="19" string="considered inappropriate" type="VP">
          <tokens>
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="20" string="the feelings" type="NP">
          <tokens>
            <token id="98" string="the" />
            <token id="99" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="21" string="to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="22" string="After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="SBAR">
          <tokens>
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="23" string="the judge 's" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
          </tokens>
        </chunking>
        <chunking id="24" string="said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="25" string="a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer" type="NP">
          <tokens>
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="26" string="some" type="NP">
          <tokens>
            <token id="31" string="some" />
          </tokens>
        </chunking>
        <chunking id="27" string="his classmates" type="NP">
          <tokens>
            <token id="114" string="his" />
            <token id="115" string="classmates" />
          </tokens>
        </chunking>
        <chunking id="28" string="the room" type="NP">
          <tokens>
            <token id="109" string="the" />
            <token id="110" string="room" />
          </tokens>
        </chunking>
        <chunking id="29" string="a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="NP">
          <tokens>
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="30" string="stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court" type="NP">
          <tokens>
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
          </tokens>
        </chunking>
        <chunking id="31" string="After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer" type="SBAR">
          <tokens>
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="32" string="fuller comment" type="NP">
          <tokens>
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
          </tokens>
        </chunking>
        <chunking id="33" string="Simon" type="NP">
          <tokens>
            <token id="96" string="Simon" />
          </tokens>
        </chunking>
        <chunking id="34" string="me" type="NP">
          <tokens>
            <token id="64" string="me" />
          </tokens>
        </chunking>
        <chunking id="35" string="offer" type="NP">
          <tokens>
            <token id="79" string="offer" />
          </tokens>
        </chunking>
        <chunking id="36" string="asked about some of his former speeches and articles That moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="29" string="asked" />
            <token id="30" string="about" />
            <token id="31" string="some" />
            <token id="32" string="of" />
            <token id="33" string="his" />
            <token id="34" string="former" />
            <token id="35" string="speeches" />
            <token id="36" string="and" />
            <token id="37" string="articles" />
            <token id="38" string="That" />
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="37" string="could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="38" string="recited a prayer" type="VP">
          <tokens>
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="39" string="moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="40" string="no notes or reference materials" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="notes" />
            <token id="14" string="or" />
            <token id="15" string="reference" />
            <token id="16" string="materials" />
          </tokens>
        </chunking>
        <chunking id="41" string="his former speeches and articles" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="former" />
            <token id="35" string="speeches" />
            <token id="36" string="and" />
            <token id="37" string="articles" />
          </tokens>
        </chunking>
        <chunking id="42" string="a lack of familiarity" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lack" />
            <token id="22" string="of" />
            <token id="23" string="familiarity" />
          </tokens>
        </chunking>
        <chunking id="43" string="who left the room each day while his classmates recited a prayer" type="SBAR">
          <tokens>
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="44" string="help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="45" string="should be considered inappropriate" type="VP">
          <tokens>
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="46" string="another hot issue" type="NP">
          <tokens>
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="47" string="future" type="NP">
          <tokens>
            <token id="69" string="future" />
          </tokens>
        </chunking>
        <chunking id="48" string="understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="49" string="stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="VP">
          <tokens>
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="50" string="decades" type="NP">
          <tokens>
            <token id="100" string="decades" />
          </tokens>
        </chunking>
        <chunking id="51" string="left the room each day while his classmates recited a prayer" type="VP">
          <tokens>
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="52" string="committee Chairman Joseph Biden" type="NP">
          <tokens>
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
          </tokens>
        </chunking>
        <chunking id="53" string="a lack" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lack" />
          </tokens>
        </chunking>
        <chunking id="54" string="familiarity" type="NP">
          <tokens>
            <token id="23" string="familiarity" />
          </tokens>
        </chunking>
        <chunking id="55" string="the nominee" type="NP">
          <tokens>
            <token id="59" string="the" />
            <token id="60" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="56" string="testifying calmly" type="VP">
          <tokens>
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
          </tokens>
        </chunking>
        <chunking id="57" string="when asked about some of his former speeches and articles That moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="SBAR">
          <tokens>
            <token id="28" string="when" />
            <token id="29" string="asked" />
            <token id="30" string="about" />
            <token id="31" string="some" />
            <token id="32" string="of" />
            <token id="33" string="his" />
            <token id="34" string="former" />
            <token id="35" string="speeches" />
            <token id="36" string="and" />
            <token id="37" string="articles" />
            <token id="38" string="That" />
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="58" string="exclusion" type="NP">
          <tokens>
            <token id="127" string="exclusion" />
          </tokens>
        </chunking>
        <chunking id="59" string="committee Chairman Joseph Biden , D-Del. ," type="NP">
          <tokens>
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
          </tokens>
        </chunking>
        <chunking id="60" string="the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer" type="NP">
          <tokens>
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="61" string="also claimed a lack of familiarity with the subject matter when asked about some of his former speeches and articles That moved committee Chairman Joseph Biden , D-Del. , to give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="18" string="also" />
            <token id="19" string="claimed" />
            <token id="20" string="a" />
            <token id="21" string="lack" />
            <token id="22" string="of" />
            <token id="23" string="familiarity" />
            <token id="24" string="with" />
            <token id="25" string="the" />
            <token id="26" string="subject" />
            <token id="27" string="matter" />
            <token id="28" string="when" />
            <token id="29" string="asked" />
            <token id="30" string="about" />
            <token id="31" string="some" />
            <token id="32" string="of" />
            <token id="33" string="his" />
            <token id="34" string="former" />
            <token id="35" string="speeches" />
            <token id="36" string="and" />
            <token id="37" string="articles" />
            <token id="38" string="That" />
            <token id="39" string="moved" />
            <token id="40" string="committee" />
            <token id="41" string="Chairman" />
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
            <token id="44" string="," />
            <token id="45" string="D-Del." />
            <token id="46" string="," />
            <token id="47" string="to" />
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="62" string="so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue" type="SBAR">
          <tokens>
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
          </tokens>
        </chunking>
        <chunking id="63" string="Thomas , testifying calmly" type="NP">
          <tokens>
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
          </tokens>
        </chunking>
        <chunking id="64" string="when" type="WHADVP">
          <tokens>
            <token id="28" string="when" />
          </tokens>
        </chunking>
        <chunking id="65" string="the judge 's past speeches" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
          </tokens>
        </chunking>
        <chunking id="66" string="the witness table" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="witness" />
            <token id="10" string="table" />
          </tokens>
        </chunking>
        <chunking id="67" string="Thomas , who sat alone at the witness table with no notes or reference materials" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="sat" />
            <token id="6" string="alone" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="witness" />
            <token id="10" string="table" />
            <token id="11" string="with" />
            <token id="12" string="no" />
            <token id="13" string="notes" />
            <token id="14" string="or" />
            <token id="15" string="reference" />
            <token id="16" string="materials" />
          </tokens>
        </chunking>
        <chunking id="68" string="Any policy of exclusion" type="NP">
          <tokens>
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
          </tokens>
        </chunking>
        <chunking id="69" string="the subject matter" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="subject" />
            <token id="27" string="matter" />
          </tokens>
        </chunking>
        <chunking id="70" string="discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer" type="VP">
          <tokens>
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="71" string="while his classmates recited a prayer" type="SBAR">
          <tokens>
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
          </tokens>
        </chunking>
        <chunking id="72" string="give Thomas a stack of the judge 's past speeches so the nominee could `` help me understand them '' during future questioning Thomas , testifying calmly but warily , did offer fuller comment on another hot issue before the high court : prayer in public schools After Simon discussed the feelings decades ago of a Jewish elementary schoolboy who left the room each day while his classmates recited a prayer , Thomas said , `` Any policy of exclusion should be considered inappropriate" type="VP">
          <tokens>
            <token id="48" string="give" />
            <token id="49" string="Thomas" />
            <token id="50" string="a" />
            <token id="51" string="stack" />
            <token id="52" string="of" />
            <token id="53" string="the" />
            <token id="54" string="judge" />
            <token id="55" string="'s" />
            <token id="56" string="past" />
            <token id="57" string="speeches" />
            <token id="58" string="so" />
            <token id="59" string="the" />
            <token id="60" string="nominee" />
            <token id="61" string="could" />
            <token id="62" string="&quot;" />
            <token id="63" string="help" />
            <token id="64" string="me" />
            <token id="65" string="understand" />
            <token id="66" string="them" />
            <token id="67" string="&quot;" />
            <token id="68" string="during" />
            <token id="69" string="future" />
            <token id="70" string="questioning" />
            <token id="71" string="Thomas" />
            <token id="72" string="," />
            <token id="73" string="testifying" />
            <token id="74" string="calmly" />
            <token id="75" string="but" />
            <token id="76" string="warily" />
            <token id="77" string="," />
            <token id="78" string="did" />
            <token id="79" string="offer" />
            <token id="80" string="fuller" />
            <token id="81" string="comment" />
            <token id="82" string="on" />
            <token id="83" string="another" />
            <token id="84" string="hot" />
            <token id="85" string="issue" />
            <token id="86" string="before" />
            <token id="87" string="the" />
            <token id="88" string="high" />
            <token id="89" string="court" />
            <token id="90" string=":" />
            <token id="91" string="prayer" />
            <token id="92" string="in" />
            <token id="93" string="public" />
            <token id="94" string="schools" />
            <token id="95" string="After" />
            <token id="96" string="Simon" />
            <token id="97" string="discussed" />
            <token id="98" string="the" />
            <token id="99" string="feelings" />
            <token id="100" string="decades" />
            <token id="101" string="ago" />
            <token id="102" string="of" />
            <token id="103" string="a" />
            <token id="104" string="Jewish" />
            <token id="105" string="elementary" />
            <token id="106" string="schoolboy" />
            <token id="107" string="who" />
            <token id="108" string="left" />
            <token id="109" string="the" />
            <token id="110" string="room" />
            <token id="111" string="each" />
            <token id="112" string="day" />
            <token id="113" string="while" />
            <token id="114" string="his" />
            <token id="115" string="classmates" />
            <token id="116" string="recited" />
            <token id="117" string="a" />
            <token id="118" string="prayer" />
            <token id="119" string="," />
            <token id="120" string="Thomas" />
            <token id="121" string="said" />
            <token id="122" string="," />
            <token id="123" string="&quot;" />
            <token id="124" string="Any" />
            <token id="125" string="policy" />
            <token id="126" string="of" />
            <token id="127" string="exclusion" />
            <token id="128" string="should" />
            <token id="129" string="be" />
            <token id="130" string="considered" />
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="73" string="inappropriate" type="ADJP">
          <tokens>
            <token id="131" string="inappropriate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="parataxis">
          <governor id="19">claimed</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">sat</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Thomas</governor>
          <dependent id="5">sat</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">sat</governor>
          <dependent id="6">alone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">table</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">table</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">table</governor>
          <dependent id="9">witness</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sat</governor>
          <dependent id="10">table</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">notes</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">notes</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sat</governor>
          <dependent id="13">notes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">notes</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">materials</governor>
          <dependent id="15">reference</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">notes</governor>
          <dependent id="16">materials</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">claimed</governor>
          <dependent id="18">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">claimed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lack</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">claimed</governor>
          <dependent id="21">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">familiarity</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">lack</governor>
          <dependent id="23">familiarity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">matter</governor>
          <dependent id="24">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">matter</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">matter</governor>
          <dependent id="26">subject</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">claimed</governor>
          <dependent id="27">matter</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">asked</governor>
          <dependent id="28">when</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">claimed</governor>
          <dependent id="29">asked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">some</governor>
          <dependent id="30">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">asked</governor>
          <dependent id="31">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">speeches</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">speeches</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">speeches</governor>
          <dependent id="34">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">some</governor>
          <dependent id="35">speeches</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">speeches</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">speeches</governor>
          <dependent id="37">articles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">moved</governor>
          <dependent id="38">That</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">some</governor>
          <dependent id="39">moved</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Biden</governor>
          <dependent id="40">committee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Biden</governor>
          <dependent id="41">Chairman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Biden</governor>
          <dependent id="42">Joseph</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">moved</governor>
          <dependent id="43">Biden</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="43">Biden</governor>
          <dependent id="45">D-Del.</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="48">give</governor>
          <dependent id="47">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="39">moved</governor>
          <dependent id="48">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="48">give</governor>
          <dependent id="49">Thomas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">stack</governor>
          <dependent id="50">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="48">give</governor>
          <dependent id="51">stack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="57">speeches</governor>
          <dependent id="52">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">judge</governor>
          <dependent id="53">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="57">speeches</governor>
          <dependent id="54">judge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">judge</governor>
          <dependent id="55">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="57">speeches</governor>
          <dependent id="56">past</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">stack</governor>
          <dependent id="57">speeches</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="63">help</governor>
          <dependent id="58">so</dependent>
        </dependency>
        <dependency type="det">
          <governor id="60">nominee</governor>
          <dependent id="59">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="63">help</governor>
          <dependent id="60">nominee</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="63">help</governor>
          <dependent id="61">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="51">stack</governor>
          <dependent id="63">help</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="65">understand</governor>
          <dependent id="64">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="63">help</governor>
          <dependent id="65">understand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="65">understand</governor>
          <dependent id="66">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">future</governor>
          <dependent id="68">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="65">understand</governor>
          <dependent id="69">future</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="69">future</governor>
          <dependent id="70">questioning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="70">questioning</governor>
          <dependent id="71">Thomas</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="71">Thomas</governor>
          <dependent id="73">testifying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="73">testifying</governor>
          <dependent id="74">calmly</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="76">warily</governor>
          <dependent id="75">but</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="70">questioning</governor>
          <dependent id="76">warily</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="76">warily</governor>
          <dependent id="78">did</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="78">did</governor>
          <dependent id="79">offer</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="81">comment</governor>
          <dependent id="80">fuller</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="78">did</governor>
          <dependent id="81">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="85">issue</governor>
          <dependent id="82">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="85">issue</governor>
          <dependent id="83">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="85">issue</governor>
          <dependent id="84">hot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="78">did</governor>
          <dependent id="85">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="89">court</governor>
          <dependent id="86">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="89">court</governor>
          <dependent id="87">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="89">court</governor>
          <dependent id="88">high</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">stack</governor>
          <dependent id="89">court</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="51">stack</governor>
          <dependent id="91">prayer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="94">schools</governor>
          <dependent id="92">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="94">schools</governor>
          <dependent id="93">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="91">prayer</governor>
          <dependent id="94">schools</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="97">discussed</governor>
          <dependent id="95">After</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="97">discussed</governor>
          <dependent id="96">Simon</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="121">said</governor>
          <dependent id="97">discussed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="99">feelings</governor>
          <dependent id="98">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="97">discussed</governor>
          <dependent id="99">feelings</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="106">schoolboy</governor>
          <dependent id="100">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="100">decades</governor>
          <dependent id="101">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="106">schoolboy</governor>
          <dependent id="102">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="106">schoolboy</governor>
          <dependent id="103">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="106">schoolboy</governor>
          <dependent id="104">Jewish</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="106">schoolboy</governor>
          <dependent id="105">elementary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="99">feelings</governor>
          <dependent id="106">schoolboy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="108">left</governor>
          <dependent id="107">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="106">schoolboy</governor>
          <dependent id="108">left</dependent>
        </dependency>
        <dependency type="det">
          <governor id="110">room</governor>
          <dependent id="109">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="108">left</governor>
          <dependent id="110">room</dependent>
        </dependency>
        <dependency type="det">
          <governor id="112">day</governor>
          <dependent id="111">each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="108">left</governor>
          <dependent id="112">day</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="116">recited</governor>
          <dependent id="113">while</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="115">classmates</governor>
          <dependent id="114">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="116">recited</governor>
          <dependent id="115">classmates</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="108">left</governor>
          <dependent id="116">recited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="118">prayer</governor>
          <dependent id="117">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="116">recited</governor>
          <dependent id="118">prayer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="121">said</governor>
          <dependent id="120">Thomas</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="91">prayer</governor>
          <dependent id="121">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="125">policy</governor>
          <dependent id="124">Any</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="130">considered</governor>
          <dependent id="125">policy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="127">exclusion</governor>
          <dependent id="126">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="125">policy</governor>
          <dependent id="127">exclusion</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="130">considered</governor>
          <dependent id="128">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="130">considered</governor>
          <dependent id="129">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="121">said</governor>
          <dependent id="130">considered</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="130">considered</governor>
          <dependent id="131">inappropriate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="each day" type="SET" score="0.0">
          <tokens>
            <token id="111" string="each" />
            <token id="112" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="108" string="left" />
          </tokens>
        </entity>
        <entity id="3" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="56" string="past" />
          </tokens>
        </entity>
        <entity id="4" string="Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="96" string="Simon" />
          </tokens>
        </entity>
        <entity id="5" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="6" string="future" type="DATE" score="0.0">
          <tokens>
            <token id="69" string="future" />
          </tokens>
        </entity>
        <entity id="7" string="Jewish" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="104" string="Jewish" />
          </tokens>
        </entity>
        <entity id="8" string="decades ago" type="DATE" score="0.0">
          <tokens>
            <token id="100" string="decades" />
            <token id="101" string="ago" />
          </tokens>
        </entity>
        <entity id="9" string="Joseph Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="Joseph" />
            <token id="43" string="Biden" />
          </tokens>
        </entity>
        <entity id="10" string="D-Del." type="LOCATION" score="0.0">
          <tokens>
            <token id="45" string="D-Del." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>; Outside the hearing room, abortion-rights advocates said Thomas should not be allowed to disavow past comments they say show he would vote to ban most, if not all, abortions &amp;quot;His most unimpressive testimony poses two equally disturbing possibilities: he is either willfully misleading the committee about his views to win confirmation, or he is a man whose convictions have shallow roots,&amp;quot; said Arthur Kropp of People for the American Way Sen. Patrick Leahy, D-Vt., said he could not understand how Thomas&amp;apost; prior statements touching on the 1973 abortion decision could have been made without considering its content.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="abortion-rights" lemma="abortion-rights" stem="abortion-right" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="advocates" lemma="advocate" stem="advoc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="allowed" lemma="allow" stem="allow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="disavow" lemma="disavow" stem="disavow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="comments" lemma="comment" stem="comment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="show" lemma="show" stem="show" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="ban" lemma="ban" stem="ban" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="abortions" lemma="abortion" stem="abort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="unimpressive" lemma="unimpressive" stem="unimpress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="poses" lemma="pose" stem="pose" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="41" string="equally" lemma="equally" stem="equal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="disturbing" lemma="disturbing" stem="disturb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="possibilities" lemma="possibility" stem="possibl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="willfully" lemma="willfully" stem="willfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="misleading" lemma="mislead" stem="mislead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="51" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="52" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="53" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="54" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="56" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="57" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="61" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="63" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="64" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="65" string="convictions" lemma="conviction" stem="convict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="66" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="67" string="shallow" lemma="shallow" stem="shallow" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="68" string="roots" lemma="root" stem="root" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="69" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="70" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="72" string="Arthur" lemma="Arthur" stem="arthur" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="73" string="Kropp" lemma="Kropp" stem="kropp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="74" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="75" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="76" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="77" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="78" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="79" string="Way" lemma="Way" stem="wai" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="80" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="81" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="82" string="Leahy" lemma="Leahy" stem="leahi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="83" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="84" string="D-Vt." lemma="D-Vt." stem="d-vt." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="85" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="86" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="87" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="88" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="89" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="90" string="understand" lemma="understand" stem="understand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="91" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="92" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="93" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="94" string="prior" lemma="prior" stem="prior" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="95" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="96" string="touching" lemma="touch" stem="touch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="97" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="98" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="99" string="1973" lemma="1973" stem="1973" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="100" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="101" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="102" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="103" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="104" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="105" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="106" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="107" string="considering" lemma="consider" stem="consid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="108" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="109" string="content" lemma="content" stem="content" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="110" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN Outside) (NP (DT the) (NN hearing) (NN room))) (, ,) (NP (NNS abortion-rights) (NNS advocates)) (VP (VBD said) (SBAR (S (NP (NNP Thomas)) (VP (MD should) (RB not) (VP (VB be) (VP (VBN allowed) (S (VP (TO to) (VP (VB disavow) (NP (NP (JJ past) (NNS comments)) (SBAR (S (NP (PRP they)) (VP (VBP say) (SBAR (S (VP (VBP show) (SBAR (S (NP (PRP he)) (VP (MD would) (VP (VB vote) (S (VP (TO to) (VP (VB ban) (ADVP (RBS most)) (, ,) (SBAR (IN if) (S (NP (RB not) (NP (DT all)) (, ,) (NP (NP (NNS abortions)) (`` ``) (S (S (NP (PRP$ His) (ADJP (RBS most) (JJ unimpressive)) (NN testimony)) (VP (VBZ poses) (NP (NP (CD two) (ADJP (RB equally) (JJ disturbing)) (NNS possibilities)) (: :) (S (NP (PRP he)) (VP (VBZ is) (CC either) (VP (ADVP (RB willfully)) (VBG misleading) (NP (NP (DT the) (NN committee)) (PP (IN about) (NP (PRP$ his) (NNS views) (S (VP (TO to) (VP (VB win) (NP (NN confirmation))))))))) (, ,)))))) (CC or) (S (NP (PRP he)) (VP (VBZ is) (NP (NP (DT a) (NN man)) (SBAR (WHNP (WP$ whose) (NNS convictions)) (S (VP (VBP have) (NP (JJ shallow) (NNS roots))))))))) (, ,) ('' ''))) (VP (VBD said) (SBAR (S (NP (NP (NNP Arthur) (NNP Kropp)) (PP (IN of) (NP (NP (NNS People)) (PP (IN for) (NP (NP (DT the) (JJ American) (NNP Way) (NNP Sen.) (NNP Patrick) (NNP Leahy)) (, ,) (NP (NNP D-Vt.)) (, ,)))))) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD could) (RB not) (VP (VB understand) (SBAR (WHADVP (WRB how)) (S (NP (NP (NP (NNP Thomas) (POS ')) (JJ prior) (NNS statements)) (VP (VBG touching) (PP (IN on) (NP (DT the) (CD 1973) (NN abortion) (NN decision))))) (VP (MD could) (VP (VB have) (VP (VBN been) (VP (VBN made) (PP (IN without) (S (VP (VBG considering) (NP (PRP$ its) (NN content)))))))))))))))))))))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="win confirmation" type="VP">
          <tokens>
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="2" string="could have been made without considering its content" type="VP">
          <tokens>
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="3" string="not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , ''" type="NP">
          <tokens>
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Thomas should not be allowed to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="Thomas" />
            <token id="11" string="should" />
            <token id="12" string="not" />
            <token id="13" string="be" />
            <token id="14" string="allowed" />
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="5" string="a man whose convictions have shallow roots" type="NP">
          <tokens>
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas should not be allowed to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="10" string="Thomas" />
            <token id="11" string="should" />
            <token id="12" string="not" />
            <token id="13" string="be" />
            <token id="14" string="allowed" />
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="7" string="been made without considering its content" type="VP">
          <tokens>
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="8" string="made without considering its content" type="VP">
          <tokens>
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="9" string="the American Way Sen. Patrick Leahy , D-Vt. ," type="NP">
          <tokens>
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="Thomas" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="11" string="People" type="NP">
          <tokens>
            <token id="75" string="People" />
          </tokens>
        </chunking>
        <chunking id="12" string="he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="13" string="its content" type="NP">
          <tokens>
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="14" string="the committee about his views to win confirmation" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="15" string="two equally disturbing possibilities" type="NP">
          <tokens>
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
          </tokens>
        </chunking>
        <chunking id="16" string="Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="17" string="His most unimpressive testimony" type="NP">
          <tokens>
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="is either willfully misleading the committee about his views to win confirmation ," type="VP">
          <tokens>
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="should not be allowed to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="11" string="should" />
            <token id="12" string="not" />
            <token id="13" string="be" />
            <token id="14" string="allowed" />
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="21" string="past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="NP">
          <tokens>
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="22" string="abortion-rights advocates" type="NP">
          <tokens>
            <token id="7" string="abortion-rights" />
            <token id="8" string="advocates" />
          </tokens>
        </chunking>
        <chunking id="23" string="willfully misleading the committee about his views to win confirmation" type="VP">
          <tokens>
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="24" string="shallow roots" type="NP">
          <tokens>
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
          </tokens>
        </chunking>
        <chunking id="25" string="is a man whose convictions have shallow roots" type="VP">
          <tokens>
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
          </tokens>
        </chunking>
        <chunking id="26" string="People for the American Way Sen. Patrick Leahy , D-Vt. ," type="NP">
          <tokens>
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
          </tokens>
        </chunking>
        <chunking id="27" string="allowed to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="14" string="allowed" />
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="28" string="he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="29" string="past comments" type="NP">
          <tokens>
            <token id="17" string="past" />
            <token id="18" string="comments" />
          </tokens>
        </chunking>
        <chunking id="30" string="to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="31" string="abortions" type="NP">
          <tokens>
            <token id="33" string="abortions" />
          </tokens>
        </chunking>
        <chunking id="32" string="abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , ''" type="NP">
          <tokens>
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="33" string="be allowed to disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="allowed" />
            <token id="15" string="to" />
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="34" string="vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="35" string="whose convictions have shallow roots" type="SBAR">
          <tokens>
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
          </tokens>
        </chunking>
        <chunking id="36" string="the committee" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="committee" />
          </tokens>
        </chunking>
        <chunking id="37" string="all" type="NP">
          <tokens>
            <token id="31" string="all" />
          </tokens>
        </chunking>
        <chunking id="38" string="Arthur Kropp" type="NP">
          <tokens>
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
          </tokens>
        </chunking>
        <chunking id="39" string="have shallow roots" type="VP">
          <tokens>
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
          </tokens>
        </chunking>
        <chunking id="40" string="said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="41" string="Thomas '" type="NP">
          <tokens>
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
          </tokens>
        </chunking>
        <chunking id="42" string="confirmation" type="NP">
          <tokens>
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="43" string="touching on the 1973 abortion decision" type="VP">
          <tokens>
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
          </tokens>
        </chunking>
        <chunking id="44" string="two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation ," type="NP">
          <tokens>
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
          </tokens>
        </chunking>
        <chunking id="45" string="say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="46" string="if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="47" string="poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation ," type="VP">
          <tokens>
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
          </tokens>
        </chunking>
        <chunking id="48" string="to win confirmation" type="VP">
          <tokens>
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
        <chunking id="49" string="Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. ," type="NP">
          <tokens>
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
          </tokens>
        </chunking>
        <chunking id="50" string="would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="51" string="disavow past comments they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="16" string="disavow" />
            <token id="17" string="past" />
            <token id="18" string="comments" />
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="52" string="could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="53" string="considering its content" type="VP">
          <tokens>
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="54" string="a man" type="NP">
          <tokens>
            <token id="62" string="a" />
            <token id="63" string="man" />
          </tokens>
        </chunking>
        <chunking id="55" string="show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="56" string="the hearing room" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="hearing" />
            <token id="5" string="room" />
          </tokens>
        </chunking>
        <chunking id="57" string="most unimpressive" type="ADJP">
          <tokens>
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
          </tokens>
        </chunking>
        <chunking id="58" string="Thomas ' prior statements" type="NP">
          <tokens>
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
          </tokens>
        </chunking>
        <chunking id="59" string="Thomas ' prior statements touching on the 1973 abortion decision" type="NP">
          <tokens>
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
          </tokens>
        </chunking>
        <chunking id="60" string="have been made without considering its content" type="VP">
          <tokens>
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="61" string="how" type="WHADVP">
          <tokens>
            <token id="91" string="how" />
          </tokens>
        </chunking>
        <chunking id="62" string="the 1973 abortion decision" type="NP">
          <tokens>
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
          </tokens>
        </chunking>
        <chunking id="63" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="64" string="equally disturbing" type="ADJP">
          <tokens>
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
          </tokens>
        </chunking>
        <chunking id="65" string="the American Way Sen. Patrick Leahy" type="NP">
          <tokens>
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
          </tokens>
        </chunking>
        <chunking id="66" string="D-Vt." type="NP">
          <tokens>
            <token id="84" string="D-Vt." />
          </tokens>
        </chunking>
        <chunking id="67" string="understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="68" string="they say show he would vote to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="19" string="they" />
            <token id="20" string="say" />
            <token id="21" string="show" />
            <token id="22" string="he" />
            <token id="23" string="would" />
            <token id="24" string="vote" />
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="69" string="ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="70" string="how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="SBAR">
          <tokens>
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="71" string="to ban most , if not all , abortions `` His most unimpressive testimony poses two equally disturbing possibilities : he is either willfully misleading the committee about his views to win confirmation , or he is a man whose convictions have shallow roots , '' said Arthur Kropp of People for the American Way Sen. Patrick Leahy , D-Vt. , said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="ban" />
            <token id="27" string="most" />
            <token id="28" string="," />
            <token id="29" string="if" />
            <token id="30" string="not" />
            <token id="31" string="all" />
            <token id="32" string="," />
            <token id="33" string="abortions" />
            <token id="34" string="&quot;" />
            <token id="35" string="His" />
            <token id="36" string="most" />
            <token id="37" string="unimpressive" />
            <token id="38" string="testimony" />
            <token id="39" string="poses" />
            <token id="40" string="two" />
            <token id="41" string="equally" />
            <token id="42" string="disturbing" />
            <token id="43" string="possibilities" />
            <token id="44" string=":" />
            <token id="45" string="he" />
            <token id="46" string="is" />
            <token id="47" string="either" />
            <token id="48" string="willfully" />
            <token id="49" string="misleading" />
            <token id="50" string="the" />
            <token id="51" string="committee" />
            <token id="52" string="about" />
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
            <token id="58" string="," />
            <token id="59" string="or" />
            <token id="60" string="he" />
            <token id="61" string="is" />
            <token id="62" string="a" />
            <token id="63" string="man" />
            <token id="64" string="whose" />
            <token id="65" string="convictions" />
            <token id="66" string="have" />
            <token id="67" string="shallow" />
            <token id="68" string="roots" />
            <token id="69" string="," />
            <token id="70" string="&quot;" />
            <token id="71" string="said" />
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
            <token id="74" string="of" />
            <token id="75" string="People" />
            <token id="76" string="for" />
            <token id="77" string="the" />
            <token id="78" string="American" />
            <token id="79" string="Way" />
            <token id="80" string="Sen." />
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
            <token id="83" string="," />
            <token id="84" string="D-Vt." />
            <token id="85" string="," />
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="72" string="said he could not understand how Thomas ' prior statements touching on the 1973 abortion decision could have been made without considering its content" type="VP">
          <tokens>
            <token id="86" string="said" />
            <token id="87" string="he" />
            <token id="88" string="could" />
            <token id="89" string="not" />
            <token id="90" string="understand" />
            <token id="91" string="how" />
            <token id="92" string="Thomas" />
            <token id="93" string="'" />
            <token id="94" string="prior" />
            <token id="95" string="statements" />
            <token id="96" string="touching" />
            <token id="97" string="on" />
            <token id="98" string="the" />
            <token id="99" string="1973" />
            <token id="100" string="abortion" />
            <token id="101" string="decision" />
            <token id="102" string="could" />
            <token id="103" string="have" />
            <token id="104" string="been" />
            <token id="105" string="made" />
            <token id="106" string="without" />
            <token id="107" string="considering" />
            <token id="108" string="its" />
            <token id="109" string="content" />
          </tokens>
        </chunking>
        <chunking id="73" string="his views to win confirmation" type="NP">
          <tokens>
            <token id="53" string="his" />
            <token id="54" string="views" />
            <token id="55" string="to" />
            <token id="56" string="win" />
            <token id="57" string="confirmation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">room</governor>
          <dependent id="2">Outside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">room</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">room</governor>
          <dependent id="4">hearing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">said</governor>
          <dependent id="5">room</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">advocates</governor>
          <dependent id="7">abortion-rights</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">advocates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">allowed</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">allowed</governor>
          <dependent id="11">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">allowed</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">allowed</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">allowed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">disavow</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">allowed</governor>
          <dependent id="16">disavow</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">comments</governor>
          <dependent id="17">past</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">disavow</governor>
          <dependent id="18">comments</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">say</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">comments</governor>
          <dependent id="20">say</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">say</governor>
          <dependent id="21">show</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">vote</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">vote</governor>
          <dependent id="23">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">show</governor>
          <dependent id="24">vote</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">ban</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">vote</governor>
          <dependent id="26">ban</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">ban</governor>
          <dependent id="27">most</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="71">said</governor>
          <dependent id="29">if</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">all</governor>
          <dependent id="30">not</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="71">said</governor>
          <dependent id="31">all</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="31">all</governor>
          <dependent id="33">abortions</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">testimony</governor>
          <dependent id="35">His</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">unimpressive</governor>
          <dependent id="36">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">testimony</governor>
          <dependent id="37">unimpressive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">poses</governor>
          <dependent id="38">testimony</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">abortions</governor>
          <dependent id="39">poses</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="43">possibilities</governor>
          <dependent id="40">two</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">disturbing</governor>
          <dependent id="41">equally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">possibilities</governor>
          <dependent id="42">disturbing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">poses</governor>
          <dependent id="43">possibilities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">is</governor>
          <dependent id="45">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="43">possibilities</governor>
          <dependent id="46">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="46">is</governor>
          <dependent id="47">either</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="49">misleading</governor>
          <dependent id="48">willfully</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="46">is</governor>
          <dependent id="49">misleading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">committee</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="49">misleading</governor>
          <dependent id="51">committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">views</governor>
          <dependent id="52">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="54">views</governor>
          <dependent id="53">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">committee</governor>
          <dependent id="54">views</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="56">win</governor>
          <dependent id="55">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="54">views</governor>
          <dependent id="56">win</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="56">win</governor>
          <dependent id="57">confirmation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="39">poses</governor>
          <dependent id="59">or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="63">man</governor>
          <dependent id="60">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="63">man</governor>
          <dependent id="61">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="63">man</governor>
          <dependent id="62">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="39">poses</governor>
          <dependent id="63">man</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="65">convictions</governor>
          <dependent id="64">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="66">have</governor>
          <dependent id="65">convictions</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="63">man</governor>
          <dependent id="66">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="68">roots</governor>
          <dependent id="67">shallow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="66">have</governor>
          <dependent id="68">roots</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">ban</governor>
          <dependent id="71">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="73">Kropp</governor>
          <dependent id="72">Arthur</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="86">said</governor>
          <dependent id="73">Kropp</dependent>
        </dependency>
        <dependency type="case">
          <governor id="75">People</governor>
          <dependent id="74">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="73">Kropp</governor>
          <dependent id="75">People</dependent>
        </dependency>
        <dependency type="case">
          <governor id="82">Leahy</governor>
          <dependent id="76">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="82">Leahy</governor>
          <dependent id="77">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="82">Leahy</governor>
          <dependent id="78">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="82">Leahy</governor>
          <dependent id="79">Way</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="82">Leahy</governor>
          <dependent id="80">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="82">Leahy</governor>
          <dependent id="81">Patrick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="75">People</governor>
          <dependent id="82">Leahy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="82">Leahy</governor>
          <dependent id="84">D-Vt.</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="71">said</governor>
          <dependent id="86">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="90">understand</governor>
          <dependent id="87">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="90">understand</governor>
          <dependent id="88">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="90">understand</governor>
          <dependent id="89">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="86">said</governor>
          <dependent id="90">understand</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="105">made</governor>
          <dependent id="91">how</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="95">statements</governor>
          <dependent id="92">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="92">Thomas</governor>
          <dependent id="93">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="95">statements</governor>
          <dependent id="94">prior</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="105">made</governor>
          <dependent id="95">statements</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="95">statements</governor>
          <dependent id="96">touching</dependent>
        </dependency>
        <dependency type="case">
          <governor id="101">decision</governor>
          <dependent id="97">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="101">decision</governor>
          <dependent id="98">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="101">decision</governor>
          <dependent id="99">1973</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="101">decision</governor>
          <dependent id="100">abortion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="96">touching</governor>
          <dependent id="101">decision</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="105">made</governor>
          <dependent id="102">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="105">made</governor>
          <dependent id="103">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="105">made</governor>
          <dependent id="104">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="90">understand</governor>
          <dependent id="105">made</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="107">considering</governor>
          <dependent id="106">without</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="105">made</governor>
          <dependent id="107">considering</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="109">content</governor>
          <dependent id="108">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="107">considering</governor>
          <dependent id="109">content</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Arthur Kropp" type="PERSON" score="0.0">
          <tokens>
            <token id="72" string="Arthur" />
            <token id="73" string="Kropp" />
          </tokens>
        </entity>
        <entity id="2" string="D-Vt." type="LOCATION" score="0.0">
          <tokens>
            <token id="84" string="D-Vt." />
          </tokens>
        </entity>
        <entity id="3" string="1973" type="DATE" score="0.0">
          <tokens>
            <token id="99" string="1973" />
          </tokens>
        </entity>
        <entity id="4" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="past" />
          </tokens>
        </entity>
        <entity id="5" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
        <entity id="6" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="40" string="two" />
          </tokens>
        </entity>
        <entity id="7" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="78" string="American" />
          </tokens>
        </entity>
        <entity id="8" string="Patrick Leahy" type="PERSON" score="0.0">
          <tokens>
            <token id="81" string="Patrick" />
            <token id="82" string="Leahy" />
          </tokens>
        </entity>
        <entity id="9" string="Way" type="MISC" score="0.0">
          <tokens>
            <token id="79" string="Way" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m not satisfied with the answers,&amp;quot; Leahy said Although Thomas appeared to back away from comments made in past speeches or articles, he told the committee, &amp;quot;My view is that I have been consistent.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="satisfied" lemma="satisfy" stem="satisfi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Leahy" lemma="Leahy" stem="leahi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="back" lemma="back" stem="back" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="comments" lemma="comment" stem="comment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="speeches" lemma="speech" stem="speech" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="consistent" lemma="consistent" stem="consist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (RB not) (ADJP (VBN satisfied) (PP (IN with) (NP (DT the) (NNS answers)))))) (, ,) ('' '') (PRN (S (NP (NNP Leahy)) (VP (VBD said) (SBAR (S (SBAR (IN Although) (S (NP (NNP Thomas)) (VP (VBD appeared) (S (VP (TO to) (VP (VB back) (ADVP (RB away)) (PP (IN from) (NP (NP (NNS comments)) (VP (VBN made) (PP (IN in) (NP (JJ past) (NNS speeches) (CC or) (NNS articles)))))))))))) (, ,) (NP (PRP he)) (VP (VBD told) (NP (DT the) (NN committee)))))))) (, ,) (`` ``) (NP (PRP$ My) (NN view)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP have) (VP (VBN been) (ADJP (JJ consistent))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="comments" type="NP">
          <tokens>
            <token id="20" string="comments" />
          </tokens>
        </chunking>
        <chunking id="2" string="Leahy" type="NP">
          <tokens>
            <token id="11" string="Leahy" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Although Thomas appeared to back away from comments made in past speeches or articles , he told the committee" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="Although" />
            <token id="14" string="Thomas" />
            <token id="15" string="appeared" />
            <token id="16" string="to" />
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
            <token id="27" string="," />
            <token id="28" string="he" />
            <token id="29" string="told" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="14" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="consistent" type="ADJP">
          <tokens>
            <token id="41" string="consistent" />
          </tokens>
        </chunking>
        <chunking id="6" string="told the committee" type="VP">
          <tokens>
            <token id="29" string="told" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
          </tokens>
        </chunking>
        <chunking id="7" string="have been consistent" type="VP">
          <tokens>
            <token id="39" string="have" />
            <token id="40" string="been" />
            <token id="41" string="consistent" />
          </tokens>
        </chunking>
        <chunking id="8" string="to back away from comments made in past speeches or articles" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="9" string="comments made in past speeches or articles" type="NP">
          <tokens>
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="10" string="Although Thomas appeared to back away from comments made in past speeches or articles , he told the committee" type="SBAR">
          <tokens>
            <token id="13" string="Although" />
            <token id="14" string="Thomas" />
            <token id="15" string="appeared" />
            <token id="16" string="to" />
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
            <token id="27" string="," />
            <token id="28" string="he" />
            <token id="29" string="told" />
            <token id="30" string="the" />
            <token id="31" string="committee" />
          </tokens>
        </chunking>
        <chunking id="11" string="appeared to back away from comments made in past speeches or articles" type="VP">
          <tokens>
            <token id="15" string="appeared" />
            <token id="16" string="to" />
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="12" string="satisfied with the answers" type="ADJP">
          <tokens>
            <token id="5" string="satisfied" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
        <chunking id="13" string="made in past speeches or articles" type="VP">
          <tokens>
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="28" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="that I have been consistent" type="SBAR">
          <tokens>
            <token id="37" string="that" />
            <token id="38" string="I" />
            <token id="39" string="have" />
            <token id="40" string="been" />
            <token id="41" string="consistent" />
          </tokens>
        </chunking>
        <chunking id="16" string="past speeches or articles" type="NP">
          <tokens>
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="17" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="18" string="back away from comments made in past speeches or articles" type="VP">
          <tokens>
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="19" string="My view" type="NP">
          <tokens>
            <token id="34" string="My" />
            <token id="35" string="view" />
          </tokens>
        </chunking>
        <chunking id="20" string="been consistent" type="VP">
          <tokens>
            <token id="40" string="been" />
            <token id="41" string="consistent" />
          </tokens>
        </chunking>
        <chunking id="21" string="is that I have been consistent" type="VP">
          <tokens>
            <token id="36" string="is" />
            <token id="37" string="that" />
            <token id="38" string="I" />
            <token id="39" string="have" />
            <token id="40" string="been" />
            <token id="41" string="consistent" />
          </tokens>
        </chunking>
        <chunking id="22" string="'m not satisfied with the answers" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="not" />
            <token id="5" string="satisfied" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
        <chunking id="23" string="Although Thomas appeared to back away from comments made in past speeches or articles" type="SBAR">
          <tokens>
            <token id="13" string="Although" />
            <token id="14" string="Thomas" />
            <token id="15" string="appeared" />
            <token id="16" string="to" />
            <token id="17" string="back" />
            <token id="18" string="away" />
            <token id="19" string="from" />
            <token id="20" string="comments" />
            <token id="21" string="made" />
            <token id="22" string="in" />
            <token id="23" string="past" />
            <token id="24" string="speeches" />
            <token id="25" string="or" />
            <token id="26" string="articles" />
          </tokens>
        </chunking>
        <chunking id="24" string="the committee" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="committee" />
          </tokens>
        </chunking>
        <chunking id="25" string="the answers" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="answers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">satisfied</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">satisfied</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">satisfied</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">is</governor>
          <dependent id="5">satisfied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">answers</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">answers</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">satisfied</governor>
          <dependent id="8">answers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">Leahy</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="36">is</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">appeared</governor>
          <dependent id="13">Although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">appeared</governor>
          <dependent id="14">Thomas</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">told</governor>
          <dependent id="15">appeared</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">back</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">appeared</governor>
          <dependent id="17">back</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">back</governor>
          <dependent id="18">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">comments</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">back</governor>
          <dependent id="20">comments</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">comments</governor>
          <dependent id="21">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">speeches</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">speeches</governor>
          <dependent id="23">past</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">made</governor>
          <dependent id="24">speeches</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">speeches</governor>
          <dependent id="25">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">speeches</governor>
          <dependent id="26">articles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">told</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="29">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">committee</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">told</governor>
          <dependent id="31">committee</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">view</governor>
          <dependent id="34">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">is</governor>
          <dependent id="35">view</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="36">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="41">consistent</governor>
          <dependent id="37">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">consistent</governor>
          <dependent id="38">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="41">consistent</governor>
          <dependent id="39">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="41">consistent</governor>
          <dependent id="40">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">is</governor>
          <dependent id="41">consistent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="past" />
          </tokens>
        </entity>
        <entity id="2" string="Leahy" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Leahy" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>; Thomas&amp;apost; opponents believe Republicans Strom Thurmond of South Carolina, Orrin Hatch of Utah, Charles Grassley of Iowa, Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy, D-Mass., and Howard Metzenbaum, D-Ohio, will be joined by the three swing-vote senators and Biden, Leahy, Simon and Kohl in voting against the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas&amp;apost; refusal to give direct answers &amp;quot;makes it more difficult to vote for him.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Republicans" lemma="republican" stem="republican" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="Strom" lemma="Strom" stem="strom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Thurmond" lemma="Thurmond" stem="thurmond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Carolina" lemma="Carolina" stem="carolina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Orrin" lemma="Orrin" stem="orrin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Hatch" lemma="Hatch" stem="hatch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Utah" lemma="Utah" stem="utah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Grassley" lemma="Grassley" stem="grasslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Iowa" lemma="Iowa" stem="iowa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Simpson" lemma="Simpson" stem="simpson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Wyoming" lemma="Wyoming" stem="wyom" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Hank" lemma="Hank" stem="hank" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="solid" lemma="solid" stem="solid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="35" string="backers" lemma="backer" stem="backer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="Sens." lemma="Sens." stem="sens." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="41" string="M." lemma="M." stem="m." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="42" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="D-Mass." lemma="D-Mass." stem="d-mass." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="47" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="48" string="Metzenbaum" lemma="Metzenbaum" stem="metzenbaum" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="49" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="50" string="D-Ohio" lemma="D-Ohio" stem="d-ohio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="joined" lemma="join" stem="join" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="58" string="swing-vote" lemma="swing-vote" stem="swing-vot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="62" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="Leahy" lemma="Leahy" stem="leahi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="64" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="66" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="Kohl" lemma="Kohl" stem="kohl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="68" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="voting" lemma="vote" stem="vote" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="72" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="73" string="Biden" lemma="Biden" stem="biden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="74" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="75" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="76" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="77" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="78" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="79" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="80" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="81" string="leanings" lemma="leaning" stem="lean" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="82" string="Metzenbaum" lemma="Metzenbaum" stem="metzenbaum" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="83" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="84" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="85" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="86" string="refusal" lemma="refusal" stem="refus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="87" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="88" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="89" string="direct" lemma="direct" stem="direct" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="90" string="answers" lemma="answer" stem="answer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="91" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="92" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="93" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="94" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="95" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="96" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="97" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="98" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="99" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="100" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="101" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (NP (NP (NNP Thomas) (POS ')) (NNS opponents)) (SBAR (S (VP (VBP believe) (NP (NP (NNS Republicans)) (SBAR (S (S (NP (NP (NP (NNP Strom) (NNP Thurmond)) (PP (IN of) (NP (NNP South) (NNP Carolina)))) (, ,) (NP (NP (NNP Orrin) (NNP Hatch)) (PP (IN of) (NP (NNP Utah)))) (, ,) (NP (NP (NNP Charles) (NNP Grassley)) (PP (IN of) (NP (NNP Iowa)))) (, ,) (NP (NP (NNP Alan) (NNP Simpson)) (PP (IN of) (NP (NNP Wyoming)))) (CC and) (NP (NP (NNP Hank) (NNP Brown)) (PP (IN of) (NP (NNP Colorado))))) (VP (VBP are) (NP (JJ solid) (NNP Thomas) (NNS backers)))) (CC But) (S (NP (PRP they)) (VP (VBP hope) (NP (NP (NNP Sens.) (NNP Edward) (NNP M.) (NNP Kennedy)) (, ,) (NP (NNP D-Mass.)) (, ,) (CC and) (NP (NP (NNP Howard) (NNP Metzenbaum)) (, ,) (NP (NNP D-Ohio)))))))))))))) (, ,) (VP (MD will) (VP (VB be) (VP (VBN joined) (PP (IN by) (NP (NP (DT the) (CD three) (JJ swing-vote) (NNS senators)) (CC and) (NP (NNP Biden) (, ,) (NNP Leahy) (, ,) (NNP Simon) (CC and) (NNP Kohl)))) (PP (IN in) (S (VP (VBG voting) (PP (IN against) (NP (NP (DT the) (NN nominee)) (SBAR (S (NP (NNP Biden) (CC and) (NNP Kennedy)) (VP (VBD declined) (NP (NN comment)) (NP-TMP (NNP Wednesday)) (PP (IN on) (NP (NP (PRP$ their) (NNS leanings)) (SBAR (S (NP (NNP Metzenbaum)) (VP (VBD said) (SBAR (S (NP (NP (NNP Thomas) (POS ')) (NN refusal) (S (VP (TO to) (VP (VB give) (NP (JJ direct) (NNS answers)))))) (`` ``) (VP (VBZ makes) (S (NP (PRP it)) (ADJP (RBR more) (JJ difficult) (S (VP (TO to) (VP (VB vote) (PP (IN for) (NP (PRP him))))))))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Strom Thurmond of South Carolina , Orrin Hatch of Utah , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="SBAR">
          <tokens>
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
            <token id="12" string="," />
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
            <token id="17" string="," />
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
            <token id="22" string="," />
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
            <token id="27" string="and" />
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
            <token id="32" string="are" />
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
            <token id="36" string="But" />
            <token id="37" string="they" />
            <token id="38" string="hope" />
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' opponents believe Republicans Strom Thurmond of South Carolina , Orrin Hatch of Utah , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
            <token id="4" string="opponents" />
            <token id="5" string="believe" />
            <token id="6" string="Republicans" />
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
            <token id="12" string="," />
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
            <token id="17" string="," />
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
            <token id="22" string="," />
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
            <token id="27" string="and" />
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
            <token id="32" string="are" />
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
            <token id="36" string="But" />
            <token id="37" string="they" />
            <token id="38" string="hope" />
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="NP">
          <tokens>
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="4" string="Charles Grassley of Iowa" type="NP">
          <tokens>
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
          </tokens>
        </chunking>
        <chunking id="5" string="Iowa" type="NP">
          <tokens>
            <token id="21" string="Iowa" />
          </tokens>
        </chunking>
        <chunking id="6" string="are solid Thomas backers" type="VP">
          <tokens>
            <token id="32" string="are" />
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
          </tokens>
        </chunking>
        <chunking id="7" string="Strom Thurmond" type="NP">
          <tokens>
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
          </tokens>
        </chunking>
        <chunking id="8" string="makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="Republicans Strom Thurmond of South Carolina , Orrin Hatch of Utah , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="NP">
          <tokens>
            <token id="6" string="Republicans" />
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
            <token id="12" string="," />
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
            <token id="17" string="," />
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
            <token id="22" string="," />
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
            <token id="27" string="and" />
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
            <token id="32" string="are" />
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
            <token id="36" string="But" />
            <token id="37" string="they" />
            <token id="38" string="hope" />
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="10" string="be joined by the three swing-vote senators and Biden , Leahy , Simon and Kohl in voting against the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="53" string="be" />
            <token id="54" string="joined" />
            <token id="55" string="by" />
            <token id="56" string="the" />
            <token id="57" string="three" />
            <token id="58" string="swing-vote" />
            <token id="59" string="senators" />
            <token id="60" string="and" />
            <token id="61" string="Biden" />
            <token id="62" string="," />
            <token id="63" string="Leahy" />
            <token id="64" string="," />
            <token id="65" string="Simon" />
            <token id="66" string="and" />
            <token id="67" string="Kohl" />
            <token id="68" string="in" />
            <token id="69" string="voting" />
            <token id="70" string="against" />
            <token id="71" string="the" />
            <token id="72" string="nominee" />
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="the three swing-vote senators" type="NP">
          <tokens>
            <token id="56" string="the" />
            <token id="57" string="three" />
            <token id="58" string="swing-vote" />
            <token id="59" string="senators" />
          </tokens>
        </chunking>
        <chunking id="12" string="Strom Thurmond of South Carolina , Orrin Hatch of Utah , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado" type="NP">
          <tokens>
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
            <token id="12" string="," />
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
            <token id="17" string="," />
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
            <token id="22" string="," />
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
            <token id="27" string="and" />
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="13" string="Orrin Hatch" type="NP">
          <tokens>
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
          </tokens>
        </chunking>
        <chunking id="14" string="declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="Thomas ' opponents" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
            <token id="4" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="16" string="direct answers" type="NP">
          <tokens>
            <token id="89" string="direct" />
            <token id="90" string="answers" />
          </tokens>
        </chunking>
        <chunking id="17" string="give direct answers" type="VP">
          <tokens>
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
          </tokens>
        </chunking>
        <chunking id="18" string="Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="SBAR">
          <tokens>
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="their leanings" type="NP">
          <tokens>
            <token id="80" string="their" />
            <token id="81" string="leanings" />
          </tokens>
        </chunking>
        <chunking id="20" string="Wyoming" type="NP">
          <tokens>
            <token id="26" string="Wyoming" />
          </tokens>
        </chunking>
        <chunking id="21" string="him" type="NP">
          <tokens>
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="22" string="D-Mass." type="NP">
          <tokens>
            <token id="44" string="D-Mass." />
          </tokens>
        </chunking>
        <chunking id="23" string="South Carolina" type="NP">
          <tokens>
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
          </tokens>
        </chunking>
        <chunking id="24" string="Hank Brown" type="NP">
          <tokens>
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="25" string="Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="SBAR">
          <tokens>
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="26" string="to give direct answers" type="VP">
          <tokens>
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
          </tokens>
        </chunking>
        <chunking id="27" string="will be joined by the three swing-vote senators and Biden , Leahy , Simon and Kohl in voting against the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="52" string="will" />
            <token id="53" string="be" />
            <token id="54" string="joined" />
            <token id="55" string="by" />
            <token id="56" string="the" />
            <token id="57" string="three" />
            <token id="58" string="swing-vote" />
            <token id="59" string="senators" />
            <token id="60" string="and" />
            <token id="61" string="Biden" />
            <token id="62" string="," />
            <token id="63" string="Leahy" />
            <token id="64" string="," />
            <token id="65" string="Simon" />
            <token id="66" string="and" />
            <token id="67" string="Kohl" />
            <token id="68" string="in" />
            <token id="69" string="voting" />
            <token id="70" string="against" />
            <token id="71" string="the" />
            <token id="72" string="nominee" />
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="28" string="the three swing-vote senators and Biden , Leahy , Simon and Kohl" type="NP">
          <tokens>
            <token id="56" string="the" />
            <token id="57" string="three" />
            <token id="58" string="swing-vote" />
            <token id="59" string="senators" />
            <token id="60" string="and" />
            <token id="61" string="Biden" />
            <token id="62" string="," />
            <token id="63" string="Leahy" />
            <token id="64" string="," />
            <token id="65" string="Simon" />
            <token id="66" string="and" />
            <token id="67" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="29" string="more difficult to vote for him" type="ADJP">
          <tokens>
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="30" string="Strom Thurmond of South Carolina" type="NP">
          <tokens>
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
          </tokens>
        </chunking>
        <chunking id="31" string="Biden and Kennedy" type="NP">
          <tokens>
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="32" string="Thomas '" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
          </tokens>
        </chunking>
        <chunking id="33" string="to vote for him" type="VP">
          <tokens>
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="34" string="it" type="NP">
          <tokens>
            <token id="93" string="it" />
          </tokens>
        </chunking>
        <chunking id="35" string="D-Ohio" type="NP">
          <tokens>
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="36" string="joined by the three swing-vote senators and Biden , Leahy , Simon and Kohl in voting against the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="54" string="joined" />
            <token id="55" string="by" />
            <token id="56" string="the" />
            <token id="57" string="three" />
            <token id="58" string="swing-vote" />
            <token id="59" string="senators" />
            <token id="60" string="and" />
            <token id="61" string="Biden" />
            <token id="62" string="," />
            <token id="63" string="Leahy" />
            <token id="64" string="," />
            <token id="65" string="Simon" />
            <token id="66" string="and" />
            <token id="67" string="Kohl" />
            <token id="68" string="in" />
            <token id="69" string="voting" />
            <token id="70" string="against" />
            <token id="71" string="the" />
            <token id="72" string="nominee" />
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="37" string="Biden , Leahy , Simon and Kohl" type="NP">
          <tokens>
            <token id="61" string="Biden" />
            <token id="62" string="," />
            <token id="63" string="Leahy" />
            <token id="64" string="," />
            <token id="65" string="Simon" />
            <token id="66" string="and" />
            <token id="67" string="Kohl" />
          </tokens>
        </chunking>
        <chunking id="38" string="the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="NP">
          <tokens>
            <token id="71" string="the" />
            <token id="72" string="nominee" />
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="39" string="Charles Grassley" type="NP">
          <tokens>
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
          </tokens>
        </chunking>
        <chunking id="40" string="Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="SBAR">
          <tokens>
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="41" string="Hank Brown of Colorado" type="NP">
          <tokens>
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="42" string="comment" type="NP">
          <tokens>
            <token id="77" string="comment" />
          </tokens>
        </chunking>
        <chunking id="43" string="believe Republicans Strom Thurmond of South Carolina , Orrin Hatch of Utah , Charles Grassley of Iowa , Alan Simpson of Wyoming and Hank Brown of Colorado are solid Thomas backers But they hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="SBAR">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="Republicans" />
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
            <token id="9" string="of" />
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
            <token id="12" string="," />
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
            <token id="17" string="," />
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
            <token id="20" string="of" />
            <token id="21" string="Iowa" />
            <token id="22" string="," />
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
            <token id="27" string="and" />
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
            <token id="30" string="of" />
            <token id="31" string="Colorado" />
            <token id="32" string="are" />
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
            <token id="36" string="But" />
            <token id="37" string="they" />
            <token id="38" string="hope" />
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="44" string="their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="NP">
          <tokens>
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="45" string="said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="46" string="Alan Simpson of Wyoming" type="NP">
          <tokens>
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
            <token id="25" string="of" />
            <token id="26" string="Wyoming" />
          </tokens>
        </chunking>
        <chunking id="47" string="the nominee" type="NP">
          <tokens>
            <token id="71" string="the" />
            <token id="72" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="48" string="Sens. Edward M. Kennedy" type="NP">
          <tokens>
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="49" string="vote for him" type="VP">
          <tokens>
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="50" string="Utah" type="NP">
          <tokens>
            <token id="16" string="Utah" />
          </tokens>
        </chunking>
        <chunking id="51" string="Alan Simpson" type="NP">
          <tokens>
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
          </tokens>
        </chunking>
        <chunking id="52" string="Republicans" type="NP">
          <tokens>
            <token id="6" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="53" string="voting against the nominee Biden and Kennedy declined comment Wednesday on their leanings Metzenbaum said Thomas ' refusal to give direct answers `` makes it more difficult to vote for him" type="VP">
          <tokens>
            <token id="69" string="voting" />
            <token id="70" string="against" />
            <token id="71" string="the" />
            <token id="72" string="nominee" />
            <token id="73" string="Biden" />
            <token id="74" string="and" />
            <token id="75" string="Kennedy" />
            <token id="76" string="declined" />
            <token id="77" string="comment" />
            <token id="78" string="Wednesday" />
            <token id="79" string="on" />
            <token id="80" string="their" />
            <token id="81" string="leanings" />
            <token id="82" string="Metzenbaum" />
            <token id="83" string="said" />
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
            <token id="91" string="&quot;" />
            <token id="92" string="makes" />
            <token id="93" string="it" />
            <token id="94" string="more" />
            <token id="95" string="difficult" />
            <token id="96" string="to" />
            <token id="97" string="vote" />
            <token id="98" string="for" />
            <token id="99" string="him" />
          </tokens>
        </chunking>
        <chunking id="54" string="they" type="NP">
          <tokens>
            <token id="37" string="they" />
          </tokens>
        </chunking>
        <chunking id="55" string="hope Sens. Edward M. Kennedy , D-Mass. , and Howard Metzenbaum , D-Ohio" type="VP">
          <tokens>
            <token id="38" string="hope" />
            <token id="39" string="Sens." />
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
            <token id="43" string="," />
            <token id="44" string="D-Mass." />
            <token id="45" string="," />
            <token id="46" string="and" />
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="56" string="Metzenbaum" type="NP">
          <tokens>
            <token id="82" string="Metzenbaum" />
          </tokens>
        </chunking>
        <chunking id="57" string="Howard Metzenbaum" type="NP">
          <tokens>
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
          </tokens>
        </chunking>
        <chunking id="58" string="Orrin Hatch of Utah" type="NP">
          <tokens>
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
            <token id="15" string="of" />
            <token id="16" string="Utah" />
          </tokens>
        </chunking>
        <chunking id="59" string="Colorado" type="NP">
          <tokens>
            <token id="31" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="60" string="solid Thomas backers" type="NP">
          <tokens>
            <token id="33" string="solid" />
            <token id="34" string="Thomas" />
            <token id="35" string="backers" />
          </tokens>
        </chunking>
        <chunking id="61" string="Howard Metzenbaum , D-Ohio" type="NP">
          <tokens>
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
            <token id="49" string="," />
            <token id="50" string="D-Ohio" />
          </tokens>
        </chunking>
        <chunking id="62" string="Thomas ' refusal to give direct answers" type="NP">
          <tokens>
            <token id="84" string="Thomas" />
            <token id="85" string="'" />
            <token id="86" string="refusal" />
            <token id="87" string="to" />
            <token id="88" string="give" />
            <token id="89" string="direct" />
            <token id="90" string="answers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">opponents</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Thomas</governor>
          <dependent id="3">'</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="54">joined</governor>
          <dependent id="4">opponents</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">opponents</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">believe</governor>
          <dependent id="6">Republicans</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Thurmond</governor>
          <dependent id="7">Strom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">backers</governor>
          <dependent id="8">Thurmond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Carolina</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Carolina</governor>
          <dependent id="10">South</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Thurmond</governor>
          <dependent id="11">Carolina</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Hatch</governor>
          <dependent id="13">Orrin</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Thurmond</governor>
          <dependent id="14">Hatch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Utah</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Hatch</governor>
          <dependent id="16">Utah</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Grassley</governor>
          <dependent id="18">Charles</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Thurmond</governor>
          <dependent id="19">Grassley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Iowa</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">Grassley</governor>
          <dependent id="21">Iowa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Simpson</governor>
          <dependent id="23">Alan</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Thurmond</governor>
          <dependent id="24">Simpson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Wyoming</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">Simpson</governor>
          <dependent id="26">Wyoming</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Thurmond</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Brown</governor>
          <dependent id="28">Hank</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Thurmond</governor>
          <dependent id="29">Brown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Colorado</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">Brown</governor>
          <dependent id="31">Colorado</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">backers</governor>
          <dependent id="32">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">backers</governor>
          <dependent id="33">solid</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">backers</governor>
          <dependent id="34">Thomas</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Republicans</governor>
          <dependent id="35">backers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">backers</governor>
          <dependent id="36">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">hope</governor>
          <dependent id="37">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">backers</governor>
          <dependent id="38">hope</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Kennedy</governor>
          <dependent id="39">Sens.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Kennedy</governor>
          <dependent id="40">Edward</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Kennedy</governor>
          <dependent id="41">M.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">hope</governor>
          <dependent id="42">Kennedy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">Kennedy</governor>
          <dependent id="44">D-Mass.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="42">Kennedy</governor>
          <dependent id="46">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Metzenbaum</governor>
          <dependent id="47">Howard</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">Kennedy</governor>
          <dependent id="48">Metzenbaum</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="48">Metzenbaum</governor>
          <dependent id="50">D-Ohio</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="54">joined</governor>
          <dependent id="52">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="54">joined</governor>
          <dependent id="53">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="54">joined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="59">senators</governor>
          <dependent id="55">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="59">senators</governor>
          <dependent id="56">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="59">senators</governor>
          <dependent id="57">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="59">senators</governor>
          <dependent id="58">swing-vote</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="54">joined</governor>
          <dependent id="59">senators</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="59">senators</governor>
          <dependent id="60">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="59">senators</governor>
          <dependent id="61">Biden</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="61">Biden</governor>
          <dependent id="63">Leahy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="61">Biden</governor>
          <dependent id="65">Simon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="61">Biden</governor>
          <dependent id="66">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="61">Biden</governor>
          <dependent id="67">Kohl</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="69">voting</governor>
          <dependent id="68">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="54">joined</governor>
          <dependent id="69">voting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="72">nominee</governor>
          <dependent id="70">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="72">nominee</governor>
          <dependent id="71">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="69">voting</governor>
          <dependent id="72">nominee</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="76">declined</governor>
          <dependent id="73">Biden</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="73">Biden</governor>
          <dependent id="74">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="73">Biden</governor>
          <dependent id="75">Kennedy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="72">nominee</governor>
          <dependent id="76">declined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="76">declined</governor>
          <dependent id="77">comment</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="76">declined</governor>
          <dependent id="78">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="81">leanings</governor>
          <dependent id="79">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="81">leanings</governor>
          <dependent id="80">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="76">declined</governor>
          <dependent id="81">leanings</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="83">said</governor>
          <dependent id="82">Metzenbaum</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="81">leanings</governor>
          <dependent id="83">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="86">refusal</governor>
          <dependent id="84">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="84">Thomas</governor>
          <dependent id="85">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="92">makes</governor>
          <dependent id="86">refusal</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="88">give</governor>
          <dependent id="87">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="86">refusal</governor>
          <dependent id="88">give</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="90">answers</governor>
          <dependent id="89">direct</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="88">give</governor>
          <dependent id="90">answers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="83">said</governor>
          <dependent id="92">makes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="95">difficult</governor>
          <dependent id="93">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="95">difficult</governor>
          <dependent id="94">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="92">makes</governor>
          <dependent id="95">difficult</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="97">vote</governor>
          <dependent id="96">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="95">difficult</governor>
          <dependent id="97">vote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="99">him</governor>
          <dependent id="98">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="97">vote</governor>
          <dependent id="99">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kohl" type="PERSON" score="0.0">
          <tokens>
            <token id="67" string="Kohl" />
          </tokens>
        </entity>
        <entity id="2" string="Wyoming" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Wyoming" />
          </tokens>
        </entity>
        <entity id="3" string="Leahy" type="PERSON" score="0.0">
          <tokens>
            <token id="63" string="Leahy" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="D-Mass." type="LOCATION" score="0.0">
          <tokens>
            <token id="44" string="D-Mass." />
          </tokens>
        </entity>
        <entity id="6" string="South Carolina" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="South" />
            <token id="11" string="Carolina" />
          </tokens>
        </entity>
        <entity id="7" string="Utah" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Utah" />
          </tokens>
        </entity>
        <entity id="8" string="Iowa" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Iowa" />
          </tokens>
        </entity>
        <entity id="9" string="Alan Simpson" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Alan" />
            <token id="24" string="Simpson" />
          </tokens>
        </entity>
        <entity id="10" string="D-Ohio" type="LOCATION" score="0.0">
          <tokens>
            <token id="50" string="D-Ohio" />
          </tokens>
        </entity>
        <entity id="11" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="57" string="three" />
          </tokens>
        </entity>
        <entity id="12" string="Hank Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Hank" />
            <token id="29" string="Brown" />
          </tokens>
        </entity>
        <entity id="13" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Republicans" />
          </tokens>
        </entity>
        <entity id="14" string="Charles Grassley" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Charles" />
            <token id="19" string="Grassley" />
          </tokens>
        </entity>
        <entity id="15" string="Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="75" string="Kennedy" />
          </tokens>
        </entity>
        <entity id="16" string="Metzenbaum" type="PERSON" score="0.0">
          <tokens>
            <token id="82" string="Metzenbaum" />
          </tokens>
        </entity>
        <entity id="17" string="Strom Thurmond" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Strom" />
            <token id="8" string="Thurmond" />
          </tokens>
        </entity>
        <entity id="18" string="Edward M. Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Edward" />
            <token id="41" string="M." />
            <token id="42" string="Kennedy" />
          </tokens>
        </entity>
        <entity id="19" string="Howard Metzenbaum" type="PERSON" score="0.0">
          <tokens>
            <token id="47" string="Howard" />
            <token id="48" string="Metzenbaum" />
          </tokens>
        </entity>
        <entity id="20" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="78" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="21" string="Biden" type="PERSON" score="0.0">
          <tokens>
            <token id="61" string="Biden" />
          </tokens>
        </entity>
        <entity id="22" string="Simon" type="PERSON" score="0.0">
          <tokens>
            <token id="65" string="Simon" />
          </tokens>
        </entity>
        <entity id="23" string="Colorado" type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Colorado" />
          </tokens>
        </entity>
        <entity id="24" string="Orrin Hatch" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Orrin" />
            <token id="14" string="Hatch" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>; THOMAS&amp;apost; VIEWS; Excerpts from Clarence Thomas&amp;apost; testimony:; On abortion: &amp;quot;I have no reason or agenda to prejudge the issue . . . or a predilection to rule one way or another on the issue of abortion.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="THOMAS" lemma="THOMAS" stem="thomas" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="VIEWS" lemma="view" stem="views" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Excerpts" lemma="excerpt" stem="excerpt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="agenda" lemma="agenda" stem="agenda" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="prejudge" lemma="prejudge" stem="prejudg" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="predilection" lemma="predilection" stem="predilect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="rule" lemma="rule" stem="rule" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="35" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="abortion" lemma="abortion" stem="abort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (PRN (: ;) (NP (NP (NNP THOMAS) (POS ')) (NNS VIEWS)) (: ;)) (NNS Excerpts)) (PP (IN from) (NP (NP (NP (NNP Clarence) (NNP Thomas) (POS ')) (NN testimony)) (: :) (SBAR (S (: ;) (PP (IN On) (NP (NN abortion))) (: :) (NP (`` ``) (PRP I)) (VP (VBP have) (NP (DT no) (NN reason)))) (CC or) (S (NP (NN agenda)) (VP (TO to) (VP (VB prejudge) (NP (DT the) (NN issue)))))))))) (: ...) (CC or) (S (NP (DT a) (NN predilection)) (VP (TO to) (VP (VB rule) (NP (NP (CD one) (NN way)) (CC or) (NP (DT another))) (PP (IN on) (NP (NP (DT the) (NN issue)) (PP (IN of) (NP (NN abortion)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="; On abortion : `` I have no reason or agenda to prejudge the issue" type="SBAR">
          <tokens>
            <token id="13" string=";" />
            <token id="14" string="On" />
            <token id="15" string="abortion" />
            <token id="16" string=":" />
            <token id="17" string="&quot;" />
            <token id="18" string="I" />
            <token id="19" string="have" />
            <token id="20" string="no" />
            <token id="21" string="reason" />
            <token id="22" string="or" />
            <token id="23" string="agenda" />
            <token id="24" string="to" />
            <token id="25" string="prejudge" />
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
        <chunking id="2" string="Clarence Thomas '" type="NP">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="the issue" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
        <chunking id="4" string="THOMAS '" type="NP">
          <tokens>
            <token id="2" string="THOMAS" />
            <token id="3" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` I" type="NP">
          <tokens>
            <token id="17" string="&quot;" />
            <token id="18" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="another" type="NP">
          <tokens>
            <token id="37" string="another" />
          </tokens>
        </chunking>
        <chunking id="7" string="agenda" type="NP">
          <tokens>
            <token id="23" string="agenda" />
          </tokens>
        </chunking>
        <chunking id="8" string="have no reason" type="VP">
          <tokens>
            <token id="19" string="have" />
            <token id="20" string="no" />
            <token id="21" string="reason" />
          </tokens>
        </chunking>
        <chunking id="9" string="prejudge the issue" type="VP">
          <tokens>
            <token id="25" string="prejudge" />
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
        <chunking id="10" string="abortion" type="NP">
          <tokens>
            <token id="15" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="11" string="; THOMAS ' VIEWS ; Excerpts" type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="THOMAS" />
            <token id="3" string="'" />
            <token id="4" string="VIEWS" />
            <token id="5" string=";" />
            <token id="6" string="Excerpts" />
          </tokens>
        </chunking>
        <chunking id="12" string="one way or another" type="NP">
          <tokens>
            <token id="34" string="one" />
            <token id="35" string="way" />
            <token id="36" string="or" />
            <token id="37" string="another" />
          </tokens>
        </chunking>
        <chunking id="13" string="to rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="rule" />
            <token id="34" string="one" />
            <token id="35" string="way" />
            <token id="36" string="or" />
            <token id="37" string="another" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="issue" />
            <token id="41" string="of" />
            <token id="42" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="14" string="no reason" type="NP">
          <tokens>
            <token id="20" string="no" />
            <token id="21" string="reason" />
          </tokens>
        </chunking>
        <chunking id="15" string="rule one way or another on the issue of abortion" type="VP">
          <tokens>
            <token id="33" string="rule" />
            <token id="34" string="one" />
            <token id="35" string="way" />
            <token id="36" string="or" />
            <token id="37" string="another" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="issue" />
            <token id="41" string="of" />
            <token id="42" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="16" string="the issue of abortion" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="issue" />
            <token id="41" string="of" />
            <token id="42" string="abortion" />
          </tokens>
        </chunking>
        <chunking id="17" string="a predilection" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="predilection" />
          </tokens>
        </chunking>
        <chunking id="18" string="THOMAS ' VIEWS" type="NP">
          <tokens>
            <token id="2" string="THOMAS" />
            <token id="3" string="'" />
            <token id="4" string="VIEWS" />
          </tokens>
        </chunking>
        <chunking id="19" string="to prejudge the issue" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="prejudge" />
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
        <chunking id="20" string="one way" type="NP">
          <tokens>
            <token id="34" string="one" />
            <token id="35" string="way" />
          </tokens>
        </chunking>
        <chunking id="21" string="; THOMAS ' VIEWS ; Excerpts from Clarence Thomas ' testimony : ; On abortion : `` I have no reason or agenda to prejudge the issue" type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="THOMAS" />
            <token id="3" string="'" />
            <token id="4" string="VIEWS" />
            <token id="5" string=";" />
            <token id="6" string="Excerpts" />
            <token id="7" string="from" />
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="testimony" />
            <token id="12" string=":" />
            <token id="13" string=";" />
            <token id="14" string="On" />
            <token id="15" string="abortion" />
            <token id="16" string=":" />
            <token id="17" string="&quot;" />
            <token id="18" string="I" />
            <token id="19" string="have" />
            <token id="20" string="no" />
            <token id="21" string="reason" />
            <token id="22" string="or" />
            <token id="23" string="agenda" />
            <token id="24" string="to" />
            <token id="25" string="prejudge" />
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
        <chunking id="22" string="Clarence Thomas ' testimony" type="NP">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="23" string="Clarence Thomas ' testimony : ; On abortion : `` I have no reason or agenda to prejudge the issue" type="NP">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
            <token id="10" string="'" />
            <token id="11" string="testimony" />
            <token id="12" string=":" />
            <token id="13" string=";" />
            <token id="14" string="On" />
            <token id="15" string="abortion" />
            <token id="16" string=":" />
            <token id="17" string="&quot;" />
            <token id="18" string="I" />
            <token id="19" string="have" />
            <token id="20" string="no" />
            <token id="21" string="reason" />
            <token id="22" string="or" />
            <token id="23" string="agenda" />
            <token id="24" string="to" />
            <token id="25" string="prejudge" />
            <token id="26" string="the" />
            <token id="27" string="issue" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">VIEWS</governor>
          <dependent id="2">THOMAS</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">THOMAS</governor>
          <dependent id="3">'</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">Excerpts</governor>
          <dependent id="4">VIEWS</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">Excerpts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">testimony</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Thomas</governor>
          <dependent id="8">Clarence</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">testimony</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Thomas</governor>
          <dependent id="10">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Excerpts</governor>
          <dependent id="11">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">abortion</governor>
          <dependent id="14">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">have</governor>
          <dependent id="15">abortion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">have</governor>
          <dependent id="18">I</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">testimony</governor>
          <dependent id="19">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">reason</governor>
          <dependent id="20">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">have</governor>
          <dependent id="21">reason</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">have</governor>
          <dependent id="22">or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">prejudge</governor>
          <dependent id="23">agenda</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">prejudge</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">have</governor>
          <dependent id="25">prejudge</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">issue</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">prejudge</governor>
          <dependent id="27">issue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Excerpts</governor>
          <dependent id="29">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">predilection</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">rule</governor>
          <dependent id="31">predilection</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">rule</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Excerpts</governor>
          <dependent id="33">rule</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">way</governor>
          <dependent id="34">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">rule</governor>
          <dependent id="35">way</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">way</governor>
          <dependent id="36">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">way</governor>
          <dependent id="37">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">issue</governor>
          <dependent id="38">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">issue</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">rule</governor>
          <dependent id="40">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">abortion</governor>
          <dependent id="41">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">issue</governor>
          <dependent id="42">abortion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Clarence" />
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>; On affirmative action: &amp;quot;The line that I drew was a line that said that we shouldn&amp;apost;t have preferences, or goals, or timetables or quotas.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="drew" lemma="draw" stem="drew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="preferences" lemma="preference" stem="prefer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="goals" lemma="goal" stem="goal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="timetables" lemma="timetable" stem="timet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="quotas" lemma="quota" stem="quota" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PRN (: ;) (PP (IN On) (NP (JJ affirmative) (NN action)))) (: :) (S (NP (`` ``) (NP (DT The) (NN line)) (SBAR (IN that) (S (NP (PRP I)) (VP (VBD drew)))))) (VP (VBD was) (NP (NP (DT a) (NN line)) (SBAR (WHNP (WDT that)) (S (VP (VBD said) (SBAR (IN that) (S (NP (PRP we)) (VP (MD should) (RB n't) (VP (VB have) (NP (NP (NP (NNS preferences)) (, ,) (CC or) (NP (NNS goals)) (, ,)) (CC or) (NP (NNS timetables) (CC or) (NNS quotas)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a line that said that we should n't have preferences , or goals , or timetables or quotas" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="line" />
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="2" string="goals" type="NP">
          <tokens>
            <token id="25" string="goals" />
          </tokens>
        </chunking>
        <chunking id="3" string="have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="a line" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="line" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="18" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="preferences" type="NP">
          <tokens>
            <token id="22" string="preferences" />
          </tokens>
        </chunking>
        <chunking id="8" string="preferences , or goals ," type="NP">
          <tokens>
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="drew" type="VP">
          <tokens>
            <token id="11" string="drew" />
          </tokens>
        </chunking>
        <chunking id="10" string="preferences , or goals , or timetables or quotas" type="NP">
          <tokens>
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="11" string="was a line that said that we should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="a" />
            <token id="14" string="line" />
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="12" string="that we should n't have preferences , or goals , or timetables or quotas" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="13" string="that I drew" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="drew" />
          </tokens>
        </chunking>
        <chunking id="14" string="should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="15" string="affirmative action" type="NP">
          <tokens>
            <token id="3" string="affirmative" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="16" string="The line" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="line" />
          </tokens>
        </chunking>
        <chunking id="17" string="that said that we should n't have preferences , or goals , or timetables or quotas" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="18" string="said that we should n't have preferences , or goals , or timetables or quotas" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="we" />
            <token id="19" string="should" />
            <token id="20" string="n't" />
            <token id="21" string="have" />
            <token id="22" string="preferences" />
            <token id="23" string="," />
            <token id="24" string="or" />
            <token id="25" string="goals" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="19" string="timetables or quotas" type="NP">
          <tokens>
            <token id="28" string="timetables" />
            <token id="29" string="or" />
            <token id="30" string="quotas" />
          </tokens>
        </chunking>
        <chunking id="20" string="`` The line that I drew" type="NP">
          <tokens>
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="line" />
            <token id="9" string="that" />
            <token id="10" string="I" />
            <token id="11" string="drew" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">action</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">action</governor>
          <dependent id="3">affirmative</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">line</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">line</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="14">line</governor>
          <dependent id="8">line</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">drew</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">drew</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">line</governor>
          <dependent id="11">drew</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">line</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">line</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">line</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">line</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">have</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">have</governor>
          <dependent id="18">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">have</governor>
          <dependent id="19">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">have</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">have</governor>
          <dependent id="22">preferences</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">preferences</governor>
          <dependent id="24">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">preferences</governor>
          <dependent id="25">goals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">preferences</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">preferences</governor>
          <dependent id="28">timetables</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">timetables</governor>
          <dependent id="29">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">timetables</governor>
          <dependent id="30">quotas</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>; On natural law: &amp;quot;At no time did I feel, nor do I feel now, that natural law is anything more than the background to our Constitution.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (PP (IN On) (NP (NP (JJ natural) (NN law)) (: :) (`` ``) (S (PP (IN At) (NP (NP (DT no) (NN time)) (SBAR (S (VP (VBD did) (SBAR (S (NP (PRP I)) (VP (VBP feel))))))))) (, ,) (NP (CC nor)) (VP (VBP do) (S (NP (PRP I)) (VP (VB feel) (ADVP (RB now)))) (, ,) (SBAR (IN that) (S (NP (JJ natural) (NN law)) (VP (VBZ is) (ADJP (ADJP (NN anything) (JJR more)) (PP (IN than) (NP (NP (DT the) (NN background)) (PP (TO to) (NP (PRP$ our) (NNP Constitution)))))))))) (. .)) ('' '')))))</syntactictree>
      <chunkings>
        <chunking id="1" string="natural law : `` At no time did I feel , nor do I feel now , that natural law is anything more than the background to our Constitution . ''" type="NP">
          <tokens>
            <token id="3" string="natural" />
            <token id="4" string="law" />
            <token id="5" string=":" />
            <token id="6" string="&quot;" />
            <token id="7" string="At" />
            <token id="8" string="no" />
            <token id="9" string="time" />
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
            <token id="13" string="," />
            <token id="14" string="nor" />
            <token id="15" string="do" />
            <token id="16" string="I" />
            <token id="17" string="feel" />
            <token id="18" string="now" />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
            <token id="32" string="." />
            <token id="33" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="anything more than the background to our Constitution" type="ADJP">
          <tokens>
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="3" string="our Constitution" type="NP">
          <tokens>
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="that natural law is anything more than the background to our Constitution" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="the background" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="background" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="feel" type="VP">
          <tokens>
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="8" string="the background to our Constitution" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="is anything more than the background to our Constitution" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="10" string="nor" type="NP">
          <tokens>
            <token id="14" string="nor" />
          </tokens>
        </chunking>
        <chunking id="11" string="feel now" type="VP">
          <tokens>
            <token id="17" string="feel" />
            <token id="18" string="now" />
          </tokens>
        </chunking>
        <chunking id="12" string="do I feel now , that natural law is anything more than the background to our Constitution" type="VP">
          <tokens>
            <token id="15" string="do" />
            <token id="16" string="I" />
            <token id="17" string="feel" />
            <token id="18" string="now" />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="natural" />
            <token id="22" string="law" />
            <token id="23" string="is" />
            <token id="24" string="anything" />
            <token id="25" string="more" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="background" />
            <token id="29" string="to" />
            <token id="30" string="our" />
            <token id="31" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="13" string="I feel" type="SBAR">
          <tokens>
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="14" string="natural law" type="NP">
          <tokens>
            <token id="3" string="natural" />
            <token id="4" string="law" />
          </tokens>
        </chunking>
        <chunking id="15" string="no time" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="anything more" type="ADJP">
          <tokens>
            <token id="24" string="anything" />
            <token id="25" string="more" />
          </tokens>
        </chunking>
        <chunking id="17" string="no time did I feel" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="time" />
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
        <chunking id="18" string="did I feel" type="SBAR">
          <tokens>
            <token id="10" string="did" />
            <token id="11" string="I" />
            <token id="12" string="feel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">law</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">law</governor>
          <dependent id="3">natural</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">law</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">time</governor>
          <dependent id="7">At</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">time</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">do</governor>
          <dependent id="9">time</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">time</governor>
          <dependent id="10">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">feel</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">did</governor>
          <dependent id="12">feel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">do</governor>
          <dependent id="14">nor</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">law</governor>
          <dependent id="15">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">feel</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">do</governor>
          <dependent id="17">feel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">feel</governor>
          <dependent id="18">now</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">anything</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">law</governor>
          <dependent id="21">natural</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">anything</governor>
          <dependent id="22">law</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">anything</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">do</governor>
          <dependent id="24">anything</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">anything</governor>
          <dependent id="25">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">background</governor>
          <dependent id="26">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">background</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">anything</governor>
          <dependent id="28">background</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Constitution</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">Constitution</governor>
          <dependent id="30">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">background</governor>
          <dependent id="31">Constitution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>; HEAR IT, SEE IT; Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO; (box) KQED, 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m (box) KPFA, 94.1 FM Live coverage begins at 6:30 a.m TELEVISION; (box) C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m (box) CNN Intermittent coverage.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="HEAR" lemma="hear" stem="hear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="IT" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="SEE" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="IT" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="weekday" lemma="weekday" stem="weekdai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="RADIO" lemma="radio" stem="radio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="KQED" lemma="kqed" stem="kqed" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="88.5" lemma="88.5" stem="88.5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="40" string="FM" lemma="FM" stem="fm" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="41" string="Tape" lemma="Tape" stem="tape" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="42" string="delay" lemma="delay" stem="delai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="beginning" lemma="begin" stem="begin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="46" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="47" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="9:30" lemma="9:30" stem="9:30" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="50" string="p.m" lemma="p.m" stem="p.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="51" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="KPFA" lemma="kpfa" stem="kpfa" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="55" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="94.1" lemma="94.1" stem="94.1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="57" string="FM" lemma="FM" stem="fm" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="58" string="Live" lemma="Live" stem="live" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="59" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="6:30" lemma="6:30" stem="6:30" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="63" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="64" string="TELEVISION" lemma="television" stem="television" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="65" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="C-SPAN" lemma="C-SPAN" stem="c-span" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="Live" lemma="Live" stem="live" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="72" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="73" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="74" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="75" string="a.m" lemma="a.m" stem="a.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="76" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="77" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="78" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="79" string="p.m" lemma="p.m" stem="p.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="80" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="81" string="box" lemma="box" stem="box" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="82" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="83" string="CNN" lemma="CNN" stem="cnn" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="84" string="Intermittent" lemma="intermittent" stem="intermitt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="85" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="86" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (VP (VBP HEAR) (NP (PRP IT)))) (, ,) (VP (VBP SEE) (NP (PRP IT)) (: ;) (S (NP (NP (NNP Senate) (NN confirmation) (NNS hearings)) (SBAR (S (SBAR (IN for) (S (NP (NNP Supreme) (NNP Court) (NN nominee) (NNP Clarence) (NNP Thomas)) (VP (VBP are) (VP (VBN scheduled) (S (VP (TO to) (VP (VB run) (PP (IN through) (NP (NP (NP (NNP Friday)) (NP (DT this) (NN week))) (CC and) (NP (NP (DT every) (NN weekday)) (PP (IN except) (NP (NNP Wednesday) (JJ next) (NN week) (NN RADIO)))))) (: ;) (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NP (NP (NN KQED)) (, ,) (NP (CD 88.5) (NNP FM) (NNP Tape) (NN delay))) (PP (VBG beginning) (PP (IN at) (NP (NP (CD 9) (RB a.m)) (VP (VBN repeated) (PP (IN at) (NP (CD 9:30) (RB p.m)) (NP (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NN KPFA)))))))))))))) (, ,) (NP (CD 94.1) (NNP FM) (NNP Live) (NN coverage)) (VP (VBZ begins) (PP (IN at) (NP (NP (CD 6:30) (RB a.m) (NN TELEVISION)) (: ;) (NP (NP (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-)) (NNP C-SPAN) (NNP Live)) (SBAR (S (NP (NN coverage)) (VP (VBZ begins) (PP (IN at) (NP (NP (CD 7) (RB a.m)) (VP (VBN repeated) (PP (IN at) (NP (CD 5) (RB p.m))))))))))))))) (PRN (-LRB- -LRB-) (NP (NN box)) (-RRB- -RRB-))) (NP (NNP CNN) (JJ Intermittent) (NN coverage)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="7 a.m" type="NP">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
          </tokens>
        </chunking>
        <chunking id="2" string="Friday this week" type="NP">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="HEAR IT" type="VP">
          <tokens>
            <token id="2" string="HEAR" />
            <token id="3" string="IT" />
          </tokens>
        </chunking>
        <chunking id="4" string="are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="5" string="KQED" type="NP">
          <tokens>
            <token id="37" string="KQED" />
          </tokens>
        </chunking>
        <chunking id="6" string="IT" type="NP">
          <tokens>
            <token id="3" string="IT" />
          </tokens>
        </chunking>
        <chunking id="7" string="7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="8" string="begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="VP">
          <tokens>
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="9" string="SEE IT ; Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m -LRB- box -RRB- CNN Intermittent coverage" type="VP">
          <tokens>
            <token id="5" string="SEE" />
            <token id="6" string="IT" />
            <token id="7" string=";" />
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
            <token id="80" string="(" />
            <token id="81" string="box" />
            <token id="82" string=")" />
            <token id="83" string="CNN" />
            <token id="84" string="Intermittent" />
            <token id="85" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="10" string="Friday this week and every weekday except Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="11" string="Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="12" string="-LRB- box -RRB- KPFA" type="NP">
          <tokens>
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="13" string="94.1 FM Live coverage" type="NP">
          <tokens>
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="14" string="coverage" type="NP">
          <tokens>
            <token id="71" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="15" string="Supreme Court nominee Clarence Thomas" type="NP">
          <tokens>
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="16" string="scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="17" string="to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="18" string="repeated at 5 p.m" type="VP">
          <tokens>
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="19" string="88.5 FM Tape delay" type="NP">
          <tokens>
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
          </tokens>
        </chunking>
        <chunking id="20" string="6:30 a.m TELEVISION" type="NP">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
          </tokens>
        </chunking>
        <chunking id="21" string="5 p.m" type="NP">
          <tokens>
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="22" string="9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="NP">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="23" string="-LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="24" string="Senate confirmation hearings for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m -LRB- box -RRB-" type="NP">
          <tokens>
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
            <token id="80" string="(" />
            <token id="81" string="box" />
            <token id="82" string=")" />
          </tokens>
        </chunking>
        <chunking id="25" string="for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="SBAR">
          <tokens>
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="26" string="begins at 7 a.m repeated at 5 p.m" type="VP">
          <tokens>
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="27" string="6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="NP">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="28" string="Senate confirmation hearings" type="NP">
          <tokens>
            <token id="8" string="Senate" />
            <token id="9" string="confirmation" />
            <token id="10" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="29" string="every weekday" type="NP">
          <tokens>
            <token id="26" string="every" />
            <token id="27" string="weekday" />
          </tokens>
        </chunking>
        <chunking id="30" string="KQED , 88.5 FM Tape delay" type="NP">
          <tokens>
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
          </tokens>
        </chunking>
        <chunking id="31" string="repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="32" string="9:30 p.m" type="NP">
          <tokens>
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="33" string="CNN Intermittent coverage" type="NP">
          <tokens>
            <token id="83" string="CNN" />
            <token id="84" string="Intermittent" />
            <token id="85" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="34" string="coverage begins at 7 a.m repeated at 5 p.m" type="SBAR">
          <tokens>
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="35" string="box" type="NP">
          <tokens>
            <token id="35" string="box" />
          </tokens>
        </chunking>
        <chunking id="36" string="9 a.m" type="NP">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
          </tokens>
        </chunking>
        <chunking id="37" string="every weekday except Wednesday next week RADIO" type="NP">
          <tokens>
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
          </tokens>
        </chunking>
        <chunking id="38" string="-LRB- box -RRB- C-SPAN Live" type="NP">
          <tokens>
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
          </tokens>
        </chunking>
        <chunking id="39" string="run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA" type="VP">
          <tokens>
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
          </tokens>
        </chunking>
        <chunking id="40" string="for Supreme Court nominee Clarence Thomas are scheduled to run through Friday this week and every weekday except Wednesday next week RADIO ; -LRB- box -RRB- KQED , 88.5 FM Tape delay beginning at 9 a.m repeated at 9:30 p.m -LRB- box -RRB- KPFA , 94.1 FM Live coverage begins at 6:30 a.m TELEVISION ; -LRB- box -RRB- C-SPAN Live coverage begins at 7 a.m repeated at 5 p.m" type="SBAR">
          <tokens>
            <token id="11" string="for" />
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
            <token id="14" string="nominee" />
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
            <token id="17" string="are" />
            <token id="18" string="scheduled" />
            <token id="19" string="to" />
            <token id="20" string="run" />
            <token id="21" string="through" />
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
            <token id="25" string="and" />
            <token id="26" string="every" />
            <token id="27" string="weekday" />
            <token id="28" string="except" />
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
            <token id="32" string="RADIO" />
            <token id="33" string=";" />
            <token id="34" string="(" />
            <token id="35" string="box" />
            <token id="36" string=")" />
            <token id="37" string="KQED" />
            <token id="38" string="," />
            <token id="39" string="88.5" />
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
            <token id="42" string="delay" />
            <token id="43" string="beginning" />
            <token id="44" string="at" />
            <token id="45" string="9" />
            <token id="46" string="a.m" />
            <token id="47" string="repeated" />
            <token id="48" string="at" />
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
            <token id="51" string="(" />
            <token id="52" string="box" />
            <token id="53" string=")" />
            <token id="54" string="KPFA" />
            <token id="55" string="," />
            <token id="56" string="94.1" />
            <token id="57" string="FM" />
            <token id="58" string="Live" />
            <token id="59" string="coverage" />
            <token id="60" string="begins" />
            <token id="61" string="at" />
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
            <token id="64" string="TELEVISION" />
            <token id="65" string=";" />
            <token id="66" string="(" />
            <token id="67" string="box" />
            <token id="68" string=")" />
            <token id="69" string="C-SPAN" />
            <token id="70" string="Live" />
            <token id="71" string="coverage" />
            <token id="72" string="begins" />
            <token id="73" string="at" />
            <token id="74" string="7" />
            <token id="75" string="a.m" />
            <token id="76" string="repeated" />
            <token id="77" string="at" />
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="41" string="Friday" type="NP">
          <tokens>
            <token id="22" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="42" string="this week" type="NP">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="parataxis">
          <governor id="5">SEE</governor>
          <dependent id="2">HEAR</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">HEAR</governor>
          <dependent id="3">IT</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">SEE</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">SEE</governor>
          <dependent id="6">IT</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">hearings</governor>
          <dependent id="8">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">hearings</governor>
          <dependent id="9">confirmation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="85">coverage</governor>
          <dependent id="10">hearings</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">scheduled</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="12">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="13">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="14">nominee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Thomas</governor>
          <dependent id="15">Clarence</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">scheduled</governor>
          <dependent id="16">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">scheduled</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="60">begins</governor>
          <dependent id="18">scheduled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">run</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">scheduled</governor>
          <dependent id="20">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Friday</governor>
          <dependent id="21">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">run</governor>
          <dependent id="22">Friday</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">week</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">Friday</governor>
          <dependent id="24">week</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Friday</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">weekday</governor>
          <dependent id="26">every</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Friday</governor>
          <dependent id="27">weekday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">RADIO</governor>
          <dependent id="28">except</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">RADIO</governor>
          <dependent id="29">Wednesday</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">RADIO</governor>
          <dependent id="30">next</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">RADIO</governor>
          <dependent id="31">week</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">weekday</governor>
          <dependent id="32">RADIO</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">run</governor>
          <dependent id="35">box</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">run</governor>
          <dependent id="37">KQED</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="42">delay</governor>
          <dependent id="39">88.5</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">delay</governor>
          <dependent id="40">FM</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">delay</governor>
          <dependent id="41">Tape</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">KQED</governor>
          <dependent id="42">delay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">9</governor>
          <dependent id="43">beginning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">9</governor>
          <dependent id="44">at</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">run</governor>
          <dependent id="45">9</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">9</governor>
          <dependent id="46">a.m</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="45">9</governor>
          <dependent id="47">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">9:30</governor>
          <dependent id="48">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">repeated</governor>
          <dependent id="49">9:30</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="49">9:30</governor>
          <dependent id="50">p.m</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="54">KPFA</governor>
          <dependent id="52">box</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="49">9:30</governor>
          <dependent id="54">KPFA</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="59">coverage</governor>
          <dependent id="56">94.1</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">coverage</governor>
          <dependent id="57">FM</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">coverage</governor>
          <dependent id="58">Live</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="60">begins</governor>
          <dependent id="59">coverage</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">hearings</governor>
          <dependent id="60">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="64">TELEVISION</governor>
          <dependent id="61">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="64">TELEVISION</governor>
          <dependent id="62">6:30</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="64">TELEVISION</governor>
          <dependent id="63">a.m</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">begins</governor>
          <dependent id="64">TELEVISION</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="70">Live</governor>
          <dependent id="67">box</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="70">Live</governor>
          <dependent id="69">C-SPAN</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="64">TELEVISION</governor>
          <dependent id="70">Live</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="72">begins</governor>
          <dependent id="71">coverage</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="70">Live</governor>
          <dependent id="72">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="74">7</governor>
          <dependent id="73">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="72">begins</governor>
          <dependent id="74">7</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="74">7</governor>
          <dependent id="75">a.m</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="74">7</governor>
          <dependent id="76">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="78">5</governor>
          <dependent id="77">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="76">repeated</governor>
          <dependent id="78">5</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="78">5</governor>
          <dependent id="79">p.m</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">hearings</governor>
          <dependent id="81">box</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="85">coverage</governor>
          <dependent id="83">CNN</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="85">coverage</governor>
          <dependent id="84">Intermittent</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">SEE</governor>
          <dependent id="85">coverage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Supreme" />
            <token id="13" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="7 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="74" string="7" />
            <token id="75" string="a.m" />
          </tokens>
        </entity>
        <entity id="3" string="Friday this week" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="Friday" />
            <token id="23" string="this" />
            <token id="24" string="week" />
          </tokens>
        </entity>
        <entity id="4" string="9:30 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="49" string="9:30" />
            <token id="50" string="p.m" />
          </tokens>
        </entity>
        <entity id="5" string="FM Live" type="MISC" score="0.0">
          <tokens>
            <token id="57" string="FM" />
            <token id="58" string="Live" />
          </tokens>
        </entity>
        <entity id="6" string="6:30 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="62" string="6:30" />
            <token id="63" string="a.m" />
          </tokens>
        </entity>
        <entity id="7" string="KQED" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="37" string="KQED" />
          </tokens>
        </entity>
        <entity id="8" string="94.1" type="NUMBER" score="0.0">
          <tokens>
            <token id="56" string="94.1" />
          </tokens>
        </entity>
        <entity id="9" string="9 a.m" type="TIME" score="0.0">
          <tokens>
            <token id="45" string="9" />
            <token id="46" string="a.m" />
          </tokens>
        </entity>
        <entity id="10" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Senate" />
          </tokens>
        </entity>
        <entity id="11" string="5 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="78" string="5" />
            <token id="79" string="p.m" />
          </tokens>
        </entity>
        <entity id="12" string="FM Tape" type="MISC" score="0.0">
          <tokens>
            <token id="40" string="FM" />
            <token id="41" string="Tape" />
          </tokens>
        </entity>
        <entity id="13" string="88.5" type="NUMBER" score="0.0">
          <tokens>
            <token id="39" string="88.5" />
          </tokens>
        </entity>
        <entity id="14" string="KPFA" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="54" string="KPFA" />
          </tokens>
        </entity>
        <entity id="15" string="Wednesday next week" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="Wednesday" />
            <token id="30" string="next" />
            <token id="31" string="week" />
          </tokens>
        </entity>
        <entity id="16" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Clarence" />
            <token id="16" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="4-5-6-7" string="the Senate Judiciary Committee" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="2" />
        <mention ids_tokens="8" string="Senate" id_sentence="20" />
        <mention ids_tokens="12-13" string="Supreme Court" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13" string="Supreme Court nominee Clarence Thomas" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6-7" string="Thomas'" id_sentence="5" />
        <mention ids_tokens="16" string="Thomas" id_sentence="6" />
        <mention ids_tokens="25" string="Thomas" id_sentence="7" />
        <mention ids_tokens="32-33" string="Thomas'" id_sentence="7" />
        <mention ids_tokens="41" string="him" id_sentence="7" />
        <mention ids_tokens="2-8" string="Thomas , a black federal appeals judge" id_sentence="9" />
        <mention ids_tokens="2" string="Thomas" id_sentence="9" />
        <mention ids_tokens="4-8" string="a black federal appeals judge" id_sentence="9" />
        <mention ids_tokens="33-35" string="the conservative Thomas" id_sentence="9" />
        <mention ids_tokens="10" string="him" id_sentence="10" />
        <mention ids_tokens="2" string="Thomas" id_sentence="11" />
        <mention ids_tokens="10" string="he" id_sentence="11" />
        <mention ids_tokens="35" string="he" id_sentence="11" />
        <mention ids_tokens="40" string="his" id_sentence="11" />
        <mention ids_tokens="7" string="he" id_sentence="12" />
        <mention ids_tokens="13" string="my" id_sentence="12" />
        <mention ids_tokens="2-16" string="Thomas , who sat alone at the witness table with no notes or reference materials" id_sentence="13" />
        <mention ids_tokens="2" string="Thomas" id_sentence="13" />
        <mention ids_tokens="33" string="his" id_sentence="13" />
        <mention ids_tokens="49" string="Thomas" id_sentence="13" />
        <mention ids_tokens="53-55" string="the judge's" id_sentence="13" />
        <mention ids_tokens="64" string="me" id_sentence="13" />
        <mention ids_tokens="71-74" string="Thomas , testifying calmly" id_sentence="13" />
        <mention ids_tokens="71" string="Thomas" id_sentence="13" />
        <mention ids_tokens="120" string="Thomas" id_sentence="13" />
        <mention ids_tokens="10" string="Thomas" id_sentence="14" />
        <mention ids_tokens="22" string="he" id_sentence="14" />
        <mention ids_tokens="35" string="His" id_sentence="14" />
        <mention ids_tokens="45" string="he" id_sentence="14" />
        <mention ids_tokens="53" string="his" id_sentence="14" />
        <mention ids_tokens="60" string="he" id_sentence="14" />
        <mention ids_tokens="62-68" string="a man whose convictions have shallow roots" id_sentence="14" />
        <mention ids_tokens="92-93" string="Thomas'" id_sentence="14" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="14" string="Thomas" id_sentence="15" />
        <mention ids_tokens="28" string="he" id_sentence="15" />
        <mention ids_tokens="34" string="My" id_sentence="15" />
        <mention ids_tokens="38" string="I" id_sentence="15" />
        <mention ids_tokens="2-3" string="Thomas'" id_sentence="16" />
        <mention ids_tokens="34" string="Thomas" id_sentence="16" />
        <mention ids_tokens="84-85" string="Thomas'" id_sentence="16" />
        <mention ids_tokens="99" string="him" id_sentence="16" />
        <mention ids_tokens="2-3" string="THOMAS'" id_sentence="17" />
        <mention ids_tokens="8-10" string="Clarence Thomas'" id_sentence="17" />
        <mention ids_tokens="17-18" string="&quot; I" id_sentence="17" />
        <mention ids_tokens="10" string="I" id_sentence="18" />
        <mention ids_tokens="11" string="I" id_sentence="19" />
        <mention ids_tokens="16" string="I" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="31-32" string="Several senators" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11" string="their" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="47-48-49-50-51-52-53" string="the 1973 Supreme Court decision legalizing abortion" id_sentence="1" />
      <mentions>
        <mention ids_tokens="43-46" string="the 1973 abortion decision" id_sentence="11" />
        <mention ids_tokens="98-101" string="the 1973 abortion decision" id_sentence="14" />
        <mention ids_tokens="108" string="its" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="8-9" string="Paul Simon" id_sentence="2" />
      <mentions>
        <mention ids_tokens="15" string="his" id_sentence="3" />
        <mention ids_tokens="18" string="his" id_sentence="3" />
        <mention ids_tokens="30" string="Simon" id_sentence="7" />
        <mention ids_tokens="96" string="Simon" id_sentence="13" />
        <mention ids_tokens="114" string="his" id_sentence="13" />
        <mention ids_tokens="65" string="Simon" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26-27-28" string="the room who does not have an opinion" id_sentence="2" />
      <mentions>
        <mention ids_tokens="109-110" string="the room" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="3-4" string="Herb Kohl" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="Kohl" id_sentence="4" />
        <mention ids_tokens="3-6" string="today's leadoff questioner" id_sentence="4" />
        <mention ids_tokens="67" string="Kohl" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="22-23" string="Howell Heflin" id_sentence="4" />
      <mentions>
        <mention ids_tokens="20" string="Heflin" id_sentence="6" />
        <mention ids_tokens="3" string="Heflin" id_sentence="7" />
        <mention ids_tokens="44" string="him" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="28-29" string="Arlen Specter" id_sentence="4" />
      <mentions>
        <mention ids_tokens="2" string="Specter" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="Thomas ' answers" id_sentence="5" />
      <mentions>
        <mention ids_tokens="7-8" string="the answers" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="10-11" string="Dennis DeConcini" id_sentence="6" />
      <mentions>
        <mention ids_tokens="29" string="DeConcini" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="35-36-37-38-39-40-41-42" string="questions of Thomas ' &quot; integrity and temperament" id_sentence="6" />
      <mentions>
        <mention ids_tokens="7" string="I" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43" string="the retiring Thurgood Marshall , the high court 's only black justice DeConcini said he thought the conservative Thomas &quot; handled the privacy questions very well &quot;" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="22-23-24-25" string="the high court 's" id_sentence="9" />
      <mentions>
        <mention ids_tokens="87-89" string="the high court" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="49-50" string="women 's" id_sentence="11" />
      <mentions>
        <mention ids_tokens="66" string="them" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="79" string="Way" id_sentence="14" />
      <mentions>
        <mention ids_tokens="18-25" string="an impartial way on such an important case" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="42-43" string="Joseph Biden" id_sentence="13" />
      <mentions>
        <mention ids_tokens="61" string="Biden" id_sentence="16" />
        <mention ids_tokens="73" string="Biden" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="83-84-85" string="another hot issue" id_sentence="13" />
      <mentions>
        <mention ids_tokens="26-27" string="the issue" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="81-82" string="Patrick Leahy" id_sentence="14" />
      <mentions>
        <mention ids_tokens="11" string="Leahy" id_sentence="15" />
        <mention ids_tokens="63" string="Leahy" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="50-51-52-53-54-55-56-57" string="the committee about his views to win confirmation" id_sentence="14" />
      <mentions>
        <mention ids_tokens="30-31" string="the committee" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="37" string="another" id_sentence="17" />
      <mentions>
        <mention ids_tokens="18" string="we" id_sentence="18" />
        <mention ids_tokens="30" string="our" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="no time did I feel" id_sentence="19" />
      <mentions>
        <mention ids_tokens="3" string="IT" id_sentence="20" />
        <mention ids_tokens="6" string="IT" id_sentence="20" />
      </mentions>
    </coreference>
  </coreferences>
</document>
