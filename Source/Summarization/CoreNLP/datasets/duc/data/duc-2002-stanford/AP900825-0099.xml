<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900825-0099">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Ousted East German leader Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists, a West German newspaper reported.</content>
      <tokens>
        <token id="1" string="Ousted" lemma="oust" stem="oust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="East" lemma="east" stem="east" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="4" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Erich" lemma="Erich" stem="erich" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="formerly" lemma="formerly" stem="formerli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Communist" lemma="communist" stem="communist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="20" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="exists" lemma="exist" stem="exist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="West" lemma="west" stem="west" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="26" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Ousted) (NP (NP (JJ East) (JJ German) (NN leader)) (SBAR (S (NP (NNP Erich) (NNP Honecker)) (VP (MD will) (RB not) (VP (VB stand) (NP (NN trial)) (PP (IN in) (NP (NNP East) (NNP Germany))) (ADVP (ADVP (RB as) (RB long)) (SBAR (IN as) (S (NP (DT the) (RB formerly) (JJ Communist) (NN country)) (VP (VBZ exists)))))))))))) (, ,) (NP (DT a) (ADJP (JJ West) (JJ German)) (NN newspaper)) (VP (VBD reported)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ousted East German leader Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists" type="VP">
          <tokens>
            <token id="1" string="Ousted" />
            <token id="2" string="East" />
            <token id="3" string="German" />
            <token id="4" string="leader" />
            <token id="5" string="Erich" />
            <token id="6" string="Honecker" />
            <token id="7" string="will" />
            <token id="8" string="not" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="East" />
            <token id="13" string="Germany" />
            <token id="14" string="as" />
            <token id="15" string="long" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="2" string="the formerly Communist country" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="stand trial in East Germany as long as the formerly Communist country exists" type="VP">
          <tokens>
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="East" />
            <token id="13" string="Germany" />
            <token id="14" string="as" />
            <token id="15" string="long" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="4" string="trial" type="NP">
          <tokens>
            <token id="10" string="trial" />
          </tokens>
        </chunking>
        <chunking id="5" string="as the formerly Communist country exists" type="SBAR">
          <tokens>
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="6" string="East German leader Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists" type="NP">
          <tokens>
            <token id="2" string="East" />
            <token id="3" string="German" />
            <token id="4" string="leader" />
            <token id="5" string="Erich" />
            <token id="6" string="Honecker" />
            <token id="7" string="will" />
            <token id="8" string="not" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="East" />
            <token id="13" string="Germany" />
            <token id="14" string="as" />
            <token id="15" string="long" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="7" string="will not stand trial in East Germany as long as the formerly Communist country exists" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="not" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="East" />
            <token id="13" string="Germany" />
            <token id="14" string="as" />
            <token id="15" string="long" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="8" string="Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists" type="SBAR">
          <tokens>
            <token id="5" string="Erich" />
            <token id="6" string="Honecker" />
            <token id="7" string="will" />
            <token id="8" string="not" />
            <token id="9" string="stand" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="East" />
            <token id="13" string="Germany" />
            <token id="14" string="as" />
            <token id="15" string="long" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="formerly" />
            <token id="19" string="Communist" />
            <token id="20" string="country" />
            <token id="21" string="exists" />
          </tokens>
        </chunking>
        <chunking id="9" string="East Germany" type="NP">
          <tokens>
            <token id="12" string="East" />
            <token id="13" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="10" string="a West German newspaper" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="West" />
            <token id="25" string="German" />
            <token id="26" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="11" string="reported" type="VP">
          <tokens>
            <token id="27" string="reported" />
          </tokens>
        </chunking>
        <chunking id="12" string="West German" type="ADJP">
          <tokens>
            <token id="24" string="West" />
            <token id="25" string="German" />
          </tokens>
        </chunking>
        <chunking id="13" string="East German leader" type="NP">
          <tokens>
            <token id="2" string="East" />
            <token id="3" string="German" />
            <token id="4" string="leader" />
          </tokens>
        </chunking>
        <chunking id="14" string="Erich Honecker" type="NP">
          <tokens>
            <token id="5" string="Erich" />
            <token id="6" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="15" string="exists" type="VP">
          <tokens>
            <token id="21" string="exists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="27">reported</governor>
          <dependent id="1">Ousted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">leader</governor>
          <dependent id="2">East</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">leader</governor>
          <dependent id="3">German</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Ousted</governor>
          <dependent id="4">leader</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Honecker</governor>
          <dependent id="5">Erich</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stand</governor>
          <dependent id="6">Honecker</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">stand</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">stand</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">leader</governor>
          <dependent id="9">stand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">stand</governor>
          <dependent id="10">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Germany</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Germany</governor>
          <dependent id="12">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stand</governor>
          <dependent id="13">Germany</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">long</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">stand</governor>
          <dependent id="15">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">exists</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">country</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">country</governor>
          <dependent id="18">formerly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">country</governor>
          <dependent id="19">Communist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">exists</governor>
          <dependent id="20">country</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">long</governor>
          <dependent id="21">exists</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">newspaper</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">German</governor>
          <dependent id="24">West</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">newspaper</governor>
          <dependent id="25">German</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">reported</governor>
          <dependent id="26">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">reported</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="East Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="East" />
            <token id="13" string="Germany" />
          </tokens>
        </entity>
        <entity id="2" string="Communist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="19" string="Communist" />
          </tokens>
        </entity>
        <entity id="3" string="West" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="West" />
          </tokens>
        </entity>
        <entity id="4" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="3" string="German" />
          </tokens>
        </entity>
        <entity id="5" string="Erich Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Erich" />
            <token id="6" string="Honecker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Hamburg-based Bild am Sonntag said Saturday that it would report in its Sunday editions that Honecker could be prosecuted in a united Germany, however, for violation of property laws.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Hamburg-based" lemma="hamburg-based" stem="hamburg-bas" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="3" string="Bild" lemma="Bild" stem="bild" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Sonntag" lemma="Sonntag" stem="sonntag" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="report" lemma="report" stem="report" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="editions" lemma="edition" stem="edit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="prosecuted" lemma="prosecute" stem="prosecut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="united" lemma="unite" stem="unit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="violation" lemma="violation" stem="violat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="property" lemma="property" stem="properti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ Hamburg-based) (NNP Bild)) (VP (VBP am) (NP (NP (NNP Sonntag)) (SBAR (S (VP (VBD said) (NP-TMP (NNP Saturday)) (SBAR (IN that) (S (NP (PRP it)) (VP (MD would) (VP (VB report) (PP (IN in) (NP (PRP$ its) (NNP Sunday) (NNS editions))) (SBAR (WHNP (WDT that)) (S (NP (NNP Honecker)) (VP (MD could) (VP (VB be) (VP (VBN prosecuted) (PP (IN in) (NP (DT a) (VBN united) (NNP Germany))) (, ,) (ADVP (RB however)) (, ,) (PP (IN for) (NP (NP (NN violation)) (PP (IN of) (NP (NN property) (NNS laws))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could be prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="2" string="am Sonntag said Saturday that it would report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="4" string="am" />
            <token id="5" string="Sonntag" />
            <token id="6" string="said" />
            <token id="7" string="Saturday" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="3" string="that it would report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="4" string="would report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="5" string="its Sunday editions" type="NP">
          <tokens>
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
          </tokens>
        </chunking>
        <chunking id="6" string="Honecker" type="NP">
          <tokens>
            <token id="17" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="7" string="be prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sonntag said Saturday that it would report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="NP">
          <tokens>
            <token id="5" string="Sonntag" />
            <token id="6" string="said" />
            <token id="7" string="Saturday" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="Sonntag" type="NP">
          <tokens>
            <token id="5" string="Sonntag" />
          </tokens>
        </chunking>
        <chunking id="11" string="violation of property laws" type="NP">
          <tokens>
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Hamburg-based Bild" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Hamburg-based" />
            <token id="3" string="Bild" />
          </tokens>
        </chunking>
        <chunking id="13" string="said Saturday that it would report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="SBAR">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="Saturday" />
            <token id="8" string="that" />
            <token id="9" string="it" />
            <token id="10" string="would" />
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="14" string="a united Germany" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="15" string="violation" type="NP">
          <tokens>
            <token id="29" string="violation" />
          </tokens>
        </chunking>
        <chunking id="16" string="property laws" type="NP">
          <tokens>
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="17" string="report in its Sunday editions that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="11" string="report" />
            <token id="12" string="in" />
            <token id="13" string="its" />
            <token id="14" string="Sunday" />
            <token id="15" string="editions" />
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="18" string="prosecuted in a united Germany , however , for violation of property laws" type="VP">
          <tokens>
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="19" string="that Honecker could be prosecuted in a united Germany , however , for violation of property laws" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="Honecker" />
            <token id="18" string="could" />
            <token id="19" string="be" />
            <token id="20" string="prosecuted" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="united" />
            <token id="24" string="Germany" />
            <token id="25" string="," />
            <token id="26" string="however" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="violation" />
            <token id="30" string="of" />
            <token id="31" string="property" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bild</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Bild</governor>
          <dependent id="2">Hamburg-based</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">Sonntag</governor>
          <dependent id="3">Bild</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Sonntag</governor>
          <dependent id="4">am</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Sonntag</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Sonntag</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">said</governor>
          <dependent id="7">Saturday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">report</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">report</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">report</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="11">report</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">editions</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">editions</governor>
          <dependent id="13">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">editions</governor>
          <dependent id="14">Sunday</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">report</governor>
          <dependent id="15">editions</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">prosecuted</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">prosecuted</governor>
          <dependent id="17">Honecker</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">prosecuted</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">prosecuted</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">report</governor>
          <dependent id="20">prosecuted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Germany</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Germany</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">Germany</governor>
          <dependent id="23">united</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">prosecuted</governor>
          <dependent id="24">Germany</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">prosecuted</governor>
          <dependent id="26">however</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">violation</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">prosecuted</governor>
          <dependent id="29">violation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">laws</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">laws</governor>
          <dependent id="31">property</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">violation</governor>
          <dependent id="32">laws</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bild am Sonntag" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Bild" />
            <token id="4" string="am" />
            <token id="5" string="Sonntag" />
          </tokens>
        </entity>
        <entity id="2" string="Hamburg-based" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Hamburg-based" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="Sunday" />
          </tokens>
        </entity>
        <entity id="4" string="Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Honecker" />
          </tokens>
        </entity>
        <entity id="5" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Saturday" />
          </tokens>
        </entity>
        <entity id="6" string="Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Bild quoted Guenter Seidel, an East German prosecutor, as saying that Honecker had used $42 million for stocking a private housing estate for leaders of the former Communist government.</content>
      <tokens>
        <token id="1" string="Bild" lemma="Bild" stem="bild" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="2" string="quoted" lemma="quote" stem="quot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Guenter" lemma="Guenter" stem="guenter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Seidel" lemma="Seidel" stem="seidel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="East" lemma="east" stem="east" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="9" string="prosecutor" lemma="prosecutor" stem="prosecutor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="19" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="stocking" lemma="stock" stem="stock" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="housing" lemma="housing" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="estate" lemma="estate" stem="estat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Communist" lemma="communist" stem="communist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="32" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bild)) (VP (VBD quoted) (NP (NP (NNP Guenter) (NNP Seidel)) (, ,) (NP (DT an) (ADJP (JJ East) (JJ German)) (NN prosecutor))) (, ,) (PP (IN as) (S (VP (VBG saying) (SBAR (IN that) (S (NP (NNP Honecker)) (VP (VBD had) (VP (VBN used) (NP (QP ($ $) (CD 42) (CD million))) (PP (IN for) (S (VP (VBG stocking) (NP (DT a) (JJ private) (NN housing) (NN estate)) (PP (IN for) (NP (NP (NNS leaders)) (PP (IN of) (NP (DT the) (JJ former) (JJ Communist) (NN government)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bild" type="NP">
          <tokens>
            <token id="1" string="Bild" />
          </tokens>
        </chunking>
        <chunking id="2" string="a private housing estate" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
          </tokens>
        </chunking>
        <chunking id="3" string="that Honecker had used $ 42 million for stocking a private housing estate for leaders of the former Communist government" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="Honecker" />
            <token id="15" string="had" />
            <token id="16" string="used" />
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
            <token id="20" string="for" />
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="4" string="used $ 42 million for stocking a private housing estate for leaders of the former Communist government" type="VP">
          <tokens>
            <token id="16" string="used" />
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
            <token id="20" string="for" />
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="5" string="stocking a private housing estate for leaders of the former Communist government" type="VP">
          <tokens>
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="6" string="Honecker" type="NP">
          <tokens>
            <token id="14" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="7" string="leaders" type="NP">
          <tokens>
            <token id="27" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="8" string="saying that Honecker had used $ 42 million for stocking a private housing estate for leaders of the former Communist government" type="VP">
          <tokens>
            <token id="12" string="saying" />
            <token id="13" string="that" />
            <token id="14" string="Honecker" />
            <token id="15" string="had" />
            <token id="16" string="used" />
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
            <token id="20" string="for" />
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="9" string="leaders of the former Communist government" type="NP">
          <tokens>
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="10" string="the former Communist government" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="11" string="an East German prosecutor" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="East" />
            <token id="8" string="German" />
            <token id="9" string="prosecutor" />
          </tokens>
        </chunking>
        <chunking id="12" string="Guenter Seidel , an East German prosecutor" type="NP">
          <tokens>
            <token id="3" string="Guenter" />
            <token id="4" string="Seidel" />
            <token id="5" string="," />
            <token id="6" string="an" />
            <token id="7" string="East" />
            <token id="8" string="German" />
            <token id="9" string="prosecutor" />
          </tokens>
        </chunking>
        <chunking id="13" string="had used $ 42 million for stocking a private housing estate for leaders of the former Communist government" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="used" />
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
            <token id="20" string="for" />
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="14" string="quoted Guenter Seidel , an East German prosecutor , as saying that Honecker had used $ 42 million for stocking a private housing estate for leaders of the former Communist government" type="VP">
          <tokens>
            <token id="2" string="quoted" />
            <token id="3" string="Guenter" />
            <token id="4" string="Seidel" />
            <token id="5" string="," />
            <token id="6" string="an" />
            <token id="7" string="East" />
            <token id="8" string="German" />
            <token id="9" string="prosecutor" />
            <token id="10" string="," />
            <token id="11" string="as" />
            <token id="12" string="saying" />
            <token id="13" string="that" />
            <token id="14" string="Honecker" />
            <token id="15" string="had" />
            <token id="16" string="used" />
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
            <token id="20" string="for" />
            <token id="21" string="stocking" />
            <token id="22" string="a" />
            <token id="23" string="private" />
            <token id="24" string="housing" />
            <token id="25" string="estate" />
            <token id="26" string="for" />
            <token id="27" string="leaders" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="former" />
            <token id="31" string="Communist" />
            <token id="32" string="government" />
          </tokens>
        </chunking>
        <chunking id="15" string="East German" type="ADJP">
          <tokens>
            <token id="7" string="East" />
            <token id="8" string="German" />
          </tokens>
        </chunking>
        <chunking id="16" string="$ 42 million" type="NP">
          <tokens>
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
          </tokens>
        </chunking>
        <chunking id="17" string="Guenter Seidel" type="NP">
          <tokens>
            <token id="3" string="Guenter" />
            <token id="4" string="Seidel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">quoted</governor>
          <dependent id="1">Bild</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">quoted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Seidel</governor>
          <dependent id="3">Guenter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">quoted</governor>
          <dependent id="4">Seidel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">prosecutor</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">German</governor>
          <dependent id="7">East</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">prosecutor</governor>
          <dependent id="8">German</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Seidel</governor>
          <dependent id="9">prosecutor</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">saying</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">quoted</governor>
          <dependent id="12">saying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">used</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">used</governor>
          <dependent id="14">Honecker</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">used</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">saying</governor>
          <dependent id="16">used</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">used</governor>
          <dependent id="17">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">million</governor>
          <dependent id="18">42</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">$</governor>
          <dependent id="19">million</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">stocking</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">used</governor>
          <dependent id="21">stocking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">estate</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">estate</governor>
          <dependent id="23">private</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">estate</governor>
          <dependent id="24">housing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">stocking</governor>
          <dependent id="25">estate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">leaders</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">stocking</governor>
          <dependent id="27">leaders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">government</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">government</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">government</governor>
          <dependent id="30">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">government</governor>
          <dependent id="31">Communist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">leaders</governor>
          <dependent id="32">government</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bild" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Bild" />
          </tokens>
        </entity>
        <entity id="2" string="Communist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="31" string="Communist" />
          </tokens>
        </entity>
        <entity id="3" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="German" />
          </tokens>
        </entity>
        <entity id="4" string="Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Honecker" />
          </tokens>
        </entity>
        <entity id="5" string="East" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="East" />
          </tokens>
        </entity>
        <entity id="6" string="$ 42 million" type="MONEY" score="0.0">
          <tokens>
            <token id="17" string="$" />
            <token id="18" string="42" />
            <token id="19" string="million" />
          </tokens>
        </entity>
        <entity id="7" string="Guenter Seidel" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Guenter" />
            <token id="4" string="Seidel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>However, Seidel said that the investigation was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct. 3.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Seidel" lemma="Seidel" stem="seidel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="merges" lemma="merge" stem="merg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (NNP Seidel)) (VP (VBD said) (SBAR (IN that) (S (NP (DT the) (NN investigation)) (VP (VBD was) (RB not) (ADJP (ADJP (RB far) (RB enough) (PP (IN along)) (S (VP (TO to) (VP (VB determine) (SBAR (IN whether) (S (NP (NNS charges)) (VP (MD could) (VP (VB be) (VP (VBN filed) (PP (IN against) (NP (NNP Honecker)))))))))))) (SBAR (IN before) (S (NP (NNP East) (NNP Germany)) (VP (VBZ merges) (PP (IN with) (NP (NP (NNP West) (NNP Germany)) (PP (IN on) (NP (NNP Oct.) (CD 3))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Honecker" type="NP">
          <tokens>
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="2" string="West Germany on Oct. 3" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="3" string="far enough along to determine whether charges could be filed against Honecker" type="ADJP">
          <tokens>
            <token id="10" string="far" />
            <token id="11" string="enough" />
            <token id="12" string="along" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="4" string="determine whether charges could be filed against Honecker" type="VP">
          <tokens>
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="5" string="could be filed against Honecker" type="VP">
          <tokens>
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="6" string="West Germany" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the investigation was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct. 3" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="investigation" />
            <token id="8" string="was" />
            <token id="9" string="not" />
            <token id="10" string="far" />
            <token id="11" string="enough" />
            <token id="12" string="along" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
            <token id="22" string="before" />
            <token id="23" string="East" />
            <token id="24" string="Germany" />
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="8" string="far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct. 3" type="ADJP">
          <tokens>
            <token id="10" string="far" />
            <token id="11" string="enough" />
            <token id="12" string="along" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
            <token id="22" string="before" />
            <token id="23" string="East" />
            <token id="24" string="Germany" />
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="9" string="Seidel" type="NP">
          <tokens>
            <token id="3" string="Seidel" />
          </tokens>
        </chunking>
        <chunking id="10" string="the investigation" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="charges" type="NP">
          <tokens>
            <token id="16" string="charges" />
          </tokens>
        </chunking>
        <chunking id="12" string="East Germany" type="NP">
          <tokens>
            <token id="23" string="East" />
            <token id="24" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="13" string="Oct. 3" type="NP">
          <tokens>
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="14" string="said that the investigation was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct. 3" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="investigation" />
            <token id="8" string="was" />
            <token id="9" string="not" />
            <token id="10" string="far" />
            <token id="11" string="enough" />
            <token id="12" string="along" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
            <token id="22" string="before" />
            <token id="23" string="East" />
            <token id="24" string="Germany" />
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="15" string="to determine whether charges could be filed against Honecker" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="16" string="filed against Honecker" type="VP">
          <tokens>
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="17" string="merges with West Germany on Oct. 3" type="VP">
          <tokens>
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="18" string="be filed against Honecker" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="19" string="whether charges could be filed against Honecker" type="SBAR">
          <tokens>
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="20" string="before East Germany merges with West Germany on Oct. 3" type="SBAR">
          <tokens>
            <token id="22" string="before" />
            <token id="23" string="East" />
            <token id="24" string="Germany" />
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
        <chunking id="21" string="was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct. 3" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="not" />
            <token id="10" string="far" />
            <token id="11" string="enough" />
            <token id="12" string="along" />
            <token id="13" string="to" />
            <token id="14" string="determine" />
            <token id="15" string="whether" />
            <token id="16" string="charges" />
            <token id="17" string="could" />
            <token id="18" string="be" />
            <token id="19" string="filed" />
            <token id="20" string="against" />
            <token id="21" string="Honecker" />
            <token id="22" string="before" />
            <token id="23" string="East" />
            <token id="24" string="Germany" />
            <token id="25" string="merges" />
            <token id="26" string="with" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="on" />
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">said</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Seidel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">enough</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">investigation</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">enough</governor>
          <dependent id="7">investigation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">enough</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">enough</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">enough</governor>
          <dependent id="10">far</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="11">enough</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">enough</governor>
          <dependent id="12">along</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">determine</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">enough</governor>
          <dependent id="14">determine</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">filed</governor>
          <dependent id="15">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">filed</governor>
          <dependent id="16">charges</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">filed</governor>
          <dependent id="17">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">filed</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">determine</governor>
          <dependent id="19">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Honecker</governor>
          <dependent id="20">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">filed</governor>
          <dependent id="21">Honecker</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">merges</governor>
          <dependent id="22">before</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Germany</governor>
          <dependent id="23">East</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">merges</governor>
          <dependent id="24">Germany</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">enough</governor>
          <dependent id="25">merges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Germany</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Germany</governor>
          <dependent id="27">West</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">merges</governor>
          <dependent id="28">Germany</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Oct.</governor>
          <dependent id="29">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">Germany</governor>
          <dependent id="30">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">Oct.</governor>
          <dependent id="31">3</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Seidel" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Seidel" />
          </tokens>
        </entity>
        <entity id="2" string="East Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="East" />
            <token id="24" string="Germany" />
          </tokens>
        </entity>
        <entity id="3" string="Oct. 3" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="Oct." />
            <token id="31" string="3" />
          </tokens>
        </entity>
        <entity id="4" string="Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Honecker" />
          </tokens>
        </entity>
        <entity id="5" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>Negotiators are still working out the merger of the two German legal systems.</content>
      <tokens>
        <token id="1" string="Negotiators" lemma="negotiator" stem="negoti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="merger" lemma="merger" stem="merger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="12" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="systems" lemma="system" stem="system" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Negotiators)) (VP (VBP are) (ADVP (RB still)) (VP (VBG working) (PP (IN out) (NP (NP (DT the) (NN merger)) (PP (IN of) (NP (DT the) (CD two) (JJ German) (JJ legal) (NNS systems))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the merger of the two German legal systems" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="merger" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="German" />
            <token id="12" string="legal" />
            <token id="13" string="systems" />
          </tokens>
        </chunking>
        <chunking id="2" string="working out the merger of the two German legal systems" type="VP">
          <tokens>
            <token id="4" string="working" />
            <token id="5" string="out" />
            <token id="6" string="the" />
            <token id="7" string="merger" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="German" />
            <token id="12" string="legal" />
            <token id="13" string="systems" />
          </tokens>
        </chunking>
        <chunking id="3" string="are still working out the merger of the two German legal systems" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="still" />
            <token id="4" string="working" />
            <token id="5" string="out" />
            <token id="6" string="the" />
            <token id="7" string="merger" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="German" />
            <token id="12" string="legal" />
            <token id="13" string="systems" />
          </tokens>
        </chunking>
        <chunking id="4" string="the two German legal systems" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="German" />
            <token id="12" string="legal" />
            <token id="13" string="systems" />
          </tokens>
        </chunking>
        <chunking id="5" string="Negotiators" type="NP">
          <tokens>
            <token id="1" string="Negotiators" />
          </tokens>
        </chunking>
        <chunking id="6" string="the merger" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="merger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">working</governor>
          <dependent id="1">Negotiators</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">working</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">working</governor>
          <dependent id="3">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">merger</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">merger</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">working</governor>
          <dependent id="7">merger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">systems</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">systems</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">systems</governor>
          <dependent id="10">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">systems</governor>
          <dependent id="11">German</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">systems</governor>
          <dependent id="12">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">merger</governor>
          <dependent id="13">systems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="11" string="German" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Honecker, 78, was ousted as East Germany&amp;apost;s leader on Oct. 18, paving the way for the country&amp;apost;s first freely elected government in March.</content>
      <tokens>
        <token id="1" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="78" lemma="78" stem="78" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ousted" lemma="oust" stem="oust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="paving" lemma="pave" stem="pave" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="24" string="freely" lemma="freely" stem="freeli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Honecker)) (, ,) (NP (CD 78)) (, ,)) (VP (VBD was) (VP (VBN ousted) (PP (IN as) (NP (NP (NNP East) (NNP Germany) (POS 's)) (NN leader))) (PP (IN on) (NP (NNP Oct.) (CD 18))) (, ,) (S (VP (VBG paving) (NP (NP (DT the) (NN way)) (PP (IN for) (NP (NP (NP (DT the) (NN country) (POS 's)) (JJ first) (ADJP (RB freely) (VBN elected)) (NN government)) (PP (IN in) (NP (NNP March)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="78" type="NP">
          <tokens>
            <token id="3" string="78" />
          </tokens>
        </chunking>
        <chunking id="2" string="the country 's" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="freely elected" type="ADJP">
          <tokens>
            <token id="24" string="freely" />
            <token id="25" string="elected" />
          </tokens>
        </chunking>
        <chunking id="4" string="Honecker , 78 ," type="NP">
          <tokens>
            <token id="1" string="Honecker" />
            <token id="2" string="," />
            <token id="3" string="78" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="March" type="NP">
          <tokens>
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="6" string="Honecker" type="NP">
          <tokens>
            <token id="1" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="7" string="ousted as East Germany 's leader on Oct. 18 , paving the way for the country 's first freely elected government in March" type="VP">
          <tokens>
            <token id="6" string="ousted" />
            <token id="7" string="as" />
            <token id="8" string="East" />
            <token id="9" string="Germany" />
            <token id="10" string="'s" />
            <token id="11" string="leader" />
            <token id="12" string="on" />
            <token id="13" string="Oct." />
            <token id="14" string="18" />
            <token id="15" string="," />
            <token id="16" string="paving" />
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
            <token id="27" string="in" />
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="8" string="Oct. 18" type="NP">
          <tokens>
            <token id="13" string="Oct." />
            <token id="14" string="18" />
          </tokens>
        </chunking>
        <chunking id="9" string="paving the way for the country 's first freely elected government in March" type="VP">
          <tokens>
            <token id="16" string="paving" />
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
            <token id="27" string="in" />
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="10" string="the way for the country 's first freely elected government in March" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
            <token id="27" string="in" />
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="11" string="East Germany 's" type="NP">
          <tokens>
            <token id="8" string="East" />
            <token id="9" string="Germany" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="was ousted as East Germany 's leader on Oct. 18 , paving the way for the country 's first freely elected government in March" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="ousted" />
            <token id="7" string="as" />
            <token id="8" string="East" />
            <token id="9" string="Germany" />
            <token id="10" string="'s" />
            <token id="11" string="leader" />
            <token id="12" string="on" />
            <token id="13" string="Oct." />
            <token id="14" string="18" />
            <token id="15" string="," />
            <token id="16" string="paving" />
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
            <token id="27" string="in" />
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="13" string="the way" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="way" />
          </tokens>
        </chunking>
        <chunking id="14" string="East Germany 's leader" type="NP">
          <tokens>
            <token id="8" string="East" />
            <token id="9" string="Germany" />
            <token id="10" string="'s" />
            <token id="11" string="leader" />
          </tokens>
        </chunking>
        <chunking id="15" string="the country 's first freely elected government in March" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
            <token id="27" string="in" />
            <token id="28" string="March" />
          </tokens>
        </chunking>
        <chunking id="16" string="the country 's first freely elected government" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="country" />
            <token id="22" string="'s" />
            <token id="23" string="first" />
            <token id="24" string="freely" />
            <token id="25" string="elected" />
            <token id="26" string="government" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">ousted</governor>
          <dependent id="1">Honecker</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Honecker</governor>
          <dependent id="3">78</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">ousted</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">ousted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">leader</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Germany</governor>
          <dependent id="8">East</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">leader</governor>
          <dependent id="9">Germany</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Germany</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ousted</governor>
          <dependent id="11">leader</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Oct.</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ousted</governor>
          <dependent id="13">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">Oct.</governor>
          <dependent id="14">18</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">ousted</governor>
          <dependent id="16">paving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">way</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">paving</governor>
          <dependent id="18">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">government</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">country</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">government</governor>
          <dependent id="21">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">country</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">government</governor>
          <dependent id="23">first</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">elected</governor>
          <dependent id="24">freely</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">government</governor>
          <dependent id="25">elected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">way</governor>
          <dependent id="26">government</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">March</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">government</governor>
          <dependent id="28">March</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="78" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="78" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="23" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="East Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="East" />
            <token id="9" string="Germany" />
          </tokens>
        </entity>
        <entity id="4" string="March" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="March" />
          </tokens>
        </entity>
        <entity id="5" string="Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Honecker" />
          </tokens>
        </entity>
        <entity id="6" string="Oct. 18" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Oct." />
            <token id="14" string="18" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Honecker is in poor health and remains confined to a Soviet military hospital in Beelitz outside East Berlin.</content>
      <tokens>
        <token id="1" string="Honecker" lemma="Honecker" stem="honeck" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="confined" lemma="confine" stem="confin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Soviet" lemma="soviet" stem="soviet" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="military" lemma="military" stem="militari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Beelitz" lemma="Beelitz" stem="beelitz" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Berlin" lemma="Berlin" stem="berlin" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Honecker)) (VP (VP (VBZ is) (PP (IN in) (NP (JJ poor) (NN health)))) (CC and) (VP (VBZ remains) (VP (VBN confined) (PP (TO to) (NP (NP (DT a) (JJ Soviet) (JJ military) (NN hospital)) (PP (IN in) (NP (NNP Beelitz))))) (PP (IN outside) (NP (NNP East) (NNP Berlin)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Beelitz" type="NP">
          <tokens>
            <token id="15" string="Beelitz" />
          </tokens>
        </chunking>
        <chunking id="2" string="remains confined to a Soviet military hospital in Beelitz outside East Berlin" type="VP">
          <tokens>
            <token id="7" string="remains" />
            <token id="8" string="confined" />
            <token id="9" string="to" />
            <token id="10" string="a" />
            <token id="11" string="Soviet" />
            <token id="12" string="military" />
            <token id="13" string="hospital" />
            <token id="14" string="in" />
            <token id="15" string="Beelitz" />
            <token id="16" string="outside" />
            <token id="17" string="East" />
            <token id="18" string="Berlin" />
          </tokens>
        </chunking>
        <chunking id="3" string="confined to a Soviet military hospital in Beelitz outside East Berlin" type="VP">
          <tokens>
            <token id="8" string="confined" />
            <token id="9" string="to" />
            <token id="10" string="a" />
            <token id="11" string="Soviet" />
            <token id="12" string="military" />
            <token id="13" string="hospital" />
            <token id="14" string="in" />
            <token id="15" string="Beelitz" />
            <token id="16" string="outside" />
            <token id="17" string="East" />
            <token id="18" string="Berlin" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Soviet military hospital" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="Soviet" />
            <token id="12" string="military" />
            <token id="13" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="5" string="Honecker" type="NP">
          <tokens>
            <token id="1" string="Honecker" />
          </tokens>
        </chunking>
        <chunking id="6" string="is in poor health" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="in" />
            <token id="4" string="poor" />
            <token id="5" string="health" />
          </tokens>
        </chunking>
        <chunking id="7" string="is in poor health and remains confined to a Soviet military hospital in Beelitz outside East Berlin" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="in" />
            <token id="4" string="poor" />
            <token id="5" string="health" />
            <token id="6" string="and" />
            <token id="7" string="remains" />
            <token id="8" string="confined" />
            <token id="9" string="to" />
            <token id="10" string="a" />
            <token id="11" string="Soviet" />
            <token id="12" string="military" />
            <token id="13" string="hospital" />
            <token id="14" string="in" />
            <token id="15" string="Beelitz" />
            <token id="16" string="outside" />
            <token id="17" string="East" />
            <token id="18" string="Berlin" />
          </tokens>
        </chunking>
        <chunking id="8" string="poor health" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="health" />
          </tokens>
        </chunking>
        <chunking id="9" string="East Berlin" type="NP">
          <tokens>
            <token id="17" string="East" />
            <token id="18" string="Berlin" />
          </tokens>
        </chunking>
        <chunking id="10" string="a Soviet military hospital in Beelitz" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="Soviet" />
            <token id="12" string="military" />
            <token id="13" string="hospital" />
            <token id="14" string="in" />
            <token id="15" string="Beelitz" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">health</governor>
          <dependent id="1">Honecker</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">health</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">health</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">health</governor>
          <dependent id="4">poor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">health</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">health</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">health</governor>
          <dependent id="7">remains</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">remains</governor>
          <dependent id="8">confined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">hospital</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">hospital</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">hospital</governor>
          <dependent id="11">Soviet</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">hospital</governor>
          <dependent id="12">military</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">confined</governor>
          <dependent id="13">hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Beelitz</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">hospital</governor>
          <dependent id="15">Beelitz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Berlin</governor>
          <dependent id="16">outside</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Berlin</governor>
          <dependent id="17">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">confined</governor>
          <dependent id="18">Berlin</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beelitz" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Beelitz" />
          </tokens>
        </entity>
        <entity id="2" string="Soviet" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Soviet" />
          </tokens>
        </entity>
        <entity id="3" string="Honecker" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Honecker" />
          </tokens>
        </entity>
        <entity id="4" string="East Berlin" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="East" />
            <token id="18" string="Berlin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>He is under investigation on allegations of abuse of power, corruption, harboring terrorists and issuing shoot-to-kill orders to prevent East Germans from escaping to West Germany when he served as the country&amp;apost;s leader.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="corruption" lemma="corruption" stem="corrupt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="harboring" lemma="harbor" stem="harbor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="terrorists" lemma="terrorist" stem="terrorist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="issuing" lemma="issue" stem="issu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="shoot-to-kill" lemma="shoot-to-kill" stem="shoot-to-kil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="orders" lemma="order" stem="order" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="prevent" lemma="prevent" stem="prevent" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="East" lemma="east" stem="east" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="23" string="Germans" lemma="german" stem="german" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="24" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="escaping" lemma="escape" stem="escap" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="served" lemma="serve" stem="serv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ is) (PP (IN under) (NP (NP (NN investigation)) (PP (IN on) (NP (NP (NNS allegations)) (PP (IN of) (NP (NP (NN abuse)) (PP (IN of) (NP (NP (NN power)) (, ,) (NP (NN corruption)) (, ,))))))))) (S (VP (VP (VBG harboring) (NP (NNS terrorists))) (CC and) (VP (VBG issuing) (NP (JJ shoot-to-kill) (NNS orders)) (S (VP (TO to) (VP (VB prevent) (NP (NNS East) (NNS Germans)) (PP (IN from) (S (VP (VBG escaping) (PP (TO to) (NP (NP (NNP West) (NNP Germany)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD served) (PP (IN as) (NP (NP (DT the) (NN country) (POS 's)) (NN leader)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to prevent East Germans from escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="prevent" />
            <token id="22" string="East" />
            <token id="23" string="Germans" />
            <token id="24" string="from" />
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="2" string="served as the country 's leader" type="VP">
          <tokens>
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="3" string="West Germany" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="4" string="the country 's leader" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="5" string="when he served as the country 's leader" type="SBAR">
          <tokens>
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="6" string="allegations" type="NP">
          <tokens>
            <token id="6" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="7" string="investigation on allegations of abuse of power , corruption ," type="NP">
          <tokens>
            <token id="4" string="investigation" />
            <token id="5" string="on" />
            <token id="6" string="allegations" />
            <token id="7" string="of" />
            <token id="8" string="abuse" />
            <token id="9" string="of" />
            <token id="10" string="power" />
            <token id="11" string="," />
            <token id="12" string="corruption" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="9" string="is under investigation on allegations of abuse of power , corruption , harboring terrorists and issuing shoot-to-kill orders to prevent East Germans from escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="under" />
            <token id="4" string="investigation" />
            <token id="5" string="on" />
            <token id="6" string="allegations" />
            <token id="7" string="of" />
            <token id="8" string="abuse" />
            <token id="9" string="of" />
            <token id="10" string="power" />
            <token id="11" string="," />
            <token id="12" string="corruption" />
            <token id="13" string="," />
            <token id="14" string="harboring" />
            <token id="15" string="terrorists" />
            <token id="16" string="and" />
            <token id="17" string="issuing" />
            <token id="18" string="shoot-to-kill" />
            <token id="19" string="orders" />
            <token id="20" string="to" />
            <token id="21" string="prevent" />
            <token id="22" string="East" />
            <token id="23" string="Germans" />
            <token id="24" string="from" />
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="10" string="investigation" type="NP">
          <tokens>
            <token id="4" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="corruption" type="NP">
          <tokens>
            <token id="12" string="corruption" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="30" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="West Germany when he served as the country 's leader" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="14" string="abuse" type="NP">
          <tokens>
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="15" string="shoot-to-kill orders" type="NP">
          <tokens>
            <token id="18" string="shoot-to-kill" />
            <token id="19" string="orders" />
          </tokens>
        </chunking>
        <chunking id="16" string="abuse of power , corruption ," type="NP">
          <tokens>
            <token id="8" string="abuse" />
            <token id="9" string="of" />
            <token id="10" string="power" />
            <token id="11" string="," />
            <token id="12" string="corruption" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="the country 's" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="terrorists" type="NP">
          <tokens>
            <token id="15" string="terrorists" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="29" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="harboring terrorists" type="VP">
          <tokens>
            <token id="14" string="harboring" />
            <token id="15" string="terrorists" />
          </tokens>
        </chunking>
        <chunking id="21" string="allegations of abuse of power , corruption ," type="NP">
          <tokens>
            <token id="6" string="allegations" />
            <token id="7" string="of" />
            <token id="8" string="abuse" />
            <token id="9" string="of" />
            <token id="10" string="power" />
            <token id="11" string="," />
            <token id="12" string="corruption" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="22" string="power , corruption ," type="NP">
          <tokens>
            <token id="10" string="power" />
            <token id="11" string="," />
            <token id="12" string="corruption" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="23" string="East Germans" type="NP">
          <tokens>
            <token id="22" string="East" />
            <token id="23" string="Germans" />
          </tokens>
        </chunking>
        <chunking id="24" string="harboring terrorists and issuing shoot-to-kill orders to prevent East Germans from escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="14" string="harboring" />
            <token id="15" string="terrorists" />
            <token id="16" string="and" />
            <token id="17" string="issuing" />
            <token id="18" string="shoot-to-kill" />
            <token id="19" string="orders" />
            <token id="20" string="to" />
            <token id="21" string="prevent" />
            <token id="22" string="East" />
            <token id="23" string="Germans" />
            <token id="24" string="from" />
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="25" string="prevent East Germans from escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="21" string="prevent" />
            <token id="22" string="East" />
            <token id="23" string="Germans" />
            <token id="24" string="from" />
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="26" string="power" type="NP">
          <tokens>
            <token id="10" string="power" />
          </tokens>
        </chunking>
        <chunking id="27" string="issuing shoot-to-kill orders to prevent East Germans from escaping to West Germany when he served as the country 's leader" type="VP">
          <tokens>
            <token id="17" string="issuing" />
            <token id="18" string="shoot-to-kill" />
            <token id="19" string="orders" />
            <token id="20" string="to" />
            <token id="21" string="prevent" />
            <token id="22" string="East" />
            <token id="23" string="Germans" />
            <token id="24" string="from" />
            <token id="25" string="escaping" />
            <token id="26" string="to" />
            <token id="27" string="West" />
            <token id="28" string="Germany" />
            <token id="29" string="when" />
            <token id="30" string="he" />
            <token id="31" string="served" />
            <token id="32" string="as" />
            <token id="33" string="the" />
            <token id="34" string="country" />
            <token id="35" string="'s" />
            <token id="36" string="leader" />
          </tokens>
        </chunking>
        <chunking id="28" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">investigation</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">investigation</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">investigation</governor>
          <dependent id="3">under</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">allegations</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">investigation</governor>
          <dependent id="6">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">abuse</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">allegations</governor>
          <dependent id="8">abuse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">power</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">abuse</governor>
          <dependent id="10">power</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">power</governor>
          <dependent id="12">corruption</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">investigation</governor>
          <dependent id="14">harboring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">harboring</governor>
          <dependent id="15">terrorists</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">harboring</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">harboring</governor>
          <dependent id="17">issuing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">orders</governor>
          <dependent id="18">shoot-to-kill</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">issuing</governor>
          <dependent id="19">orders</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">prevent</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">issuing</governor>
          <dependent id="21">prevent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Germans</governor>
          <dependent id="22">East</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">prevent</governor>
          <dependent id="23">Germans</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">escaping</governor>
          <dependent id="24">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">prevent</governor>
          <dependent id="25">escaping</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Germany</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Germany</governor>
          <dependent id="27">West</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">escaping</governor>
          <dependent id="28">Germany</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">served</governor>
          <dependent id="29">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">served</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">Germany</governor>
          <dependent id="31">served</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">leader</governor>
          <dependent id="32">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">country</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">leader</governor>
          <dependent id="34">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">country</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">served</governor>
          <dependent id="36">leader</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="East Germans" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="East" />
            <token id="23" string="Germans" />
          </tokens>
        </entity>
        <entity id="2" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Bild said that Erich Mielke, the ex-head of East Germany&amp;apost;s former secret police, was also unlikely to go to court in East Germany.</content>
      <tokens>
        <token id="1" string="Bild" lemma="Bild" stem="bild" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Erich" lemma="Erich" stem="erich" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Mielke" lemma="Mielke" stem="mielk" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="ex-head" lemma="ex-head" stem="ex-head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="secret" lemma="secret" stem="secret" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="unlikely" lemma="unlikely" stem="unlik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bild)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (NNP Erich) (NNP Mielke)) (, ,) (NP (NP (DT the) (NN ex-head)) (PP (IN of) (NP (NP (NNP East) (NNP Germany) (POS 's)) (JJ former) (JJ secret) (NN police)))) (, ,)) (VP (VBD was) (ADVP (RB also)) (ADJP (JJ unlikely) (S (VP (TO to) (VP (VB go) (PP (TO to) (NP (NP (NN court)) (PP (IN in) (NP (NNP East) (NNP Germany))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bild" type="NP">
          <tokens>
            <token id="1" string="Bild" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ex-head of East Germany 's former secret police" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="ex-head" />
            <token id="9" string="of" />
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
            <token id="13" string="former" />
            <token id="14" string="secret" />
            <token id="15" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="the ex-head" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="ex-head" />
          </tokens>
        </chunking>
        <chunking id="4" string="unlikely to go to court in East Germany" type="ADJP">
          <tokens>
            <token id="19" string="unlikely" />
            <token id="20" string="to" />
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="5" string="court" type="NP">
          <tokens>
            <token id="23" string="court" />
          </tokens>
        </chunking>
        <chunking id="6" string="East Germany 's" type="NP">
          <tokens>
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="was also unlikely to go to court in East Germany" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="also" />
            <token id="19" string="unlikely" />
            <token id="20" string="to" />
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="8" string="court in East Germany" type="NP">
          <tokens>
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="9" string="said that Erich Mielke , the ex-head of East Germany 's former secret police , was also unlikely to go to court in East Germany" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="Erich" />
            <token id="5" string="Mielke" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="ex-head" />
            <token id="9" string="of" />
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
            <token id="13" string="former" />
            <token id="14" string="secret" />
            <token id="15" string="police" />
            <token id="16" string="," />
            <token id="17" string="was" />
            <token id="18" string="also" />
            <token id="19" string="unlikely" />
            <token id="20" string="to" />
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="10" string="that Erich Mielke , the ex-head of East Germany 's former secret police , was also unlikely to go to court in East Germany" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="Erich" />
            <token id="5" string="Mielke" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="ex-head" />
            <token id="9" string="of" />
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
            <token id="13" string="former" />
            <token id="14" string="secret" />
            <token id="15" string="police" />
            <token id="16" string="," />
            <token id="17" string="was" />
            <token id="18" string="also" />
            <token id="19" string="unlikely" />
            <token id="20" string="to" />
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="11" string="East Germany 's former secret police" type="NP">
          <tokens>
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
            <token id="13" string="former" />
            <token id="14" string="secret" />
            <token id="15" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="East Germany" type="NP">
          <tokens>
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="13" string="to go to court in East Germany" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="14" string="Erich Mielke" type="NP">
          <tokens>
            <token id="4" string="Erich" />
            <token id="5" string="Mielke" />
          </tokens>
        </chunking>
        <chunking id="15" string="Erich Mielke , the ex-head of East Germany 's former secret police ," type="NP">
          <tokens>
            <token id="4" string="Erich" />
            <token id="5" string="Mielke" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="ex-head" />
            <token id="9" string="of" />
            <token id="10" string="East" />
            <token id="11" string="Germany" />
            <token id="12" string="'s" />
            <token id="13" string="former" />
            <token id="14" string="secret" />
            <token id="15" string="police" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="go to court in East Germany" type="VP">
          <tokens>
            <token id="21" string="go" />
            <token id="22" string="to" />
            <token id="23" string="court" />
            <token id="24" string="in" />
            <token id="25" string="East" />
            <token id="26" string="Germany" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Bild</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">unlikely</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Mielke</governor>
          <dependent id="4">Erich</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">unlikely</governor>
          <dependent id="5">Mielke</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">ex-head</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Mielke</governor>
          <dependent id="8">ex-head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">police</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Germany</governor>
          <dependent id="10">East</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">police</governor>
          <dependent id="11">Germany</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Germany</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">police</governor>
          <dependent id="13">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">police</governor>
          <dependent id="14">secret</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">ex-head</governor>
          <dependent id="15">police</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">unlikely</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">unlikely</governor>
          <dependent id="18">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="19">unlikely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">go</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">unlikely</governor>
          <dependent id="21">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">court</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">go</governor>
          <dependent id="23">court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Germany</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Germany</governor>
          <dependent id="25">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">court</governor>
          <dependent id="26">Germany</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bild" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Bild" />
          </tokens>
        </entity>
        <entity id="2" string="East Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="East" />
            <token id="11" string="Germany" />
          </tokens>
        </entity>
        <entity id="3" string="Erich Mielke" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Erich" />
            <token id="5" string="Mielke" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``I am at the end.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP am) (PP (IN at) (NP (DT the) (NN end)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the end" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="end" />
          </tokens>
        </chunking>
        <chunking id="2" string="am at the end" type="VP">
          <tokens>
            <token id="3" string="am" />
            <token id="4" string="at" />
            <token id="5" string="the" />
            <token id="6" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">end</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">end</governor>
          <dependent id="3">am</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">end</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">end</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">end</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>I am a dead man,&amp;apost;&amp;apost; Bild quoted Mielke, 82, as saying at his last interrogation.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Bild" lemma="Bild" stem="bild" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="quoted" lemma="quote" stem="quot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Mielke" lemma="Mielke" stem="mielk" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="82" lemma="82" stem="82" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="interrogation" lemma="interrogation" stem="interrog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP am) (NP (DT a) (JJ dead) (NN man)))) (, ,) ('' '') (NP (NNP Bild)) (VP (VBD quoted) (NP (NP (NNP Mielke)) (, ,) (NP (CD 82)) (, ,)) (PP (IN as) (S (VP (VBG saying) (PP (IN at) (NP (PRP$ his) (JJ last) (NN interrogation))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mielke" type="NP">
          <tokens>
            <token id="10" string="Mielke" />
          </tokens>
        </chunking>
        <chunking id="2" string="Bild" type="NP">
          <tokens>
            <token id="8" string="Bild" />
          </tokens>
        </chunking>
        <chunking id="3" string="am a dead man" type="VP">
          <tokens>
            <token id="2" string="am" />
            <token id="3" string="a" />
            <token id="4" string="dead" />
            <token id="5" string="man" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="a dead man" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="dead" />
            <token id="5" string="man" />
          </tokens>
        </chunking>
        <chunking id="6" string="saying at his last interrogation" type="VP">
          <tokens>
            <token id="15" string="saying" />
            <token id="16" string="at" />
            <token id="17" string="his" />
            <token id="18" string="last" />
            <token id="19" string="interrogation" />
          </tokens>
        </chunking>
        <chunking id="7" string="82" type="NP">
          <tokens>
            <token id="12" string="82" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mielke , 82 ," type="NP">
          <tokens>
            <token id="10" string="Mielke" />
            <token id="11" string="," />
            <token id="12" string="82" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="quoted Mielke , 82 , as saying at his last interrogation" type="VP">
          <tokens>
            <token id="9" string="quoted" />
            <token id="10" string="Mielke" />
            <token id="11" string="," />
            <token id="12" string="82" />
            <token id="13" string="," />
            <token id="14" string="as" />
            <token id="15" string="saying" />
            <token id="16" string="at" />
            <token id="17" string="his" />
            <token id="18" string="last" />
            <token id="19" string="interrogation" />
          </tokens>
        </chunking>
        <chunking id="10" string="his last interrogation" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="last" />
            <token id="19" string="interrogation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">man</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">man</governor>
          <dependent id="2">am</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">man</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">man</governor>
          <dependent id="4">dead</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">quoted</governor>
          <dependent id="5">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">quoted</governor>
          <dependent id="8">Bild</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">quoted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">quoted</governor>
          <dependent id="10">Mielke</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Mielke</governor>
          <dependent id="12">82</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">saying</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">quoted</governor>
          <dependent id="15">saying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">interrogation</governor>
          <dependent id="16">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">interrogation</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">interrogation</governor>
          <dependent id="18">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">saying</governor>
          <dependent id="19">interrogation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mielke" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Mielke" />
          </tokens>
        </entity>
        <entity id="2" string="Bild" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Bild" />
          </tokens>
        </entity>
        <entity id="3" string="82" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="82" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5-6" string="Erich Honecker" id_sentence="1" />
      <mentions>
        <mention ids_tokens="17" string="Honecker" id_sentence="2" />
        <mention ids_tokens="14" string="Honecker" id_sentence="3" />
        <mention ids_tokens="21" string="Honecker" id_sentence="4" />
        <mention ids_tokens="1-3" string="Honecker , 78" id_sentence="6" />
        <mention ids_tokens="1" string="Honecker" id_sentence="6" />
        <mention ids_tokens="1" string="Honecker" id_sentence="7" />
        <mention ids_tokens="1" string="He" id_sentence="8" />
        <mention ids_tokens="30" string="he" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="12-13" string="East Germany" id_sentence="1" />
      <mentions>
        <mention ids_tokens="24" string="Germany" id_sentence="2" />
        <mention ids_tokens="8-10" string="East Germany's" id_sentence="6" />
        <mention ids_tokens="10-12" string="East Germany's" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20" string="the formerly Communist country" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20-22" string="the country's" id_sentence="6" />
        <mention ids_tokens="33-35" string="the country's" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The Hamburg-based Bild" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="Bild" id_sentence="3" />
        <mention ids_tokens="1" string="Bild" id_sentence="9" />
        <mention ids_tokens="8" string="Bild" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="3-4" string="Guenter Seidel" id_sentence="3" />
      <mentions>
        <mention ids_tokens="3" string="Seidel" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="4-5" string="Erich Mielke" id_sentence="9" />
      <mentions>
        <mention ids_tokens="10" string="Mielke" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="5-6" string="the end" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="11" />
      </mentions>
    </coreference>
  </coreferences>
</document>
