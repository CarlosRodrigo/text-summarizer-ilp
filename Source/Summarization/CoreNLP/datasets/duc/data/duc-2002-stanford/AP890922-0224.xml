<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890922-0224">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Six novels have been nominated for the Booker Prize, Britain&amp;apost;s most prestigious fiction award, and bookmakers say the favorite is ``The Remains of the Day&amp;apost;&amp;apost; by Japanese author Kazuo Ishiguro.</content>
      <tokens>
        <token id="1" string="Six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="nominated" lemma="nominate" stem="nomin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="9" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="prestigious" lemma="prestigious" stem="prestigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bookmakers" lemma="bookmaker" stem="bookmak" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="Remains" lemma="remains" stem="remain" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="29" string="Day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="30" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="Japanese" lemma="japanese" stem="japanes" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="33" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="Kazuo" lemma="Kazuo" stem="kazuo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="Ishiguro" lemma="Ishiguro" stem="ishiguro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (CD Six) (NNS novels)) (VP (VBP have) (VP (VBN been) (VP (VBN nominated) (PP (IN for) (NP (NP (DT the) (NNP Booker) (NNP Prize)) (, ,) (NP (NP (NNP Britain) (POS 's)) (JJS most) (JJ prestigious) (NN fiction) (NN award)))))))) (, ,) (CC and) (S (NP (NNS bookmakers)) (VP (VBP say) (SBAR (S (NP (DT the) (JJ favorite)) (VP (VBZ is) (NP (NP (`` ``) (DT The) (NX (NX (NNS Remains)) (PP (IN of) (NP (DT the) (NN Day)))) ('' '')) (PP (IN by) (NP (JJ Japanese) (NN author) (NNP Kazuo) (NNP Ishiguro))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Booker Prize , Britain 's most prestigious fiction award" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
            <token id="10" string="," />
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prestigious" />
            <token id="15" string="fiction" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="2" string="Japanese author Kazuo Ishiguro" type="NP">
          <tokens>
            <token id="32" string="Japanese" />
            <token id="33" string="author" />
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="3" string="nominated for the Booker Prize , Britain 's most prestigious fiction award" type="VP">
          <tokens>
            <token id="5" string="nominated" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
            <token id="10" string="," />
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prestigious" />
            <token id="15" string="fiction" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Day" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Day" />
          </tokens>
        </chunking>
        <chunking id="5" string="Six novels" type="NP">
          <tokens>
            <token id="1" string="Six" />
            <token id="2" string="novels" />
          </tokens>
        </chunking>
        <chunking id="6" string="been nominated for the Booker Prize , Britain 's most prestigious fiction award" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="nominated" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
            <token id="10" string="," />
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prestigious" />
            <token id="15" string="fiction" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="7" string="have been nominated for the Booker Prize , Britain 's most prestigious fiction award" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="nominated" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
            <token id="10" string="," />
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prestigious" />
            <token id="15" string="fiction" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Booker Prize" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="9" string="`` The Remains of the Day '' by Japanese author Kazuo Ishiguro" type="NP">
          <tokens>
            <token id="24" string="``" />
            <token id="25" string="The" />
            <token id="26" string="Remains" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Day" />
            <token id="30" string="''" />
            <token id="31" string="by" />
            <token id="32" string="Japanese" />
            <token id="33" string="author" />
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="10" string="`` The Remains of the Day ''" type="NP">
          <tokens>
            <token id="24" string="``" />
            <token id="25" string="The" />
            <token id="26" string="Remains" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Day" />
            <token id="30" string="''" />
          </tokens>
        </chunking>
        <chunking id="11" string="Britain 's most prestigious fiction award" type="NP">
          <tokens>
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prestigious" />
            <token id="15" string="fiction" />
            <token id="16" string="award" />
          </tokens>
        </chunking>
        <chunking id="12" string="say the favorite is `` The Remains of the Day '' by Japanese author Kazuo Ishiguro" type="VP">
          <tokens>
            <token id="20" string="say" />
            <token id="21" string="the" />
            <token id="22" string="favorite" />
            <token id="23" string="is" />
            <token id="24" string="``" />
            <token id="25" string="The" />
            <token id="26" string="Remains" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Day" />
            <token id="30" string="''" />
            <token id="31" string="by" />
            <token id="32" string="Japanese" />
            <token id="33" string="author" />
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="13" string="the favorite is `` The Remains of the Day '' by Japanese author Kazuo Ishiguro" type="SBAR">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="favorite" />
            <token id="23" string="is" />
            <token id="24" string="``" />
            <token id="25" string="The" />
            <token id="26" string="Remains" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Day" />
            <token id="30" string="''" />
            <token id="31" string="by" />
            <token id="32" string="Japanese" />
            <token id="33" string="author" />
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="14" string="is `` The Remains of the Day '' by Japanese author Kazuo Ishiguro" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="``" />
            <token id="25" string="The" />
            <token id="26" string="Remains" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="Day" />
            <token id="30" string="''" />
            <token id="31" string="by" />
            <token id="32" string="Japanese" />
            <token id="33" string="author" />
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="15" string="Britain 's" type="NP">
          <tokens>
            <token id="11" string="Britain" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="bookmakers" type="NP">
          <tokens>
            <token id="19" string="bookmakers" />
          </tokens>
        </chunking>
        <chunking id="17" string="the favorite" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="favorite" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">novels</governor>
          <dependent id="1">Six</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">nominated</governor>
          <dependent id="2">novels</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">nominated</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">nominated</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">nominated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Prize</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Prize</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Prize</governor>
          <dependent id="8">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">nominated</governor>
          <dependent id="9">Prize</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">award</governor>
          <dependent id="11">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Britain</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">award</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">award</governor>
          <dependent id="14">prestigious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">award</governor>
          <dependent id="15">fiction</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Prize</governor>
          <dependent id="16">award</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">nominated</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">say</governor>
          <dependent id="19">bookmakers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">nominated</governor>
          <dependent id="20">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">favorite</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">Remains</governor>
          <dependent id="22">favorite</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">Remains</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Remains</governor>
          <dependent id="25">The</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">say</governor>
          <dependent id="26">Remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Day</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Day</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Remains</governor>
          <dependent id="29">Day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Ishiguro</governor>
          <dependent id="31">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">Ishiguro</governor>
          <dependent id="32">Japanese</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Ishiguro</governor>
          <dependent id="33">author</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Ishiguro</governor>
          <dependent id="34">Kazuo</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Remains</governor>
          <dependent id="35">Ishiguro</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Six" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Six" />
          </tokens>
        </entity>
        <entity id="2" string="Kazuo Ishiguro" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Kazuo" />
            <token id="35" string="Ishiguro" />
          </tokens>
        </entity>
        <entity id="3" string="the Day" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Day" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Booker" />
            <token id="9" string="Prize" />
          </tokens>
        </entity>
        <entity id="5" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Britain" />
          </tokens>
        </entity>
        <entity id="6" string="Japanese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="32" string="Japanese" />
          </tokens>
        </entity>
        <entity id="7" string="Remains of" type="MISC" score="0.0">
          <tokens>
            <token id="26" string="Remains" />
            <token id="27" string="of" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The award, to be announced Oct. 26, carries a $31,600 prize funded by the Booker McConnell food company.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="carries" lemma="carry" stem="carri" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="31,600" lemma="31,600" stem="31,600" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="funded" lemma="fund" stem="fund" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="McConnell" lemma="McConnell" stem="mcconnel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN award)) (, ,) (S (VP (TO to) (VP (VB be) (VP (VBN announced) (NP-TMP (NNP Oct.) (CD 26)))))) (, ,) (VP (VBZ carries) (NP (NP (DT a) (ADJP (QP ($ $) (CD 31,600))) (NN prize)) (VP (VBN funded) (PP (IN by) (NP (DT the) (NNP Booker) (NNP McConnell) (NN food) (NN company)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The award" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="award" />
          </tokens>
        </chunking>
        <chunking id="2" string="a $ 31,600 prize funded by the Booker McConnell food company" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="$" />
            <token id="13" string="31,600" />
            <token id="14" string="prize" />
            <token id="15" string="funded" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Booker" />
            <token id="19" string="McConnell" />
            <token id="20" string="food" />
            <token id="21" string="company" />
          </tokens>
        </chunking>
        <chunking id="3" string="announced Oct. 26" type="VP">
          <tokens>
            <token id="6" string="announced" />
            <token id="7" string="Oct." />
            <token id="8" string="26" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 31,600" type="ADJP">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="31,600" />
          </tokens>
        </chunking>
        <chunking id="5" string="funded by the Booker McConnell food company" type="VP">
          <tokens>
            <token id="15" string="funded" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Booker" />
            <token id="19" string="McConnell" />
            <token id="20" string="food" />
            <token id="21" string="company" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be announced Oct. 26" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="announced" />
            <token id="7" string="Oct." />
            <token id="8" string="26" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Booker McConnell food company" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Booker" />
            <token id="19" string="McConnell" />
            <token id="20" string="food" />
            <token id="21" string="company" />
          </tokens>
        </chunking>
        <chunking id="8" string="carries a $ 31,600 prize funded by the Booker McConnell food company" type="VP">
          <tokens>
            <token id="10" string="carries" />
            <token id="11" string="a" />
            <token id="12" string="$" />
            <token id="13" string="31,600" />
            <token id="14" string="prize" />
            <token id="15" string="funded" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Booker" />
            <token id="19" string="McConnell" />
            <token id="20" string="food" />
            <token id="21" string="company" />
          </tokens>
        </chunking>
        <chunking id="9" string="a $ 31,600 prize" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="$" />
            <token id="13" string="31,600" />
            <token id="14" string="prize" />
          </tokens>
        </chunking>
        <chunking id="10" string="be announced Oct. 26" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="announced" />
            <token id="7" string="Oct." />
            <token id="8" string="26" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">award</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">carries</governor>
          <dependent id="2">award</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">announced</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">announced</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">carries</governor>
          <dependent id="6">announced</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">announced</governor>
          <dependent id="7">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">Oct.</governor>
          <dependent id="8">26</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">carries</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">prize</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">prize</governor>
          <dependent id="12">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">$</governor>
          <dependent id="13">31,600</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">carries</governor>
          <dependent id="14">prize</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">prize</governor>
          <dependent id="15">funded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">company</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">company</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">company</governor>
          <dependent id="18">Booker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">company</governor>
          <dependent id="19">McConnell</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">company</governor>
          <dependent id="20">food</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">funded</governor>
          <dependent id="21">company</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oct. 26" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Oct." />
            <token id="8" string="26" />
          </tokens>
        </entity>
        <entity id="2" string="$ 31,600" type="MONEY" score="0.0">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="31,600" />
          </tokens>
        </entity>
        <entity id="3" string="Booker McConnell" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Booker" />
            <token id="19" string="McConnell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Oddsmaker William Hill gave 7-to-4 odds on Ishiguro&amp;apost;s novel about a butler&amp;apost;s travels through Britain&amp;apost;s West Country and said it was ``a firm favorite&amp;apost;&amp;apost; to win.</content>
      <tokens>
        <token id="1" string="Oddsmaker" lemma="oddsmaker" stem="oddsmaker" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="7-to-4" lemma="7-to-4" stem="7-to-4" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ishiguro" lemma="Ishiguro" stem="ishiguro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="butler" lemma="butler" stem="butler" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="travels" lemma="travels" stem="travel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="20" string="Country" lemma="Country" stem="countri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="firm" lemma="firm" stem="firm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Oddsmaker) (NNP William) (NNP Hill)) (VP (VP (VBD gave) (NP (JJ 7-to-4) (NNS odds)) (PP (IN on) (NP (NP (NP (NNP Ishiguro) (POS 's)) (JJ novel)) (PP (IN about) (NP (NP (DT a) (NN butler) (POS 's)) (NNS travels))))) (PP (IN through) (NP (NP (NNP Britain) (POS 's)) (NNP West) (NNP Country)))) (CC and) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (`` ``) (ADJP (NP (DT a) (NN firm)) (JJ favorite)) ('' ''))))) (S (VP (TO to) (VP (VB win))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was `` a firm favorite ''" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="firm" />
            <token id="28" string="favorite" />
            <token id="29" string="''" />
          </tokens>
        </chunking>
        <chunking id="2" string="a firm favorite" type="ADJP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="firm" />
            <token id="28" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="3" string="a firm" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="firm" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain 's West Country" type="NP">
          <tokens>
            <token id="17" string="Britain" />
            <token id="18" string="'s" />
            <token id="19" string="West" />
            <token id="20" string="Country" />
          </tokens>
        </chunking>
        <chunking id="5" string="a butler 's" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="butler" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="to win" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="win" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ishiguro 's" type="NP">
          <tokens>
            <token id="8" string="Ishiguro" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="gave 7-to-4 odds on Ishiguro 's novel about a butler 's travels through Britain 's West Country and said it was `` a firm favorite '' to win" type="VP">
          <tokens>
            <token id="4" string="gave" />
            <token id="5" string="7-to-4" />
            <token id="6" string="odds" />
            <token id="7" string="on" />
            <token id="8" string="Ishiguro" />
            <token id="9" string="'s" />
            <token id="10" string="novel" />
            <token id="11" string="about" />
            <token id="12" string="a" />
            <token id="13" string="butler" />
            <token id="14" string="'s" />
            <token id="15" string="travels" />
            <token id="16" string="through" />
            <token id="17" string="Britain" />
            <token id="18" string="'s" />
            <token id="19" string="West" />
            <token id="20" string="Country" />
            <token id="21" string="and" />
            <token id="22" string="said" />
            <token id="23" string="it" />
            <token id="24" string="was" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="firm" />
            <token id="28" string="favorite" />
            <token id="29" string="''" />
            <token id="30" string="to" />
            <token id="31" string="win" />
          </tokens>
        </chunking>
        <chunking id="10" string="said it was `` a firm favorite ''" type="VP">
          <tokens>
            <token id="22" string="said" />
            <token id="23" string="it" />
            <token id="24" string="was" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="firm" />
            <token id="28" string="favorite" />
            <token id="29" string="''" />
          </tokens>
        </chunking>
        <chunking id="11" string="Oddsmaker William Hill" type="NP">
          <tokens>
            <token id="1" string="Oddsmaker" />
            <token id="2" string="William" />
            <token id="3" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="12" string="7-to-4 odds" type="NP">
          <tokens>
            <token id="5" string="7-to-4" />
            <token id="6" string="odds" />
          </tokens>
        </chunking>
        <chunking id="13" string="gave 7-to-4 odds on Ishiguro 's novel about a butler 's travels through Britain 's West Country" type="VP">
          <tokens>
            <token id="4" string="gave" />
            <token id="5" string="7-to-4" />
            <token id="6" string="odds" />
            <token id="7" string="on" />
            <token id="8" string="Ishiguro" />
            <token id="9" string="'s" />
            <token id="10" string="novel" />
            <token id="11" string="about" />
            <token id="12" string="a" />
            <token id="13" string="butler" />
            <token id="14" string="'s" />
            <token id="15" string="travels" />
            <token id="16" string="through" />
            <token id="17" string="Britain" />
            <token id="18" string="'s" />
            <token id="19" string="West" />
            <token id="20" string="Country" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ishiguro 's novel about a butler 's travels" type="NP">
          <tokens>
            <token id="8" string="Ishiguro" />
            <token id="9" string="'s" />
            <token id="10" string="novel" />
            <token id="11" string="about" />
            <token id="12" string="a" />
            <token id="13" string="butler" />
            <token id="14" string="'s" />
            <token id="15" string="travels" />
          </tokens>
        </chunking>
        <chunking id="15" string="a butler 's travels" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="butler" />
            <token id="14" string="'s" />
            <token id="15" string="travels" />
          </tokens>
        </chunking>
        <chunking id="16" string="Britain 's" type="NP">
          <tokens>
            <token id="17" string="Britain" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="win" type="VP">
          <tokens>
            <token id="31" string="win" />
          </tokens>
        </chunking>
        <chunking id="18" string="Ishiguro 's novel" type="NP">
          <tokens>
            <token id="8" string="Ishiguro" />
            <token id="9" string="'s" />
            <token id="10" string="novel" />
          </tokens>
        </chunking>
        <chunking id="19" string="it was `` a firm favorite ''" type="SBAR">
          <tokens>
            <token id="23" string="it" />
            <token id="24" string="was" />
            <token id="25" string="``" />
            <token id="26" string="a" />
            <token id="27" string="firm" />
            <token id="28" string="favorite" />
            <token id="29" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Hill</governor>
          <dependent id="1">Oddsmaker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Hill</governor>
          <dependent id="2">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">gave</governor>
          <dependent id="3">Hill</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gave</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">odds</governor>
          <dependent id="5">7-to-4</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">gave</governor>
          <dependent id="6">odds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Ishiguro</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gave</governor>
          <dependent id="8">Ishiguro</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Ishiguro</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Ishiguro</governor>
          <dependent id="10">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">travels</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">butler</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">travels</governor>
          <dependent id="13">butler</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">butler</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Ishiguro</governor>
          <dependent id="15">travels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Country</governor>
          <dependent id="16">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">Country</governor>
          <dependent id="17">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Britain</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Country</governor>
          <dependent id="19">West</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gave</governor>
          <dependent id="20">Country</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">gave</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">gave</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">favorite</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">favorite</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">firm</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="28">favorite</governor>
          <dependent id="27">firm</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="28">favorite</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">win</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">gave</governor>
          <dependent id="31">win</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ishiguro" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ishiguro" />
          </tokens>
        </entity>
        <entity id="2" string="William Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="William" />
            <token id="3" string="Hill" />
          </tokens>
        </entity>
        <entity id="3" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Britain" />
          </tokens>
        </entity>
        <entity id="4" string="West Country" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="West" />
            <token id="20" string="Country" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Ishiguro, previously nominated for the award, ``was beaten as the Booker favorite in 1986, which makes his chances that much stronger this time in our view,&amp;apost;&amp;apost; said William Hill spokesman Graham Sharpe.</content>
      <tokens>
        <token id="1" string="Ishiguro" lemma="Ishiguro" stem="ishiguro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="previously" lemma="previously" stem="previous" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="nominated" lemma="nominate" stem="nomin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="favorite" lemma="favorite" stem="favorit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="chances" lemma="chance" stem="chanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="stronger" lemma="stronger" stem="stronger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="35" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="36" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="Graham" lemma="Graham" stem="graham" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="Sharpe" lemma="Sharpe" stem="sharp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NNP Ishiguro)) (, ,) (VP (ADVP (RB previously)) (VBN nominated) (PP (IN for) (NP (DT the) (NN award)))) (, ,)) (`` ``) (VP (VBD was) (VP (VBN beaten) (PP (IN as) (NP (NP (DT the) (NNP Booker) (NN favorite)) (PP (IN in) (NP (CD 1986))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (NP (NP (PRP$ his) (NNS chances)) (SBAR (WHNP (WDT that)) (S (ADJP (RB much) (JJR stronger)))))))))) (NP-TMP (DT this) (NN time)) (PP (IN in) (NP (PRP$ our) (NN view)))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP William) (NNP Hill) (NN spokesman) (NNP Graham) (NNP Sharpe)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was beaten as the Booker favorite in 1986 , which makes his chances that much stronger this time in our view" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="beaten" />
            <token id="12" string="as" />
            <token id="13" string="the" />
            <token id="14" string="Booker" />
            <token id="15" string="favorite" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="makes" />
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
            <token id="26" string="this" />
            <token id="27" string="time" />
            <token id="28" string="in" />
            <token id="29" string="our" />
            <token id="30" string="view" />
          </tokens>
        </chunking>
        <chunking id="2" string="his chances" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="chances" />
          </tokens>
        </chunking>
        <chunking id="3" string="our view" type="NP">
          <tokens>
            <token id="29" string="our" />
            <token id="30" string="view" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ishiguro" type="NP">
          <tokens>
            <token id="1" string="Ishiguro" />
          </tokens>
        </chunking>
        <chunking id="5" string="which makes his chances that much stronger" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="makes" />
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="6" string="William Hill spokesman Graham Sharpe" type="NP">
          <tokens>
            <token id="34" string="William" />
            <token id="35" string="Hill" />
            <token id="36" string="spokesman" />
            <token id="37" string="Graham" />
            <token id="38" string="Sharpe" />
          </tokens>
        </chunking>
        <chunking id="7" string="his chances that much stronger" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Booker favorite in 1986 , which makes his chances that much stronger" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Booker" />
            <token id="15" string="favorite" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="makes" />
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="9" string="1986" type="NP">
          <tokens>
            <token id="17" string="1986" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Booker favorite" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Booker" />
            <token id="15" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="11" string="beaten as the Booker favorite in 1986 , which makes his chances that much stronger this time in our view" type="VP">
          <tokens>
            <token id="11" string="beaten" />
            <token id="12" string="as" />
            <token id="13" string="the" />
            <token id="14" string="Booker" />
            <token id="15" string="favorite" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="makes" />
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
            <token id="26" string="this" />
            <token id="27" string="time" />
            <token id="28" string="in" />
            <token id="29" string="our" />
            <token id="30" string="view" />
          </tokens>
        </chunking>
        <chunking id="12" string="that much stronger" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="13" string="the award" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="award" />
          </tokens>
        </chunking>
        <chunking id="14" string="makes his chances that much stronger" type="VP">
          <tokens>
            <token id="20" string="makes" />
            <token id="21" string="his" />
            <token id="22" string="chances" />
            <token id="23" string="that" />
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="15" string="much stronger" type="ADJP">
          <tokens>
            <token id="24" string="much" />
            <token id="25" string="stronger" />
          </tokens>
        </chunking>
        <chunking id="16" string="previously nominated for the award" type="VP">
          <tokens>
            <token id="3" string="previously" />
            <token id="4" string="nominated" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="award" />
          </tokens>
        </chunking>
        <chunking id="17" string="Ishiguro , previously nominated for the award ," type="NP">
          <tokens>
            <token id="1" string="Ishiguro" />
            <token id="2" string="," />
            <token id="3" string="previously" />
            <token id="4" string="nominated" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="award" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="33" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="11">beaten</governor>
          <dependent id="1">Ishiguro</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">nominated</governor>
          <dependent id="3">previously</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Ishiguro</governor>
          <dependent id="4">nominated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">award</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">award</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">nominated</governor>
          <dependent id="7">award</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">beaten</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="11">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">favorite</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">favorite</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">favorite</governor>
          <dependent id="14">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">beaten</governor>
          <dependent id="15">favorite</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1986</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">favorite</governor>
          <dependent id="17">1986</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">makes</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">favorite</governor>
          <dependent id="20">makes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">chances</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">makes</governor>
          <dependent id="22">chances</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">stronger</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">stronger</governor>
          <dependent id="24">much</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">chances</governor>
          <dependent id="25">stronger</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">time</governor>
          <dependent id="26">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="11">beaten</governor>
          <dependent id="27">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">view</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">view</governor>
          <dependent id="29">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">beaten</governor>
          <dependent id="30">view</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Sharpe</governor>
          <dependent id="34">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Sharpe</governor>
          <dependent id="35">Hill</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Sharpe</governor>
          <dependent id="36">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Sharpe</governor>
          <dependent id="37">Graham</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="38">Sharpe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="previously" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="previously" />
          </tokens>
        </entity>
        <entity id="3" string="Graham Sharpe" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Graham" />
            <token id="38" string="Sharpe" />
          </tokens>
        </entity>
        <entity id="4" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Booker" />
          </tokens>
        </entity>
        <entity id="5" string="Ishiguro" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ishiguro" />
          </tokens>
        </entity>
        <entity id="6" string="William Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="William" />
            <token id="35" string="Hill" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>The other books nominated are: _ ``Cat&amp;apost;s Eye,&amp;apost;&amp;apost; a story of painter Elaine Risley and her return to her childhood home in Toronto by Canadian author Margaret Atwood, also a previous nominee.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="nominated" lemma="nominate" stem="nomin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Eye" lemma="Eye" stem="eye" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="painter" lemma="painter" stem="painter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Elaine" lemma="Elaine" stem="elain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Risley" lemma="Risley" stem="rislei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="childhood" lemma="childhood" stem="childhood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Canadian" lemma="Canadian" stem="canadian" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="31" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="33" string="Atwood" lemma="Atwood" stem="atwood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="previous" lemma="previous" stem="previou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ other) (NNS books)) (VP (VBN nominated))) (VP (VBP are) (: :) (NP (NP (CD _)) (VP (NP (`` ``) (NP (NP (NN Cat) (POS 's)) (NNP Eye)) (, ,) ('' '') (NP (NP (NP (DT a) (NN story)) (PP (IN of) (NP (NN painter) (NNP Elaine) (NNP Risley)))) (CC and) (NP (NP (PRP$ her) (NN return)) (PP (TO to) (NP (NP (PRP$ her) (NN childhood) (NN home)) (PP (IN in) (NP (NNP Toronto)))))))) (PP (IN by) (NP (NP (NNP Canadian) (NN author) (NNP Margaret) (NNP Atwood)) (, ,) (ADVP (RB also)) (NP (DT a) (JJ previous) (NN nominee))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Cat 's Eye , '' a story of painter Elaine Risley and her return to her childhood home in Toronto by Canadian author Margaret Atwood , also a previous nominee" type="VP">
          <tokens>
            <token id="8" string="``" />
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
            <token id="11" string="Eye" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
            <token id="20" string="and" />
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
            <token id="29" string="by" />
            <token id="30" string="Canadian" />
            <token id="31" string="author" />
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
            <token id="34" string="," />
            <token id="35" string="also" />
            <token id="36" string="a" />
            <token id="37" string="previous" />
            <token id="38" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="2" string="Cat 's Eye" type="NP">
          <tokens>
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
            <token id="11" string="Eye" />
          </tokens>
        </chunking>
        <chunking id="3" string="The other books nominated" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="other" />
            <token id="3" string="books" />
            <token id="4" string="nominated" />
          </tokens>
        </chunking>
        <chunking id="4" string="The other books" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="other" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
        <chunking id="5" string="Canadian author Margaret Atwood , also a previous nominee" type="NP">
          <tokens>
            <token id="30" string="Canadian" />
            <token id="31" string="author" />
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
            <token id="34" string="," />
            <token id="35" string="also" />
            <token id="36" string="a" />
            <token id="37" string="previous" />
            <token id="38" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="6" string="_ `` Cat 's Eye , '' a story of painter Elaine Risley and her return to her childhood home in Toronto by Canadian author Margaret Atwood , also a previous nominee" type="NP">
          <tokens>
            <token id="7" string="_" />
            <token id="8" string="``" />
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
            <token id="11" string="Eye" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
            <token id="20" string="and" />
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
            <token id="29" string="by" />
            <token id="30" string="Canadian" />
            <token id="31" string="author" />
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
            <token id="34" string="," />
            <token id="35" string="also" />
            <token id="36" string="a" />
            <token id="37" string="previous" />
            <token id="38" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` Cat 's Eye , '' a story of painter Elaine Risley and her return to her childhood home in Toronto" type="NP">
          <tokens>
            <token id="8" string="``" />
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
            <token id="11" string="Eye" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
            <token id="20" string="and" />
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="8" string="her return to her childhood home in Toronto" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="9" string="her return" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="return" />
          </tokens>
        </chunking>
        <chunking id="10" string="a story of painter Elaine Risley" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
          </tokens>
        </chunking>
        <chunking id="11" string="a story of painter Elaine Risley and her return to her childhood home in Toronto" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
            <token id="20" string="and" />
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="12" string="painter Elaine Risley" type="NP">
          <tokens>
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
          </tokens>
        </chunking>
        <chunking id="13" string="Cat 's" type="NP">
          <tokens>
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="a story" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="story" />
          </tokens>
        </chunking>
        <chunking id="15" string="Canadian author Margaret Atwood" type="NP">
          <tokens>
            <token id="30" string="Canadian" />
            <token id="31" string="author" />
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
          </tokens>
        </chunking>
        <chunking id="16" string="a previous nominee" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="previous" />
            <token id="38" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="17" string="nominated" type="VP">
          <tokens>
            <token id="4" string="nominated" />
          </tokens>
        </chunking>
        <chunking id="18" string="her childhood home in Toronto" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="19" string="are : _ `` Cat 's Eye , '' a story of painter Elaine Risley and her return to her childhood home in Toronto by Canadian author Margaret Atwood , also a previous nominee" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string=":" />
            <token id="7" string="_" />
            <token id="8" string="``" />
            <token id="9" string="Cat" />
            <token id="10" string="'s" />
            <token id="11" string="Eye" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="a" />
            <token id="15" string="story" />
            <token id="16" string="of" />
            <token id="17" string="painter" />
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
            <token id="20" string="and" />
            <token id="21" string="her" />
            <token id="22" string="return" />
            <token id="23" string="to" />
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
            <token id="27" string="in" />
            <token id="28" string="Toronto" />
            <token id="29" string="by" />
            <token id="30" string="Canadian" />
            <token id="31" string="author" />
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
            <token id="34" string="," />
            <token id="35" string="also" />
            <token id="36" string="a" />
            <token id="37" string="previous" />
            <token id="38" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="20" string="_" type="NP">
          <tokens>
            <token id="7" string="_" />
          </tokens>
        </chunking>
        <chunking id="21" string="her childhood home" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="childhood" />
            <token id="26" string="home" />
          </tokens>
        </chunking>
        <chunking id="22" string="Toronto" type="NP">
          <tokens>
            <token id="28" string="Toronto" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">books</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">books</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">_</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">books</governor>
          <dependent id="4">nominated</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">_</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">_</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">Eye</governor>
          <dependent id="9">Cat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Cat</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">_</governor>
          <dependent id="11">Eye</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">story</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Eye</governor>
          <dependent id="15">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Risley</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Risley</governor>
          <dependent id="17">painter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Risley</governor>
          <dependent id="18">Elaine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">story</governor>
          <dependent id="19">Risley</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">story</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">return</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">story</governor>
          <dependent id="22">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">home</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">home</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">home</governor>
          <dependent id="25">childhood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">return</governor>
          <dependent id="26">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Toronto</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">home</governor>
          <dependent id="28">Toronto</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Atwood</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Atwood</governor>
          <dependent id="30">Canadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Atwood</governor>
          <dependent id="31">author</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Atwood</governor>
          <dependent id="32">Margaret</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Eye</governor>
          <dependent id="33">Atwood</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">nominee</governor>
          <dependent id="35">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">nominee</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">nominee</governor>
          <dependent id="37">previous</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="33">Atwood</governor>
          <dependent id="38">nominee</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="30" string="Canadian" />
          </tokens>
        </entity>
        <entity id="2" string="Elaine Risley" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Elaine" />
            <token id="19" string="Risley" />
          </tokens>
        </entity>
        <entity id="3" string="Margaret Atwood" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Margaret" />
            <token id="33" string="Atwood" />
          </tokens>
        </entity>
        <entity id="4" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="_" />
          </tokens>
        </entity>
        <entity id="5" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>_ ``The Book of Evidence,&amp;apost;&amp;apost; a prison story of kidnap and murder convict Freddie Montgomery by John Banville, literary editor of The Irish Times newspaper.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Evidence" lemma="evidence" stem="evidenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="prison" lemma="prison" stem="prison" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="kidnap" lemma="kidnap" stem="kidnap" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="murder" lemma="murder" stem="murder" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="16" string="convict" lemma="convict" stem="convict" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Freddie" lemma="Freddie" stem="freddi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Montgomery" lemma="Montgomery" stem="montgomeri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Banville" lemma="Banville" stem="banvil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="editor" lemma="editor" stem="editor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Irish" lemma="irish" stem="irish" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NN _)) (SBAR (S (NP (`` ``) (NP (NP (DT The) (NN Book)) (PP (IN of) (NP (NN Evidence)))) (, ,) ('' '') (NP (NP (DT a) (NN prison) (NN story)) (PP (IN of) (NP (S (VP (VB kidnap))) (CC and) (NP (NN murder)))))) (VP (VBP convict) (NP (NNP Freddie) (NNP Montgomery)) (PP (IN by) (NP (NP (NNP John) (NNP Banville)) (, ,) (NP (NP (JJ literary) (NN editor)) (PP (IN of) (NP (DT The) (JJ Irish) (NNP Times) (NN newspaper))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="murder" type="NP">
          <tokens>
            <token id="15" string="murder" />
          </tokens>
        </chunking>
        <chunking id="2" string="literary editor of The Irish Times newspaper" type="NP">
          <tokens>
            <token id="23" string="literary" />
            <token id="24" string="editor" />
            <token id="25" string="of" />
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` The Book of Evidence , '' a prison story of kidnap and murder convict Freddie Montgomery by John Banville , literary editor of The Irish Times newspaper" type="SBAR">
          <tokens>
            <token id="2" string="``" />
            <token id="3" string="The" />
            <token id="4" string="Book" />
            <token id="5" string="of" />
            <token id="6" string="Evidence" />
            <token id="7" string="," />
            <token id="8" string="''" />
            <token id="9" string="a" />
            <token id="10" string="prison" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="kidnap" />
            <token id="14" string="and" />
            <token id="15" string="murder" />
            <token id="16" string="convict" />
            <token id="17" string="Freddie" />
            <token id="18" string="Montgomery" />
            <token id="19" string="by" />
            <token id="20" string="John" />
            <token id="21" string="Banville" />
            <token id="22" string="," />
            <token id="23" string="literary" />
            <token id="24" string="editor" />
            <token id="25" string="of" />
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="4" string="literary editor" type="NP">
          <tokens>
            <token id="23" string="literary" />
            <token id="24" string="editor" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Banville" type="NP">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Banville" />
          </tokens>
        </chunking>
        <chunking id="6" string="convict Freddie Montgomery by John Banville , literary editor of The Irish Times newspaper" type="VP">
          <tokens>
            <token id="16" string="convict" />
            <token id="17" string="Freddie" />
            <token id="18" string="Montgomery" />
            <token id="19" string="by" />
            <token id="20" string="John" />
            <token id="21" string="Banville" />
            <token id="22" string="," />
            <token id="23" string="literary" />
            <token id="24" string="editor" />
            <token id="25" string="of" />
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="7" string="John Banville , literary editor of The Irish Times newspaper" type="NP">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Banville" />
            <token id="22" string="," />
            <token id="23" string="literary" />
            <token id="24" string="editor" />
            <token id="25" string="of" />
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="8" string="_ `` The Book of Evidence , '' a prison story of kidnap and murder convict Freddie Montgomery by John Banville , literary editor of The Irish Times newspaper ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="``" />
            <token id="3" string="The" />
            <token id="4" string="Book" />
            <token id="5" string="of" />
            <token id="6" string="Evidence" />
            <token id="7" string="," />
            <token id="8" string="''" />
            <token id="9" string="a" />
            <token id="10" string="prison" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="kidnap" />
            <token id="14" string="and" />
            <token id="15" string="murder" />
            <token id="16" string="convict" />
            <token id="17" string="Freddie" />
            <token id="18" string="Montgomery" />
            <token id="19" string="by" />
            <token id="20" string="John" />
            <token id="21" string="Banville" />
            <token id="22" string="," />
            <token id="23" string="literary" />
            <token id="24" string="editor" />
            <token id="25" string="of" />
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
            <token id="30" string="." />
          </tokens>
        </chunking>
        <chunking id="9" string="kidnap and murder" type="NP">
          <tokens>
            <token id="13" string="kidnap" />
            <token id="14" string="and" />
            <token id="15" string="murder" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Book" type="NP">
          <tokens>
            <token id="3" string="The" />
            <token id="4" string="Book" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Book of Evidence" type="NP">
          <tokens>
            <token id="3" string="The" />
            <token id="4" string="Book" />
            <token id="5" string="of" />
            <token id="6" string="Evidence" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Irish Times newspaper" type="NP">
          <tokens>
            <token id="26" string="The" />
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
            <token id="29" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="13" string="a prison story" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="prison" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="14" string="`` The Book of Evidence , '' a prison story of kidnap and murder" type="NP">
          <tokens>
            <token id="2" string="``" />
            <token id="3" string="The" />
            <token id="4" string="Book" />
            <token id="5" string="of" />
            <token id="6" string="Evidence" />
            <token id="7" string="," />
            <token id="8" string="''" />
            <token id="9" string="a" />
            <token id="10" string="prison" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="kidnap" />
            <token id="14" string="and" />
            <token id="15" string="murder" />
          </tokens>
        </chunking>
        <chunking id="15" string="Evidence" type="NP">
          <tokens>
            <token id="6" string="Evidence" />
          </tokens>
        </chunking>
        <chunking id="16" string="a prison story of kidnap and murder" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="prison" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="kidnap" />
            <token id="14" string="and" />
            <token id="15" string="murder" />
          </tokens>
        </chunking>
        <chunking id="17" string="Freddie Montgomery" type="NP">
          <tokens>
            <token id="17" string="Freddie" />
            <token id="18" string="Montgomery" />
          </tokens>
        </chunking>
        <chunking id="18" string="kidnap" type="VP">
          <tokens>
            <token id="13" string="kidnap" />
          </tokens>
        </chunking>
        <chunking id="19" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Book</governor>
          <dependent id="3">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">convict</governor>
          <dependent id="4">Book</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Evidence</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Book</governor>
          <dependent id="6">Evidence</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">story</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">story</governor>
          <dependent id="10">prison</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">Book</governor>
          <dependent id="11">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">kidnap</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">story</governor>
          <dependent id="13">kidnap</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">kidnap</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">kidnap</governor>
          <dependent id="15">murder</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">_</governor>
          <dependent id="16">convict</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Montgomery</governor>
          <dependent id="17">Freddie</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">convict</governor>
          <dependent id="18">Montgomery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Banville</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Banville</governor>
          <dependent id="20">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">convict</governor>
          <dependent id="21">Banville</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">editor</governor>
          <dependent id="23">literary</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">Banville</governor>
          <dependent id="24">editor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">newspaper</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">newspaper</governor>
          <dependent id="26">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">newspaper</governor>
          <dependent id="27">Irish</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">newspaper</governor>
          <dependent id="28">Times</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">editor</governor>
          <dependent id="29">newspaper</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="murder" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="15" string="murder" />
          </tokens>
        </entity>
        <entity id="2" string="Irish Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="Irish" />
            <token id="28" string="Times" />
          </tokens>
        </entity>
        <entity id="3" string="Freddie Montgomery" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Freddie" />
            <token id="18" string="Montgomery" />
          </tokens>
        </entity>
        <entity id="4" string="John Banville" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Banville" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>_ ``Jigsaw,&amp;apost;&amp;apost; by Sybille Bedford, an autobiographical novel about an adolescent&amp;apost;s travels through Germany, Italy and France.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Jigsaw" lemma="Jigsaw" stem="jigsaw" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sybille" lemma="Sybille" stem="sybil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Bedford" lemma="Bedford" stem="bedford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="autobiographical" lemma="autobiographical" stem="autobiograph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="adolescent" lemma="adolescent" stem="adolesc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="travels" lemma="travels" stem="travel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NN _)) (PP (PP (NP (`` ``) (NP (NNP Jigsaw)) (, ,) ('' '') (PP (IN by) (NP (NP (NNP Sybille) (NNP Bedford)) (, ,) (NP (DT an) (ADJP (JJ autobiographical) (JJ novel)))))) (IN about) (NP (NP (DT an) (JJ adolescent) (POS 's)) (NNS travels))) (PP (IN through) (NP (NNP Germany) (, ,) (NNP Italy) (CC and) (NNP France)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="autobiographical novel" type="ADJP">
          <tokens>
            <token id="11" string="autobiographical" />
            <token id="12" string="novel" />
          </tokens>
        </chunking>
        <chunking id="2" string="an adolescent 's travels" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="adolescent" />
            <token id="16" string="'s" />
            <token id="17" string="travels" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Jigsaw , '' by Sybille Bedford , an autobiographical novel" type="NP">
          <tokens>
            <token id="2" string="``" />
            <token id="3" string="Jigsaw" />
            <token id="4" string="," />
            <token id="5" string="''" />
            <token id="6" string="by" />
            <token id="7" string="Sybille" />
            <token id="8" string="Bedford" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="autobiographical" />
            <token id="12" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="an adolescent 's" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="adolescent" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Germany , Italy and France" type="NP">
          <tokens>
            <token id="19" string="Germany" />
            <token id="20" string="," />
            <token id="21" string="Italy" />
            <token id="22" string="and" />
            <token id="23" string="France" />
          </tokens>
        </chunking>
        <chunking id="6" string="an autobiographical novel" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="autobiographical" />
            <token id="12" string="novel" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sybille Bedford , an autobiographical novel" type="NP">
          <tokens>
            <token id="7" string="Sybille" />
            <token id="8" string="Bedford" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="autobiographical" />
            <token id="12" string="novel" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sybille Bedford" type="NP">
          <tokens>
            <token id="7" string="Sybille" />
            <token id="8" string="Bedford" />
          </tokens>
        </chunking>
        <chunking id="9" string="_ `` Jigsaw , '' by Sybille Bedford , an autobiographical novel about an adolescent 's travels through Germany , Italy and France ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="``" />
            <token id="3" string="Jigsaw" />
            <token id="4" string="," />
            <token id="5" string="''" />
            <token id="6" string="by" />
            <token id="7" string="Sybille" />
            <token id="8" string="Bedford" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="autobiographical" />
            <token id="12" string="novel" />
            <token id="13" string="about" />
            <token id="14" string="an" />
            <token id="15" string="adolescent" />
            <token id="16" string="'s" />
            <token id="17" string="travels" />
            <token id="18" string="through" />
            <token id="19" string="Germany" />
            <token id="20" string="," />
            <token id="21" string="Italy" />
            <token id="22" string="and" />
            <token id="23" string="France" />
            <token id="24" string="." />
          </tokens>
        </chunking>
        <chunking id="10" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jigsaw" type="NP">
          <tokens>
            <token id="3" string="Jigsaw" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="3">Jigsaw</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Bedford</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bedford</governor>
          <dependent id="7">Sybille</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Jigsaw</governor>
          <dependent id="8">Bedford</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">novel</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">novel</governor>
          <dependent id="11">autobiographical</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Bedford</governor>
          <dependent id="12">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Jigsaw</governor>
          <dependent id="13">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">adolescent</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">travels</governor>
          <dependent id="15">adolescent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">adolescent</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Jigsaw</governor>
          <dependent id="17">travels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Germany</governor>
          <dependent id="18">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Jigsaw</governor>
          <dependent id="19">Germany</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Germany</governor>
          <dependent id="21">Italy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Germany</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Germany</governor>
          <dependent id="23">France</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Italy" />
          </tokens>
        </entity>
        <entity id="2" string="Sybille Bedford" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Sybille" />
            <token id="8" string="Bedford" />
          </tokens>
        </entity>
        <entity id="3" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="France" />
          </tokens>
        </entity>
        <entity id="4" string="Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>_ ``A Disaffection,&amp;apost;&amp;apost; Scottish novelist James Kelman&amp;apost;s story about a school teacher, Patrick Doyle, whose professional frustrations are fueled by a drinking problem and unrequited love for a colleague.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Disaffection" lemma="disaffection" stem="disaffect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Scottish" lemma="scottish" stem="scottish" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Kelman" lemma="Kelman" stem="kelman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Doyle" lemma="Doyle" stem="doyl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="frustrations" lemma="frustration" stem="frustrat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="fueled" lemma="fuel" stem="fuel" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="drinking" lemma="drinking" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="unrequited" lemma="unrequited" stem="unrequit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="colleague" lemma="colleague" stem="colleagu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NP (NN _)) (`` ``) (NP (DT A) (NN Disaffection))) (, ,) ('' '') (NP (NP (NP (JJ Scottish) (NN novelist) (NNP James) (NNP Kelman) (POS 's)) (NN story)) (PP (IN about) (NP (NP (DT a) (NN school) (NN teacher)) (, ,) (NP (NNP Patrick) (NNP Doyle)) (, ,) (SBAR (WP$ whose) (S (NP (JJ professional) (NNS frustrations)) (VP (VBP are) (VP (VBN fueled) (PP (IN by) (NP (DT a) (NN drinking) (NN problem)))))))))) (CC and) (NP (NP (JJ unrequited) (NN love)) (PP (IN for) (NP (DT a) (NN colleague))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Scottish novelist James Kelman 's" type="NP">
          <tokens>
            <token id="7" string="Scottish" />
            <token id="8" string="novelist" />
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="a school teacher , Patrick Doyle , whose professional frustrations are fueled by a drinking problem" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="school" />
            <token id="16" string="teacher" />
            <token id="17" string="," />
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
            <token id="20" string="," />
            <token id="21" string="whose" />
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="unrequited love" type="NP">
          <tokens>
            <token id="31" string="unrequited" />
            <token id="32" string="love" />
          </tokens>
        </chunking>
        <chunking id="4" string="_ `` A Disaffection , '' Scottish novelist James Kelman 's story about a school teacher , Patrick Doyle , whose professional frustrations are fueled by a drinking problem and unrequited love for a colleague ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="``" />
            <token id="3" string="A" />
            <token id="4" string="Disaffection" />
            <token id="5" string="," />
            <token id="6" string="''" />
            <token id="7" string="Scottish" />
            <token id="8" string="novelist" />
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
            <token id="13" string="about" />
            <token id="14" string="a" />
            <token id="15" string="school" />
            <token id="16" string="teacher" />
            <token id="17" string="," />
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
            <token id="20" string="," />
            <token id="21" string="whose" />
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
            <token id="30" string="and" />
            <token id="31" string="unrequited" />
            <token id="32" string="love" />
            <token id="33" string="for" />
            <token id="34" string="a" />
            <token id="35" string="colleague" />
            <token id="36" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="a drinking problem" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="6" string="Scottish novelist James Kelman 's story about a school teacher , Patrick Doyle , whose professional frustrations are fueled by a drinking problem" type="NP">
          <tokens>
            <token id="7" string="Scottish" />
            <token id="8" string="novelist" />
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
            <token id="13" string="about" />
            <token id="14" string="a" />
            <token id="15" string="school" />
            <token id="16" string="teacher" />
            <token id="17" string="," />
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
            <token id="20" string="," />
            <token id="21" string="whose" />
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="7" string="fueled by a drinking problem" type="VP">
          <tokens>
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="8" string="Patrick Doyle" type="NP">
          <tokens>
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
          </tokens>
        </chunking>
        <chunking id="9" string="are fueled by a drinking problem" type="VP">
          <tokens>
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="10" string="_ `` A Disaffection , '' Scottish novelist James Kelman 's story about a school teacher , Patrick Doyle , whose professional frustrations are fueled by a drinking problem and unrequited love for a colleague" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="``" />
            <token id="3" string="A" />
            <token id="4" string="Disaffection" />
            <token id="5" string="," />
            <token id="6" string="''" />
            <token id="7" string="Scottish" />
            <token id="8" string="novelist" />
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
            <token id="13" string="about" />
            <token id="14" string="a" />
            <token id="15" string="school" />
            <token id="16" string="teacher" />
            <token id="17" string="," />
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
            <token id="20" string="," />
            <token id="21" string="whose" />
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
            <token id="30" string="and" />
            <token id="31" string="unrequited" />
            <token id="32" string="love" />
            <token id="33" string="for" />
            <token id="34" string="a" />
            <token id="35" string="colleague" />
          </tokens>
        </chunking>
        <chunking id="11" string="Scottish novelist James Kelman 's story" type="NP">
          <tokens>
            <token id="7" string="Scottish" />
            <token id="8" string="novelist" />
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
            <token id="11" string="'s" />
            <token id="12" string="story" />
          </tokens>
        </chunking>
        <chunking id="12" string="A Disaffection" type="NP">
          <tokens>
            <token id="3" string="A" />
            <token id="4" string="Disaffection" />
          </tokens>
        </chunking>
        <chunking id="13" string="a school teacher" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="school" />
            <token id="16" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="14" string="professional frustrations" type="NP">
          <tokens>
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
          </tokens>
        </chunking>
        <chunking id="15" string="a colleague" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="colleague" />
          </tokens>
        </chunking>
        <chunking id="16" string="_ `` A Disaffection" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="``" />
            <token id="3" string="A" />
            <token id="4" string="Disaffection" />
          </tokens>
        </chunking>
        <chunking id="17" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="18" string="whose professional frustrations are fueled by a drinking problem" type="SBAR">
          <tokens>
            <token id="21" string="whose" />
            <token id="22" string="professional" />
            <token id="23" string="frustrations" />
            <token id="24" string="are" />
            <token id="25" string="fueled" />
            <token id="26" string="by" />
            <token id="27" string="a" />
            <token id="28" string="drinking" />
            <token id="29" string="problem" />
          </tokens>
        </chunking>
        <chunking id="19" string="unrequited love for a colleague" type="NP">
          <tokens>
            <token id="31" string="unrequited" />
            <token id="32" string="love" />
            <token id="33" string="for" />
            <token id="34" string="a" />
            <token id="35" string="colleague" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Disaffection</governor>
          <dependent id="3">A</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="4">Disaffection</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Kelman</governor>
          <dependent id="7">Scottish</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Kelman</governor>
          <dependent id="8">novelist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Kelman</governor>
          <dependent id="9">James</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">story</governor>
          <dependent id="10">Kelman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Kelman</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">_</governor>
          <dependent id="12">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">teacher</governor>
          <dependent id="13">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">teacher</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">teacher</governor>
          <dependent id="15">school</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">story</governor>
          <dependent id="16">teacher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Doyle</governor>
          <dependent id="18">Patrick</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">teacher</governor>
          <dependent id="19">Doyle</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">fueled</governor>
          <dependent id="21">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">frustrations</governor>
          <dependent id="22">professional</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">fueled</governor>
          <dependent id="23">frustrations</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">fueled</governor>
          <dependent id="24">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">teacher</governor>
          <dependent id="25">fueled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">problem</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">problem</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">problem</governor>
          <dependent id="28">drinking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">fueled</governor>
          <dependent id="29">problem</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">_</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">love</governor>
          <dependent id="31">unrequited</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">_</governor>
          <dependent id="32">love</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">colleague</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">colleague</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">love</governor>
          <dependent id="35">colleague</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="James Kelman" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="James" />
            <token id="10" string="Kelman" />
          </tokens>
        </entity>
        <entity id="2" string="Scottish" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Scottish" />
          </tokens>
        </entity>
        <entity id="3" string="Patrick Doyle" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Patrick" />
            <token id="19" string="Doyle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>_ ``Restoration,&amp;apost;&amp;apost; British author Rose Tremain&amp;apost;s story of Robert Merivel, a favorite of King Charles II who married the monarch&amp;apost;s youngest mistress.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Restoration" lemma="Restoration" stem="restor" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Rose" lemma="Rose" stem="rose" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Tremain" lemma="Tremain" stem="tremain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Merivel" lemma="Merivel" stem="merivel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="favorite" lemma="favorite" stem="favorit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="20" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="II" lemma="II" stem="ii" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="married" lemma="marry" stem="marri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="monarch" lemma="monarch" stem="monarch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="youngest" lemma="youngest" stem="youngest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="mistress" lemma="mistress" stem="mistress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN _)) (VP (S (NP (`` ``) (NP (NNP Restoration)) (, ,) ('' '') (NP (NP (NP (JJ British) (NN author) (NNP Rose) (NNP Tremain) (POS 's)) (NN story)) (PP (IN of) (NP (NP (NNP Robert) (NNP Merivel)) (, ,) (NP (NP (DT a) (NN favorite)) (PP (IN of) (NP (NP (NNP King) (NNP Charles) (NNP II)) (SBAR (WHNP (WP who)) (S (VP (VBD married) (NP (NP (DT the) (NN monarch) (POS 's)) (JJS youngest) (NN mistress)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="British author Rose Tremain 's story of Robert Merivel , a favorite of King Charles II who married the monarch 's youngest mistress" type="NP">
          <tokens>
            <token id="6" string="British" />
            <token id="7" string="author" />
            <token id="8" string="Rose" />
            <token id="9" string="Tremain" />
            <token id="10" string="'s" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="Robert" />
            <token id="14" string="Merivel" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="favorite" />
            <token id="18" string="of" />
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` Restoration , '' British author Rose Tremain 's story of Robert Merivel , a favorite of King Charles II who married the monarch 's youngest mistress" type="VP">
          <tokens>
            <token id="2" string="``" />
            <token id="3" string="Restoration" />
            <token id="4" string="," />
            <token id="5" string="''" />
            <token id="6" string="British" />
            <token id="7" string="author" />
            <token id="8" string="Rose" />
            <token id="9" string="Tremain" />
            <token id="10" string="'s" />
            <token id="11" string="story" />
            <token id="12" string="of" />
            <token id="13" string="Robert" />
            <token id="14" string="Merivel" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="favorite" />
            <token id="18" string="of" />
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="3" string="British author Rose Tremain 's" type="NP">
          <tokens>
            <token id="6" string="British" />
            <token id="7" string="author" />
            <token id="8" string="Rose" />
            <token id="9" string="Tremain" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Robert Merivel" type="NP">
          <tokens>
            <token id="13" string="Robert" />
            <token id="14" string="Merivel" />
          </tokens>
        </chunking>
        <chunking id="5" string="King Charles II" type="NP">
          <tokens>
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
          </tokens>
        </chunking>
        <chunking id="6" string="a favorite of King Charles II who married the monarch 's youngest mistress" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="favorite" />
            <token id="18" string="of" />
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="7" string="Robert Merivel , a favorite of King Charles II who married the monarch 's youngest mistress" type="NP">
          <tokens>
            <token id="13" string="Robert" />
            <token id="14" string="Merivel" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="favorite" />
            <token id="18" string="of" />
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="8" string="married the monarch 's youngest mistress" type="VP">
          <tokens>
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="9" string="King Charles II who married the monarch 's youngest mistress" type="NP">
          <tokens>
            <token id="19" string="King" />
            <token id="20" string="Charles" />
            <token id="21" string="II" />
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="10" string="Restoration" type="NP">
          <tokens>
            <token id="3" string="Restoration" />
          </tokens>
        </chunking>
        <chunking id="11" string="British author Rose Tremain 's story" type="NP">
          <tokens>
            <token id="6" string="British" />
            <token id="7" string="author" />
            <token id="8" string="Rose" />
            <token id="9" string="Tremain" />
            <token id="10" string="'s" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="12" string="the monarch 's" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="a favorite" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="14" string="the monarch 's youngest mistress" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
        <chunking id="15" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="16" string="who married the monarch 's youngest mistress" type="SBAR">
          <tokens>
            <token id="22" string="who" />
            <token id="23" string="married" />
            <token id="24" string="the" />
            <token id="25" string="monarch" />
            <token id="26" string="'s" />
            <token id="27" string="youngest" />
            <token id="28" string="mistress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">Restoration</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Restoration</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Tremain</governor>
          <dependent id="6">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Tremain</governor>
          <dependent id="7">author</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Tremain</governor>
          <dependent id="8">Rose</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">story</governor>
          <dependent id="9">Tremain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Tremain</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Restoration</governor>
          <dependent id="11">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Merivel</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Merivel</governor>
          <dependent id="13">Robert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">story</governor>
          <dependent id="14">Merivel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">favorite</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">Merivel</governor>
          <dependent id="17">favorite</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">II</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">II</governor>
          <dependent id="19">King</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">II</governor>
          <dependent id="20">Charles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">favorite</governor>
          <dependent id="21">II</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">married</governor>
          <dependent id="22">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">II</governor>
          <dependent id="23">married</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">monarch</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">mistress</governor>
          <dependent id="25">monarch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">monarch</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">mistress</governor>
          <dependent id="27">youngest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">married</governor>
          <dependent id="28">mistress</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="19" string="King" />
          </tokens>
        </entity>
        <entity id="3" string="Charles II" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Charles" />
            <token id="21" string="II" />
          </tokens>
        </entity>
        <entity id="4" string="Rose Tremain" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Rose" />
            <token id="9" string="Tremain" />
          </tokens>
        </entity>
        <entity id="5" string="Robert Merivel" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Robert" />
            <token id="14" string="Merivel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``We expect more interest in this year&amp;apost;s Booker Prize than ever before, partly thanks to last year&amp;apost;s controversy over Salman Rushdie&amp;apost;s `Satanic Verses,&amp;apost;&amp;apost;&amp;apost; Sharpe said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="expect" lemma="expect" stem="expect" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="12" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="partly" lemma="partly" stem="partli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="thanks" lemma="thanks" stem="thank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Salman" lemma="Salman" stem="salman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Rushdie" lemma="Rushdie" stem="rushdi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Satanic" lemma="satanic" stem="satan" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="Verses" lemma="verse" stem="vers" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Sharpe" lemma="Sharpe" stem="sharp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBP expect) (NP (NP (JJR more) (NN interest)) (PP (IN in) (NP (NP (DT this) (NN year) (POS 's)) (NNP Booker) (NNP Prize)))) (PP (IN than) (ADVP (RB ever) (RB before))) (, ,) (ADVP (ADVP (RB partly) (NP (NNS thanks)) (PP (TO to) (NP (NP-TMP (JJ last) (NN year) (POS 's)) (NN controversy)))) (PP (IN over) (NP (NP (NNP Salman) (NNP Rushdie) (POS 's)) (`` `) (NP (JJ Satanic) (NNS Verses))))))) (, ,) ('' '') ('' ') (NP (NNP Sharpe)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this year 's Booker Prize" type="NP">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="2" string="Satanic Verses" type="NP">
          <tokens>
            <token id="28" string="Satanic" />
            <token id="29" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="3" string="last year 's controversy" type="NP">
          <tokens>
            <token id="19" string="last" />
            <token id="20" string="year" />
            <token id="21" string="'s" />
            <token id="22" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="4" string="Salman Rushdie 's ` Satanic Verses" type="NP">
          <tokens>
            <token id="24" string="Salman" />
            <token id="25" string="Rushdie" />
            <token id="26" string="'s" />
            <token id="27" string="`" />
            <token id="28" string="Satanic" />
            <token id="29" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="this year 's" type="NP">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="thanks" type="NP">
          <tokens>
            <token id="17" string="thanks" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sharpe" type="NP">
          <tokens>
            <token id="33" string="Sharpe" />
          </tokens>
        </chunking>
        <chunking id="9" string="Salman Rushdie 's" type="NP">
          <tokens>
            <token id="24" string="Salman" />
            <token id="25" string="Rushdie" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="more interest in this year 's Booker Prize" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="interest" />
            <token id="6" string="in" />
            <token id="7" string="this" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="11" string="more interest" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="interest" />
          </tokens>
        </chunking>
        <chunking id="12" string="expect more interest in this year 's Booker Prize than ever before , partly thanks to last year 's controversy over Salman Rushdie 's ` Satanic Verses" type="VP">
          <tokens>
            <token id="3" string="expect" />
            <token id="4" string="more" />
            <token id="5" string="interest" />
            <token id="6" string="in" />
            <token id="7" string="this" />
            <token id="8" string="year" />
            <token id="9" string="'s" />
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
            <token id="12" string="than" />
            <token id="13" string="ever" />
            <token id="14" string="before" />
            <token id="15" string="," />
            <token id="16" string="partly" />
            <token id="17" string="thanks" />
            <token id="18" string="to" />
            <token id="19" string="last" />
            <token id="20" string="year" />
            <token id="21" string="'s" />
            <token id="22" string="controversy" />
            <token id="23" string="over" />
            <token id="24" string="Salman" />
            <token id="25" string="Rushdie" />
            <token id="26" string="'s" />
            <token id="27" string="`" />
            <token id="28" string="Satanic" />
            <token id="29" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="34" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">expect</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="34">said</governor>
          <dependent id="3">expect</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">interest</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">expect</governor>
          <dependent id="5">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Prize</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">year</governor>
          <dependent id="7">this</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">Prize</governor>
          <dependent id="8">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">year</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Prize</governor>
          <dependent id="10">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">interest</governor>
          <dependent id="11">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">before</governor>
          <dependent id="12">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">before</governor>
          <dependent id="13">ever</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">expect</governor>
          <dependent id="14">before</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">expect</governor>
          <dependent id="16">partly</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="16">partly</governor>
          <dependent id="17">thanks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">controversy</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">year</governor>
          <dependent id="19">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="22">controversy</governor>
          <dependent id="20">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">year</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">partly</governor>
          <dependent id="22">controversy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Rushdie</governor>
          <dependent id="23">over</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Rushdie</governor>
          <dependent id="24">Salman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">partly</governor>
          <dependent id="25">Rushdie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Rushdie</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">Verses</governor>
          <dependent id="28">Satanic</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">Rushdie</governor>
          <dependent id="29">Verses</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">said</governor>
          <dependent id="33">Sharpe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="34">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sharpe" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Sharpe" />
          </tokens>
        </entity>
        <entity id="2" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Booker" />
            <token id="11" string="Prize" />
          </tokens>
        </entity>
        <entity id="3" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Salman Rushdie" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Salman" />
            <token id="25" string="Rushdie" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Rushdie was nominated for the prize last year but it was won by Australian author Peter Carey for his love story ``Oscar and Lucinda.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Rushdie" lemma="Rushdie" stem="rushdi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="nominated" lemma="nominate" stem="nomin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="8" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Australian" lemma="australian" stem="australian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="15" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Oscar" lemma="Oscar" stem="oscar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Lucinda" lemma="Lucinda" stem="lucinda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Rushdie)) (VP (VBD was) (VP (VBN nominated) (PP (IN for) (NP (DT the) (NN prize))) (NP-TMP (JJ last) (NN year))))) (CC but) (S (NP (PRP it)) (VP (VBD was) (VP (VBN won) (PP (IN by) (NP (NP (JJ Australian) (NN author) (NNP Peter) (NNP Carey)) (PP (IN for) (NP (PRP$ his) (NN love) (NN story))))) (`` ``) (NP (NNP Oscar) (CC and) (NNP Lucinda))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Australian author Peter Carey for his love story" type="NP">
          <tokens>
            <token id="14" string="Australian" />
            <token id="15" string="author" />
            <token id="16" string="Peter" />
            <token id="17" string="Carey" />
            <token id="18" string="for" />
            <token id="19" string="his" />
            <token id="20" string="love" />
            <token id="21" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="was nominated for the prize last year" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="nominated" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="last" />
            <token id="8" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="Australian author Peter Carey" type="NP">
          <tokens>
            <token id="14" string="Australian" />
            <token id="15" string="author" />
            <token id="16" string="Peter" />
            <token id="17" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="Rushdie" type="NP">
          <tokens>
            <token id="1" string="Rushdie" />
          </tokens>
        </chunking>
        <chunking id="6" string="his love story" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="love" />
            <token id="21" string="story" />
          </tokens>
        </chunking>
        <chunking id="7" string="Oscar and Lucinda" type="NP">
          <tokens>
            <token id="23" string="Oscar" />
            <token id="24" string="and" />
            <token id="25" string="Lucinda" />
          </tokens>
        </chunking>
        <chunking id="8" string="nominated for the prize last year" type="VP">
          <tokens>
            <token id="3" string="nominated" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="last" />
            <token id="8" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="the prize" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="prize" />
          </tokens>
        </chunking>
        <chunking id="10" string="won by Australian author Peter Carey for his love story `` Oscar and Lucinda" type="VP">
          <tokens>
            <token id="12" string="won" />
            <token id="13" string="by" />
            <token id="14" string="Australian" />
            <token id="15" string="author" />
            <token id="16" string="Peter" />
            <token id="17" string="Carey" />
            <token id="18" string="for" />
            <token id="19" string="his" />
            <token id="20" string="love" />
            <token id="21" string="story" />
            <token id="22" string="``" />
            <token id="23" string="Oscar" />
            <token id="24" string="and" />
            <token id="25" string="Lucinda" />
          </tokens>
        </chunking>
        <chunking id="11" string="was won by Australian author Peter Carey for his love story `` Oscar and Lucinda" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="won" />
            <token id="13" string="by" />
            <token id="14" string="Australian" />
            <token id="15" string="author" />
            <token id="16" string="Peter" />
            <token id="17" string="Carey" />
            <token id="18" string="for" />
            <token id="19" string="his" />
            <token id="20" string="love" />
            <token id="21" string="story" />
            <token id="22" string="``" />
            <token id="23" string="Oscar" />
            <token id="24" string="and" />
            <token id="25" string="Lucinda" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">nominated</governor>
          <dependent id="1">Rushdie</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">nominated</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">nominated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">prize</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">prize</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">nominated</governor>
          <dependent id="6">prize</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">year</governor>
          <dependent id="7">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">nominated</governor>
          <dependent id="8">year</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">nominated</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">won</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">won</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">nominated</governor>
          <dependent id="12">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Carey</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Carey</governor>
          <dependent id="14">Australian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Carey</governor>
          <dependent id="15">author</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Carey</governor>
          <dependent id="16">Peter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">won</governor>
          <dependent id="17">Carey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">story</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">story</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">story</governor>
          <dependent id="20">love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">Carey</governor>
          <dependent id="21">story</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">won</governor>
          <dependent id="23">Oscar</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Oscar</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Oscar</governor>
          <dependent id="25">Lucinda</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="Australian" />
          </tokens>
        </entity>
        <entity id="2" string="Peter Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Peter" />
            <token id="17" string="Carey" />
          </tokens>
        </entity>
        <entity id="3" string="Rushdie" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Rushdie" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="last" />
            <token id="8" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Lucinda" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Lucinda" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Rushdie, a British citizen, has been in hiding since Feb. 14 when the late Iranian leader Ayatollah Ruhollah Khomeini ordered he be killed for allegedly blaspheming Islam in ``Satanic Verses.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Rushdie" lemma="Rushdie" stem="rushdi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="5" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hiding" lemma="hide" stem="hide" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Feb." lemma="Feb." stem="feb." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Iranian" lemma="iranian" stem="iranian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="18" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="Ayatollah" lemma="Ayatollah" stem="ayatollah" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="Ruhollah" lemma="Ruhollah" stem="ruhollah" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Khomeini" lemma="Khomeini" stem="khomeini" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="ordered" lemma="order" stem="order" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="allegedly" lemma="allegedly" stem="allegedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="blaspheming" lemma="blaspheme" stem="blasphem" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Islam" lemma="Islam" stem="islam" pos="NNP" type="Word" isStopWord="false" ner="RELIGION" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Satanic" lemma="satanic" stem="satan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Verses" lemma="verse" stem="vers" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Rushdie)) (, ,) (NP (DT a) (JJ British) (NN citizen)) (, ,)) (VP (VBZ has) (VP (VBN been) (PP (IN in) (S (VP (VBG hiding) (ADVP (IN since)) (NP-TMP (NNP Feb.) (CD 14))))) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (JJ late) (JJ Iranian) (NN leader) (NNP Ayatollah) (NNP Ruhollah) (NNP Khomeini)) (VP (VBD ordered) (S (NP (PRP he)) (VP (VB be) (VP (VBN killed) (PP (IN for) (S (ADVP (RB allegedly)) (VP (VBG blaspheming) (NP (NNP Islam)) (PP (IN in) (`` ``) (NP (JJ Satanic) (NNS Verses)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been in hiding since Feb. 14 when the late Iranian leader Ayatollah Ruhollah Khomeini ordered he be killed for allegedly blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="been" />
            <token id="9" string="in" />
            <token id="10" string="hiding" />
            <token id="11" string="since" />
            <token id="12" string="Feb." />
            <token id="13" string="14" />
            <token id="14" string="when" />
            <token id="15" string="the" />
            <token id="16" string="late" />
            <token id="17" string="Iranian" />
            <token id="18" string="leader" />
            <token id="19" string="Ayatollah" />
            <token id="20" string="Ruhollah" />
            <token id="21" string="Khomeini" />
            <token id="22" string="ordered" />
            <token id="23" string="he" />
            <token id="24" string="be" />
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="2" string="Satanic Verses" type="NP">
          <tokens>
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="3" string="killed for allegedly blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="4" string="ordered he be killed for allegedly blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="22" string="ordered" />
            <token id="23" string="he" />
            <token id="24" string="be" />
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="5" string="Rushdie , a British citizen ," type="NP">
          <tokens>
            <token id="1" string="Rushdie" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="British" />
            <token id="5" string="citizen" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="Rushdie" type="NP">
          <tokens>
            <token id="1" string="Rushdie" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="the late Iranian leader Ayatollah Ruhollah Khomeini" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="late" />
            <token id="17" string="Iranian" />
            <token id="18" string="leader" />
            <token id="19" string="Ayatollah" />
            <token id="20" string="Ruhollah" />
            <token id="21" string="Khomeini" />
          </tokens>
        </chunking>
        <chunking id="9" string="been in hiding since Feb. 14 when the late Iranian leader Ayatollah Ruhollah Khomeini ordered he be killed for allegedly blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="in" />
            <token id="10" string="hiding" />
            <token id="11" string="since" />
            <token id="12" string="Feb." />
            <token id="13" string="14" />
            <token id="14" string="when" />
            <token id="15" string="the" />
            <token id="16" string="late" />
            <token id="17" string="Iranian" />
            <token id="18" string="leader" />
            <token id="19" string="Ayatollah" />
            <token id="20" string="Ruhollah" />
            <token id="21" string="Khomeini" />
            <token id="22" string="ordered" />
            <token id="23" string="he" />
            <token id="24" string="be" />
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="10" string="when the late Iranian leader Ayatollah Ruhollah Khomeini ordered he be killed for allegedly blaspheming Islam in `` Satanic Verses" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="the" />
            <token id="16" string="late" />
            <token id="17" string="Iranian" />
            <token id="18" string="leader" />
            <token id="19" string="Ayatollah" />
            <token id="20" string="Ruhollah" />
            <token id="21" string="Khomeini" />
            <token id="22" string="ordered" />
            <token id="23" string="he" />
            <token id="24" string="be" />
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="11" string="Islam" type="NP">
          <tokens>
            <token id="29" string="Islam" />
          </tokens>
        </chunking>
        <chunking id="12" string="a British citizen" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="British" />
            <token id="5" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="13" string="hiding since Feb. 14" type="VP">
          <tokens>
            <token id="10" string="hiding" />
            <token id="11" string="since" />
            <token id="12" string="Feb." />
            <token id="13" string="14" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="be killed for allegedly blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="killed" />
            <token id="26" string="for" />
            <token id="27" string="allegedly" />
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
        <chunking id="16" string="blaspheming Islam in `` Satanic Verses" type="VP">
          <tokens>
            <token id="28" string="blaspheming" />
            <token id="29" string="Islam" />
            <token id="30" string="in" />
            <token id="31" string="``" />
            <token id="32" string="Satanic" />
            <token id="33" string="Verses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">hiding</governor>
          <dependent id="1">Rushdie</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">citizen</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">citizen</governor>
          <dependent id="4">British</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Rushdie</governor>
          <dependent id="5">citizen</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">hiding</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">hiding</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">hiding</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">hiding</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">hiding</governor>
          <dependent id="11">since</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">hiding</governor>
          <dependent id="12">Feb.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Feb.</governor>
          <dependent id="13">14</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">ordered</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Khomeini</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Khomeini</governor>
          <dependent id="16">late</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Khomeini</governor>
          <dependent id="17">Iranian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Khomeini</governor>
          <dependent id="18">leader</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Khomeini</governor>
          <dependent id="19">Ayatollah</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Khomeini</governor>
          <dependent id="20">Ruhollah</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">ordered</governor>
          <dependent id="21">Khomeini</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">hiding</governor>
          <dependent id="22">ordered</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">killed</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">killed</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">ordered</governor>
          <dependent id="25">killed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">blaspheming</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">blaspheming</governor>
          <dependent id="27">allegedly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">killed</governor>
          <dependent id="28">blaspheming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">blaspheming</governor>
          <dependent id="29">Islam</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Verses</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">Verses</governor>
          <dependent id="32">Satanic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">blaspheming</governor>
          <dependent id="33">Verses</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="Iranian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="17" string="Iranian" />
          </tokens>
        </entity>
        <entity id="3" string="Islam" type="RELIGION" score="0.0">
          <tokens>
            <token id="29" string="Islam" />
          </tokens>
        </entity>
        <entity id="4" string="Ayatollah Ruhollah Khomeini" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Ayatollah" />
            <token id="20" string="Ruhollah" />
            <token id="21" string="Khomeini" />
          </tokens>
        </entity>
        <entity id="5" string="Rushdie" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Rushdie" />
          </tokens>
        </entity>
        <entity id="6" string="Feb. 14" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Feb." />
            <token id="13" string="14" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>This year&amp;apost;s six nominees were chosen Thursday from 102 books considered by a panel headed by David Lodge, a British literary critic and novelist who was nominated for the prize last year for his book, ``Nice Work.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="nominees" lemma="nominee" stem="nomine" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="102" lemma="102" stem="102" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="headed" lemma="head" stem="head" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Lodge" lemma="Lodge" stem="lodg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="23" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="critic" lemma="critic" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="nominated" lemma="nominate" stem="nomin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="34" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="35" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Nice" lemma="nice" stem="nice" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="Work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT This) (NN year) (POS 's)) (CD six) (NNS nominees)) (VP (VBD were) (VP (VBN chosen) (NP-TMP (NNP Thursday)) (PP (IN from) (NP (NP (CD 102) (NNS books)) (VP (VBN considered) (PP (IN by) (NP (NP (DT a) (NN panel)) (VP (VBN headed) (PP (IN by) (NP (NP (NNP David) (NNP Lodge)) (, ,) (NP (DT a) (JJ British) (JJ literary) (NN critic)) (CC and) (NP (NP (NN novelist)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN nominated) (PP (IN for) (NP (DT the) (NN prize))) (NP-TMP (JJ last) (NN year)) (PP (IN for) (NP (NP (PRP$ his) (NN book)) (, ,) (`` ``) (NP (JJ Nice) (NN Work))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="This year 's" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="102 books" type="NP">
          <tokens>
            <token id="10" string="102" />
            <token id="11" string="books" />
          </tokens>
        </chunking>
        <chunking id="3" string="novelist who was nominated for the prize last year for his book , `` Nice Work" type="NP">
          <tokens>
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="4" string="his book" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="book" />
          </tokens>
        </chunking>
        <chunking id="5" string="considered by a panel headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="12" string="considered" />
            <token id="13" string="by" />
            <token id="14" string="a" />
            <token id="15" string="panel" />
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="6" string="a British literary critic" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
          </tokens>
        </chunking>
        <chunking id="7" string="who was nominated for the prize last year for his book , `` Nice Work" type="SBAR">
          <tokens>
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="8" string="a panel headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="panel" />
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="9" string="This year 's six nominees" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
            <token id="4" string="six" />
            <token id="5" string="nominees" />
          </tokens>
        </chunking>
        <chunking id="10" string="were chosen Thursday from 102 books considered by a panel headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="chosen" />
            <token id="8" string="Thursday" />
            <token id="9" string="from" />
            <token id="10" string="102" />
            <token id="11" string="books" />
            <token id="12" string="considered" />
            <token id="13" string="by" />
            <token id="14" string="a" />
            <token id="15" string="panel" />
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="11" string="David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="NP">
          <tokens>
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="12" string="a panel" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="panel" />
          </tokens>
        </chunking>
        <chunking id="13" string="chosen Thursday from 102 books considered by a panel headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="7" string="chosen" />
            <token id="8" string="Thursday" />
            <token id="9" string="from" />
            <token id="10" string="102" />
            <token id="11" string="books" />
            <token id="12" string="considered" />
            <token id="13" string="by" />
            <token id="14" string="a" />
            <token id="15" string="panel" />
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="14" string="the prize" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="prize" />
          </tokens>
        </chunking>
        <chunking id="15" string="headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="16" string="Nice Work" type="NP">
          <tokens>
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="17" string="nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="18" string="David Lodge" type="NP">
          <tokens>
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
          </tokens>
        </chunking>
        <chunking id="19" string="his book , `` Nice Work" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="20" string="102 books considered by a panel headed by David Lodge , a British literary critic and novelist who was nominated for the prize last year for his book , `` Nice Work" type="NP">
          <tokens>
            <token id="10" string="102" />
            <token id="11" string="books" />
            <token id="12" string="considered" />
            <token id="13" string="by" />
            <token id="14" string="a" />
            <token id="15" string="panel" />
            <token id="16" string="headed" />
            <token id="17" string="by" />
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="British" />
            <token id="23" string="literary" />
            <token id="24" string="critic" />
            <token id="25" string="and" />
            <token id="26" string="novelist" />
            <token id="27" string="who" />
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="21" string="was nominated for the prize last year for his book , `` Nice Work" type="VP">
          <tokens>
            <token id="28" string="was" />
            <token id="29" string="nominated" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="prize" />
            <token id="33" string="last" />
            <token id="34" string="year" />
            <token id="35" string="for" />
            <token id="36" string="his" />
            <token id="37" string="book" />
            <token id="38" string="," />
            <token id="39" string="``" />
            <token id="40" string="Nice" />
            <token id="41" string="Work" />
          </tokens>
        </chunking>
        <chunking id="22" string="novelist" type="NP">
          <tokens>
            <token id="26" string="novelist" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">nominees</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">year</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">nominees</governor>
          <dependent id="4">six</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">chosen</governor>
          <dependent id="5">nominees</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">chosen</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">chosen</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">chosen</governor>
          <dependent id="8">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">books</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">books</governor>
          <dependent id="10">102</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chosen</governor>
          <dependent id="11">books</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">books</governor>
          <dependent id="12">considered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">panel</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">panel</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">considered</governor>
          <dependent id="15">panel</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">panel</governor>
          <dependent id="16">headed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Lodge</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Lodge</governor>
          <dependent id="18">David</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">headed</governor>
          <dependent id="19">Lodge</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">critic</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">critic</governor>
          <dependent id="22">British</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">critic</governor>
          <dependent id="23">literary</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Lodge</governor>
          <dependent id="24">critic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Lodge</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Lodge</governor>
          <dependent id="26">novelist</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">nominated</governor>
          <dependent id="27">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">nominated</governor>
          <dependent id="28">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">novelist</governor>
          <dependent id="29">nominated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">prize</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">prize</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">nominated</governor>
          <dependent id="32">prize</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">year</governor>
          <dependent id="33">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">nominated</governor>
          <dependent id="34">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">book</governor>
          <dependent id="35">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">book</governor>
          <dependent id="36">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">nominated</governor>
          <dependent id="37">book</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">Work</governor>
          <dependent id="40">Nice</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">book</governor>
          <dependent id="41">Work</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="102" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="102" />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="British" />
          </tokens>
        </entity>
        <entity id="4" string="David Lodge" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="David" />
            <token id="19" string="Lodge" />
          </tokens>
        </entity>
        <entity id="5" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Thursday" />
          </tokens>
        </entity>
        <entity id="6" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="7" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="last" />
            <token id="34" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11" string="this year 's Booker Prize" id_sentence="10" />
      <mentions>
        <mention ids_tokens="8-9" string="Booker Prize" id_sentence="1" />
        <mention ids_tokens="11-16" string="Britain's most prestigious fiction award" id_sentence="1" />
        <mention ids_tokens="1-2" string="The award" id_sentence="2" />
        <mention ids_tokens="6-7" string="the award" id_sentence="4" />
        <mention ids_tokens="5-6" string="the prize" id_sentence="11" />
        <mention ids_tokens="10" string="it" id_sentence="11" />
        <mention ids_tokens="31-32" string="the prize" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="19" string="bookmakers" id_sentence="1" />
      <mentions>
        <mention ids_tokens="29" string="our" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="32-33-34-35" string="Japanese author Kazuo Ishiguro" id_sentence="1" />
      <mentions>
        <mention ids_tokens="8-15" string="Ishiguro's novel about a butler's travels" id_sentence="3" />
        <mention ids_tokens="1-7" string="Ishiguro , previously nominated for the award" id_sentence="4" />
        <mention ids_tokens="1" string="Ishiguro" id_sentence="4" />
        <mention ids_tokens="21" string="his" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="18-19" string="Booker McConnell" id_sentence="2" />
      <mentions>
        <mention ids_tokens="14" string="Booker" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Oddsmaker William Hill" id_sentence="3" />
      <mentions>
        <mention ids_tokens="34-35" string="William Hill" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="34-35-36-37-38" string="William Hill spokesman Graham Sharpe" id_sentence="4" />
      <mentions>
        <mention ids_tokens="33" string="Sharpe" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15" string="`` The Book of Evidence , '' a prison story of kidnap and murder" id_sentence="6" />
      <mentions>
        <mention ids_tokens="36-37" string="his book" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="14-15-16" string="an adolescent 's" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="19-20-21" string="last year 's" id_sentence="10" />
      <mentions>
        <mention ids_tokens="7-8" string="last year" id_sentence="11" />
        <mention ids_tokens="33-34" string="last year" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="1" string="Rushdie" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1-5" string="Rushdie , a British citizen" id_sentence="12" />
        <mention ids_tokens="3-5" string="a British citizen" id_sentence="12" />
      </mentions>
    </coreference>
  </coreferences>
</document>
